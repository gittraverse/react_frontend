export default [{"size":1330,"relativepath":"gunicorn.conf.py","filename":"gunicorn.conf.py","extension":".py","content":"# -*- coding: utf-8 -*-\nimport os\n\nif 'GUNICORN_TIMEOUT' in os.environ:\n    timeout = int(os.environ['GUNICORN_TIMEOUT'])\n\n# Smart detect heroku stack and assume a trusted proxy.\n# This is a convenience that should hopefully not be too surprising.\nif 'heroku' in os.environ.get('LD_LIBRARY_PATH', ''):\n    forwarded_allow_ips = '*'\n\nif not os.environ.get('GUNICORN_STATS_DISABLE', None):\n    if 'STATSD_PORT_8125_UDP_ADDR' in os.environ and \\\n       'STATSD_PORT_8125_UDP_PORT' in os.environ:\n            _host = os.environ['STATSD_PORT_8125_UDP_ADDR']\n            _port = os.environ['STATSD_PORT_8125_UDP_PORT']\n            statsd_host = '{}:{}'.format(_host, _port)\n\n    elif 'STATSD_HOST' in os.environ:\n        _host = os.environ['STATSD_HOST']\n        _port = os.environ.get('STATSD_PORT', '8125')\n        statsd_host = '{}:{}'.format(_host, _port)\n\n\ndef post_fork(server, worker):\n    # Support back-ported SSL changes on Debian / Ubuntu\n    import _ssl\n    import gevent.hub\n    if hasattr(_ssl, 'SSLContext') and not hasattr(_ssl, '_sslwrap'):\n        gevent.hub.PYGTE279 = True\n\n    # Patch psycopg2 if we're asked to by the worker class\n    if getattr(server.worker_class, 'use_psycogreen', False):\n        import psycogreen.gevent\n        psycogreen.gevent.patch_psycopg()\n        worker.log.info(\"Made psycopg green\")\n"},{"size":149,"relativepath":"bin/hypothesis","filename":"hypothesis","extension":"","content":"#!/bin/sh\n\nset -eu\n\ncd \"$(dirname \"$0\")\"\ncd ..\n\nexport PYTHONPATH=\"${PWD}:${PYTHONPATH:-}\"\nexport PATH=\"${PWD}/bin:${PATH:-}\"\n\nexec python -m h \"$@\"\n"},{"size":156,"relativepath":"setup.cfg","filename":"setup.cfg","extension":".cfg","content":"[flake8]\nexclude = h/migrations/versions/*\nmax-line-length = 160\n\n[isort]\ninclude_trailing_comma = True\nmulti_line_output = 3\n\n[yapf]\nbased_on_style = pep8\n"},{"size":3474,"relativepath":"tests/common/matchers.py","filename":"matchers.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"\nMatchers for use in tests.\n\nThis module contains objects which can be used to write tests which are easier\nto read, especially when using assertions against :py:class:`mock.Mock`\nobjects. Each matcher defines an __eq__ method, allowing instances of these\nmatchers to be used wherever you would usually pass a plain value.\n\nFor example, imagine you wanted to ensure that the `set_value` method of the\n`foo` mock object was called exactly once with an integer. Previously you\nwould have to do something like:\n\n    assert foo.set_value.call_count == 1\n    assert isinstance(foo.set_value.call_args[0][0], int)\n\nBy using the `instance_of` matcher you can simply write:\n\n    foo.set_value.assert_called_once_with(matchers.instance_of(int))\n\nAs a bonus, the second test will print substantially more useful debugging\noutput if it fails, e.g.\n\n    E       AssertionError: Expected call: set_value(<instance of <type 'int'>>)\n    E       Actual call: set_value('a string')\n\n\"\"\"\nfrom pyramid import httpexceptions\n\n\nclass any_callable(object):  # noqa: N801\n    \"\"\"An object __eq__ to any callable object.\"\"\"\n\n    def __eq__(self, other):\n        \"\"\"Return ``True`` if ``other`` is callable, ``False`` otherwise.\"\"\"\n        return callable(other)\n\n\nclass instance_of(object):  # noqa: N801\n    \"\"\"An object __eq__ to any object which is an instance of `type_`.\"\"\"\n\n    def __init__(self, type_):\n        self.type = type_\n\n    def __eq__(self, other):\n        return isinstance(other, self.type)\n\n    def __repr__(self):\n        return '<instance of {!r}>'.format(self.type)\n\n\nclass iterable_with(object):  # noqa: N801\n    \"\"\"An object __eq__ to any iterable which yields `items`.\"\"\"\n\n    def __init__(self, items):\n        self.items = items\n\n    def __eq__(self, other):\n        return list(other) == self.items\n\n    def __repr__(self):\n        return '<iterable with {!r}>'.format(self.items)\n\n\nclass mapping_containing(object):  # noqa: N801\n    \"\"\"An object __eq__ to any mapping with the passed `key`.\"\"\"\n\n    def __init__(self, key):\n        self.key = key\n\n    def __eq__(self, other):\n        try:\n            other[self.key]\n        except (TypeError, KeyError):\n            return False\n        else:\n            return True\n\n    def __repr__(self):\n        return '<mapping containing {!r}>'.format(self.key)\n\n\nclass redirect_302_to(object):\n    \"\"\"Matches any HTTPFound redirect to the given URL.\"\"\"\n\n    def __init__(self, location):\n        self.location = location\n\n    def __eq__(self, other):\n        if not isinstance(other, httpexceptions.HTTPFound):\n            return False\n        return other.location == self.location\n\n\nclass redirect_303_to(object):\n    \"\"\"Matches any HTTPSeeOther redirect to the given URL.\"\"\"\n\n    def __init__(self, location):\n        self.location = location\n\n    def __eq__(self, other):\n        if not isinstance(other, httpexceptions.HTTPSeeOther):\n            return False\n        return other.location == self.location\n\n\nclass unordered_list(object):\n    \"\"\"\n    Matches a list with the same items in any order.\n\n    Matches any list that contains the same items as the given list\n    (and no more), regardless of order.\n\n    \"\"\"\n\n    def __init__(self, items):\n        self.items = items\n\n    def __eq__(self, other):\n        if len(self.items) != len(other):\n            return False\n        for item in self.items:\n            if item not in other:\n                return False\n        return True\n"},{"size":3440,"relativepath":"tests/common/factories.py","filename":"factories.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"Factory classes for easily generating test objects.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import unicode_literals\n\nimport base64\nimport os\nfrom datetime import (datetime, timedelta)\n\nimport factory\nimport faker\n\nfrom h import models\n\nfrom ..memex import factories as memex_factories\n\n\nFAKER = faker.Factory.create()\nSESSION = None\n\nAnnotation = memex_factories.Annotation\nDocument = memex_factories.Document\nDocumentMeta = memex_factories.DocumentMeta\nDocumentURI = memex_factories.DocumentURI\n\n\ndef set_session(value):\n    global SESSION\n\n    SESSION = value\n    memex_factories.SESSION = value\n\n\nclass ModelFactory(factory.alchemy.SQLAlchemyModelFactory):\n    class Meta:  # pylint: disable=no-init, old-style-class\n        abstract = True\n\n    @classmethod\n    def _create(cls, model_class, *args, **kwargs):\n        # We override SQLAlchemyModelFactory's default _create classmethod so\n        # that rather than fetching the session from cls._meta (which is\n        # created at parse time... ugh) we fetch it from the SESSION global,\n        # which is dynamically filled out by the `factories` fixture when\n        # used.\n        if SESSION is None:\n            raise RuntimeError('no session: did you use the factories fixture?')\n        obj = model_class(*args, **kwargs)\n        SESSION.add(obj)\n        if cls._meta.force_flush:\n            SESSION.flush()\n        return obj\n\n\nclass Activation(ModelFactory):\n\n    class Meta(object):\n        model = models.Activation\n        force_flush = True\n\n\nclass AuthClient(ModelFactory):\n\n    class Meta(object):\n        model = models.AuthClient\n        force_flush = True\n\n    authority = 'example.com'\n    secret = factory.LazyAttribute(lambda _: unicode(FAKER.sha256()))\n\n\nclass User(factory.Factory):\n\n    \"\"\"A factory class that generates h.models.User objects.\n\n    Note that this class doesn't add the User to the database session for you,\n    if tests want the user added to a session they should do that themselves.\n\n    \"\"\"\n\n    class Meta(object):\n        model = models.User\n\n    class Params(object):\n        inactive = factory.Trait(\n            activation=factory.SubFactory(Activation),\n        )\n\n    authority = 'example.com'\n    username = factory.Faker('user_name')\n    email = factory.Faker('email')\n\n    @factory.lazy_attribute\n    def uid(self):\n        return self.username.replace('.', '').lower()\n\n\nclass Group(ModelFactory):\n\n    class Meta:  # pylint: disable=no-init, old-style-class\n        model = models.Group\n        force_flush = True\n\n    name = factory.Sequence(lambda n:'Test Group {n}'.format(n=str(n)))\n    creator = factory.SubFactory(User)\n\n\nclass AuthTicket(ModelFactory):\n\n    class Meta:  # pylint: disable=no-init, old-style-class\n        model = models.AuthTicket\n\n    # Simulate how pyramid_authsanity generates ticket ids\n    id = factory.LazyAttribute(lambda _: base64.urlsafe_b64encode(os.urandom(32)).rstrip(b\"=\").decode('ascii'))\n    user = factory.SubFactory(User)\n    expires = factory.LazyAttribute(lambda _: (datetime.utcnow() + timedelta(minutes=10)))\n\n    @factory.lazy_attribute\n    def user_userid(self):\n        return self.user.userid\n\n\nclass Token(ModelFactory):\n\n    class Meta:  # pylint: disable=no-init, old-style-class\n        model = models.Token\n        force_flush = True\n\n    userid = factory.LazyAttribute(lambda _: ('acct:' + FAKER.user_name() + '@example.com'))\n"},{"size":4236,"relativepath":"tests/memex/links_test.py","filename":"links_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport mock\nimport pytest\n\nfrom memex.links import LinksService\nfrom memex.links import add_annotation_link_generator\nfrom memex.links import links_factory\n\n\nclass TestLinksService(object):\n    def test_get_returns_link_text(self, registry):\n        svc = LinksService(base_url='http://example.com', registry=registry)\n\n        result = svc.get(mock.sentinel.annotation, 'giraffe')\n\n        assert result == 'http://giraffes.com'\n\n    def test_get_returns_link_text_for_hidden_links(self, registry):\n        svc = LinksService(base_url='http://example.com', registry=registry)\n\n        result = svc.get(mock.sentinel.annotation, 'kiwi')\n\n        assert result == 'http://kiwi.net'\n\n    def test_get_passes_generators_request_with_base_url(self, registry):\n        svc = LinksService(base_url='http://donkeys.com', registry=registry)\n\n        result = svc.get(mock.sentinel.annotation, 'namedroute')\n\n        assert result == 'http://donkeys.com/some/path'\n\n    def test_get_passes_generators_annotation(self, registry):\n        annotation = mock.Mock(id=12345)\n        svc = LinksService(base_url='http://example.com', registry=registry)\n\n        result = svc.get(annotation, 'paramroute')\n\n        assert result == 'http://example.com/annotations/12345'\n\n    def test_get_all_includes_nonhidden_links(self, registry):\n        svc = LinksService(base_url='http://example.com', registry=registry)\n\n        result = svc.get_all(mock.sentinel.annotation)\n\n        assert result['giraffe'] == 'http://giraffes.com'\n        assert result['elephant'] == 'https://elephant.org'\n\n    def test_get_all_does_not_include_hidden_links(self, registry):\n        svc = LinksService(base_url='http://example.com', registry=registry)\n\n        result = svc.get_all(mock.sentinel.annotation)\n\n        assert 'kiwi' not in result\n\n    def test_get_all_does_not_include_links_returning_none(self, registry):\n        svc = LinksService(base_url='http://example.com', registry=registry)\n\n        result = svc.get_all(mock.sentinel.annotation)\n\n        assert 'returnsnone' not in result\n\n\nclass TestLinksFactory(object):\n    def test_returns_links_service(self, pyramid_request):\n        svc = links_factory(None, pyramid_request)\n\n        assert isinstance(svc, LinksService)\n\n    def test_base_url_is_development_base_if_not_set(self, pyramid_request):\n        svc = links_factory(None, pyramid_request)\n\n        assert svc.base_url == 'http://localhost:5000'\n\n    def test_base_url_is_app_url_setting_if_set(self, pyramid_request):\n        pyramid_request.registry.settings['h.app_url'] = 'https://hypothes.is'\n\n        svc = links_factory(None, pyramid_request)\n\n        assert svc.base_url == 'https://hypothes.is'\n\n    def test_registry_is_request_registry(self, pyramid_request):\n        svc = links_factory(None, pyramid_request)\n\n        assert svc.registry == pyramid_request.registry\n\n\n@pytest.fixture\ndef registry(pyramid_config):\n    pyramid_config.add_route('some.named.route', '/some/path')\n    pyramid_config.add_route('param.route', '/annotations/{id}')\n\n    registry = pyramid_config.registry\n\n    add_annotation_link_generator(registry,\n                                  'giraffe',\n                                  lambda r, a: 'http://giraffes.com')\n    add_annotation_link_generator(registry,\n                                  'elephant',\n                                  lambda r, a: 'https://elephant.org')\n    add_annotation_link_generator(registry,\n                                  'kiwi',\n                                  lambda r, a: 'http://kiwi.net',\n                                  hidden=True)\n    add_annotation_link_generator(registry,\n                                  'returnsnone',\n                                  lambda r, a: None)\n    add_annotation_link_generator(registry,\n                                  'namedroute',\n                                  lambda r, a: r.route_url('some.named.route'))\n    add_annotation_link_generator(registry,\n                                  'paramroute',\n                                  lambda r, a: r.route_url('param.route', id=a.id),\n                                  hidden=True)\n\n    return registry\n"},{"size":1032,"relativepath":"tests/memex/resources_test.py","filename":"resources_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom mock import Mock\nimport pytest\n\nfrom memex.resources import AnnotationFactory\n\n\nclass TestAnnotationFactory(object):\n    def test_get_item_fetches_annotation(self, pyramid_request, storage):\n        factory = AnnotationFactory(pyramid_request)\n\n        factory['123']\n        storage.fetch_annotation.assert_called_once_with(pyramid_request.db, '123')\n\n    def test_get_item_returns_annotation(self, pyramid_request, storage):\n        factory = AnnotationFactory(pyramid_request)\n        storage.fetch_annotation.return_value = Mock()\n\n        annotation = factory['123']\n        assert annotation == storage.fetch_annotation.return_value\n\n    def test_get_item_raises_when_annotation_is_not_found(self, storage, pyramid_request):\n        factory = AnnotationFactory(pyramid_request)\n        storage.fetch_annotation.return_value = None\n\n        with pytest.raises(KeyError):\n            factory['123']\n\n    @pytest.fixture\n    def storage(self, patch):\n        return patch('memex.resources.storage')\n"},{"size":21383,"relativepath":"tests/memex/schemas_test.py","filename":"schemas_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nimport mock\nimport pytest\n\nfrom memex import schemas\n\n\nclass ExampleSchema(schemas.JSONSchema):\n    schema = {\n        b'$schema': b'http://json-schema.org/draft-04/schema#',\n        b'type': b'string',\n    }\n\n\nclass TestJSONSchema(object):\n\n    def test_it_returns_data_when_valid(self):\n        data = \"a string\"\n\n        assert ExampleSchema().validate(data) == data\n\n    def test_it_raises_when_data_invalid(self):\n        data = 123  # not a string\n\n        with pytest.raises(schemas.ValidationError):\n            ExampleSchema().validate(data)\n\n    def test_it_sets_appropriate_error_message_when_data_invalid(self):\n        data = 123  # not a string\n\n        with pytest.raises(schemas.ValidationError) as e:\n            ExampleSchema().validate(data)\n\n        message = e.value.message\n        assert message.startswith(\"123 is not of type 'string'\")\n\n\ndef create_annotation_schema_validate(request, data):\n    # 'uri' is required when creating new annotations.\n    if 'uri' not in data:\n        data['uri'] = 'http://example.com/example'\n\n    schema = schemas.CreateAnnotationSchema(request)\n    return schema.validate(data)\n\n\ndef update_annotation_schema_validate(request,\n                                      data,\n                                      existing_target_uri='',\n                                      groupid=''):\n    schema = schemas.UpdateAnnotationSchema(request,\n                                            existing_target_uri,\n                                            groupid)\n    return schema.validate(data)\n\n\n@pytest.mark.parametrize('validate',\n    [\n        create_annotation_schema_validate,\n        update_annotation_schema_validate,\n    ],\n    ids=[\n        'CreateAnnotationSchema.validate()',\n        'UpdateAnnotationSchema.validate()'\n    ]\n)\nclass TestCreateUpdateAnnotationSchema(object):\n\n    \"\"\"Shared tests for CreateAnnotationSchema and UpdateAnnotationSchema.\"\"\"\n\n    def test_it_does_not_raise_for_minimal_valid_data(self, pyramid_request, validate):\n        validate(pyramid_request, {})\n\n    def test_it_does_not_raise_for_full_valid_data(self, pyramid_request, validate):\n        # Use all the keys to make sure that valid data for all of them passes.\n        validate(pyramid_request, {\n            'document': {\n                'dc': {\n                    'identifier': ['foo', 'bar']\n                },\n                'highwire': {\n                    'doi': ['foo', 'bar'],\n                    'pdf_url': ['foo', 'bar'],\n                },\n                'link': [\n                    {\n                        'href': 'foo',\n                        'type': 'foo',\n                    },\n                    {\n                        'href': 'foo',\n                        'type': 'foo',\n                    }\n                ],\n            },\n            'group': 'foo',\n            'permissions': {\n                'admin': ['acct:foo', 'group:bar'],\n                'delete': ['acct:foo', 'group:bar'],\n                'read': ['acct:foo', 'group:bar'],\n                'update': ['acct:foo', 'group:bar'],\n            },\n            'references': ['foo', 'bar'],\n            'tags': ['foo', 'bar'],\n            'target': [\n                {\n                    'selector': 'foo'\n                },\n                {\n                    'selector': 'foo'\n                },\n            ],\n            'text': 'foo',\n            'uri': 'foo',\n        })\n\n    @pytest.mark.parametrize(\"input_data,error_message\", [\n        ({'document': False}, \"document: False is not of type 'object'\"),\n\n        ({'document': {'dc': False}},\n         \"document.dc: False is not of type 'object'\"),\n\n        ({'document': {'dc': {'identifier': False}}},\n         \"document.dc.identifier: False is not of type 'array'\"),\n\n        ({'document': {'dc': {'identifier': [False]}}},\n         \"document.dc.identifier.0: False is not of type 'string'\"),\n\n        ({'document': {'highwire': False}},\n         \"document.highwire: False is not of type 'object'\"),\n\n        ({'document': {'highwire': {'doi': False}}},\n         \"document.highwire.doi: False is not of type 'array'\"),\n\n        ({'document': {'highwire': {'doi': [False]}}},\n         \"document.highwire.doi.0: False is not of type 'string'\"),\n\n        ({'document': {'highwire': {'pdf_url': False}}},\n         \"document.highwire.pdf_url: False is not of type 'array'\"),\n\n        ({'document': {'highwire': {'pdf_url': [False]}}},\n         \"document.highwire.pdf_url.0: False is not of type 'string'\"),\n\n        ({'document': {'link': False}},\n         \"document.link: False is not of type 'array'\"),\n\n        ({'document': {'link': [False]}},\n         \"document.link.0: False is not of type 'object'\"),\n\n        ({'document': {'link': [{}]}},\n         \"document.link.0: 'href' is a required property\"),\n\n        ({'document': {'link': [{'href': False}]}},\n         \"document.link.0.href: False is not of type 'string'\"),\n\n        ({'document': {\n            'link': [\n                {\n                    'href': 'http://example.com',\n                    'type': False\n                }\n            ]\n        }}, \"document.link.0.type: False is not of type 'string'\"),\n\n        ({'group': False}, \"group: False is not of type 'string'\"),\n\n        ({'permissions': False}, \"permissions: False is not of type 'object'\"),\n\n        ({'permissions': {}}, \"permissions: 'read' is a required property\"),\n\n        ({'permissions': {'read': False}},\n         \"permissions.read: False is not of type 'array'\"),\n\n        ({'permissions': {'read': [False]}},\n         \"permissions.read.0: False is not of type 'string'\"),\n\n        ({'permissions': {'read': [\"foo\"]}},\n         \"permissions.read.0: u'foo' does not match '^(acct:|group:).+$'\"),\n\n        ({'references': False}, \"references: False is not of type 'array'\"),\n\n        ({'references': [False]},\n         \"references.0: False is not of type 'string'\"),\n\n        ({'tags': False}, \"tags: False is not of type 'array'\"),\n\n        ({'tags': [False]}, \"tags.0: False is not of type 'string'\"),\n\n        ({'target': False}, \"target: False is not of type 'array'\"),\n\n        ({'target': [False]}, \"target.0: False is not of type 'object'\"),\n\n        ({'text': False}, \"text: False is not of type 'string'\"),\n\n        ({'uri': False}, \"uri: False is not of type 'string'\"),\n\n        ({'uri': ''}, \"uri: 'uri' is a required property\"),\n\n        ({'uri': ' '}, \"uri: 'uri' is a required property\"),\n    ])\n    def test_it_raises_for_invalid_data(self,\n                                        pyramid_request,\n                                        validate,\n                                        input_data,\n                                        error_message):\n        with pytest.raises(schemas.ValidationError) as exc:\n            validate(pyramid_request, input_data)\n\n        assert str(exc.value) == error_message\n\n    @pytest.mark.parametrize('field', [\n        'created',\n        'updated',\n        'user',\n        'id',\n        'links',\n    ])\n    def test_it_removes_protected_fields(self, pyramid_request, validate, field):\n        data = {}\n        data[field] = 'something forbidden'\n        appstruct = validate(pyramid_request, data)\n\n        assert field not in appstruct\n        assert field not in appstruct.get('extra', {})\n\n    def test_it_renames_uri_to_target_uri(self, pyramid_request, validate):\n        appstruct = validate(pyramid_request,\n                             {'uri': 'http://example.com/example'})\n\n        assert appstruct['target_uri'] == 'http://example.com/example'\n        assert 'uri' not in appstruct\n\n    def test_it_strips_leading_and_trailing_whitespace_from_uri(\n            self, pyramid_request, validate):\n        appstruct = validate(pyramid_request,\n                             {'uri': ' foo '})\n\n        assert appstruct['target_uri'] == 'foo'\n\n    def test_it_keeps_text(self, pyramid_request, validate):\n        appstruct = validate(pyramid_request,\n                             {'text': 'some annotation text'})\n\n        assert appstruct['text'] == 'some annotation text'\n\n    def test_it_keeps_tags(self, pyramid_request, validate):\n        appstruct = validate(pyramid_request, {'tags': ['foo', 'bar']})\n\n        assert appstruct['tags'] == ['foo', 'bar']\n\n    def test_it_replaces_target_with_target_selectors(self, pyramid_request, validate):\n        appstruct = validate(pyramid_request, {\n            'target': [\n                {\n                    'foo': 'bar',  # This should be removed,\n                    'selector': 'the selectors',\n                },\n                'this should be removed',\n            ]\n        })\n\n        assert appstruct['target_selectors'] == 'the selectors'\n\n    def test_it_extracts_document_uris_from_the_document(\n            self,\n            pyramid_request,\n            parse_document_claims,\n            validate):\n        target_uri = 'http://example.com/example'\n        document_data = {'foo': 'bar'}\n\n        validate(pyramid_request, {'document': document_data, 'uri': target_uri})\n\n        parse_document_claims.document_uris_from_data.assert_called_once_with(\n            document_data,\n            claimant=target_uri,\n        )\n\n    def test_it_puts_document_uris_in_appstruct(self,\n                                                parse_document_claims,\n                                                pyramid_request,\n                                                validate):\n        appstruct = validate(pyramid_request, {'document': {}})\n\n        assert appstruct['document']['document_uri_dicts'] == (\n            parse_document_claims.document_uris_from_data.return_value)\n\n    def test_it_extracts_document_metas_from_the_document(\n            self,\n            parse_document_claims,\n            pyramid_request,\n            validate):\n        document_data = {'foo': 'bar'}\n        target_uri = 'http://example.com/example'\n\n        validate(pyramid_request,\n                 {'document': {'foo': 'bar'}, 'uri': target_uri})\n\n        parse_document_claims.document_metas_from_data.assert_called_once_with(\n            document_data,\n            claimant=target_uri,\n        )\n\n    def test_it_does_not_pass_modified_dict_to_document_metas_from_data(\n            self,\n            parse_document_claims,\n            pyramid_request,\n            validate):\n        \"\"\"\n\n        If document_uris_from_data() modifies the document dict that it's\n        given, the original dict (or one with the same values as it) should be\n        passed t document_metas_from_data(), not the modified copy.\n\n        \"\"\"\n        document = {\n            'top_level_key': 'original_value',\n            'sub_dict': {\n                'key': 'original_value'\n            }\n        }\n\n        def document_uris_from_data(document, claimant):\n            document['new_key'] = 'new_value'\n            document['top_level_key'] = 'new_value'\n            document['sub_dict']['key'] = 'new_value'\n        parse_document_claims.document_uris_from_data.side_effect = (\n            document_uris_from_data)\n\n        validate(pyramid_request, {'document': document})\n\n        assert (\n            parse_document_claims.document_metas_from_data.call_args[0][0] ==\n            document)\n\n    def test_it_puts_document_metas_in_appstruct(self,\n                                                 parse_document_claims,\n                                                 pyramid_request,\n                                                 validate):\n        appstruct = validate(pyramid_request, {'document': {}})\n\n        assert appstruct['document']['document_meta_dicts'] == (\n            parse_document_claims.document_metas_from_data.return_value)\n\n    def test_it_clears_existing_keys_from_document(self, pyramid_request, validate):\n        \"\"\"\n        Any keys in the document dict should be removed.\n\n        They're replaced with the 'document_uri_dicts' and\n        'document_meta_dicts' keys.\n\n        \"\"\"\n        appstruct = validate(pyramid_request, {\n            'document': {\n                'foo': 'bar'  # This should be deleted.\n            }\n        })\n\n        assert 'foo' not in appstruct['document']\n\n    def test_document_does_not_end_up_in_extra(self, pyramid_request, validate):\n        appstruct = validate(pyramid_request, {'document': {'foo': 'bar'}})\n\n        assert 'document' not in appstruct.get('extra', {})\n\n    def test_it_moves_extra_data_into_extra_sub_dict(self, pyramid_request, validate):\n        appstruct = validate(pyramid_request, {\n            # Throw in all the fields, just to make sure that none of them get\n            # into extra.\n            'created': 'created',\n            'updated': 'updated',\n            'user': 'user',\n            'id': 'id',\n            'uri': 'uri',\n            'text': 'text',\n            'tags': ['gar', 'har'],\n            'permissions': {'read': ['group:__world__']},\n            'target': [],\n            'group': '__world__',\n            'references': ['parent'],\n\n            # These should end up in extra.\n            'foo': 1,\n            'bar': 2,\n        })\n\n        assert appstruct['extra'] == {'foo': 1, 'bar': 2}\n\n    def test_it_does_not_modify_extra_fields_that_are_not_sent(self, pyramid_request, validate):\n        appstruct = validate(pyramid_request, {'foo': 'bar'})\n\n        assert 'custom' not in appstruct['extra']\n\n    def test_it_does_not_modify_extra_fields_if_none_are_sent(self, pyramid_request, validate):\n        appstruct = validate(pyramid_request, {})\n\n        assert not appstruct.get('extra')\n\n\nclass TestCreateAnnotationSchema(object):\n\n    def test_it_raises_if_data_has_no_uri(self, pyramid_request):\n        data = self.valid_data()\n        del data['uri']\n        schema = schemas.CreateAnnotationSchema(pyramid_request)\n\n        with pytest.raises(schemas.ValidationError) as exc:\n            schema.validate(data)\n\n        assert exc.value.message == \"uri: 'uri' is a required property\"\n\n    def test_it_sets_userid(self, pyramid_config, pyramid_request):\n        pyramid_config.testing_securitypolicy('acct:harriet@example.com')\n        schema = schemas.CreateAnnotationSchema(pyramid_request)\n\n        appstruct = schema.validate(self.valid_data())\n\n        assert appstruct['userid'] == 'acct:harriet@example.com'\n\n    def test_it_inserts_empty_string_if_data_contains_no_text(self, pyramid_request):\n        schema = schemas.CreateAnnotationSchema(pyramid_request)\n\n        assert schema.validate(self.valid_data())['text'] == ''\n\n    def test_it_inserts_empty_list_if_data_contains_no_tags(self, pyramid_request):\n        schema = schemas.CreateAnnotationSchema(pyramid_request)\n\n        assert schema.validate(self.valid_data())['tags'] == []\n\n    def test_it_replaces_private_permissions_with_shared_False(self, pyramid_request):\n        schema = schemas.CreateAnnotationSchema(pyramid_request)\n\n        appstruct = schema.validate(self.valid_data(\n            permissions={'read': ['acct:harriet@example.com']}\n        ))\n\n        assert appstruct['shared'] is False\n        assert 'permissions' not in appstruct\n\n    def test_it_replaces_shared_permissions_with_shared_True(self, pyramid_request):\n        schema = schemas.CreateAnnotationSchema(pyramid_request)\n\n        appstruct = schema.validate(self.valid_data(\n            permissions={'read': ['group:__world__']},\n            group='__world__'\n        ))\n\n        assert appstruct['shared'] is True\n        assert 'permissions' not in appstruct\n\n    def test_it_defaults_to_private_if_no_permissions_object_sent(self, pyramid_request):\n        schema = schemas.CreateAnnotationSchema(pyramid_request)\n\n        appstruct = schema.validate(self.valid_data())\n\n        assert appstruct['shared'] is False\n\n    def test_it_renames_group_to_groupid(self, pyramid_request):\n        schema = schemas.CreateAnnotationSchema(pyramid_request)\n\n        appstruct = schema.validate(self.valid_data(group='foo'))\n\n        assert appstruct['groupid'] == 'foo'\n        assert 'group' not in appstruct\n\n    def test_it_inserts_default_groupid_if_no_group(self, pyramid_request):\n        schema = schemas.CreateAnnotationSchema(pyramid_request)\n\n        appstruct = schema.validate(self.valid_data())\n\n        assert appstruct['groupid'] == '__world__'\n\n    def test_it_keeps_references(self, pyramid_request):\n        schema = schemas.CreateAnnotationSchema(pyramid_request)\n\n        appstruct = schema.validate(self.valid_data(\n            references=['parent id', 'parent id 2']\n        ))\n\n        assert appstruct['references'] == ['parent id', 'parent id 2']\n\n    def test_it_inserts_empty_list_if_no_references(self, pyramid_request):\n        schema = schemas.CreateAnnotationSchema(pyramid_request)\n\n        appstruct = schema.validate(self.valid_data())\n\n        assert appstruct['references'] == []\n\n    def test_it_deletes_groupid_for_replies(self, pyramid_request):\n        schema = schemas.CreateAnnotationSchema(pyramid_request)\n\n        appstruct = schema.validate(self.valid_data(\n            group='foo',\n            references=['parent annotation id']\n        ))\n\n        assert 'groupid' not in appstruct\n\n    def valid_data(self, **kwargs):\n        \"\"\"Return minimal valid data for creating a new annotation.\"\"\"\n        data = {\n            'uri': 'http://example.com/example',\n        }\n        data.update(kwargs)\n        return data\n\n\nclass TestUpdateAnnotationSchema(object):\n\n    def test_you_cannot_change_an_annotations_group(self, pyramid_request):\n        schema = schemas.UpdateAnnotationSchema(pyramid_request, '', '')\n\n        appstruct = schema.validate({\n            'groupid': 'new-group',\n            'group': 'new-group'\n        })\n\n\n        assert 'groupid' not in appstruct\n        assert 'groupid' not in appstruct.get('extra', {})\n        assert 'group' not in appstruct\n        assert 'group' not in appstruct.get('extra', {})\n\n    def test_you_cannot_change_an_annotations_userid(self, pyramid_request):\n        schema = schemas.UpdateAnnotationSchema(pyramid_request, '', '')\n\n        appstruct = schema.validate({'userid': 'new_userid'})\n\n        assert 'userid' not in appstruct\n        assert 'userid' not in appstruct.get('extra', {})\n\n    def test_you_cannot_change_an_annotations_references(self, pyramid_request):\n        schema = schemas.UpdateAnnotationSchema(pyramid_request, '', '')\n\n        appstruct = schema.validate({'references': ['new_parent']})\n\n        assert 'references' not in appstruct\n        assert 'references' not in appstruct.get('extra', {})\n\n    def test_it_replaces_private_permissions_with_shared_False(self, pyramid_request):\n        schema = schemas.UpdateAnnotationSchema(pyramid_request, '', '')\n\n        appstruct = schema.validate({\n            'permissions': {'read': ['acct:harriet@example.com']}\n        })\n\n        assert appstruct['shared'] is False\n        assert 'permissions' not in appstruct\n        assert 'permissions' not in appstruct.get('extras', {})\n\n    def test_it_replaces_shared_permissions_with_shared_True(self, pyramid_request):\n        schema = schemas.UpdateAnnotationSchema(pyramid_request,\n                                                '',\n                                                '__world__')\n\n        appstruct = schema.validate({\n            'permissions': {'read': ['group:__world__']}\n        })\n\n        assert appstruct['shared'] is True\n        assert 'permissions' not in appstruct\n        assert 'permissions' not in appstruct.get('extras', {})\n\n    def test_it_passes_existing_target_uri_to_document_uris_from_data(\n            self,\n            parse_document_claims,\n            pyramid_request):\n        \"\"\"\n        If no 'uri' is given it should use the existing target_uri.\n\n        If no 'uri' is given in the update request then\n        document_uris_from_data() should be called with the existing\n        target_uri of the annotation in the database.\n\n        \"\"\"\n        document_data = {'foo': 'bar'}\n        schema = schemas.UpdateAnnotationSchema(pyramid_request,\n                                                mock.sentinel.target_uri,\n                                                '')\n\n        schema.validate({'document': document_data})\n\n        parse_document_claims.document_uris_from_data.assert_called_once_with(\n            document_data,\n            claimant=mock.sentinel.target_uri)\n\n    def test_it_passes_existing_target_uri_to_document_metas_from_data(\n            self,\n            parse_document_claims,\n            pyramid_request):\n        \"\"\"\n        If no 'uri' is given it should use the existing target_uri.\n\n        If no 'uri' is given in the update request then\n        document_metas_from_data() should be called with the existing\n        target_uri of the annotation in the database.\n\n        \"\"\"\n        document_data = {'foo': 'bar'}\n        schema = schemas.UpdateAnnotationSchema(pyramid_request,\n                                                mock.sentinel.target_uri,\n                                                '')\n\n        schema.validate({'document': document_data})\n\n        parse_document_claims.document_metas_from_data.assert_called_once_with(\n            document_data,\n            claimant=mock.sentinel.target_uri)\n\n\n@pytest.fixture\ndef parse_document_claims(patch):\n    return patch('memex.schemas.parse_document_claims')\n"},{"size":10440,"relativepath":"tests/memex/search/core_test.py","filename":"core_test.py","extension":".py","content":"import mock\nimport pytest\n\nfrom memex.search import core\n\n\nclass TestSearch(object):\n    def test_run_searches_annotations(self, pyramid_request, search_annotations):\n        params = mock.Mock()\n\n        search_annotations.return_value = (0, [], {})\n\n        search = core.Search(pyramid_request)\n        search.run(params)\n\n        search_annotations.assert_called_once_with(search, params)\n\n    def test_run_searches_replies(self,\n                                  pyramid_request,\n                                  search_replies,\n                                  search_annotations):\n        annotation_ids = [mock.Mock(), mock.Mock()]\n        search_annotations.return_value = (2, annotation_ids, {})\n\n        search = core.Search(pyramid_request)\n        search.run({})\n\n        search_replies.assert_called_once_with(search, annotation_ids)\n\n    def test_run_returns_search_results(self,\n                                        pyramid_request,\n                                        search_annotations,\n                                        search_replies):\n        total = 4\n        annotation_ids = ['id-1', 'id-3', 'id-6', 'id-5']\n        reply_ids = ['reply-8', 'reply-5']\n        aggregations = {'foo': 'bar'}\n        search_annotations.return_value = (total, annotation_ids, aggregations)\n        search_replies.return_value = reply_ids\n\n        search = core.Search(pyramid_request)\n        result = search.run({})\n\n        assert result == core.SearchResult(total, annotation_ids, reply_ids, aggregations)\n\n    def test_search_annotations_includes_replies_by_default(self, pyramid_request, query):\n        search = core.Search(pyramid_request)\n        search.search_annotations({})\n\n        assert not query.TopLevelAnnotationsFilter.called, (\n                \"Replies should not be filtered out of the 'rows' list if \"\n                \"separate_replies=True is not given\")\n\n    def test_search_annotations_parses_aggregation_results(self, pyramid_request):\n        search = core.Search(pyramid_request)\n        search.es.conn.search.return_value = {\n            'hits': {\n                'total': 0,\n                'hits': [],\n            },\n            'aggregations': {\n                'foobar': {'foo': 'bar'},\n                'bazqux': {'baz': 'qux'},\n            }\n        }\n        foobaragg = mock.Mock(key='foobar')\n        bazquxagg = mock.Mock(key='bazqux')\n        search.append_aggregation(foobaragg)\n        search.append_aggregation(bazquxagg)\n\n        search.search_annotations({})\n\n        foobaragg.parse_result.assert_called_with({'foo': 'bar'})\n        bazquxagg.parse_result.assert_called_with({'baz': 'qux'})\n\n    def test_search_annotations_returns_parsed_aggregations(self, pyramid_request):\n        search = core.Search(pyramid_request)\n        search.es.conn.search.return_value = {\n            'hits': {'total': 0, 'hits': []},\n            'aggregations': {'foobar': {'foo': 'bar'}}\n        }\n        foobaragg = mock.Mock(key='foobar')\n        search.append_aggregation(foobaragg)\n\n        _, _, aggregations = search.search_annotations({})\n        assert aggregations == {'foobar': foobaragg.parse_result.return_value}\n\n    def test_search_replies_skips_search_by_default(self, pyramid_request):\n        search = core.Search(pyramid_request)\n        search.search_replies(['id-1', 'id-2'])\n\n        assert not search.es.conn.search.called\n\n    def test_search_annotations_excludes_replies_when_asked(self, pyramid_request, query):\n        search = core.Search(pyramid_request, separate_replies=True)\n\n        search.search_annotations({})\n\n        assert mock.call(query.TopLevelAnnotationsFilter()) in \\\n            search.builder.append_filter.call_args_list\n\n    def test_search_replies_adds_a_replies_matcher(self, pyramid_request, query):\n        search = core.Search(pyramid_request, separate_replies=True)\n\n        search.search_replies(['id-1', 'id-2'])\n\n        assert mock.call(query.RepliesMatcher(['id-1', 'id-2'])) in \\\n            search.reply_builder.append_matcher.call_args_list\n\n    def test_search_replies_searches_replies_when_asked(self, pyramid_request):\n        search = core.Search(pyramid_request, separate_replies=True)\n\n        search.es.conn.search.return_value = {\n            'hits': {\n                'total': 2,\n                'hits': [{'_id': 'reply-1'}, {'_id': 'reply-2'}],\n            }\n        }\n\n        assert search.search_replies(['id-1']) == ['reply-1', 'reply-2']\n\n    def test_search_replies_logs_warning_if_there_are_too_many_replies(self, pyramid_request, log):\n        search = core.Search(pyramid_request, separate_replies=True)\n\n        search.es.conn.search.return_value = {\n            'hits': {\n                'total': 1100,\n                'hits': [{'_id': 'reply-1'}],\n            }\n        }\n\n        search.search_replies(['id-1'])\n        assert log.warn.call_count == 1\n\n    def test_append_filter_appends_to_annotation_builder(self, pyramid_request):\n        filter_ = mock.Mock()\n        search = core.Search(pyramid_request)\n        search.builder = mock.Mock()\n\n        search.append_filter(filter_)\n\n        search.builder.append_filter.assert_called_once_with(filter_)\n\n    def test_append_filter_appends_to_reply_builder(self, pyramid_request):\n        filter_ = mock.Mock()\n        search = core.Search(pyramid_request)\n        search.reply_builder = mock.Mock()\n\n        search.append_filter(filter_)\n\n        search.reply_builder.append_filter.assert_called_once_with(filter_)\n\n    def test_append_matcher_appends_to_annotation_builder(self, pyramid_request):\n        matcher = mock.Mock()\n\n        search = core.Search(pyramid_request)\n        search.builder = mock.Mock()\n        search.append_matcher(matcher)\n\n        search.builder.append_matcher.assert_called_once_with(matcher)\n\n    def test_append_matcher_appends_to_reply_builder(self, pyramid_request):\n        matcher = mock.Mock()\n        search = core.Search(pyramid_request)\n        search.reply_builder = mock.Mock()\n\n        search.append_matcher(matcher)\n\n        search.reply_builder.append_matcher.assert_called_once_with(matcher)\n\n    def test_append_aggregation_appends_to_annotation_builder(self, pyramid_request):\n        aggregation = mock.Mock()\n        search = core.Search(pyramid_request)\n        search.builder = mock.Mock()\n\n        search.append_aggregation(aggregation)\n\n        search.builder.append_aggregation.assert_called_once_with(aggregation)\n\n    @pytest.fixture\n    def search_annotations(self, patch):\n        return patch('memex.search.core.Search.search_annotations')\n\n    @pytest.fixture\n    def search_replies(self, patch):\n        return patch('memex.search.core.Search.search_replies')\n\n    @pytest.fixture\n    def query(self, patch):\n        return patch('memex.search.core.query')\n\n    @pytest.fixture\n    def log(self, patch):\n        return patch('memex.search.core.log')\n\n\n# @search_fixtures\n# def test_search_logs_a_warning_if_there_are_too_many_replies(log, pyramid_request):\n#     \"\"\"It should log a warning if there's more than one page of replies.\"\"\"\n#     parent_results = dummy_search_results(count=3)\n#     replies_results = dummy_search_results(count=100, name='reply')\n#     # The second call to search() returns 'total': 11000 but only returns\n#     # the first 100 of 11000 hits.\n#     replies_results['hits']['total'] = 11000\n#     pyramid_request.es.conn.search.side_effect = [parent_results, replies_results]\n#\n#     core.search(pyramid_request, {}, separate_replies=True)\n#\n#     assert log.warn.call_count == 1\n\n\n# @search_fixtures\n# def test_search_does_not_log_a_warning_if_there_are_not_too_many_replies(log, pyramid_request):\n#     \"\"\"It should not log a warning if there's less than one page of replies.\"\"\"\n#     pyramid_request.es.conn.search.side_effect = [\n#         dummy_search_results(count=3),\n#         dummy_search_results(count=100, start=4, name='reply'),\n#     ]\n#\n#     core.search(pyramid_request, {}, separate_replies=True)\n#\n#     assert not log.warn.called\n\n\n@pytest.mark.parametrize('filter_type', [\n    'AuthFilter',\n    'UriFilter',\n    'UserFilter',\n    'GroupFilter',\n])\ndef test_default_querybuilder_includes_default_filters(filter_type, matchers, pyramid_request):\n    from memex.search import query\n    builder = core.default_querybuilder(pyramid_request)\n    type_ = getattr(query, filter_type)\n\n    assert matchers.instance_of(type_) in builder.filters\n\n\ndef test_default_querybuilder_includes_registered_filters(pyramid_request):\n    filter_factory = mock.Mock(return_value=mock.sentinel.MY_FILTER,\n                               spec_set=[])\n    pyramid_request.registry[core.FILTERS_KEY] = [filter_factory]\n\n    builder = core.default_querybuilder(pyramid_request)\n\n    filter_factory.assert_called_once_with(pyramid_request)\n    assert mock.sentinel.MY_FILTER in builder.filters\n\n\n@pytest.mark.parametrize('matcher_type', [\n    'AnyMatcher',\n    'TagsMatcher',\n])\ndef test_default_querybuilder_includes_default_matchers(matchers, matcher_type, pyramid_request):\n    from memex.search import query\n    builder = core.default_querybuilder(pyramid_request)\n    type_ = getattr(query, matcher_type)\n\n    assert matchers.instance_of(type_) in builder.matchers\n\n\ndef test_default_querybuilder_includes_registered_matchers(pyramid_request):\n    matcher_factory = mock.Mock(return_value=mock.sentinel.MY_MATCHER,\n                                spec_set=[])\n    pyramid_request.registry[core.MATCHERS_KEY] = [matcher_factory]\n\n    builder = core.default_querybuilder(pyramid_request)\n\n    matcher_factory.assert_called_once_with(pyramid_request)\n    assert mock.sentinel.MY_MATCHER in builder.matchers\n\n\ndef dummy_search_results(start=1, count=0, name='annotation'):\n    \"\"\"Generate some dummy search results.\"\"\"\n    out = {'hits': {'total': 0, 'hits': []}}\n\n    for i in range(start, start + count):\n        out['hits']['total'] += 1\n        out['hits']['hits'].append({\n            '_id': 'id_{}'.format(i),\n            '_source': {'name': '{}_{}'.format(name, i)},\n        })\n\n    return out\n\n\n@pytest.fixture\ndef pyramid_request(pyramid_request):\n    \"\"\"Return a mock request with a faked out Elasticsearch connection.\"\"\"\n    pyramid_request.es = mock.Mock(spec_set=['conn', 'index', 't'])\n    pyramid_request.es.conn.search.return_value = dummy_search_results(0)\n    return pyramid_request\n\n\n@pytest.fixture\ndef log(patch):\n    return patch('memex.search.core.log')\n"},{"size":15268,"relativepath":"tests/memex/search/index_test.py","filename":"index_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nimport mock\nimport pytest\n\nimport elasticsearch\n\nfrom memex import presenters\nfrom memex.search import client\nfrom memex.search import index\n\n\n@pytest.mark.usefixtures('presenters')\nclass TestIndexAnnotation:\n\n    def test_it_presents_the_annotation(self, es, presenters, pyramid_request):\n        annotation = mock.Mock()\n\n        index.index(es, annotation, pyramid_request)\n\n        presenters.AnnotationSearchIndexPresenter.assert_called_once_with(annotation)\n\n    def test_it_creates_an_annotation_before_save_event(self,\n                                                        AnnotationTransformEvent,\n                                                        es,\n                                                        presenters,\n                                                        pyramid_request):\n        presented = presenters.AnnotationSearchIndexPresenter.return_value.asdict()\n\n        index.index(es, mock.Mock(), pyramid_request)\n\n        AnnotationTransformEvent.assert_called_once_with(pyramid_request, presented)\n\n    def test_it_notifies_before_save_event(self,\n                                           AnnotationTransformEvent,\n                                           es,\n                                           notify,\n                                           presenters,\n                                           pyramid_request):\n        index.index(es, mock.Mock(), pyramid_request)\n\n        event = AnnotationTransformEvent.return_value\n        notify.assert_called_once_with(event)\n\n    def test_it_indexes_the_annotation(self, es, presenters, pyramid_request):\n        index.index(es, mock.Mock(), pyramid_request)\n\n        es.conn.index.assert_called_once_with(\n            index='hypothesis',\n            doc_type='annotation',\n            body=presenters.AnnotationSearchIndexPresenter.return_value.asdict.return_value,\n            id='test_annotation_id',\n        )\n\n    @pytest.fixture\n    def presenters(self, patch):\n        presenters = patch('memex.search.index.presenters')\n        presenter = presenters.AnnotationSearchIndexPresenter.return_value\n        presenter.asdict.return_value = {\n            'id': 'test_annotation_id',\n            'target': [\n                {\n                    'source': 'http://example.com/example',\n                },\n            ],\n        }\n        return presenters\n\n\n@pytest.mark.usefixtures('log')\nclass TestDeleteAnnotation:\n\n    def test_it_deletes_the_annotation(self, es):\n        index.delete(es, 'test_annotation_id')\n\n        es.conn.delete.assert_called_once_with(\n            index='hypothesis',\n            doc_type='annotation',\n            id='test_annotation_id',\n        )\n\n    def test_it_logs_NotFoundErrors(self, es, log):\n        \"\"\"NotFoundErrors from elasticsearch should be caught and logged.\"\"\"\n        es.conn.delete.side_effect = elasticsearch.NotFoundError()\n\n        index.delete(es, mock.Mock())\n\n        assert log.exception.called\n\n    @pytest.fixture\n    def log(self, patch):\n        return patch('memex.search.index.log')\n\n\n@pytest.mark.usefixtures('BatchIndexer', 'BatchDeleter')\nclass TestReindex(object):\n    def test_it_indexes_all_annotations(self, BatchIndexer):\n        index.reindex(mock.sentinel.session, mock.sentinel.es, mock.sentinel.request)\n\n        BatchIndexer.assert_called_once_with(\n            mock.sentinel.session, mock.sentinel.es, mock.sentinel.request)\n        assert BatchIndexer.return_value.index_all.called\n\n    def test_it_removes_all_deleted_annotations(self, BatchDeleter):\n        index.reindex(mock.sentinel.session, mock.sentinel.es, mock.sentinel.request)\n\n        BatchDeleter.assert_called_once_with(mock.sentinel.session, mock.sentinel.es)\n        assert BatchDeleter.return_value.delete_all.called\n\n    @pytest.fixture\n    def BatchIndexer(self, patch):\n        return patch('memex.search.index.BatchIndexer')\n\n    @pytest.fixture\n    def BatchDeleter(self, patch):\n        return patch('memex.search.index.BatchDeleter')\n\n\nclass TestBatchIndexer(object):\n    def test_index_all(self, indexer, index):\n        indexer.index_all()\n        assert index.called\n\n    def test_index_all_retries_failed_index_attempts_once(self, indexer, index):\n        index.return_value = set(['id-1'])\n        indexer.index_all()\n        assert index.call_args_list == [\n            mock.call(indexer, None),\n            mock.call(indexer, set(['id-1'])),\n        ]\n\n    def test_index_indexes_all_annotations_to_es(self, db_session, indexer, matchers, streaming_bulk, factories):\n        ann_1, ann_2 = factories.Annotation(), factories.Annotation()\n\n        indexer.index()\n\n        streaming_bulk.assert_called_once_with(\n            indexer.es_client.conn, matchers.iterable_with([ann_1, ann_2]),\n            chunk_size=mock.ANY, raise_on_error=False, expand_action_callback=mock.ANY)\n\n    def test_index_indexes_filtered_annotations_to_es(self, db_session, indexer, matchers, streaming_bulk, factories):\n        ann_1, ann_2 = factories.Annotation(), factories.Annotation()\n\n        indexer.index([ann_2.id])\n\n        streaming_bulk.assert_called_once_with(\n            indexer.es_client.conn, matchers.iterable_with([ann_2]),\n            chunk_size=mock.ANY, raise_on_error=False, expand_action_callback=mock.ANY)\n\n    def test_index_correctly_presents_bulk_actions(self,\n                                                   db_session,\n                                                   indexer,\n                                                   pyramid_request,\n                                                   streaming_bulk,\n                                                   factories):\n        annotation = factories.Annotation()\n        db_session.add(annotation)\n        db_session.flush()\n        results = []\n\n        def fake_streaming_bulk(*args, **kwargs):\n            ann = list(args[1])[0]\n            callback = kwargs.get('expand_action_callback')\n            results.append(callback(ann))\n            return set()\n\n        streaming_bulk.side_effect = fake_streaming_bulk\n\n        indexer.index()\n\n        rendered = presenters.AnnotationSearchIndexPresenter(annotation).asdict()\n        rendered['target'][0]['scope'] = [annotation.target_uri_normalized]\n        assert results[0] == (\n            {'index': {'_type': indexer.es_client.t.annotation,\n                       '_index': indexer.es_client.index,\n                       '_id': annotation.id}},\n            rendered\n        )\n\n    def test_index_emits_AnnotationTransformEvent_when_presenting_bulk_actions(self,\n                                                                               db_session,\n                                                                               indexer,\n                                                                               pyramid_request,\n                                                                               streaming_bulk,\n                                                                               pyramid_config,\n                                                                               factories):\n\n        annotation = factories.Annotation()\n        results = []\n\n        def fake_streaming_bulk(*args, **kwargs):\n            ann = list(args[1])[0]\n            callback = kwargs.get('expand_action_callback')\n            results.append(callback(ann))\n            return set()\n\n        streaming_bulk.side_effect = fake_streaming_bulk\n\n        def transform(event):\n            data = event.annotation_dict\n            data['transformed'] = True\n\n        pyramid_config.add_subscriber(transform, 'memex.events.AnnotationTransformEvent')\n\n        indexer.index()\n\n        rendered = presenters.AnnotationSearchIndexPresenter(annotation).asdict()\n        rendered['transformed'] = True\n        rendered['target'][0]['scope'] = [annotation.target_uri_normalized]\n\n        assert results[0] == (\n            {'index': {'_type': indexer.es_client.t.annotation,\n                       '_index': indexer.es_client.index,\n                       '_id': annotation.id}},\n            rendered\n        )\n\n    def test_index_returns_failed_bulk_actions(self, db_session, indexer, streaming_bulk, factories):\n        ann_success_1, ann_success_2 = factories.Annotation(), factories.Annotation()\n        ann_fail_1, ann_fail_2 = factories.Annotation(), factories.Annotation()\n\n        def fake_streaming_bulk(*args, **kwargs):\n            for ann in args[1]:\n                if ann.id in [ann_fail_1.id, ann_fail_2.id]:\n                    yield (False, {'index': {'_id': ann.id}})\n                elif ann.id in [ann_success_1.id, ann_success_2.id]:\n                    yield (True, {'index': {'_id': ann.id}})\n\n        streaming_bulk.side_effect = fake_streaming_bulk\n\n        result = indexer.index()\n        assert result == set([ann_fail_1.id, ann_fail_2.id])\n\n    @pytest.fixture\n    def indexer(self, db_session, pyramid_request):\n        return index.BatchIndexer(db_session, mock.MagicMock(), pyramid_request)\n\n    @pytest.fixture\n    def index(self, patch):\n        return patch('memex.search.index.BatchIndexer.index')\n\n    @pytest.fixture\n    def streaming_bulk(self, patch):\n        return patch('memex.search.index.es_helpers.streaming_bulk')\n\n\nclass TestBatchDeleter(object):\n    def test_delete_all_fetches_deleted_annotation_ids(self, deleter, deleted_annotation_ids):\n        deleter.delete_all()\n        assert deleted_annotation_ids.call_count == 1\n\n    def test_delete_all_deletes_annotation_ids(self, deleter, deleted_annotation_ids, delete):\n        deleted_annotation_ids.return_value = set([mock.Mock()])\n        delete.return_value = set()\n\n        deleter.delete_all()\n        delete.assert_called_once_with(deleter, deleted_annotation_ids.return_value)\n\n    def test_delete_all_skips_deleting_when_no_deleted_annotation_ids(self,\n                                                                      deleter,\n                                                                      deleted_annotation_ids,\n                                                                      delete):\n        deleted_annotation_ids.return_value = set()\n\n        deleter.delete_all()\n        assert not delete.called\n\n    def test_delete_all_retries_failed_deletion_attempts_once(self,\n                                                              deleter,\n                                                              deleted_annotation_ids,\n                                                              delete):\n        deleted_annotation_ids.return_value = set(['id-1', 'id-2'])\n        delete.return_value = set(['id-1'])\n\n        deleter.delete_all()\n        assert delete.call_args_list == [\n            mock.call(deleter, set(['id-1', 'id-2'])),\n            mock.call(deleter, set(['id-1']))\n        ]\n\n    def test_deleted_annotation_ids(self, db_session, es_scan, annotation):\n        deleter = self.deleter(session=db_session)\n\n        es_scan.return_value = [\n            {'_id': 'deleted-from-postgres-id',\n             '_source': {'uri': 'http://example.org'}}]\n\n        deleted_ids = deleter.deleted_annotation_ids()\n        assert deleted_ids == set(['deleted-from-postgres-id'])\n\n    def test_deleted_annotation_ids_no_changes(self,\n                                               annotation,\n                                               db_session,\n                                               es_scan,\n                                               pyramid_request):\n        deleter = self.deleter(session=db_session)\n\n        es_scan.return_value = [\n            {'_id': annotation.id,\n             '_source': presenters.AnnotationSearchIndexPresenter(annotation)}]\n\n        deleted_ids = deleter.deleted_annotation_ids()\n        assert len(deleted_ids) == 0\n\n    def test_delete_deletes_from_es(self, deleter, streaming_bulk):\n        ids = set(['test-annotation-id'])\n\n        deleter.delete(ids)\n        streaming_bulk.assert_called_once_with(\n            deleter.es_client.conn, ids, chunk_size=mock.ANY,\n            raise_on_error=False, expand_action_callback=mock.ANY)\n\n    def test_delete_correctly_presents_bulk_actions(self, deleter, streaming_bulk):\n        results = []\n\n        def fake_streaming_bulk(*args, **kwargs):\n            id_ = args[1][0]\n            callback = kwargs.get('expand_action_callback')\n            results.append(callback(id_))\n            return set()\n\n        streaming_bulk.side_effect = fake_streaming_bulk\n\n        deleter.delete(['test-annotation-id'])\n        assert results[0] == (\n            {'delete': {'_type': deleter.es_client.t.annotation,\n                        '_index': deleter.es_client.index,\n                        '_id': 'test-annotation-id'}},\n            None,\n        )\n\n    def test_delete_returns_failed_bulk_actions(self, deleter, streaming_bulk):\n        def fake_streaming_bulk(*args, **kwargs):\n            ids = args[1]\n            for id_ in ids:\n                if id_.startswith('fail'):\n                    yield (False, {'delete': {'_id': id_, 'status': 504}})\n                else:\n                    yield (True, {'delete': {'_id': id_, 'status': 200}})\n\n        streaming_bulk.side_effect = fake_streaming_bulk\n\n        result = deleter.delete(['succeed-1', 'fail-1', 'fail-2', 'succeed-2'])\n        assert result == set(['fail-1', 'fail-2'])\n\n    def test_delete_does_not_return_failed_404_bulk_actions(self, deleter, streaming_bulk):\n        def fake_streaming_bulk(*args, **kwargs):\n            ids = args[1]\n            for id_ in ids:\n                if id_ == 'fail-404':\n                    yield (False, {'delete': {'_id': id_, 'status': 404}})\n                elif id_.startswith('fail-504'):\n                    yield (False, {'delete': {'_id': id_, 'status': 504}})\n                else:\n                    yield (True, {'delete': {'_id': id_, 'status': 200}})\n\n        streaming_bulk.side_effect = fake_streaming_bulk\n\n        result = deleter.delete(['succeed-1', 'fail-404', 'fail-504'])\n        assert result == set(['fail-504'])\n\n    @pytest.fixture\n    def deleter(self, session=None):\n        if session is None:\n            session = mock.MagicMock()\n        return index.BatchDeleter(session, mock.MagicMock())\n\n    @pytest.fixture\n    def deleted_annotation_ids(self, patch):\n        return patch('memex.search.index.BatchDeleter.deleted_annotation_ids')\n\n    @pytest.fixture\n    def delete(self, patch):\n        return patch('memex.search.index.BatchDeleter.delete')\n\n    @pytest.fixture\n    def es_scan(self, patch):\n        return patch('memex.search.index.es_helpers.scan')\n\n    @pytest.fixture\n    def streaming_bulk(self, patch):\n        return patch('memex.search.index.es_helpers.streaming_bulk')\n\n    @pytest.fixture\n    def annotation(self, db_session, factories):\n        ann = factories.Annotation(userid=\"bob\", target_uri=\"http://example.com\")\n        return ann\n\n\n@pytest.fixture\ndef es():\n    mock_es = mock.Mock(spec=client.Client('localhost', 'hypothesis'))\n    mock_es.index = 'hypothesis'\n    mock_es.t.annotation = 'annotation'\n    return mock_es\n\n\n@pytest.fixture\ndef AnnotationTransformEvent(patch):\n    return patch('memex.search.index.AnnotationTransformEvent')\n"},{"size":16256,"relativepath":"tests/memex/search/query_test.py","filename":"query_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\nimport pytest\nfrom hypothesis import strategies as st\nfrom hypothesis import given\nfrom webob import multidict\n\nfrom memex.search import query\n\nMISSING = object()\n\nOFFSET_DEFAULT = 0\nLIMIT_DEFAULT = 20\nLIMIT_MAX = 200\n\n\nclass TestBuilder(object):\n    @pytest.mark.parametrize('offset,from_', [\n        # defaults to OFFSET_DEFAULT\n        (MISSING, OFFSET_DEFAULT),\n        # straightforward pass-through\n        (7, 7),\n        (42, 42),\n        # string values should be converted\n        (\"23\", 23),\n        (\"82\", 82),\n        # invalid values should be ignored and the default should be returned\n        (\"foo\",  OFFSET_DEFAULT),\n        (\"\",     OFFSET_DEFAULT),\n        (\"   \",  OFFSET_DEFAULT),\n        (\"-23\",  OFFSET_DEFAULT),\n        (\"32.7\", OFFSET_DEFAULT),\n    ])\n    def test_offset(self, offset, from_):\n        builder = query.Builder()\n\n        if offset is MISSING:\n            q = builder.build({})\n        else:\n            q = builder.build({\"offset\": offset})\n\n        assert q[\"from\"] == from_\n\n    @given(st.text())\n    @pytest.mark.fuzz\n    def test_limit_output_within_bounds(self, text):\n        \"\"\"Given any string input, output should be in the allowed range.\"\"\"\n        builder = query.Builder()\n\n        q = builder.build({\"limit\": text})\n\n        assert isinstance(q[\"size\"], int)\n        assert 0 <= q[\"size\"] <= LIMIT_MAX\n\n    @given(st.integers())\n    @pytest.mark.fuzz\n    def test_limit_output_within_bounds_int_input(self, lim):\n        \"\"\"Given any integer input, output should be in the allowed range.\"\"\"\n        builder = query.Builder()\n\n        q = builder.build({\"limit\": str(lim)})\n\n        assert isinstance(q[\"size\"], int)\n        assert 0 <= q[\"size\"] <= LIMIT_MAX\n\n    @given(st.integers(min_value=0, max_value=LIMIT_MAX))\n    @pytest.mark.fuzz\n    def test_limit_matches_input(self, lim):\n        \"\"\"Given an integer in the allowed range, it should be passed through.\"\"\"\n        builder = query.Builder()\n\n        q = builder.build({\"limit\": str(lim)})\n\n        assert q[\"size\"] == lim\n\n    def test_limit_missing(self):\n        builder = query.Builder()\n\n        q = builder.build({})\n\n        assert q[\"size\"] == LIMIT_DEFAULT\n\n    def test_sort_is_by_updated(self):\n        \"\"\"Sort defaults to \"updated\".\"\"\"\n        builder = query.Builder()\n\n        q = builder.build({})\n\n        sort = q[\"sort\"]\n        assert len(sort) == 1\n        assert sort[0].keys() == [\"updated\"]\n\n    def test_sort_includes_ignore_unmapped(self):\n        \"\"\"'ignore_unmapped': True is used in the sort clause.\"\"\"\n        builder = query.Builder()\n\n        q = builder.build({})\n\n        assert q[\"sort\"][0][\"updated\"][\"ignore_unmapped\"] == True\n\n    def test_with_custom_sort(self):\n        \"\"\"Custom sorts are returned in the query dict.\"\"\"\n        builder = query.Builder()\n\n        q = builder.build({\"sort\": \"title\"})\n\n        assert q[\"sort\"] == [{'title': {'ignore_unmapped': True, 'order': 'desc'}}]\n\n    def test_order_defaults_to_desc(self):\n        \"\"\"'order': \"desc\" is returned in the q dict by default.\"\"\"\n        builder = query.Builder()\n\n        q = builder.build({})\n\n        sort = q[\"sort\"]\n        assert sort[0][\"updated\"][\"order\"] == \"desc\"\n\n    def test_with_custom_order(self):\n        \"\"\"'order' params are returned in the query dict if given.\"\"\"\n        builder = query.Builder()\n\n        q = builder.build({\"order\": \"asc\"})\n\n        sort = q[\"sort\"]\n        assert sort[0][\"updated\"][\"order\"] == \"asc\"\n\n    def test_defaults_to_match_all(self):\n        \"\"\"If no query params are given a \"match_all\": {} query is returned.\"\"\"\n        builder = query.Builder()\n\n        q = builder.build({})\n\n        assert q[\"query\"] == {\"match_all\": {}}\n\n    def test_default_param_action(self):\n        \"\"\"Other params are added as \"match\" clauses.\"\"\"\n        builder = query.Builder()\n\n        q = builder.build({\"foo\": \"bar\"})\n\n        assert q[\"query\"] == {\"bool\": {\"must\": [{\"match\": {\"foo\": \"bar\"}}]}}\n\n    def test_default_params_multidict(self):\n        \"\"\"Multiple params go into multiple \"match\" dicts.\"\"\"\n        builder = query.Builder()\n        params = multidict.MultiDict()\n        params.add(\"user\", \"fred\")\n        params.add(\"user\", \"bob\")\n\n        q = builder.build(params)\n\n        assert q[\"query\"] == {\n            \"bool\": {\n                \"must\": [\n                    {\"match\": {\"user\": \"fred\"}},\n                    {\"match\": {\"user\": \"bob\"}}\n                ]\n            }\n        }\n\n    def test_with_evil_arguments(self):\n        builder = query.Builder()\n        params = {\n            \"offset\": \"3foo\",\n            \"limit\": '\\' drop table annotations'\n        }\n\n        q = builder.build(params)\n\n        assert q[\"from\"] == 0\n        assert q[\"size\"] == 20\n        assert q[\"query\"] == {'match_all': {}}\n\n    def test_passes_params_to_filters(self):\n        testfilter = mock.Mock()\n        builder = query.Builder()\n        builder.append_filter(testfilter)\n\n        builder.build({\"foo\": \"bar\"})\n\n        testfilter.assert_called_with({\"foo\": \"bar\"})\n\n    def test_ignores_filters_returning_none(self):\n        testfilter = mock.Mock()\n        testfilter.return_value = None\n        builder = query.Builder()\n        builder.append_filter(testfilter)\n\n        q = builder.build({})\n\n        assert q[\"query\"] == {\"match_all\": {}}\n\n    def test_filters_query_by_filter_results(self):\n        testfilter = mock.Mock()\n        testfilter.return_value = {\"term\": {\"giraffe\": \"nose\"}}\n        builder = query.Builder()\n        builder.append_filter(testfilter)\n\n        q = builder.build({})\n\n        assert q[\"query\"] == {\n            \"filtered\": {\n                \"filter\": {\"and\": [{\"term\": {\"giraffe\": \"nose\"}}]},\n                \"query\": {\"match_all\": {}},\n            },\n        }\n\n    def test_passes_params_to_matchers(self):\n        testmatcher = mock.Mock()\n        builder = query.Builder()\n        builder.append_matcher(testmatcher)\n\n        builder.build({\"foo\": \"bar\"})\n\n        testmatcher.assert_called_with({\"foo\": \"bar\"})\n\n    def test_adds_matchers_to_query(self):\n        testmatcher = mock.Mock()\n        testmatcher.return_value = {\"match\": {\"giraffe\": \"nose\"}}\n        builder = query.Builder()\n        builder.append_matcher(testmatcher)\n\n        q = builder.build({})\n\n        assert q[\"query\"] == {\n            \"bool\": {\"must\": [{\"match\": {\"giraffe\": \"nose\"}}]},\n        }\n\n    def test_passes_params_to_aggregations(self):\n        testaggregation = mock.Mock()\n        builder = query.Builder()\n        builder.append_aggregation(testaggregation)\n\n        builder.build({\"foo\": \"bar\"})\n\n        testaggregation.assert_called_with({\"foo\": \"bar\"})\n\n    def test_adds_aggregations_to_query(self):\n        testaggregation = mock.Mock(key=\"foobar\")\n        # testaggregation.key.return_value = \"foobar\"\n        testaggregation.return_value = {\"terms\": {\"field\": \"foo\"}}\n        builder = query.Builder()\n        builder.append_aggregation(testaggregation)\n\n        q = builder.build({})\n\n        assert q[\"aggs\"] == {\n            \"foobar\": {\"terms\": {\"field\": \"foo\"}}\n        }\n\n\nclass TestAuthFilter(object):\n    def test_world_not_in_principals(self):\n        request = mock.Mock(effective_principals=['foo'])\n        authfilter = query.AuthFilter(request)\n\n        assert authfilter({}) == {\n            'terms': {'permissions.read': ['group:__world__', 'foo']}\n        }\n\n    def test_world_in_principals(self):\n        request = mock.Mock(effective_principals=['group:__world__', 'foo'])\n        authfilter = query.AuthFilter(request)\n\n        assert authfilter({}) == {\n            'terms': {'permissions.read': ['group:__world__', 'foo']}\n        }\n\n\nclass TestGroupFilter(object):\n    def test_term_filters_for_group(self):\n        groupfilter = query.GroupFilter()\n\n        assert groupfilter({\"group\": \"wibble\"}) == {\"term\": {\"group\": \"wibble\"}}\n\n    def test_strips_param(self):\n        groupfilter = query.GroupFilter()\n        params = {\"group\": \"wibble\"}\n\n        groupfilter(params)\n\n        assert params == {}\n\n    def test_returns_none_when_no_param(self):\n        groupfilter = query.GroupFilter()\n\n        assert groupfilter({}) is None\n\n\nclass TestUriFilter(object):\n    @pytest.mark.usefixtures('uri')\n    def test_inactive_when_no_uri_param(self):\n        \"\"\"\n        When there's no `uri` parameter, return None.\n        \"\"\"\n        request = mock.Mock()\n        urifilter = query.UriFilter(request)\n\n        assert urifilter({\"foo\": \"bar\"}) is None\n\n    def test_expands_and_normalizes_into_terms_filter(self, storage):\n        \"\"\"\n        Uses a `terms` filter against target.scope to filter for URI.\n\n        UriFilter should use a `terms` filter against the normalized version of the\n        target source field, which we store in `target.scope`.\n\n        It should expand the input URI before searching, and normalize the results\n        of the expansion.\n        \"\"\"\n        request = mock.Mock()\n        storage.expand_uri.side_effect = lambda _, x: [\n            \"http://giraffes.com/\",\n            \"https://elephants.com/\",\n        ]\n\n        urifilter = query.UriFilter(request)\n\n        result = urifilter({\"uri\": \"http://example.com/\"})\n        query_uris = result[\"terms\"][\"target.scope\"]\n\n        storage.expand_uri.assert_called_with(request.db, \"http://example.com/\")\n        assert sorted(query_uris) == sorted([\"httpx://giraffes.com\",\n                                             \"httpx://elephants.com\"])\n\n    def test_queries_multiple_uris(self, storage):\n        \"\"\"\n        Uses a `terms` filter against target.scope to filter for URI.\n\n        When multiple \"uri\" fields are supplied, the normalized URIs of all of\n        them should be collected into a set and sent in the query.\n        \"\"\"\n        request = mock.Mock()\n        params = multidict.MultiDict()\n        params.add(\"uri\", \"http://example.com\")\n        params.add(\"uri\", \"http://example.net\")\n        storage.expand_uri.side_effect = [\n            [\"http://giraffes.com/\", \"https://elephants.com/\"],\n            [\"http://tigers.com/\", \"https://elephants.com/\"],\n        ]\n\n        urifilter = query.UriFilter(request)\n\n        result = urifilter(params)\n        query_uris = result[\"terms\"][\"target.scope\"]\n\n        storage.expand_uri.assert_any_call(request.db, \"http://example.com\")\n        storage.expand_uri.assert_any_call(request.db, \"http://example.net\")\n        assert sorted(query_uris) == sorted([\"httpx://giraffes.com\",\n                                             \"httpx://elephants.com\",\n                                             \"httpx://tigers.com\"])\n\n    @pytest.fixture\n    def storage(self, patch):\n        storage = patch('memex.search.query.storage')\n        storage.expand_uri.side_effect = lambda x: [x]\n        return storage\n\n    @pytest.fixture\n    def uri(self, patch):\n        uri = patch('memex.search.query.uri')\n        uri.normalize.side_effect = lambda x: x\n        return uri\n\n\nclass TestUserFilter(object):\n    def test_term_filters_for_user(self):\n        userfilter = query.UserFilter()\n\n        assert userfilter({\"user\": \"luke\"}) == {\"terms\": {\"user\": [\"luke\"]}}\n\n    def test_supports_filtering_for_multiple_users(self):\n        userfilter = query.UserFilter()\n\n        params = multidict.MultiDict()\n        params.add(\"user\", \"alice\")\n        params.add(\"user\", \"luke\")\n\n        assert userfilter(params) == {\n            \"terms\": {\n                \"user\": [\"alice\", \"luke\"]\n            }\n        }\n\n    def test_lowercases_value(self):\n        userfilter = query.UserFilter()\n\n        assert userfilter({\"user\": \"LUkE\"}) == {\"terms\": {\"user\": [\"luke\"]}}\n\n    def test_strips_param(self):\n        userfilter = query.UserFilter()\n        params = {\"user\": \"luke\"}\n\n        userfilter(params)\n\n        assert params == {}\n\n    def test_returns_none_when_no_param(self):\n        userfilter = query.UserFilter()\n\n        assert userfilter({}) is None\n\n\nclass TestAnyMatcher():\n    def test_any_query(self):\n        anymatcher = query.AnyMatcher()\n\n        result = anymatcher({\"any\": \"foo\"})\n\n        assert result == {\n            \"simple_query_string\": {\n                \"fields\": [\"quote\", \"tags\", \"text\", \"uri.parts\"],\n                \"query\": \"foo\",\n            }\n        }\n\n    def test_multiple_params(self):\n        \"\"\"Multiple keywords at once are handled correctly.\"\"\"\n        anymatcher = query.AnyMatcher()\n        params = multidict.MultiDict()\n        params.add(\"any\", \"howdy\")\n        params.add(\"any\", \"there\")\n\n        result = anymatcher(params)\n\n        assert result == {\n            \"simple_query_string\": {\n                \"fields\": [\"quote\", \"tags\", \"text\", \"uri.parts\"],\n                \"query\": \"howdy there\",\n            }\n        }\n\n    def test_aliases_tag_to_tags(self):\n        \"\"\"'tag' params should be transformed into 'tags' queries.\n\n        'tag' is aliased to 'tags' because users often type tag instead of tags.\n\n        \"\"\"\n        params = multidict.MultiDict()\n        params.add('tag', 'foo')\n        params.add('tag', 'bar')\n\n        result = query.TagsMatcher()(params)\n\n        assert list(result.keys()) == ['bool']\n        assert list(result['bool'].keys()) == ['must']\n        assert len(result['bool']['must']) == 2\n        assert {'match': {'tags': {'query': 'foo', 'operator': 'and'}}} in result['bool']['must']\n        assert {'match': {'tags': {'query': 'bar', 'operator': 'and'}}} in result['bool']['must']\n\n    def test_with_both_tag_and_tags(self):\n        \"\"\"If both 'tag' and 'tags' params are used they should all become tags.\"\"\"\n        params = {'tag': 'foo', 'tags': 'bar'}\n\n        result = query.TagsMatcher()(params)\n\n        assert list(result.keys()) == ['bool']\n        assert list(result['bool'].keys()) == ['must']\n        assert len(result['bool']['must']) == 2\n        assert {'match': {'tags': {'query': 'foo', 'operator': 'and'}}} in result['bool']['must']\n        assert {'match': {'tags': {'query': 'bar', 'operator': 'and'}}} in result['bool']['must']\n\n\nclass TestTagsAggregations(object):\n    def test_key_is_tags(self):\n        assert query.TagsAggregation().key == 'tags'\n\n    def test_elasticsearch_aggregation(self):\n        agg = query.TagsAggregation()\n        assert agg({}) == {\n            'terms': {'field': 'tags', 'size': 0}\n        }\n\n    def test_it_allows_to_set_a_limit(self):\n        agg = query.TagsAggregation(limit=14)\n        assert agg({}) == {\n            'terms': {'field': 'tags', 'size': 14}\n        }\n\n    def parse_result(self):\n        agg = query.TagsAggregation()\n        elasticsearch_result = {\n            'buckets': [\n                {'key': 'tag-4', 'doc_count': 42},\n                {'key': 'tag-2', 'doc_count': 28},\n            ]\n        }\n\n        assert agg(elasticsearch_result) == [\n            {'tag': 'tag-4', 'count': 42},\n            {'tag': 'tag-2', 'count': 28},\n        ]\n\n    def parse_result_with_none(self):\n        agg = query.TagsAggregation()\n        assert agg.parse_result(None) == {}\n\n    def parse_result_with_empty(self):\n        agg = query.TagsAggregation()\n        assert agg.parse_result({}) == {}\n\n\nclass TestUsersAggregation(object):\n    def test_key_is_users(self):\n        assert query.UsersAggregation().key == 'users'\n\n    def test_elasticsearch_aggregation(self):\n        agg = query.UsersAggregation()\n        assert agg({}) == {\n            'terms': {'field': 'user_raw', 'size': 0}\n        }\n\n    def test_it_allows_to_set_a_limit(self):\n        agg = query.UsersAggregation(limit=14)\n        assert agg({}) == {\n            'terms': {'field': 'user_raw', 'size': 14}\n        }\n\n    def parse_result(self):\n        agg = query.UsersAggregation()\n        elasticsearch_result = {\n            'buckets': [\n                {'key': 'alice', 'doc_count': 42},\n                {'key': 'luke', 'doc_count': 28},\n            ]\n        }\n\n        assert agg(elasticsearch_result) == [\n            {'user': 'alice', 'count': 42},\n            {'user': 'luke', 'count': 28},\n        ]\n\n    def parse_result_with_none(self):\n        agg = query.UsersAggregation()\n        assert agg.parse_result(None) == {}\n\n    def parse_result_with_empty(self):\n        agg = query.UsersAggregation()\n        assert agg.parse_result({}) == {}\n"},{"size":5800,"relativepath":"tests/memex/search/parser_test.py","filename":"parser_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\nfrom hypothesis import strategies as st\nfrom hypothesis import given\nfrom webob.multidict import MultiDict\n\nfrom memex.search import parser\n\n\n@pytest.mark.parametrize(\"query_in,query_out\", [\n    # user field\n    ('user:luke', MultiDict([('user', 'luke')])),\n    ('user:luke@hypothes.is', MultiDict([('user', 'luke@hypothes.is')])),\n    ('user:acct:luke@hypothes.is', MultiDict([('user', 'acct:luke@hypothes.is')])),\n    ('user:luke user:alice', MultiDict([('user', 'luke'), ('user', 'alice')])),\n    ('user:\"luke and alice\"', MultiDict([('user', 'luke and alice')])),\n    ('user:\"luke\"', MultiDict([('user', 'luke')])),\n    ('USER:luke', MultiDict([('user', 'luke')])),\n\n\n    # tag field\n    ('tag:foo', MultiDict([('tag', 'foo')])),\n    ('tag:foo tag:bar', MultiDict([('tag', 'foo'), ('tag', 'bar')])),\n    ('tag:\\'foo bar\\'', MultiDict([('tag', 'foo bar')])),\n    ('tag:\"foo bar\"', MultiDict([('tag', 'foo bar')])),\n    ('tag:\\'foobar\\'', MultiDict([('tag', 'foobar')])),\n    ('Tag:foo', MultiDict([('tag', 'foo')])),\n\n    # group field\n    ('group:__world__', MultiDict([('group', '__world__')])),\n    ('group:__world__ group:My-Group', MultiDict([('group', '__world__'), ('group', 'My-Group')])),\n    ('GrOuP:__world__', MultiDict([('group', '__world__')])),\n\n    # uri field\n    ('uri:https://example.com', MultiDict([('uri', 'https://example.com')])),\n    ('uri:urn:x-pdf:hthe-fingerprint', MultiDict([('uri', 'urn:x-pdf:hthe-fingerprint')])),\n    ('uri:https://foo.com uri:http://bar.com', MultiDict([('uri', 'https://foo.com'), ('uri', 'http://bar.com')])),\n    ('uri:https://example.com?foo=bar&baz=qux#hello', MultiDict([('uri', 'https://example.com?foo=bar&baz=qux#hello')])),\n    ('URI:https://example.com', MultiDict([('uri', 'https://example.com')])),\n\n    # any field\n    ('foo', MultiDict([('any', 'foo')])),\n    ('foo bar', MultiDict([('any', 'foo'), ('any', 'bar')])),\n    ('foo \"bar baz\"', MultiDict([('any', 'foo'), ('any', 'bar baz')])),\n\n    # unrecognized fields go into any\n    ('bogus:hello', MultiDict([('any', 'bogus:hello')])),\n\n    # combinations\n    ('user:luke group:__world__ tag:foobar hello world', MultiDict([\n        ('user', 'luke'),\n        ('group', '__world__'),\n        ('tag', 'foobar'),\n        ('any', 'hello'),\n        ('any', 'world'),\n    ])),\n    ('tag:foo bar gRoup:__world__ giraffe', MultiDict([\n        ('group', '__world__'),\n        ('tag', 'foo'),\n        ('any', 'bar'),\n        ('any', 'giraffe'),\n    ])),\n])\ndef test_parse(query_in, query_out):\n    assert parser.parse(query_in) == query_out\n\n\n@pytest.mark.parametrize(\"query_in,query_out\", [\n    ('\"\"', MultiDict([('any', '')])),\n    (\"''\", MultiDict([('any', \"\")])),\n    ('tag:\"\"', MultiDict([('tag', '')])),\n    ('tag:\"\"\"', MultiDict([('tag', '\"\"\"')])),\n    ('\"\"\"', MultiDict([('any', '\"\"\"')])),\n    (\"'''\", MultiDict([('any', \"'''\")])),\n    ('tag:\"\"\"\"', MultiDict([('tag', '\"\"')])),\n    ('\"\"\"\"', MultiDict([('any', '\"\"')])),\n    (\"''''\", MultiDict([('any', \"''\")])),\n    ('tag:\"\"\"\"\"', MultiDict([('tag', '\"\"\"\"\"')])),\n    ('\"\"\"\"\"', MultiDict([('any', '\"\"\"\"\"')])),\n    (\"'''''\", MultiDict([('any', \"'''''\")])),\n    ('\"\"0', MultiDict([('any', ''), ('any', '0')])),\n    ('0\"\"', MultiDict([('any', '0\"\"')])),\n    ('\\'\\'0\"\"', MultiDict([('any', '0\"\"')])),\n    ('\\'0\"', MultiDict([('any', '\\'0\"')])),\n])\ndef test_parse_with_odd_quotes_combinations(query_in, query_out):\n    assert parser.parse(query_in) == query_out\n\n\n@given(st.text())\n@pytest.mark.fuzz\ndef test_parse_always_return_a_multidict(text):\n    \"\"\"Given any string input, output should always be a MultiDict.\"\"\"\n    result = parser.parse(text)\n    assert isinstance(result, MultiDict)\n\n\n# Combinations of strings containing any number of quotes are already tested\n# separately.\nchar_blacklist = parser.whitespace.union(set('\\'\"'))\nnonwhitespace_chars = st.characters(blacklist_characters=char_blacklist)\nnonwhitespace_text = st.text(alphabet=nonwhitespace_chars, min_size=1)\n\n\n@given(kw=st.sampled_from(parser.named_fields),\n       value=nonwhitespace_text)\n@pytest.mark.fuzz\ndef test_parse_with_any_nonwhitespace_text(kw, value):\n    result = parser.parse(kw + ':' + value)\n    assert result.get(kw) == value\n\n\n@pytest.mark.parametrize(\"query\", [\n    # Plain dictionary\n    {'user': 'luke'},\n    {'user': 'luke', 'tag': 'foo'},\n\n    # MultiDict\n    MultiDict([('user', 'luke')]),\n    MultiDict([('user', 'luke'), ('user', 'alice')]),\n\n    # Items containing whitespace\n    {'user': 'luke duke'},\n    {'user': 'luke\\u00a0duke'},\n    MultiDict([('user', 'luke duke')]),\n    MultiDict([('user', 'luke duke'), ('user', 'alice and friends')]),\n\n    # Minimally quoted terms including quotes\n    {'user': \"luke's duke\"},\n    {'tag': 'and then he said \"no way\" yes really'},\n\n    # Items which used escape sequences rather than using alternate quotes,\n    # e.g. original queries such as:\n    #\n    #     group:\"foo \\\"hello\\\" bar\"\n    #     tag:'wibble \\'giraffe\\' bang'\n    {'group': 'foo \\\\\"hello\\\\\" bar'},\n    {'tag': 'wibble \\\\\\'giraffe\\\\\\' bang'},\n\n    # Items which contain both single and double quotes\n    {'group': 'but \"that can\\\\\\'t be\", can it?'},\n    {'tag': \"that is 'one \\\\\\\"interesting\\\\\\\" way' of looking at it\"},\n\n    # 'any' terms\n    {'any': 'foo'},\n    MultiDict([('any', 'foo')]),\n    MultiDict([('any', 'foo'), ('any', 'bar baz')]),\n    MultiDict([('user', 'donkeys'), ('any', 'foo'), ('any', 'bar baz')]),\n])\ndef test_unparse(query):\n    result = parser.unparse(query)\n\n    # We can't trivially test that the output is exactly what we expect,\n    # because of uncertainty in the ordering of keys. Instead, we check that\n    # parsing the result gives us an object equal to the original query.\n    assert parser.parse(result) == query\n"},{"size":1975,"relativepath":"tests/memex/search/config_test.py","filename":"config_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport itertools\nimport re\nimport urllib\n\nfrom memex.search.config import ANNOTATION_ANALYSIS\n\n\ndef test_strip_scheme_char_filter():\n    f = ANNOTATION_ANALYSIS['char_filter']['strip_scheme']\n    p = f['pattern']\n    r = f['replacement']\n    assert(re.sub(p, r, 'http://ping/pong#hash') == 'ping/pong#hash')\n    assert(re.sub(p, r, 'chrome-extension://1234/a.js') == '1234/a.js')\n    assert(re.sub(p, r, 'a+b.c://1234/a.js') == '1234/a.js')\n    assert(re.sub(p, r, 'uri:x-pdf:1234') == 'x-pdf:1234')\n    assert(re.sub(p, r, 'example.com') == 'example.com')\n    # This is ambiguous, and possibly cannot be expected to work.\n    # assert(re.sub(p, r, 'localhost:5000') == 'localhost:5000')\n\n\ndef test_path_url_filter():\n    patterns = ANNOTATION_ANALYSIS['filter']['path_url']['patterns']\n    assert(captures(patterns, 'example.com/foo/bar?query#hash') == [\n        'example.com/foo/bar'\n    ])\n    assert(captures(patterns, 'example.com/foo/bar/') == [\n        'example.com/foo/bar/'\n    ])\n\n\ndef test_rstrip_slash_filter():\n    p = ANNOTATION_ANALYSIS['filter']['rstrip_slash']['pattern']\n    r = ANNOTATION_ANALYSIS['filter']['rstrip_slash']['replacement']\n    assert(re.sub(p, r, 'example.com/') == 'example.com')\n    assert(re.sub(p, r, 'example.com/foo/bar/') == 'example.com/foo/bar')\n\n\ndef test_uri_part_tokenizer():\n    text = 'http://a.b/foo/bar?c=d#stuff'\n    pattern = ANNOTATION_ANALYSIS['tokenizer']['uri_part']['pattern']\n    assert(re.split(pattern, text) == [\n        'http', '', '', 'a', 'b', 'foo', 'bar', 'c', 'd', 'stuff'\n    ])\n\n    text = urllib.quote_plus(text)\n    assert(re.split(pattern, 'http://jump.to/?u=' + text) == [\n        'http', '', '', 'jump', 'to', '', 'u',\n        'http', '', '', 'a', 'b', 'foo', 'bar', 'c', 'd', 'stuff'\n    ])\n\n\ndef captures(patterns, text):\n    return list(itertools.chain(*(groups(p, text) for p in patterns)))\n\n\ndef groups(pattern, text):\n    return re.search(pattern, text).groups() or []\n"},{"size":35951,"relativepath":"tests/memex/models/document_test.py","filename":"document_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\nimport datetime\n\nimport mock\nimport pytest\nimport sqlalchemy as sa\nimport transaction\n\nfrom memex import models\nfrom memex.models import document\n\n\nclass TestDocumentFindByURIs(object):\n\n    def test_with_one_matching_Document(self, db_session):\n        # One Document with a non-matching DocumentURI pointing to it.\n        # find_by_uris() should not return this Document.\n        document1 = document.Document()\n        uri1 = 'https://de.wikipedia.org/wiki/Hauptseite'\n        document1.document_uris.append(\n            document.DocumentURI(claimant=uri1, uri=uri1))\n\n        # A second Document with one matching and one non-matching DocumentURI\n        # pointing to it. find_by_uris() should return this Document.\n        document2 = document.Document()\n        uri2 = 'https://en.wikipedia.org/wiki/Main_Page'\n        document2.document_uris.append(\n            document.DocumentURI(claimant=uri2, uri=uri2))\n        uri3 = 'https://en.wikipedia.org'\n        document2.document_uris.append(\n            document.DocumentURI(claimant=uri3, uri=uri2))\n\n        db_session.add_all([document1, document2])\n        db_session.flush()\n\n        actual = document.Document.find_by_uris(db_session, [\n            'https://en.wikipedia.org/wiki/Main_Page',\n            'https://m.en.wikipedia.org/wiki/Main_Page'])\n\n        assert actual.count() == 1\n        assert actual.first() == document2\n\n    def test_no_matches(self, db_session):\n        document_ = document.Document()\n        document_.document_uris.append(document.DocumentURI(\n            claimant='https://en.wikipedia.org/wiki/Main_Page',\n            uri='https://en.wikipedia.org/wiki/Main_Page'))\n        db_session.add(document_)\n        db_session.flush()\n\n        actual = document.Document.find_by_uris(\n            db_session, ['https://de.wikipedia.org/wiki/Hauptseite'])\n        assert actual.count() == 0\n\n\nclass TestDocumentFindOrCreateByURIs(object):\n\n    def test_with_one_existing_Document(self, db_session):\n        \"\"\"\n        When there's one matching Document it should return that Document.\n\n        When searching with two URIs that match two DocumentURIs that both\n        point to the same Document, it should return that Document.\n\n        \"\"\"\n        document_ = document.Document()\n        docuri1 = document.DocumentURI(\n            claimant='https://en.wikipedia.org/wiki/Main_Page',\n            uri='https://en.wikipedia.org/wiki/Main_Page',\n            document=document_)\n        docuri2 = document.DocumentURI(\n            claimant='https://en.wikipedia.org/wiki/http/en.m.wikipedia.org/wiki/Main_Page',\n            uri='https://en.wikipedia.org/wiki/Main_Page',\n            document=document_)\n\n        db_session.add(docuri1)\n        db_session.add(docuri2)\n        db_session.flush()\n\n        actual = document.Document.find_or_create_by_uris(db_session,\n            'https://en.wikipedia.org/wiki/Main_Page',\n            ['https://en.wikipedia.org/wiki/http/en.m.wikipedia.org/wiki/Main_Page',\n            'https://m.en.wikipedia.org/wiki/Main_Page'])\n\n        assert actual.count() == 1\n        assert actual.first() == document_\n\n    def test_with_no_existing_documents(self, db_session):\n        \"\"\"When there are no matching Documents it creates and returns one.\"\"\"\n        document_ = document.Document()\n        docuri = document.DocumentURI(\n            claimant='https://en.wikipedia.org/wiki/Main_Page',\n            uri='https://en.wikipedia.org/wiki/Main_Page',\n            document=document_)\n\n        db_session.add(docuri)\n        db_session.flush()\n\n        documents = document.Document.find_or_create_by_uris(\n            db_session,\n            'https://en.wikipedia.org/wiki/Pluto',\n            ['https://m.en.wikipedia.org/wiki/Pluto'])\n\n        assert documents.count() == 1\n\n        actual = documents.first()\n        assert isinstance(actual, document.Document)\n        assert len(actual.document_uris) == 1\n\n        docuri = actual.document_uris[0]\n        assert docuri.claimant == 'https://en.wikipedia.org/wiki/Pluto'\n        assert docuri.uri == 'https://en.wikipedia.org/wiki/Pluto'\n        assert docuri.type == 'self-claim'\n\n    def test_raises_retryable_error_when_flush_fails(self, db_session, monkeypatch):\n        def err():\n            raise sa.exc.IntegrityError(None, None, None)\n        monkeypatch.setattr(db_session, 'flush', err)\n\n        with pytest.raises(transaction.interfaces.TransientError):\n            with db_session.no_autoflush:  # prevent premature IntegrityError\n                document.Document.find_or_create_by_uris(\n                    db_session,\n                    'https://en.wikipedia.org/wiki/Pluto',\n                    ['https://m.en.wikipedia.org/wiki/Pluto'])\n\n\nclass TestDocumentURI(object):\n\n    def test_type_defaults_to_empty_string(self, db_session):\n        document_uri = document.DocumentURI(claimant='http://www.example.com',\n                                            uri='http://www.example.com',\n                                            type=None,\n                                            content_type='bar',\n                                            document=document.Document())\n        db_session.add(document_uri)\n\n        db_session.flush()\n\n        assert document_uri.type == ''\n\n    def test_you_cannot_set_type_to_null(self, db_session):\n        document_uri = document.DocumentURI(claimant='http://www.example.com',\n                                            uri='http://www.example.com',\n                                            type='foo',\n                                            content_type='bar',\n                                            document=document.Document())\n        db_session.add(document_uri)\n        db_session.flush()\n\n        document_uri.type = None\n\n        with pytest.raises(sa.exc.IntegrityError):\n            db_session.flush()\n\n    def test_content_type_defaults_to_empty_string(self, db_session):\n        document_uri = document.DocumentURI(claimant='http://www.example.com',\n                                            uri='http://www.example.com',\n                                            type='bar',\n                                            content_type=None,\n                                            document=document.Document())\n        db_session.add(document_uri)\n\n        db_session.flush()\n\n        assert document_uri.content_type == ''\n\n    def test_you_cannot_set_content_type_to_null(self, db_session):\n        document_uri = document.DocumentURI(claimant='http://www.example.com',\n                                            uri='http://www.example.com',\n                                            type='foo',\n                                            content_type='bar',\n                                            document=document.Document())\n        db_session.add(document_uri)\n        db_session.flush()\n\n        document_uri.content_type = None\n\n        with pytest.raises(sa.exc.IntegrityError):\n            db_session.flush()\n\n    def test_you_cannot_add_duplicate_document_uris(self, db_session):\n        \"\"\"\n        You can't add duplicate DocumentURI's to the database.\n\n        You can't add DocumentURI's with the same claimant, uri, type and\n        content_type, even if they have different documents.\n\n        \"\"\"\n        db_session.add_all([\n            document.DocumentURI(claimant='http://www.example.com',\n                                 uri='http://www.example.com',\n                                 type='foo',\n                                 content_type='bar',\n                                 document=document.Document()),\n            document.DocumentURI(claimant='http://www.example.com',\n                                 uri='http://www.example.com',\n                                 type='foo',\n                                 content_type='bar',\n                                 document=document.Document())\n        ])\n\n        with pytest.raises(sa.exc.IntegrityError):\n            db_session.commit()\n\n\n@pytest.mark.usefixtures(\n    'log',\n)\nclass TestCreateOrUpdateDocumentURI(object):\n\n    def test_it_updates_the_existing_DocumentURI_if_there_is_one(self, db_session):\n        claimant = 'http://example.com/example_claimant.html'\n        uri = 'http://example.com/example_uri.html'\n        type_ = 'self-claim'\n        content_type = ''\n        document_ = document.Document()\n        created = yesterday()\n        updated = yesterday()\n        document_uri = document.DocumentURI(\n            claimant=claimant,\n            uri=uri,\n            type=type_,\n            content_type=content_type,\n            document=document_,\n            created=created,\n            updated=updated,\n        )\n        db_session.add(document_uri)\n\n        now_ = now()\n        document.create_or_update_document_uri(\n            session=db_session,\n            claimant=claimant,\n            uri=uri,\n            type=type_,\n            content_type=content_type,\n            document=document_,\n            created=now_,\n            updated=now_,\n        )\n\n        assert document_uri.created == created\n        assert document_uri.updated == now_\n        assert len(db_session.query(document.DocumentURI).all()) == 1, (\n            \"It shouldn't have added any new objects to the db\")\n\n    def test_it_creates_a_new_DocumentURI_if_there_is_no_existing_one(self, db_session):\n        claimant = 'http://example.com/example_claimant.html'\n        uri = 'http://example.com/example_uri.html'\n        type_ = 'self-claim'\n        content_type = ''\n        document_ = document.Document()\n        created = yesterday()\n        updated = yesterday()\n\n        # Add one non-matching DocumentURI to the database.\n        db_session.add(document.DocumentURI(\n            claimant=claimant,\n            uri=uri,\n            type=type_,\n            # Different content_type means this DocumentURI should not match\n            # the query.\n            content_type='different',\n            document=document_,\n            created=created,\n            updated=updated,\n        ))\n\n        document.create_or_update_document_uri(\n            session=db_session,\n            claimant=claimant,\n            uri=uri,\n            type=type_,\n            content_type=content_type,\n            document=document_,\n            created=now(),\n            updated=now(),\n        )\n\n        document_uri = db_session.query(document.DocumentURI).all()[-1]\n        assert document_uri.claimant == claimant\n        assert document_uri.uri == uri\n        assert document_uri.type == type_\n        assert document_uri.content_type == content_type\n        assert document_uri.document == document_\n        assert document_uri.created > created\n        assert document_uri.updated > updated\n\n    def test_it_denormalizes_http_uri_to_document_when_none(self, db_session):\n        uri = 'http://example.com/example_uri.html'\n\n        document_ = document.Document(web_uri=None)\n        db_session.add(document_)\n\n        document.create_or_update_document_uri(\n            session=db_session,\n            claimant='http://example.com/example_claimant.html',\n            uri=uri,\n            type='self-claim',\n            content_type='',\n            document=document_,\n            created=now(),\n            updated=now(),\n        )\n\n        document_ = db_session.query(document.Document).get(document_.id)\n        assert document_.web_uri == uri\n\n    def test_it_denormalizes_https_uri_to_document_when_empty(self, db_session):\n        uri = 'https://example.com/example_uri.html'\n\n        document_ = document.Document(web_uri='')\n        db_session.add(document_)\n\n        document.create_or_update_document_uri(\n            session=db_session,\n            claimant='http://example.com/example_claimant.html',\n            uri=uri,\n            type='self-claim',\n            content_type='',\n            document=document_,\n            created=now(),\n            updated=now(),\n        )\n\n        document_ = db_session.query(document.Document).get(document_.id)\n        assert document_.web_uri == uri\n\n    def test_it_skips_denormalizing_http_s_uri_to_document(self, db_session):\n        document_ = document.Document(web_uri='http://example.com/first_uri.html')\n        db_session.add(document_)\n\n        document.create_or_update_document_uri(\n            session=db_session,\n            claimant='http://example.com/example_claimant.html',\n            uri='http://example.com/second_uri.html',\n            type='self-claim',\n            content_type='',\n            document=document_,\n            created=now(),\n            updated=now(),\n        )\n\n        document_ = db_session.query(document.Document).get(document_.id)\n        assert document_.web_uri == 'http://example.com/first_uri.html'\n\n    def test_it_logs_a_warning_if_document_ids_differ(self, log):\n        \"\"\"\n        It should log a warning on Document objects mismatch.\n\n        If there's an existing DocumentURI and its .document property is\n        different to the given document it shoulg log a warning.\n\n        \"\"\"\n        session = mock_db_session()\n\n        # existing_document_uri.document won't be equal to the given document.\n        existing_document_uri = mock.Mock(document=mock_document())\n        session.query.return_value.filter.return_value.first.return_value = (\n            existing_document_uri)\n\n        document.create_or_update_document_uri(\n            session=session,\n            claimant='http://example.com/example_claimant.html',\n            uri='http://example.com/example_uri.html',\n            type='self-claim',\n            content_type=None,\n            document=mock_document(),\n            created=now(),\n            updated=now())\n\n        assert log.warn.call_count == 1\n\n    def test_raises_retryable_error_when_flush_fails(self, db_session, monkeypatch):\n        document_ = document.Document()\n\n        def err():\n            raise sa.exc.IntegrityError(None, None, None)\n        monkeypatch.setattr(db_session, 'flush', err)\n\n        with pytest.raises(transaction.interfaces.TransientError):\n            with db_session.no_autoflush:  # prevent premature IntegrityError\n                document.create_or_update_document_uri(\n                    session=db_session,\n                    claimant='http://example.com',\n                    uri='http://example.org',\n                    type='rel-canonical',\n                    content_type='text/html',\n                    document=document_,\n                    created=now(),\n                    updated=now(),\n                )\n\n\nclass TestCreateOrUpdateDocumentMeta(object):\n\n    def test_it_creates_a_new_DocumentMeta_if_there_is_no_existing_one(self, db_session):\n        claimant = 'http://example.com/claimant'\n        type_ = 'title'\n        value = 'the title'\n        document_ = document.Document()\n        created = yesterday()\n        updated = now()\n\n        # Add one non-matching DocumentMeta to the database.\n        # This should be ignored.\n        db_session.add(document.DocumentMeta(\n            claimant=claimant,\n            # Different type means this should not match the query.\n            type='different',\n            value=value,\n            document=document_,\n            created=created,\n            updated=updated,\n        ))\n\n        document.create_or_update_document_meta(\n            session=db_session,\n            claimant=claimant,\n            type=type_,\n            value=value,\n            document=document_,\n            created=created,\n            updated=updated,\n        )\n\n        document_meta = db_session.query(document.DocumentMeta).all()[-1]\n        assert document_meta.claimant == claimant\n        assert document_meta.type == type_\n        assert document_meta.value == value\n        assert document_meta.document == document_\n        assert document_meta.created == created\n        assert document_meta.updated == updated\n\n    def test_it_updates_an_existing_DocumentMeta_if_there_is_one(self, db_session):\n        claimant = 'http://example.com/claimant'\n        type_ = 'title'\n        value = 'the title'\n        document_ = document.Document()\n        created = yesterday()\n        updated = now()\n        document_meta = document.DocumentMeta(\n            claimant=claimant,\n            type=type_,\n            value=value,\n            document=document_,\n            created=created,\n            updated=updated,\n        )\n        db_session.add(document_meta)\n\n        new_updated = now()\n        document.create_or_update_document_meta(\n            session=db_session,\n            claimant=claimant,\n            type=type_,\n            value='new value',\n            document=document.Document(),  # This should be ignored.\n            created=now(),  # This should be ignored.\n            updated=new_updated,\n        )\n\n        assert document_meta.value == 'new value'\n        assert document_meta.updated == new_updated\n        assert document_meta.created == created, \"It shouldn't update created\"\n        assert document_meta.document == document_, (\n            \"It shouldn't update document\")\n        assert len(db_session.query(document.DocumentMeta).all()) == 1, (\n            \"It shouldn't have added any new objects to the db\")\n\n    def test_it_denormalizes_title_to_document_when_none(self, db_session):\n        claimant = 'http://example.com/claimant'\n        type_ = 'title'\n        value = ['the title']\n        document_ = document.Document(title=None)\n        created = yesterday()\n        updated = now()\n        db_session.add(document_)\n\n        document.create_or_update_document_meta(\n            session=db_session,\n            claimant=claimant,\n            type=type_,\n            value=value,\n            document=document_,\n            created=created,\n            updated=updated,\n        )\n\n        document_ = db_session.query(document.Document).get(document_.id)\n        assert document_.title == value[0]\n\n    def test_it_denormalizes_title_to_document_when_empty(self, db_session):\n        claimant = 'http://example.com/claimant'\n        type_ = 'title'\n        value = ['the title']\n        document_ = document.Document(title='')\n        created = yesterday()\n        updated = now()\n        db_session.add(document_)\n\n        document.create_or_update_document_meta(\n            session=db_session,\n            claimant=claimant,\n            type=type_,\n            value=value,\n            document=document_,\n            created=created,\n            updated=updated,\n        )\n\n        document_ = db_session.query(document.Document).get(document_.id)\n        assert document_.title == value[0]\n\n    def test_it_skips_denormalizing_title_to_document_when_already_set(self, db_session):\n        claimant = 'http://example.com/claimant'\n        type_ = 'title'\n        value = ['the title']\n        document_ = document.Document(title='foobar')\n        created = yesterday()\n        updated = now()\n        db_session.add(document_)\n\n        document.create_or_update_document_meta(\n            session=db_session,\n            claimant=claimant,\n            type=type_,\n            value=value,\n            document=document_,\n            created=created,\n            updated=updated,\n        )\n\n        document_ = db_session.query(document.Document).get(document_.id)\n        assert document_.title == 'foobar'\n\n    def test_it_logs_a_warning(self, log):\n        \"\"\"\n        It should warn on document mismatches.\n\n        It should warn if there's an existing DocumentMeta with a different\n        Document.\n\n        \"\"\"\n        session = mock_db_session()\n        document_one = mock_document()\n        document_two = mock_document()\n        existing_document_meta = mock_document_meta(document=document_one)\n        session.query.return_value.filter.return_value.one_or_none\\\n            .return_value = existing_document_meta\n\n        document.create_or_update_document_meta(\n            session=session,\n            claimant='http://example.com/claimant',\n            type='title',\n            value='new value',\n            document=document_two,\n            created=yesterday(),\n            updated=now(),\n        )\n\n        assert log.warn.call_count == 1\n\n    def test_raises_retryable_error_when_flush_fails(self, db_session, monkeypatch):\n        document_ = document.Document()\n\n        def err():\n            raise sa.exc.IntegrityError(None, None, None)\n        monkeypatch.setattr(db_session, 'flush', err)\n\n        with pytest.raises(transaction.interfaces.TransientError):\n            with db_session.no_autoflush:  # prevent premature IntegrityError\n                document.create_or_update_document_meta(\n                    session=db_session,\n                    claimant='http://example.com',\n                    type='title',\n                    value='My Title',\n                    document=document_,\n                    created=now(),\n                    updated=now(),\n                )\n\n\n@pytest.mark.usefixtures('merge_data')\nclass TestMergeDocuments(object):\n\n    def test_merge_documents_returns_master(self, db_session, merge_data):\n        master, _, _ = merge_data\n\n        merged_master = document.merge_documents(db_session, merge_data)\n\n        assert merged_master == master\n\n    def test_merge_documents_deletes_duplicate_documents(self, db_session, merge_data):\n        _, duplicate_1, duplicate_2 = merge_data\n\n        document.merge_documents(db_session, merge_data)\n        db_session.flush()\n\n        count = db_session.query(document.Document) \\\n            .filter(document.Document.id.in_([duplicate_1.id, duplicate_2.id])) \\\n            .count()\n\n        assert count == 0\n\n    def test_merge_documents_rewires_document_uris(self, db_session, merge_data):\n        master, duplicate_1, duplicate_2 = merge_data\n\n        document.merge_documents(db_session, merge_data)\n        db_session.flush()\n\n        assert len(master.document_uris) == 3\n        assert len(duplicate_1.document_uris) == 0\n        assert len(duplicate_2.document_uris) == 0\n\n    def test_merge_documents_rewires_document_meta(self, db_session, merge_data):\n        master, duplicate_1, duplicate_2 = merge_data\n\n        document.merge_documents(db_session, merge_data)\n        db_session.flush()\n\n        assert len(master.meta) == 3\n        assert len(duplicate_1.meta) == 0\n        assert len(duplicate_2.meta) == 0\n\n    def test_merge_documents_rewires_annotations(self, db_session, merge_data):\n        master, duplicate_1, duplicate_2 = merge_data\n\n        document.merge_documents(db_session, merge_data)\n        db_session.flush()\n\n        assert 6 == \\\n            db_session.query(models.Annotation).filter_by(document_id=master.id).count()\n        assert 0 == \\\n            db_session.query(models.Annotation).filter_by(document_id=duplicate_1.id).count()\n        assert 0 == \\\n            db_session.query(models.Annotation).filter_by(document_id=duplicate_2.id).count()\n\n    def test_raises_retryable_error_when_flush_fails(self, db_session, merge_data, monkeypatch):\n        def err():\n            raise sa.exc.IntegrityError(None, None, None)\n        monkeypatch.setattr(db_session, 'flush', err)\n\n        with pytest.raises(transaction.interfaces.TransientError):\n            document.merge_documents(db_session, merge_data)\n\n    @pytest.fixture\n    def merge_data(self, db_session, request):\n        master = document.Document(document_uris=[document.DocumentURI(\n                claimant='https://en.wikipedia.org/wiki/Main_Page',\n                uri='https://en.wikipedia.org/wiki/Main_Page',\n                type='self-claim')],\n                meta=[document.DocumentMeta(\n                    claimant='https://en.wikipedia.org/wiki/Main_Page',\n                    type='title',\n                    value='Wikipedia, the free encyclopedia')])\n        duplicate_1 = document.Document(document_uris=[document.DocumentURI(\n                claimant='https://m.en.wikipedia.org/wiki/Main_Page',\n                uri='https://en.wikipedia.org/wiki/Main_Page',\n                type='rel-canonical')],\n                meta=[document.DocumentMeta(\n                    claimant='https://m.en.wikipedia.org/wiki/Main_Page',\n                    type='title',\n                    value='Wikipedia, the free encyclopedia')])\n        duplicate_2 = document.Document(document_uris=[document.DocumentURI(\n                claimant='https://en.wikipedia.org/wiki/Home',\n                uri='https://en.wikipedia.org/wiki/Main_Page',\n                type='rel-canonical')],\n                meta=[document.DocumentMeta(\n                    claimant='https://en.wikipedia.org/wiki/Home',\n                    type='title',\n                    value='Wikipedia, the free encyclopedia')])\n\n        db_session.add_all([master, duplicate_1, duplicate_2])\n        db_session.flush()\n\n        master_ann_1 = models.Annotation(userid='luke', document_id=master.id)\n        master_ann_2 = models.Annotation(userid='alice', document_id=master.id)\n        duplicate_1_ann_1 = models.Annotation(userid='lucy', document_id=duplicate_1.id)\n        duplicate_1_ann_2 = models.Annotation(userid='bob', document_id=duplicate_1.id)\n        duplicate_2_ann_1 = models.Annotation(userid='amy', document_id=duplicate_2.id)\n        duplicate_2_ann_2 = models.Annotation(userid='dan', document_id=duplicate_2.id)\n        db_session.add_all([master_ann_1, master_ann_2,\n                            duplicate_1_ann_1, duplicate_1_ann_2,\n                            duplicate_2_ann_1, duplicate_2_ann_2])\n        return (master, duplicate_1, duplicate_2)\n\n\nclass TestUpdateDocumentMetadata(object):\n\n    def test_it_uses_the_target_uri_to_get_the_document(self,\n                                                        annotation,\n                                                        Document,\n                                                        session):\n        document_uri_dicts = [\n            {\n                'uri': 'http://example.com/example_1',\n                'claimant': 'http://example.com/claimant',\n                'type': 'type',\n                'content_type': None,\n            },\n            {\n                'uri': 'http://example.com/example_2',\n                'claimant': 'http://example.com/claimant',\n                'type': 'type',\n                'content_type': None,\n            },\n            {\n                'uri': 'http://example.com/example_3',\n                'claimant': 'http://example.com/claimant',\n                'type': 'type',\n                'content_type': None,\n            },\n        ]\n\n        document.update_document_metadata(session,\n                                          annotation.target_uri,\n                                          [],\n                                          document_uri_dicts,\n                                          annotation.created,\n                                          annotation.updated)\n\n        Document.find_or_create_by_uris.assert_called_once_with(\n            session,\n            annotation.target_uri,\n            [\n                'http://example.com/example_1',\n                'http://example.com/example_2',\n                'http://example.com/example_3',\n            ],\n            created=annotation.created,\n            updated=annotation.updated,\n        )\n\n    def test_if_there_are_multiple_documents_it_merges_them_into_one(\n            self,\n            annotation,\n            Document,\n            merge_documents,\n            session):\n        \"\"\"If it finds more than one document it calls merge_documents().\"\"\"\n        Document.find_or_create_by_uris.return_value = mock.Mock(\n            count=mock.Mock(return_value=3))\n\n        document.update_document_metadata(session,\n                                          annotation.target_uri,\n                                          [],\n                                          [],\n                                          annotation.created,\n                                          annotation.updated)\n\n        merge_documents.assert_called_once_with(\n            session,\n            Document.find_or_create_by_uris.return_value,\n            updated=annotation.updated)\n\n    def test_it_calls_first(self, annotation, session, Document):\n        \"\"\"If it finds only one document it calls first().\"\"\"\n        Document.find_or_create_by_uris.return_value = mock.Mock(\n            count=mock.Mock(return_value=1))\n\n        document.update_document_metadata(session, annotation, [], [])\n\n        Document.find_or_create_by_uris.return_value\\\n            .first.assert_called_once_with()\n\n    def test_it_updates_document_updated(self,\n                                         annotation,\n                                         Document,\n                                         merge_documents,\n                                         session):\n        yesterday_ = \"yesterday\"\n        document_ = merge_documents.return_value = mock.Mock(\n            updated=yesterday_)\n        Document.find_or_create_by_uris.return_value.first.return_value = (\n            document_)\n\n        document.update_document_metadata(session,\n                                          annotation.target_uri,\n                                          [],\n                                          [],\n                                          annotation.created,\n                                          annotation.updated)\n\n        assert document_.updated == annotation.updated\n\n    def test_it_saves_all_the_document_uris(self,\n                                            session,\n                                            annotation,\n                                            Document,\n                                            create_or_update_document_uri):\n        \"\"\"It creates or updates a DocumentURI for each document URI dict.\"\"\"\n        Document.find_or_create_by_uris.return_value.count.return_value = 1\n\n        document_uri_dicts = [\n            {\n                'uri': 'http://example.com/example_1',\n                'claimant': 'http://example.com/claimant',\n                'type': 'type',\n                'content_type': None,\n            },\n            {\n                'uri': 'http://example.com/example_2',\n                'claimant': 'http://example.com/claimant',\n                'type': 'type',\n                'content_type': None,\n            },\n            {\n                'uri': 'http://example.com/example_3',\n                'claimant': 'http://example.com/claimant',\n                'type': 'type',\n                'content_type': None,\n            },\n        ]\n\n        document.update_document_metadata(session,\n                                          annotation.target_uri,\n                                          [],\n                                          document_uri_dicts,\n                                          annotation.created,\n                                          annotation.updated)\n\n        assert create_or_update_document_uri.call_count == 3\n        for doc_uri_dict in document_uri_dicts:\n            create_or_update_document_uri.assert_any_call(\n                session=session,\n                document=Document.find_or_create_by_uris.return_value.first.return_value,\n                created=annotation.created,\n                updated=annotation.updated,\n                **doc_uri_dict\n            )\n\n    def test_it_saves_all_the_document_metas(self,\n                                             annotation,\n                                             create_or_update_document_meta,\n                                             Document,\n                                             session):\n        \"\"\"It creates or updates a DocumentMeta for each document meta dict.\"\"\"\n        Document.find_or_create_by_uris.return_value.count\\\n            .return_value = 1\n\n        document_meta_dicts = [\n            {\n                'claimant': 'http://example.com/claimant',\n                'type': 'title',\n                'value': 'foo',\n            },\n            {\n                'type': 'article title',\n                'value': 'bar',\n                'claimant': 'http://example.com/claimant',\n            },\n            {\n                'type': 'site title',\n                'value': 'gar',\n                'claimant': 'http://example.com/claimant',\n            },\n        ]\n\n        document.update_document_metadata(session,\n                                          annotation.target_uri,\n                                          document_meta_dicts,\n                                          [],\n                                          annotation.created,\n                                          annotation.updated)\n\n        assert create_or_update_document_meta.call_count == 3\n        for document_meta_dict in document_meta_dicts:\n            create_or_update_document_meta.assert_any_call(\n                session=session,\n                document=Document.find_or_create_by_uris.return_value.first.return_value,\n                created=annotation.created,\n                updated=annotation.updated,\n                **document_meta_dict\n            )\n\n    def test_it_returns_a_document(self,\n                                   annotation,\n                                   create_or_update_document_meta,\n                                   Document,\n                                   session):\n        Document.find_or_create_by_uris.return_value.count.return_value = 1\n\n        result = document.update_document_metadata(session,\n                                                   annotation.target_uri,\n                                                   [],\n                                                   [],\n                                                   annotation.created,\n                                                   annotation.updated)\n\n        assert result == Document.find_or_create_by_uris.return_value.first.return_value\n\n    @pytest.fixture\n    def annotation(self):\n        return mock.Mock(spec=models.Annotation())\n\n    @pytest.fixture\n    def create_or_update_document_meta(self, patch):\n        return patch('memex.models.document.create_or_update_document_meta')\n\n    @pytest.fixture\n    def create_or_update_document_uri(self, patch):\n        return patch('memex.models.document.create_or_update_document_uri')\n\n    @pytest.fixture\n    def Document(self, patch):\n        return patch('memex.models.document.Document')\n\n    @pytest.fixture\n    def merge_documents(self, patch):\n        return patch('memex.models.document.merge_documents')\n\n    @pytest.fixture\n    def session(self, db_session):\n        return mock.Mock(spec=db_session)\n\n\ndef now():\n    return datetime.datetime.now()\n\n\ndef yesterday():\n    return now() - datetime.timedelta(days=1)\n\n\ndef mock_db_session():\n    \"\"\"Return a mock db session object.\"\"\"\n    class DB(object):\n        def add(self, obj):\n            pass\n        def query(self, cls):\n            pass\n        def flush(self):\n            pass\n    return mock.Mock(spec=DB())\n\n\ndef mock_document():\n    \"\"\"Return a mock Document object.\"\"\"\n    return mock.Mock(spec=document.Document())\n\n\ndef mock_document_meta(document=None):\n\n    # We define a class to use as the mock spec here because we can't use the\n    # real DocumentMeta class because that class may be patched in the tests\n    # that are calling this function (so we'd end up using a mock object as a\n    # spec instead, and get completely the wrong spec).\n    class DocumentMeta(object):\n        def __init__(self):\n            self.type = None\n            self.value = None\n            self.created = None\n            self.updated = None\n            self.document = document\n            self.id = None\n            self.document_id = None\n\n    return mock.Mock(spec=DocumentMeta())\n\n\n@pytest.fixture\ndef log(patch):\n    return patch('memex.models.document.log')\n"},{"size":5433,"relativepath":"tests/memex/models/annotation_test.py","filename":"annotation_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom pyramid import security\nimport pytest\n\nfrom memex.models.annotation import Annotation\n\n\nannotation_fixture = pytest.mark.usefixtures('annotation')\n\n\ndef test_parent_id_of_direct_reply():\n    ann = Annotation(references=['parent_id'])\n\n    assert ann.parent_id == 'parent_id'\n\n\ndef test_parent_id_of_reply_to_reply():\n    ann = Annotation(references=['reply1', 'reply2', 'parent_id'])\n\n    assert ann.parent_id == 'parent_id'\n\n\ndef test_parent_id_of_annotation():\n    ann = Annotation()\n\n    assert ann.parent_id is None\n\n\ndef test_thread_root_id_returns_id_if_no_references():\n    annotation = Annotation(id='GBhy1DoHEea6htPothzqZQ')\n\n    assert annotation.thread_root_id == 'GBhy1DoHEea6htPothzqZQ'\n\n\ndef test_thread_root_id_returns_id_if_references_empty():\n    annotation = Annotation(id='jANlljoHEea6hsv8FY7ipw',\n                            references=[])\n\n    assert annotation.thread_root_id == 'jANlljoHEea6hsv8FY7ipw'\n\n\ndef test_thread_root_id_returns_reference_if_only_one_reference():\n    annotation = Annotation(id='qvJnIjoHEea6hiv0nJK7gw',\n                            references=['yiSVIDoHEea6hjcSFuROLw'])\n\n    assert annotation.thread_root_id == 'yiSVIDoHEea6hjcSFuROLw'\n\n\ndef test_thread_root_id_returns_first_reference_if_many_references():\n    annotation = Annotation(id='uK9yVjoHEea6hsewWuiKtQ',\n                            references=['1Ife3DoHEea6hpv8vWujdQ',\n                                        'uVuItjoHEea6hiNgv1wvmg',\n                                        'Qe7fpc5ZRgWy0RSHEP9UNg'])\n\n    assert annotation.thread_root_id == '1Ife3DoHEea6hpv8vWujdQ'\n\n\ndef test_text_setter_renders_markdown(markdown):\n    markdown.render.return_value = '<p>foobar</p>'\n\n    annotation = Annotation()\n    annotation.text = 'foobar'\n\n    markdown.render.assert_called_once_with('foobar')\n\n    annotation.text_rendered == markdown.render.return_value\n\n\ndef test_acl_private():\n    ann = Annotation(shared=False, userid='saoirse')\n    actual = ann.__acl__()\n    expect = [(security.Allow, 'saoirse', 'read'),\n              (security.Allow, 'saoirse', 'admin'),\n              (security.Allow, 'saoirse', 'update'),\n              (security.Allow, 'saoirse', 'delete'),\n              security.DENY_ALL]\n    assert actual == expect\n\n\ndef test_acl_world_shared():\n    ann = Annotation(shared=True, userid='saoirse', groupid='__world__')\n    actual = ann.__acl__()\n    expect = [(security.Allow, security.Everyone, 'read'),\n              (security.Allow, 'saoirse', 'admin'),\n              (security.Allow, 'saoirse', 'update'),\n              (security.Allow, 'saoirse', 'delete'),\n              security.DENY_ALL]\n    assert actual == expect\n\n\ndef test_acl_group_shared():\n    ann = Annotation(shared=True, userid='saoirse', groupid='lulapalooza')\n    actual = ann.__acl__()\n    expect = [(security.Allow, 'group:lulapalooza', 'read'),\n              (security.Allow, 'saoirse', 'admin'),\n              (security.Allow, 'saoirse', 'update'),\n              (security.Allow, 'saoirse', 'delete'),\n              security.DENY_ALL]\n    assert actual == expect\n\n\ndef test_setting_extras_inline_is_persisted(db_session, factories):\n    \"\"\"\n    In-place changes to Annotation.extra should be persisted.\n\n    Setting an Annotation.extra value in-place:\n\n        my_annotation.extra['foo'] = 'bar'\n\n    should be persisted to the database.\n\n    \"\"\"\n    annotation = factories.Annotation(userid='fred')\n\n    annotation.extra['foo'] = 'bar'\n\n    # We need to commit the db session here so that the in-place change to\n    # annotation.extra above would be lost if annotation.extra was a normal\n    # dict. Without this commit() this test would never fail.\n    db_session.commit()\n\n    annotation = db_session.query(Annotation).get(annotation.id)\n\n    assert annotation.extra == {'foo': 'bar'}\n\n\ndef test_deleting_extras_inline_is_persisted(db_session, factories):\n    \"\"\"\n    In-place changes to Annotation.extra should be persisted.\n\n    Deleting an Annotation.extra value in-place should be persisted to the\n    database.\n\n    \"\"\"\n    annotation = factories.Annotation(userid='fred', extra={'foo': 'bar'})\n\n    del annotation.extra['foo']\n    db_session.commit()\n    annotation = db_session.query(Annotation).get(annotation.id)\n\n    assert 'foo' not in annotation.extra\n\n\ndef test_appending_tags_inline_is_persisted(db_session, factories):\n    \"\"\"\n    In-place changes to Annotation.tags should be persisted.\n\n    Changes made by Annotation.tags.append() should be persisted to the\n    database.\n\n    \"\"\"\n    annotation = factories.Annotation(userid='fred', tags=['foo'])\n\n    annotation.tags.append('bar')\n    db_session.commit()\n    annotation = db_session.query(Annotation).get(annotation.id)\n\n    assert 'bar' in annotation.tags\n\n\ndef test_deleting_tags_inline_is_persisted(db_session, factories):\n    \"\"\"In-place deletions of annotation tags should be persisted.\"\"\"\n    annotation = factories.Annotation(userid='fred', tags=['foo'])\n\n    del annotation.tags[0]\n    db_session.commit()\n    annotation = db_session.query(Annotation).get(annotation.id)\n\n    assert 'foo' not in annotation.tags\n\n\n@pytest.fixture\ndef annotation(db_session):\n    ann = Annotation(userid=\"testuser\", target_uri=\"http://example.com\")\n\n    db_session.add(ann)\n    db_session.flush()\n    return ann\n\n\n@pytest.fixture\ndef markdown(patch):\n    return patch('memex.models.annotation.markdown')\n"},{"size":18868,"relativepath":"tests/memex/views_test.py","filename":"views_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\nimport pytest\n\nfrom pyramid import testing\n\nfrom memex import presenters\nfrom memex import views\nfrom memex.schemas import ValidationError\nfrom memex.search.core import SearchResult\n\n\nclass TestError(object):\n\n    def test_it_sets_status_code_from_error(self, pyramid_request):\n        exc = views.APIError(\"it exploded\", status_code=429)\n\n        views.error_api(exc, pyramid_request)\n\n        assert pyramid_request.response.status_code == 429\n\n    def test_it_returns_status_object(self, pyramid_request):\n        exc = views.APIError(\"it exploded\", status_code=429)\n\n        result = views.error_api(exc, pyramid_request)\n\n        assert result == {'status': 'failure', 'reason': 'it exploded'}\n\n    def test_it_sets_bad_request_status_code(self, pyramid_request):\n        exc = mock.Mock(message=\"it exploded\")\n\n        views.error_validation(exc, pyramid_request)\n\n        assert pyramid_request.response.status_code == 400\n\n\nclass TestIndex(object):\n\n    def test_it_returns_the_right_links(self, pyramid_config, pyramid_request):\n        pyramid_config.add_route('api.search', '/dummy/search')\n        pyramid_config.add_route('api.annotations', '/dummy/annotations')\n        pyramid_config.add_route('api.annotation', '/dummy/annotations/:id')\n\n        result = views.index(testing.DummyResource(), pyramid_request)\n\n        host = 'http://example.com'  # Pyramid's default host URL'\n        links = result['links']\n        assert links['annotation']['create']['method'] == 'POST'\n        assert links['annotation']['create']['url'] == (\n            host + '/dummy/annotations')\n        assert links['annotation']['delete']['method'] == 'DELETE'\n        assert links['annotation']['delete']['url'] == (\n            host + '/dummy/annotations/:id')\n        assert links['annotation']['read']['method'] == 'GET'\n        assert links['annotation']['read']['url'] == (\n            host + '/dummy/annotations/:id')\n        assert links['annotation']['update']['method'] == 'PUT'\n        assert links['annotation']['update']['url'] == (\n            host + '/dummy/annotations/:id')\n        assert links['search']['method'] == 'GET'\n        assert links['search']['url'] == host + '/dummy/search'\n\n\n@pytest.mark.usefixtures('links_service', 'search_lib')\nclass TestSearch(object):\n\n    def test_it_searches(self, pyramid_request, search_lib):\n        views.search(pyramid_request)\n\n        search = search_lib.Search.return_value\n        search_lib.Search.assert_called_with(pyramid_request, separate_replies=False)\n        search.run.assert_called_once_with(pyramid_request.params)\n\n    def test_it_loads_annotations_from_database(self, pyramid_request, search_run, storage):\n        search_run.return_value = SearchResult(2, ['row-1', 'row-2'], [], {})\n\n        views.search(pyramid_request)\n\n        storage.fetch_ordered_annotations.assert_called_once_with(\n            pyramid_request.db, ['row-1', 'row-2'], query_processor=mock.ANY)\n\n    def test_it_renders_search_results(self, links_service, pyramid_request, search_run, factories):\n        ann1 = factories.Annotation(userid='luke')\n        ann2 = factories.Annotation(userid='sarah')\n\n        search_run.return_value = SearchResult(2, [ann1.id, ann2.id], [], {})\n\n        expected = {\n            'total': 2,\n            'rows': [\n                presenters.AnnotationJSONPresenter(ann1, links_service).asdict(),\n                presenters.AnnotationJSONPresenter(ann2, links_service).asdict(),\n            ]\n        }\n\n        assert views.search(pyramid_request) == expected\n\n    def test_it_loads_replies_from_database(self, pyramid_request, search_run, storage):\n        pyramid_request.params = {'_separate_replies': '1'}\n        search_run.return_value = SearchResult(1, ['row-1'], ['reply-1', 'reply-2'], {})\n\n        views.search(pyramid_request)\n\n        assert mock.call(pyramid_request.db, ['reply-1', 'reply-2'],\n                         query_processor=mock.ANY) in storage.fetch_ordered_annotations.call_args_list\n\n    def test_it_renders_replies(self, links_service, pyramid_request, search_run, factories):\n        ann = factories.Annotation(userid='luke')\n        reply1 = factories.Annotation(userid='sarah', references=[ann.id])\n        reply2 = factories.Annotation(userid='sarah', references=[ann.id])\n\n        search_run.return_value = SearchResult(1, [ann.id], [reply1.id, reply2.id], {})\n\n        pyramid_request.params = {'_separate_replies': '1'}\n\n        expected = {\n            'total': 1,\n            'rows': [presenters.AnnotationJSONPresenter(ann, links_service).asdict()],\n            'replies': [\n                presenters.AnnotationJSONPresenter(reply1, links_service).asdict(),\n                presenters.AnnotationJSONPresenter(reply2, links_service).asdict(),\n            ]\n        }\n\n        assert views.search(pyramid_request) == expected\n\n    @pytest.fixture\n    def search_lib(self, patch):\n        return patch('memex.views.search_lib')\n\n    @pytest.fixture\n    def search_run(self, search_lib):\n        return search_lib.Search.return_value.run\n\n    @pytest.fixture\n    def storage(self, patch):\n        return patch('memex.views.storage')\n\n\n@pytest.mark.usefixtures('AnnotationEvent',\n                         'AnnotationJSONPresenter',\n                         'links_service',\n                         'schemas',\n                         'storage')\nclass TestCreate(object):\n\n    def test_it_raises_if_json_parsing_fails(self, pyramid_request):\n        \"\"\"It raises PayloadError if parsing of the request body fails.\"\"\"\n        # Make accessing the request.json_body property raise ValueError.\n        type(pyramid_request).json_body = {}\n        with mock.patch.object(type(pyramid_request),\n                               'json_body',\n                               new_callable=mock.PropertyMock) as json_body:\n            json_body.side_effect = ValueError()\n            with pytest.raises(views.PayloadError):\n                views.create(pyramid_request)\n\n    def test_it_inits_CreateAnnotationSchema(self, pyramid_request, schemas):\n        views.create(pyramid_request)\n\n        schemas.CreateAnnotationSchema.assert_called_once_with(pyramid_request)\n\n    def test_it_validates_the_posted_data(self, pyramid_request, schemas):\n        \"\"\"It should call validate() with a request.json_body.\"\"\"\n        views.create(pyramid_request)\n\n        schemas.CreateAnnotationSchema.return_value.validate\\\n            .assert_called_once_with(pyramid_request.json_body)\n\n    def test_it_raises_if_validate_raises(self, pyramid_request, schemas):\n        schemas.CreateAnnotationSchema.return_value.validate.side_effect = (\n            ValidationError('asplode'))\n\n        with pytest.raises(ValidationError) as exc:\n            views.create(pyramid_request)\n\n        assert exc.value.message == 'asplode'\n\n    def test_it_creates_the_annotation_in_storage(self,\n                                                  pyramid_request,\n                                                  storage,\n                                                  schemas):\n        schema = schemas.CreateAnnotationSchema.return_value\n\n        views.create(pyramid_request)\n\n        storage.create_annotation.assert_called_once_with(\n            pyramid_request, schema.validate.return_value)\n\n    def test_it_raises_if_create_annotation_raises(self,\n                                                   pyramid_request,\n                                                   storage):\n        storage.create_annotation.side_effect = ValidationError('asplode')\n\n        with pytest.raises(ValidationError) as exc:\n            views.create(pyramid_request)\n\n        assert exc.value.message == 'asplode'\n\n    def test_it_inits_AnnotationJSONPresenter(self,\n                                              AnnotationJSONPresenter,\n                                              links_service,\n                                              pyramid_request,\n                                              storage):\n        views.create(pyramid_request)\n\n        AnnotationJSONPresenter.assert_called_once_with(\n            storage.create_annotation.return_value,\n            links_service)\n\n    def test_it_publishes_annotation_event(self,\n                                           AnnotationEvent,\n                                           pyramid_request,\n                                           storage):\n        \"\"\"It publishes an annotation \"create\" event for the annotation.\"\"\"\n        views.create(pyramid_request)\n\n        annotation = storage.create_annotation.return_value\n\n        AnnotationEvent.assert_called_once_with(\n            pyramid_request, annotation.id, 'create', annotation_dict=None)\n        pyramid_request.notify_after_commit.assert_called_once_with(\n            AnnotationEvent.return_value)\n\n    def test_it_returns_presented_annotation(self,\n                                             AnnotationJSONPresenter,\n                                             pyramid_request):\n        result = views.create(pyramid_request)\n\n        AnnotationJSONPresenter.return_value.asdict.assert_called_once_with()\n        assert result == (\n            AnnotationJSONPresenter.return_value.asdict.return_value)\n\n    @pytest.fixture\n    def pyramid_request(self, pyramid_request):\n        pyramid_request.json_body = {}\n        pyramid_request.notify_after_commit = mock.Mock()\n        return pyramid_request\n\n\n@pytest.mark.usefixtures('AnnotationJSONPresenter', 'links_service')\nclass TestRead(object):\n\n    def test_it_returns_presented_annotation(self,\n                                             AnnotationJSONPresenter,\n                                             links_service,\n                                             pyramid_request):\n        annotation = mock.Mock()\n        presenter = mock.Mock()\n        AnnotationJSONPresenter.return_value = presenter\n\n        result = views.read(annotation, pyramid_request)\n\n        AnnotationJSONPresenter.assert_called_once_with(annotation,\n                                                        links_service)\n        assert result == presenter.asdict()\n\n\n@pytest.mark.usefixtures('AnnotationJSONLDPresenter', 'links_service')\nclass TestReadJSONLD(object):\n\n    def test_it_sets_correct_content_type(self, AnnotationJSONLDPresenter, pyramid_request):\n        AnnotationJSONLDPresenter.CONTEXT_URL = 'http://foo.com/context.jsonld'\n\n        annotation = mock.Mock()\n\n        views.read_jsonld(annotation, pyramid_request)\n\n        assert pyramid_request.response.content_type == 'application/ld+json'\n        assert pyramid_request.response.content_type_params == {\n            'profile': 'http://foo.com/context.jsonld'\n        }\n\n    def test_it_returns_presented_annotation(self,\n                                             AnnotationJSONLDPresenter,\n                                             links_service,\n                                             pyramid_request):\n        annotation = mock.Mock()\n        presenter = mock.Mock()\n        AnnotationJSONLDPresenter.return_value = presenter\n        AnnotationJSONLDPresenter.CONTEXT_URL = 'http://foo.com/context.jsonld'\n\n        result = views.read_jsonld(annotation, pyramid_request)\n\n        AnnotationJSONLDPresenter.assert_called_once_with(annotation,\n                                                          links_service)\n        assert result == presenter.asdict()\n\n    @pytest.fixture\n    def AnnotationJSONLDPresenter(self, patch):\n        return patch('memex.views.AnnotationJSONLDPresenter')\n\n\n@pytest.mark.usefixtures('AnnotationEvent',\n                         'AnnotationJSONPresenter',\n                         'links_service',\n                         'schemas',\n                         'storage')\nclass TestUpdate(object):\n\n    def test_it_inits_the_schema(self, pyramid_request, schemas):\n        annotation = mock.Mock()\n\n        views.update(annotation, pyramid_request)\n\n        schemas.UpdateAnnotationSchema.assert_called_once_with(\n            pyramid_request,\n            annotation.target_uri,\n            annotation.groupid)\n\n    def test_it_raises_if_json_parsing_fails(self, pyramid_request):\n        \"\"\"It raises PayloadError if parsing of the request body fails.\"\"\"\n        # Make accessing the request.json_body property raise ValueError.\n        type(pyramid_request).json_body = {}\n        with mock.patch.object(type(pyramid_request),\n                               'json_body',\n                               new_callable=mock.PropertyMock) as json_body:\n            json_body.side_effect = ValueError()\n            with pytest.raises(views.PayloadError):\n                views.update(mock.Mock(), pyramid_request)\n\n    def test_it_validates_the_posted_data(self, pyramid_request, schemas):\n        annotation = mock.Mock()\n        schema = schemas.UpdateAnnotationSchema.return_value\n\n        views.update(annotation, pyramid_request)\n\n        schema.validate.assert_called_once_with(pyramid_request.json_body)\n\n    def test_it_raises_if_validate_raises(self, pyramid_request, schemas):\n        schemas.UpdateAnnotationSchema.return_value.validate\\\n            .side_effect = ValidationError('asplode')\n\n        with pytest.raises(ValidationError):\n            views.update(mock.Mock(), pyramid_request)\n\n    def test_it_updates_the_annotation_in_storage(self,\n                                                  pyramid_request,\n                                                  storage,\n                                                  schemas):\n        annotation = mock.Mock()\n        schema = schemas.UpdateAnnotationSchema.return_value\n        schema.validate.return_value = mock.sentinel.validated_data\n\n        views.update(annotation, pyramid_request)\n\n        storage.update_annotation.assert_called_once_with(\n            pyramid_request.db,\n            annotation.id,\n            mock.sentinel.validated_data\n        )\n\n    def test_it_raises_if_storage_raises(self, pyramid_request, storage):\n        storage.update_annotation.side_effect = ValidationError('asplode')\n\n        with pytest.raises(ValidationError):\n            views.update(mock.Mock(), pyramid_request)\n\n    def test_it_inits_an_AnnotationEvent(self,\n                                         AnnotationEvent,\n                                         storage,\n                                         pyramid_request):\n        annotation = mock.Mock()\n\n        views.update(annotation, pyramid_request)\n\n        AnnotationEvent.assert_called_once_with(\n            pyramid_request, storage.update_annotation.return_value.id, 'update',\n            annotation_dict=None)\n\n    def test_it_fires_the_AnnotationEvent(self, AnnotationEvent, pyramid_request):\n        views.update(mock.Mock(), pyramid_request)\n\n        pyramid_request.notify_after_commit.assert_called_once_with(\n            AnnotationEvent.return_value)\n\n    def test_it_inits_a_presenter(self,\n                                  AnnotationJSONPresenter,\n                                  links_service,\n                                  pyramid_request,\n                                  storage):\n        views.update(mock.Mock(), pyramid_request)\n\n        AnnotationJSONPresenter.assert_any_call(\n            storage.update_annotation.return_value,\n            links_service)\n\n    def test_it_dictizes_the_presenter(self,\n                                       AnnotationJSONPresenter,\n                                       pyramid_request):\n        views.update(mock.Mock(), pyramid_request)\n\n        AnnotationJSONPresenter.return_value.asdict.assert_called_with()\n\n    def test_it_returns_a_presented_dict(self,\n                                         AnnotationJSONPresenter,\n                                         pyramid_request):\n        returned = views.update(mock.Mock(), pyramid_request)\n\n        assert returned == (\n            AnnotationJSONPresenter.return_value.asdict.return_value)\n\n    @pytest.fixture\n    def pyramid_request(self, pyramid_request):\n        pyramid_request.json_body = {}\n        pyramid_request.notify_after_commit = mock.Mock()\n        return pyramid_request\n\n\n@pytest.mark.usefixtures('AnnotationEvent',\n                         'AnnotationJSONPresenter',\n                         'links_service',\n                         'storage')\nclass TestDelete(object):\n\n    def test_it_deletes_then_annotation_from_storage(self, pyramid_request, storage):\n        annotation = mock.Mock()\n\n        views.delete(annotation, pyramid_request)\n\n        storage.delete_annotation.assert_called_once_with(pyramid_request.db,\n                                                          annotation.id)\n\n    def test_it_serializes_the_annotation(self,\n                                          AnnotationJSONPresenter,\n                                          links_service,\n                                          pyramid_request):\n        annotation = mock.Mock()\n\n        views.delete(annotation, pyramid_request)\n\n        AnnotationJSONPresenter.assert_called_once_with(annotation, links_service)\n\n    def test_it_inits_and_fires_an_AnnotationEvent(self,\n                                                   AnnotationEvent,\n                                                   AnnotationJSONPresenter,\n                                                   pyramid_request):\n        annotation = mock.Mock()\n        event = AnnotationEvent.return_value\n        annotation_dict = AnnotationJSONPresenter.return_value.asdict.return_value\n\n        views.delete(annotation, pyramid_request)\n\n        AnnotationEvent.assert_called_once_with(pyramid_request,\n                                                annotation.id,\n                                                'delete',\n                                                annotation_dict=annotation_dict)\n        pyramid_request.notify_after_commit.assert_called_once_with(event)\n\n    def test_it_returns_object(self, pyramid_request):\n        annotation = mock.Mock()\n\n        result = views.delete(annotation, pyramid_request)\n\n        assert result == {'id': annotation.id, 'deleted': True}\n\n\n@pytest.fixture\ndef AnnotationEvent(patch):\n    return patch('memex.views.AnnotationEvent')\n\n\n@pytest.fixture\ndef AnnotationJSONPresenter(patch):\n    return patch('memex.views.AnnotationJSONPresenter')\n\n\n@pytest.fixture\ndef links_service(pyramid_config):\n    service = mock.Mock(spec_set=['get', 'get_all'])\n    pyramid_config.register_service(service, name='links')\n    return service\n\n\n@pytest.fixture\ndef pyramid_request(pyramid_request):\n    pyramid_request.notify_after_commit = mock.Mock(spec_set=[])\n    return pyramid_request\n\n\n@pytest.fixture\ndef search_lib(patch):\n    return patch('memex.views.search_lib')\n\n\n@pytest.fixture\ndef schemas(patch):\n    return patch('memex.views.schemas')\n\n\n@pytest.fixture\ndef storage(patch):\n    return patch('memex.views.storage')\n"},{"size":6612,"relativepath":"tests/memex/factories.py","filename":"factories.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"Factory classes for easily generating test objects.\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport random\n\nimport factory\nimport faker\nfrom sqlalchemy import orm\n\nfrom memex import models\n\nFAKER = faker.Factory.create()\nSESSION = None\n\n\nclass ModelFactory(factory.alchemy.SQLAlchemyModelFactory):\n    class Meta:  # pylint: disable=no-init, old-style-class\n        abstract = True\n\n    @classmethod\n    def _create(cls, model_class, *args, **kwargs):\n        # We override SQLAlchemyModelFactory's default _create classmethod so\n        # that rather than fetching the session from cls._meta (which is\n        # created at parse time... ugh) we fetch it from the SESSION global,\n        # which is dynamically filled out by the `factories` fixture when\n        # used.\n        if SESSION is None:\n            raise RuntimeError('no session: did you use the factories fixture?')\n        obj = model_class(*args, **kwargs)\n        SESSION.add(obj)\n        if cls._meta.force_flush:\n            SESSION.flush()\n        return obj\n\n\nclass Document(ModelFactory):\n\n    class Meta:  # pylint: disable=no-init, old-style-class\n        model = models.Document\n\n\nclass DocumentMeta(ModelFactory):\n\n    class Meta:  # pylint: disable=no-init, old-style-class\n        model = models.DocumentMeta\n\n    # Trying to add two DocumentMetas with the same claimant and type to the\n    # db will crash. We use a sequence instead of something like FAKER.url()\n    # for claimant here so that never happens (unless you pass in your own\n    # claimant).\n    claimant = factory.Sequence(\n        lambda n: 'http://example.com/document_' + str(n) + '/')\n\n    type = factory.Iterator([\n        'title', 'twitter.url.main_url', 'twitter.title', 'favicon'])\n    document = factory.SubFactory(Document)\n\n    @factory.lazy_attribute\n    def value(self):\n        if self.type == 'twitter.url.main_url':\n            return [FAKER.url()]\n        elif self.type == 'favicon':\n            return [FAKER.image_url()]\n        else:\n            return [FAKER.bs()]\n\n\nclass DocumentURI(ModelFactory):\n\n    class Meta:  # pylint: disable=no-init, old-style-class\n        model = models.DocumentURI\n\n    # Trying to add two DocumentURIs with the same claimant, uri, type and\n    # content_type to the db will crash. We use a sequence instead of something\n    # like FAKER.url() for claimant here so that never happens (unless you pass\n    # in your own claimant).\n    claimant = factory.Sequence(\n        lambda n: 'http://example.com/document_' + str(n) + '/')\n\n    uri = factory.LazyAttribute(lambda obj: obj.claimant)\n    type = factory.Iterator(['rel-alternate', 'rel-canonical', 'highwire-pdf',\n                             'dc-doi'])\n    content_type = factory.Iterator(['text/html', 'application/pdf',\n                                     'text/plain'])\n    document = factory.SubFactory(Document)\n\n\nclass Annotation(ModelFactory):\n\n    class Meta:  # pylint: disable=no-init, old-style-class\n        model = models.Annotation\n        force_flush = True  # Always flush the db to generate annotation.id.\n\n    tags = factory.LazyFunction(\n        lambda: FAKER.words(nb=random.randint(0, 5)))\n    target_uri = factory.Faker('uri')\n    text = factory.Faker('paragraph')\n    userid = factory.Faker('user_name')\n    document = factory.SubFactory(Document)\n\n    @factory.lazy_attribute\n    def target_selectors(self):  # pylint: disable=no-self-use\n        return [\n            {\n                'endContainer': '/div[1]/article[1]/section[1]/div[1]/div[2]/div[1]',\n                'endOffset': 76,\n                'startContainer': '/div[1]/article[1]/section[1]/div[1]/div[2]/div[1]',\n                'startOffset': 0,\n                'type': 'RangeSelector'\n            },\n            {\n                'end': 362,\n                'start': 286,\n                'type': 'TextPositionSelector'\n            },\n            {\n                'exact': 'If you wish to install Hypothesis on your own site then head over to GitHub.',\n                'prefix': ' browser extension.\\n            ',\n                'suffix': '\\n          \\n        \\n      \\n    ',\n                'type': 'TextQuoteSelector'\n            },\n        ]\n\n    @factory.post_generation\n    def make_metadata(self, create, extracted, **kwargs):\n        \"\"\"Create associated document metadata for the annotation.\"\"\"\n        # The metadata objects are going to be added to the db, so if we're not\n        # using the create strategy then simply don't make any.\n        if not create:\n            return\n\n        def document_uri_dict():\n            \"\"\"\n            Return a randomly generated DocumentURI dict for this annotation.\n\n            This doesn't add anything to the database session yet.\n            \"\"\"\n            document_uri = DocumentURI.build(document=self.document,\n                                             claimant=self.target_uri,\n                                             uri=self.target_uri)\n            return dict(\n                claimant=document_uri.claimant,\n                uri=document_uri.uri,\n                type=document_uri.type,\n                content_type=document_uri.content_type,\n            )\n\n        document_uri_dicts = [document_uri_dict()\n                              for _ in range(random.randint(1, 3))]\n\n        def document_meta_dict(**kwargs):\n            \"\"\"\n            Return a randomly generated DocumentMeta dict for this annotation.\n\n            This doesn't add anything to the database session yet.\n            \"\"\"\n            kwargs.setdefault('document', self.document)\n            kwargs.setdefault('claimant', self.target_uri)\n            document_meta = DocumentMeta.build(**kwargs)\n            return dict(\n                claimant=document_meta.claimant,\n                type=document_meta.type,\n                value=document_meta.value,\n            )\n\n        document_meta_dicts = [document_meta_dict()\n                               for _ in range(random.randint(1, 3))]\n\n        # Make sure that there's always at least one DocumentMeta with\n        # type='title', so that we never get annotation.document.title is None:\n        if 'title' not in [m['type'] for m in document_meta_dicts]:\n            document_meta_dicts.append(document_meta_dict(type='title'))\n\n        self.document = models.update_document_metadata(\n            orm.object_session(self),\n            self.target_uri,\n            document_meta_dicts=document_meta_dicts,\n            document_uri_dicts=document_uri_dicts,\n            created=self.created,\n            updated=self.updated,\n        )\n"},{"size":3247,"relativepath":"tests/memex/eventqueue_test.py","filename":"eventqueue_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\nimport pytest\n\nfrom memex import eventqueue\n\n\nclass TestEventQueue(object):\n    def test_init_adds_response_callback(self, pyramid_request):\n        request = mock.Mock()\n        queue = eventqueue.EventQueue(request)\n\n        request.add_response_callback.assert_called_once_with(queue.response_callback)\n\n    def test_call_appends_event_to_queue(self):\n        queue = eventqueue.EventQueue(mock.Mock())\n\n        assert len(queue.queue) == 0\n        event = mock.Mock()\n        queue(event)\n        assert list(queue.queue) == [event]\n\n    def test_publish_all_notifies_events_in_fifo_order(self, notify, pyramid_request):\n        queue = eventqueue.EventQueue(pyramid_request)\n        firstevent = mock.Mock(request=pyramid_request)\n        queue(firstevent)\n        secondevent = mock.Mock(request=pyramid_request)\n        queue(secondevent)\n\n        queue.publish_all()\n\n        assert notify.call_args_list == [\n            mock.call(firstevent),\n            mock.call(secondevent)\n        ]\n\n    def test_publish_all_sandboxes_each_event(self, notify, pyramid_request):\n        queue = eventqueue.EventQueue(pyramid_request)\n        firstevent = mock.Mock(request=pyramid_request)\n        queue(firstevent)\n        secondevent = mock.Mock(request=pyramid_request)\n        queue(secondevent)\n\n        queue.publish_all()\n\n        assert notify.call_args_list == [\n            mock.call(firstevent),\n            mock.call(secondevent)\n        ]\n\n    def test_publish_all_sends_exception_to_sentry(self, notify, pyramid_request):\n        pyramid_request.sentry = mock.Mock()\n        notify.side_effect = ValueError('exploded!')\n        queue = eventqueue.EventQueue(pyramid_request)\n        event = mock.Mock(request=pyramid_request)\n        queue(event)\n\n        queue.publish_all()\n        assert pyramid_request.sentry.captureException.called\n\n    def test_publish_all_logs_exception_when_sentry_is_not_available(self, log, notify, pyramid_request):\n        notify.side_effect = ValueError('exploded!')\n        queue = eventqueue.EventQueue(pyramid_request)\n        event = mock.Mock(request=pyramid_request)\n        queue(event)\n\n        queue.publish_all()\n\n        assert log.exception.called\n\n    def test_response_callback_skips_publishing_events_on_exception(self, publish_all, pyramid_request):\n        pyramid_request.exception = ValueError('exploded!')\n        queue = eventqueue.EventQueue(pyramid_request)\n        queue.response_callback(pyramid_request, None)\n        assert not publish_all.called\n\n    def test_response_callback_publishes_events(self, publish_all, pyramid_request):\n        pyramid_request.tm = mock.MagicMock()\n        queue = eventqueue.EventQueue(pyramid_request)\n        queue(mock.Mock())\n        queue.response_callback(pyramid_request, None)\n        assert publish_all.called\n\n    @pytest.fixture\n    def log(self, patch):\n        return patch('memex.eventqueue.log')\n\n    @pytest.fixture\n    def publish_all(self, patch):\n        return patch('memex.eventqueue.EventQueue.publish_all')\n\n    @pytest.fixture\n    def pyramid_request(self, pyramid_request):\n        pyramid_request.debug = False\n        pyramid_request.exception = None\n        return pyramid_request\n"},{"size":17638,"relativepath":"tests/memex/presenters_test.py","filename":"presenters_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nimport datetime\nimport mock\nimport pytest\n\nfrom memex import models\nfrom memex.presenters import AnnotationBasePresenter\nfrom memex.presenters import AnnotationJSONPresenter\nfrom memex.presenters import AnnotationSearchIndexPresenter\nfrom memex.presenters import AnnotationJSONLDPresenter\nfrom memex.presenters import DocumentJSONPresenter\nfrom memex.presenters import DocumentSearchIndexPresenter\nfrom memex.presenters import utc_iso8601, deep_merge_dict\n\n\nclass TestAnnotationBasePresenter(object):\n\n    def test_constructor_args(self, fake_links_service):\n        annotation = mock.Mock()\n\n        presenter = AnnotationBasePresenter(annotation, fake_links_service)\n\n        assert presenter.annotation == annotation\n\n    def test_created_returns_none_if_missing(self, fake_links_service):\n        annotation = mock.Mock(created=None)\n\n        created = AnnotationBasePresenter(annotation, fake_links_service).created\n\n        assert created is None\n\n    def test_created_uses_iso_format(self, fake_links_service):\n        when = datetime.datetime(2012, 3, 14, 23, 34, 47, 12)\n        annotation = mock.Mock(created=when)\n\n        created = AnnotationBasePresenter(annotation, fake_links_service).created\n\n        assert created == '2012-03-14T23:34:47.000012+00:00'\n\n    def test_updated_returns_none_if_missing(self, fake_links_service):\n        annotation = mock.Mock(updated=None)\n\n        updated = AnnotationBasePresenter(annotation, fake_links_service).updated\n\n        assert updated is None\n\n    def test_updated_uses_iso_format(self, fake_links_service):\n        when = datetime.datetime(1983, 8, 31, 7, 18, 20, 98763)\n        annotation = mock.Mock(updated=when)\n\n        updated = AnnotationBasePresenter(annotation, fake_links_service).updated\n\n        assert updated == '1983-08-31T07:18:20.098763+00:00'\n\n    def test_links(self, fake_links_service):\n        annotation = mock.Mock()\n\n        links = AnnotationBasePresenter(annotation, fake_links_service).links\n\n        assert links == {'giraffe': 'http://giraffe.com',\n                         'toad': 'http://toad.net'}\n\n    def test_links_passes_annotation(self, fake_links_service):\n        annotation = mock.Mock()\n\n        links = AnnotationBasePresenter(annotation, fake_links_service).links\n\n        assert fake_links_service.last_annotation == annotation\n\n    def test_text(self, fake_links_service):\n        ann = mock.Mock(text='It is magical!')\n        presenter = AnnotationBasePresenter(ann, fake_links_service)\n\n        assert 'It is magical!' == presenter.text\n\n    def test_text_missing(self, fake_links_service):\n        ann = mock.Mock(text=None)\n        presenter = AnnotationBasePresenter(ann, fake_links_service)\n\n        assert '' == presenter.text\n\n    def test_tags(self, fake_links_service):\n        ann = mock.Mock(tags=['interesting', 'magic'])\n        presenter = AnnotationBasePresenter(ann, fake_links_service)\n\n        assert ['interesting', 'magic'] == presenter.tags\n\n    def test_tags_missing(self, fake_links_service):\n        ann = mock.Mock(tags=None)\n        presenter = AnnotationBasePresenter(ann, fake_links_service)\n\n        assert [] == presenter.tags\n\n    def test_target(self, fake_links_service):\n        ann = mock.Mock(target_uri='http://example.com',\n                        target_selectors={'PositionSelector': {'start': 0, 'end': 12}})\n\n        expected = [{'source': 'http://example.com', 'selector': {'PositionSelector': {'start': 0, 'end': 12}}}]\n        actual = AnnotationBasePresenter(ann, fake_links_service).target\n        assert expected == actual\n\n    def test_target_missing_selectors(self, fake_links_service):\n        ann = mock.Mock(target_uri='http://example.com',\n                        target_selectors=None)\n\n        expected = [{'source': 'http://example.com'}]\n        actual = AnnotationBasePresenter(ann, fake_links_service).target\n        assert expected == actual\n\n\nclass TestAnnotationJSONPresenter(object):\n    def test_asdict(self, document_asdict, fake_links_service):\n        ann = mock.Mock(id='the-id',\n                        created=datetime.datetime(2016, 2, 24, 18, 3, 25, 768),\n                        updated=datetime.datetime(2016, 2, 29, 10, 24, 5, 564),\n                        userid='acct:luke',\n                        target_uri='http://example.com',\n                        text='It is magical!',\n                        tags=['magic'],\n                        groupid='__world__',\n                        shared=True,\n                        target_selectors=[{'TestSelector': 'foobar'}],\n                        references=['referenced-id-1', 'referenced-id-2'],\n                        extra={'extra-1': 'foo', 'extra-2': 'bar'})\n\n        document_asdict.return_value = {'foo': 'bar'}\n\n        expected = {'id': 'the-id',\n                    'created': '2016-02-24T18:03:25.000768+00:00',\n                    'updated': '2016-02-29T10:24:05.000564+00:00',\n                    'user': 'acct:luke',\n                    'uri': 'http://example.com',\n                    'text': 'It is magical!',\n                    'tags': ['magic'],\n                    'group': '__world__',\n                    'permissions': {'read': ['group:__world__'],\n                                    'admin': ['acct:luke'],\n                                    'update': ['acct:luke'],\n                                    'delete': ['acct:luke']},\n                    'target': [{'source': 'http://example.com',\n                                'selector': [{'TestSelector': 'foobar'}]}],\n                    'document': {'foo': 'bar'},\n                    'links': {'giraffe': 'http://giraffe.com',\n                              'toad': 'http://toad.net'},\n                    'references': ['referenced-id-1', 'referenced-id-2'],\n                    'extra-1': 'foo',\n                    'extra-2': 'bar'}\n\n        result = AnnotationJSONPresenter(ann, fake_links_service).asdict()\n\n        assert result == expected\n\n    def test_asdict_extra_cannot_override_other_data(self, document_asdict, fake_links_service):\n        ann = mock.Mock(id='the-real-id', extra={'id': 'the-extra-id'})\n        document_asdict.return_value = {}\n\n        presented = AnnotationJSONPresenter(ann, fake_links_service).asdict()\n        assert presented['id'] == 'the-real-id'\n\n    def test_asdict_extra_uses_copy_of_extra(self, document_asdict, fake_links_service):\n        extra = {'foo': 'bar'}\n        ann = mock.Mock(id='my-id', extra=extra)\n        document_asdict.return_value = {}\n\n        presented = AnnotationJSONPresenter(ann, fake_links_service).asdict()\n\n        # Presenting the annotation shouldn't change the \"extra\" dict.\n        assert extra == {'foo': 'bar'}\n\n    @pytest.mark.parametrize('annotation,action,expected', [\n        (mock.Mock(userid='acct:luke', shared=False), 'read', ['acct:luke']),\n        (mock.Mock(groupid='__world__', shared=True), 'read', ['group:__world__']),\n        (mock.Mock(groupid='lulapalooza', shared=True), 'read', ['group:lulapalooza']),\n        (mock.Mock(userid='acct:luke'), 'admin', ['acct:luke']),\n        (mock.Mock(userid='acct:luke'), 'update', ['acct:luke']),\n        (mock.Mock(userid='acct:luke'), 'delete', ['acct:luke']),\n        ])\n    def test_permissions(self, annotation, action, expected, fake_links_service):\n        presenter = AnnotationJSONPresenter(annotation, fake_links_service)\n        assert expected == presenter.permissions[action]\n\n    @pytest.fixture\n    def document_asdict(self, patch):\n        return patch('memex.presenters.DocumentJSONPresenter.asdict')\n\n\n@pytest.mark.usefixtures('DocumentSearchIndexPresenter')\nclass TestAnnotationSearchIndexPresenter(object):\n\n    def test_asdict(self, DocumentSearchIndexPresenter):\n        annotation = mock.Mock(\n            id='xyz123',\n            created=datetime.datetime(2016, 2, 24, 18, 3, 25, 768),\n            updated=datetime.datetime(2016, 2, 29, 10, 24, 5, 564),\n            userid='acct:luke@hypothes.is',\n            target_uri='http://example.com',\n            target_uri_normalized='http://example.com/normalized',\n            text='It is magical!',\n            tags=['magic'],\n            groupid='__world__',\n            shared=True,\n            target_selectors=[{'TestSelector': 'foobar'}],\n            references=['referenced-id-1', 'referenced-id-2'],\n            extra={'extra-1': 'foo', 'extra-2': 'bar'})\n        DocumentSearchIndexPresenter.return_value.asdict.return_value = {'foo': 'bar'}\n\n        annotation_dict = AnnotationSearchIndexPresenter(annotation).asdict()\n\n        assert annotation_dict == {\n            'id': 'xyz123',\n            'created': '2016-02-24T18:03:25.000768+00:00',\n            'updated': '2016-02-29T10:24:05.000564+00:00',\n            'user': 'acct:luke@hypothes.is',\n            'user_raw': 'acct:luke@hypothes.is',\n            'uri': 'http://example.com',\n            'text': 'It is magical!',\n            'tags': ['magic'],\n            'group': '__world__',\n            'permissions': {'read': ['group:__world__'],\n                            'admin': ['acct:luke@hypothes.is'],\n                            'update': ['acct:luke@hypothes.is'],\n                            'delete': ['acct:luke@hypothes.is']},\n            'target': [{'scope': ['http://example.com/normalized'],\n                        'source': 'http://example.com',\n                        'selector': [{'TestSelector': 'foobar'}]}],\n            'document': {'foo': 'bar'},\n            'references': ['referenced-id-1', 'referenced-id-2'],\n            'extra-1': 'foo',\n            'extra-2': 'bar',\n        }\n\n    def test_asdict_extra_cannot_override_other_data(self):\n        annotation = mock.Mock(id='the-real-id', extra={'id': 'the-extra-id'})\n\n        annotation_dict = AnnotationSearchIndexPresenter(annotation).asdict()\n\n        assert annotation_dict['id'] == 'the-real-id'\n\n    def test_asdict_does_not_modify_extra(self):\n        extra = {'foo': 'bar'}\n        annotation = mock.Mock(id='my-id', extra=extra)\n\n        AnnotationSearchIndexPresenter(annotation).asdict()\n\n        assert extra == {'foo': 'bar'}, (\n                \"Presenting the annotation shouldn't change the 'extra' dict\")\n\n    @pytest.mark.parametrize('annotation,action,expected', [\n        (mock.Mock(userid='acct:luke', shared=False), 'read', ['acct:luke']),\n        (mock.Mock(groupid='__world__', shared=True), 'read',\n            ['group:__world__']),\n        (mock.Mock(groupid='lulapalooza', shared=True), 'read',\n            ['group:lulapalooza']),\n        (mock.Mock(userid='acct:luke'), 'admin', ['acct:luke']),\n        (mock.Mock(userid='acct:luke'), 'update', ['acct:luke']),\n        (mock.Mock(userid='acct:luke'), 'delete', ['acct:luke']),\n        ])\n    def test_permissions(self, annotation, action, expected):\n        presenter = AnnotationSearchIndexPresenter(annotation)\n\n        assert expected == presenter.permissions[action]\n\n    def test_it_copies_target_uri_normalized_to_target_scope(self):\n        annotation = mock.Mock(\n            target_uri_normalized='http://example.com/normalized',\n            extra={})\n\n        annotation_dict = AnnotationSearchIndexPresenter(annotation).asdict()\n\n        assert annotation_dict['target'][0]['scope'] == [\n            'http://example.com/normalized']\n\n    @pytest.fixture\n    def DocumentSearchIndexPresenter(self, patch):\n        class_ = patch('memex.presenters.DocumentSearchIndexPresenter')\n        class_.return_value.asdict.return_value = {}\n        return class_\n\n\nclass TestAnnotationJSONLDPresenter(object):\n\n    def test_asdict(self, fake_links_service):\n        annotation = mock.Mock(\n            id='foobar',\n            created=datetime.datetime(2016, 2, 24, 18, 3, 25, 768),\n            updated=datetime.datetime(2016, 2, 29, 10, 24, 5, 564),\n            userid='acct:luke',\n            target_uri='http://example.com',\n            text='It is magical!',\n            tags=['magic'],\n            target_selectors=[{'TestSelector': 'foobar'}])\n        expected = {\n            '@context': 'http://www.w3.org/ns/anno.jsonld',\n            'type': 'Annotation',\n            'id': 'http://fake-link/jsonld_id',\n            'created': '2016-02-24T18:03:25.000768+00:00',\n            'modified': '2016-02-29T10:24:05.000564+00:00',\n            'creator': 'acct:luke',\n            'body': [{'type': 'TextualBody',\n                      'format': 'text/markdown',\n                      'text': 'It is magical!'},\n                     {'type': 'TextualBody',\n                      'purpose': 'tagging',\n                      'text': 'magic'}],\n            'target': [{'source': 'http://example.com',\n                        'selector': [{'TestSelector': 'foobar'}]}]\n        }\n\n        result = AnnotationJSONLDPresenter(annotation, fake_links_service).asdict()\n\n        assert result == expected\n\n    def test_id_returns_jsonld_id_link(self, fake_links_service):\n        annotation = mock.Mock(id='foobar')\n\n        presenter = AnnotationJSONLDPresenter(annotation, fake_links_service)\n\n        assert presenter.id == 'http://fake-link/jsonld_id'\n\n    def test_id_passes_annotation_to_link_service(self, fake_links_service):\n        annotation = mock.Mock(id='foobar')\n\n        presenter = AnnotationJSONLDPresenter(annotation, fake_links_service)\n        _ = presenter.id\n\n        assert fake_links_service.last_annotation == annotation\n\n    def test_bodies_returns_textual_body(self, fake_links_service):\n        annotation = mock.Mock(text='Flib flob flab', tags=None)\n\n        bodies = AnnotationJSONLDPresenter(annotation, fake_links_service).bodies\n\n        assert bodies == [{\n            'type': 'TextualBody',\n            'text': 'Flib flob flab',\n            'format': 'text/markdown',\n        }]\n\n    def test_bodies_appends_tag_bodies(self, fake_links_service):\n        annotation = mock.Mock(text='Flib flob flab', tags=['giraffe', 'lion'])\n\n        bodies = AnnotationJSONLDPresenter(annotation, fake_links_service).bodies\n\n        assert {\n            'type': 'TextualBody',\n            'text': 'giraffe',\n            'purpose': 'tagging',\n        } in bodies\n        assert {\n            'type': 'TextualBody',\n            'text': 'lion',\n            'purpose': 'tagging',\n        } in bodies\n\n\nclass TestDocumentJSONPresenter(object):\n    def test_asdict(self, db_session):\n        document = models.Document(\n            title='Foo',\n            document_uris=[models.DocumentURI(uri='http://foo.com', claimant='http://foo.com'),\n                           models.DocumentURI(uri='http://foo.org', claimant='http://foo.com', type='rel-canonical')])\n        db_session.add(document)\n        db_session.flush()\n\n        presenter = DocumentJSONPresenter(document)\n        expected = {'title': ['Foo']}\n        assert expected == presenter.asdict()\n\n    def test_asdict_when_none_document(self):\n        assert {} == DocumentJSONPresenter(None).asdict()\n\n    def test_asdict_does_not_render_other_meta_than_title(self, db_session):\n        document = models.Document(\n            title='Foo',\n            meta=[models.DocumentMeta(type='title', value=['Foo'], claimant='http://foo.com'),\n                  models.DocumentMeta(type='twitter.url', value=['http://foo.com'], claimant='http://foo.com'),\n                  models.DocumentMeta(type='facebook.title', value=['FB Title'], claimant='http://foo.com')])\n        db_session.add(document)\n        db_session.flush()\n\n        presenter = DocumentJSONPresenter(document)\n        assert {'title': ['Foo']} == presenter.asdict()\n\n\nclass TestDocumentSearchIndexPresenter(object):\n    @pytest.mark.parametrize('document,expected', [\n        (models.Document(title='Foo'), {'title': ['Foo']}),\n        (models.Document(title=''), {}),\n        (models.Document(title=None), {}),\n        (models.Document(web_uri='http://foo.org'), {'web_uri': 'http://foo.org'}),\n        (models.Document(web_uri=''), {}),\n        (models.Document(web_uri=None), {}),\n        (models.Document(title='Foo', web_uri='http://foo.org'), {'title': ['Foo'], 'web_uri': 'http://foo.org'}),\n        (None, {})\n    ])\n    def test_asdict(self, document, expected):\n        assert expected == DocumentSearchIndexPresenter(document).asdict()\n\n\ndef test_utc_iso8601():\n    t = datetime.datetime(2016, 2, 24, 18, 03, 25, 7685)\n    assert utc_iso8601(t) == '2016-02-24T18:03:25.007685+00:00'\n\n\ndef test_utc_iso8601_ignores_timezone():\n    t = datetime.datetime(2016, 2, 24, 18, 03, 25, 7685, Berlin())\n    assert utc_iso8601(t) == '2016-02-24T18:03:25.007685+00:00'\n\n\ndef test_deep_merge_dict():\n    a = {'foo': 1, 'bar': 2, 'baz': {'foo': 3, 'bar': 4}}\n    b = {'bar': 8, 'baz': {'bar': 6, 'qux': 7}, 'qux': 15}\n    deep_merge_dict(a, b)\n\n    assert a == {\n        'foo': 1,\n        'bar': 8,\n        'baz': {\n            'foo': 3,\n            'bar': 6,\n            'qux': 7},\n        'qux': 15}\n\n\nclass Berlin(datetime.tzinfo):\n    \"\"\"Berlin timezone, without DST support\"\"\"\n\n    def utcoffset(self, dt):\n        return datetime.timedelta(hours=1)\n\n    def tzname(self, dt):\n        return \"Berlin\"\n\n    def dst(self, dt):\n        return datetime.timedelta()\n\n\nclass FakeLinksService(object):\n    def __init__(self):\n        self.last_annotation = None\n\n    def get(self, annotation, name):\n        self.last_annotation = annotation\n        return 'http://fake-link/' + name\n\n    def get_all(self, annotation):\n        self.last_annotation = annotation\n        return {'giraffe': 'http://giraffe.com', 'toad': 'http://toad.net'}\n\n\n@pytest.fixture\ndef fake_links_service():\n    return FakeLinksService()\n"},{"size":3360,"relativepath":"tests/memex/markdown_test.py","filename":"markdown_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\n\nfrom memex import markdown\n\n\nclass TestRender(object):\n    def test_it_renders_markdown(self):\n        actual = markdown.render('_emphasis_ **bold**')\n        assert '<p><em>emphasis</em> <strong>bold</strong></p>\\n' == actual\n\n    def test_it_ignores_math_block(self):\n        actual = markdown.render('$$1 + 1 = 2$$')\n        assert '<p>$$1 + 1 = 2$$</p>\\n' == actual\n\n    def test_it_ignores_inline_match(self):\n        actual = markdown.render('Foobar \\(1 + 1 = 2\\)')\n        assert '<p>Foobar \\(1 + 1 = 2\\)</p>\\n' == actual\n\n    def test_it_sanitizes_the_output(self, markdown_render, sanitize):\n        markdown.render('foobar')\n        sanitize.assert_called_once_with(markdown_render.return_value)\n\n    @pytest.fixture\n    def markdown_render(self, patch):\n        return patch('memex.markdown.markdown')\n\n    @pytest.fixture\n    def sanitize(self, patch):\n        return patch('memex.markdown.sanitize')\n\n\nclass TestSanitize(object):\n    @pytest.mark.parametrize(\"text,expected\", [\n        ('<a href=\"https://example.org\">example</a>', '<a href=\"https://example.org\" rel=\"nofollow noopener\" target=\"_blank\">example</a>'),\n        ('<a title=\"foobar\">example</a>', None),\n        ('<a href=\"https://example.org\" rel=\"nofollow noopener\" target=\"_blank\" title=\"foobar\">example</a>', None),\n        ('<blockquote>Foobar</blockquote>', None),\n        ('<code>foobar</code>', None),\n        ('<em>foobar</em>', None),\n        ('<hr>', None),\n        ('<h1>foobar</h1>', None),\n        ('<h2>foobar</h2>', None),\n        ('<h3>foobar</h3>', None),\n        ('<h4>foobar</h4>', None),\n        ('<h5>foobar</h5>', None),\n        ('<h6>foobar</h6>', None),\n        ('<img src=\"http://example.com/img.jpg\">', None),\n        ('<img src=\"/img.jpg\">', None),\n        ('<img alt=\"foobar\" src=\"/img.jpg\">', None),\n        ('<img src=\"/img.jpg\" title=\"foobar\">', None),\n        ('<img alt=\"hello\" src=\"/img.jpg\" title=\"foobar\">', None),\n        ('<ol><li>foobar</li></ol>', None),\n        ('<p>foobar</p>', None),\n        ('<pre>foobar</pre>', None),\n        ('<strong>foobar</strong>', None),\n        ('<ul><li>foobar</li></ul>', None),\n    ])\n    def test_it_allows_markdown_html(self, text, expected):\n        if expected is None:\n            expected = text\n\n        assert markdown.sanitize(text) == expected\n\n    @pytest.mark.parametrize(\"text,expected\", [\n        ('<script>evil()</script>', '&lt;script&gt;evil()&lt;/script&gt;'),\n        ('<a href=\"#\" onclick=\"evil()\">foobar</a>', '<a href=\"#\" rel=\"nofollow noopener\" target=\"_blank\">foobar</a>'),\n        ('<a href=\"#\" onclick=evil()>foobar</a>', '<a href=\"#\" rel=\"nofollow noopener\" target=\"_blank\">foobar</a>'),\n        ('<a href=\"javascript:alert(\\'evil\\')\">foobar</a>', '<a>foobar</a>'),\n        ('<img src=\"/evil.jpg\" onclick=\"evil()\">', '<img src=\"/evil.jpg\">'),\n        ('<img src=\"javascript:alert(\\'evil\\')\">', '<img>'),\n    ])\n    def test_it_escapes_evil_html(self, text, expected):\n        assert markdown.sanitize(text) == expected\n\n    def test_it_adds_target_blank_and_rel_nofollow_to_links(self):\n        actual = markdown.sanitize('<a href=\"https://example.org\">Hello</a>')\n        expected = '<a href=\"https://example.org\" rel=\"nofollow noopener\" target=\"_blank\">Hello</a>'\n\n        assert actual == expected\n"},{"size":30928,"relativepath":"tests/memex/parse_document_claims_test.py","filename":"parse_document_claims_test.py","extension":".py","content":"import mock\nimport pytest\n\nfrom memex import parse_document_claims\n\n\nclass TestDocumentURIsFromLinks(object):\n\n    def test_it_ignores_href_links_that_match_the_claimant_uri(self):\n        \"\"\"\n        Links containing only the claimant URI should be ignored.\n\n        If document.link contains a link dict with just an \"href\" and no other\n        keys, and the value of the \"href\" key is the same as the claimant URI,\n        then this link dict should be ignored and not produce an additional\n        document URI dict in the output (since the document URI that it would\n        generate would be the same as the \"self-claim\" claimant URI one that is\n        always generated anyway).\n\n        \"\"\"\n        claimant = 'http://localhost:5000/docs/help'\n        link_dicts = [{'href': claimant}]\n\n        document_uris = parse_document_claims.document_uris_from_links(\n            link_dicts,\n            claimant,\n        )\n\n        assert document_uris == []\n\n    def test_it_ignores_doi_links(self):\n        \"\"\"\n        Links containing only an href that starts with doi should be ignored.\n\n        If document.link contains a link dict with just an \"href\" and no other\n        keys, and the value of the \"href\" key begins with \"doi:\", then the link\n        dict should be ignored and not produce a document URI dict in the\n        output.\n\n        This is because document URI dicts for doi: URIs are generate\n        separately from other metadata in the document dict outside of the\n        \"link\" list.\n\n        \"\"\"\n        link_dicts = [{'href': 'doi:10.3389/fenvs.2014.00003'}]\n\n        document_uris = parse_document_claims.document_uris_from_links(\n            link_dicts,\n            claimant='http://localhost:5000/docs/help'\n        )\n\n        assert document_uris == []\n\n    def test_it_ignores_highwire_pdf_links(self):\n        pdf_url = 'http://example.com/example.pdf'\n        link_dicts = [{'href': pdf_url, 'type': 'application/pdf'}]\n\n        document_uris = parse_document_claims.document_uris_from_links(\n            link_dicts,\n            claimant='http://localhost:5000/docs/help',\n        )\n\n        assert document_uris == []\n\n    def test_it_returns_rel_alternate_document_uris_for_rel_alternate_links(\n            self):\n        alternate_url = 'http://example.com/alternate'\n        link_dicts = [{'href': alternate_url, 'rel': 'alternate'}]\n\n        document_uris = parse_document_claims.document_uris_from_links(\n            link_dicts,\n            claimant='http://localhost:5000/docs/help',\n        )\n\n        alternate_document_uri = one(\n            [d for d in document_uris if d['type'] == 'rel-alternate'])\n        assert alternate_document_uri == {\n            'type': 'rel-alternate',\n            'claimant': 'http://localhost:5000/docs/help',\n            'content_type': '',\n            'uri': alternate_url,\n        }\n\n    def test_it_uses_link_types_as_document_uri_content_types(self):\n        \"\"\"\n        Link types get converted to document URI content_types.\n\n        The value of the 'type' key in link dicts ends up as the value of the\n        'content_type' key in the returned document URI dicts.\n\n        \"\"\"\n        link_dicts = [{'href': 'http://example.com/example.html',\n                       'type': 'text/html'}]\n\n        document_uris = parse_document_claims.document_uris_from_links(\n            link_dicts,\n            claimant='http://example.com/example.html',\n        )\n\n        assert one(\n            [d for d in document_uris if d.get('content_type') == 'text/html'])\n\n    def test_it_returns_multiple_document_URI_dicts(self):\n        \"\"\"If there are multiple claims it should return multiple dicts.\"\"\"\n        link_dicts = [\n            {\n                'href': 'http://example.com/example.html',\n                'type': 'text/html'\n            },\n            {\n                'href': 'http://example.com/alternate.html',\n                'rel': 'alternate'\n            },\n            {\n                'href': 'http://example.com/example2.html',\n                'type': 'text/html'\n            },\n        ]\n\n        document_uris = parse_document_claims.document_uris_from_links(\n            link_dicts,\n            claimant='http://example.com/claimant.html',\n        )\n\n        assert len(document_uris) == 3\n\n\nclass TestDocumentMetasFromData(object):\n\n    @pytest.mark.parametrize(\"input_,output\", [\n        # String values get turned into length 1 lists.\n        (\n            {\n                'foo': 'string',\n            },\n            {\n                'type': 'foo',\n                'value': ['string']\n            }\n        ),\n\n        # List values get copied over unchanged.\n        (\n            {\n                'foo': ['one', 'two'],\n            },\n            {\n                'type': 'foo',\n                'value': ['one', 'two']\n            }\n        ),\n\n        # Sub-dicts get flattened using a '.' separator in the key,\n        # and length 1 list values in sub-dicts get copied over unchanged.\n        (\n            {\n                'facebook': {\n                    'description': ['document description'],\n                }\n            },\n            {\n                'type': 'facebook.description',\n                'value': ['document description']\n            }\n        ),\n\n        # Length >1 list values in sub-dicts get copied over unchanged.\n        (\n            {\n                'facebook': {\n                    'image': [\n                        'http://example.com/image1.png',\n                        'http://example.com/image2.png',\n                        'http://example.com/image3.jpeg',\n                    ],\n                }\n            },\n            {\n                'type': 'facebook.image',\n                'value': [\n                    'http://example.com/image1.png',\n                    'http://example.com/image2.png',\n                    'http://example.com/image3.jpeg'\n                ]\n            }\n        ),\n\n        # String values in sub-dicts get turned into length 1 lists.\n        (\n            {\n                'foo': {\n                    'bar': 'string'\n                }\n            },\n            {\n                'type': 'foo.bar',\n                'value': ['string']\n            }\n        ),\n\n        # Leading and trailing whitespace gets stripped from document titles.\n        (\n            {\n                'title': ['   My Document',\n                          'My Document   ',\n                          ' My Document ',\n                          '\\nMy Document\\n\\n',\n                          '\\rMy Document\\r\\n',\n                          '\\tMy Document \\t \\t '],\n\n            },\n            {\n                'type': 'title',\n                'value': ['My Document', 'My Document', 'My Document',\n                          'My Document', 'My Document', 'My Document']\n            }\n        ),\n\n        # Leading and trailing whitespace does not get-stripped from non-titles.\n        (\n            {\n                'foo': ['   My Document',\n                          'My Document   ',\n                          ' My Document ',\n                          '\\nMy Document\\n\\n',\n                          '\\rMy Document\\r\\n',\n                          '\\tMy Document \\t \\t '],\n\n            },\n            {\n                'type': 'foo',\n                'value': ['   My Document', 'My Document   ', ' My Document ',\n                          '\\nMy Document\\n\\n', '\\rMy Document\\r\\n',\n                          '\\tMy Document \\t \\t ']\n            }\n        ),\n    ])\n    def test_document_metas_from_data(self, input_, output):\n        claimant = 'http://example.com/claimant/'\n\n        document_metas = parse_document_claims.document_metas_from_data(\n            document_data=input_,\n            claimant=claimant)\n\n        assert document_metas == [{\n            'type': output['type'],\n            'value': output['value'],\n            'claimant': claimant,\n        }]\n\n    def test_document_metas_from_data_ignores_links_list(self):\n        \"\"\"It should ignore the \"link\" list in the document_data.\"\"\"\n        document_data = {\n            'link': [\n                {'href': 'http://example.com/link'},\n            ]\n        }\n\n        document_metas = parse_document_claims.document_metas_from_data(\n            document_data, 'http://example/claimant')\n\n        assert document_metas == []\n\n    def test_document_metas_from_data_with_multiple_metadata_claims(self):\n        \"\"\"\n        It should create one DocumentMeta for each metadata claim.\n\n        If document_data contains multiple metadata claims it should init one\n        DocumentMeta for each claim.\n\n        \"\"\"\n        claimant = 'http://example/claimant'\n        document_data = {\n            'title': 'the title',\n            'description': 'the description',\n            'site_title': 'the site title'\n        }\n\n        document_metas = parse_document_claims.document_metas_from_data(\n            document_data, claimant)\n\n        assert len(document_metas) == len(document_data.items())\n        for key, value in document_data.items():\n            assert {\n                'type': key,\n                'value': [value],\n                'claimant': claimant,\n                } in document_metas\n\n    def test_document_metas_from_data_ignores_null_titles(self):\n        \"\"\"It should ignore null document titles.\"\"\"\n        for title in (None, [None, None]):\n            document_data = {'title': title}\n\n            document_metas = parse_document_claims.document_metas_from_data(\n                document_data, 'http://example/claimant')\n\n            assert document_metas == []\n\n    def test_document_metas_from_data_allows_null_non_titles(self):\n        \"\"\"Null values are allowed if 'type' isn't 'title'.\"\"\"\n        for value in (None, [None, None]):\n            document_data = {'foo': value}\n\n            document_metas = parse_document_claims.document_metas_from_data(\n                document_data, 'http://example/claimant')\n\n            if not isinstance(value, list):\n                # We expect it to turn non-lists into length-1 lists.\n                value = [value]\n\n            assert document_metas == [{\n                'type': 'foo',\n                'value': value,\n                'claimant': 'http://example/claimant',\n            }]\n\n    def test_document_metas_from_data_ignores_empty_string_titles(self):\n        \"\"\"It should ignore empty document titles.\"\"\"\n        for title in ('', ['', '']):\n            document_data = {'title': title}\n\n            document_metas = parse_document_claims.document_metas_from_data(\n                document_data, 'http://example/claimant')\n\n            assert document_metas == []\n\n    def test_document_metas_from_data_allows_empty_string_non_titles(self):\n        \"\"\"Empty strings are allowed if 'type' isn't 'title'.\"\"\"\n        for value in ('', ['', '']):\n            document_data = {'foo': value}\n\n            document_metas = parse_document_claims.document_metas_from_data(\n                document_data, 'http://example/claimant')\n\n            if not isinstance(value, list):\n                # We expect it to turn non-lists into length-1 lists.\n                value = [value]\n\n            assert document_metas == [{\n                'type': 'foo',\n                'value': value,\n                'claimant': 'http://example/claimant',\n            }]\n\n    def test_document_metas_from_data_ignores_whitespace_only_titles(self):\n        \"\"\"It should ignore whitespace-only document titles.\"\"\"\n        for title in (' ', [' ', ' '], '\\n\\n  \\n'):\n            document_data = {'title': title}\n\n            document_metas = parse_document_claims.document_metas_from_data(\n                document_data, 'http://example/claimant')\n\n            assert document_metas == []\n\n    def test_document_metas_from_data_allows_whitespace_only_non_titles(self):\n        \"\"\"Whitespace-only strings are allowed if 'type' isn't 'title'.\"\"\"\n        for value in (' ', [' ', ' '], '\\n\\n  \\n'):\n            document_data = {'foo': value}\n\n            document_metas = parse_document_claims.document_metas_from_data(\n                document_data, 'http://example/claimant')\n\n            if not isinstance(value, list):\n                # We expect it to turn non-lists into length-1 lists.\n                value = [value]\n\n            assert document_metas == [{\n                'type': 'foo',\n                'value': value,\n                'claimant': 'http://example/claimant',\n            }]\n\n\nclass TestDocumentURIsFromHighwirePDF(object):\n\n    def test_highwire_pdf_values_produce_highwire_pdf_document_uris(self):\n        highwire_dict = {\n                'pdf_url': ['http://example.com/1.pdf',\n                            'http://example.com/2.pdf',\n                            'http://example.com/3.pdf'],\n        }\n\n        document_uris = parse_document_claims.document_uris_from_highwire_pdf(\n            highwire_dict,\n            claimant='http://example.com/example.html',\n        )\n\n        for pdf in highwire_dict['pdf_url']:\n            document_uri = one([d for d in document_uris\n                                if d.get('uri') == pdf])\n            assert document_uri == {\n                'claimant': 'http://example.com/example.html',\n                'uri': pdf,\n                'type': 'highwire-pdf',\n                'content_type': 'application/pdf',\n            }\n\n\nclass TestDocumentURIsFromHighwireDOI(object):\n\n    def test_highwire_doi_values_produce_highwire_doi_document_uris(self):\n        highwire_dict = {\n            'doi': ['doi:10.10.1038/nphys1170', 'doi:10.1002/0470841559.ch1',\n                    'doi:10.1594/PANGAEA.726855'],\n        }\n\n        document_uris = parse_document_claims.document_uris_from_highwire_doi(\n            highwire_dict,\n            claimant='http://example.com/example.html',\n        )\n\n        for doi in highwire_dict['doi']:\n            document_uri = one([d for d in document_uris\n                                if d.get('uri') == doi])\n            assert document_uri == {\n                'claimant': 'http://example.com/example.html',\n                'uri': doi,\n                'type': 'highwire-doi',\n                'content_type': '',\n            }\n\n    def test_doi_is_prepended_to_highwire_dois(self):\n        \"\"\"If a highwire DOI doesn't begin with 'doi:' it is prepended.\"\"\"\n        highwire_dict = {'doi': ['10.10.1038/nphys1170']}\n\n        document_uris = parse_document_claims.document_uris_from_highwire_doi(\n            highwire_dict,\n            claimant='http://example.com/example.html',\n        )\n\n        expected_uri = 'doi:' + highwire_dict['doi'][0]\n        one([d for d in document_uris if d.get('uri') == expected_uri])\n\n    def test_empty_string_dois_are_ignored(self):\n        for doi in ('', 'doi:'):\n            highwire_dict = {'doi': [doi]}\n\n            document_uris = parse_document_claims.document_uris_from_highwire_doi(\n                highwire_dict,\n                claimant='http://example.com/example.html',\n            )\n\n            assert document_uris == []\n\n    def test_whitespace_only_dois_are_ignored(self):\n        for doi in (' ', 'doi: '):\n            highwire_dict = {'doi': [doi]}\n\n            document_uris = parse_document_claims.document_uris_from_highwire_doi(\n                highwire_dict,\n                claimant='http://example.com/example.html',\n            )\n\n            assert document_uris == []\n\n    def test_whitespace_is_stripped_from_dois(self):\n        for doi in (' foo ', 'doi: foo ', ' doi:foo ', ' doi: foo '):\n            highwire_dict = {'doi': [doi]}\n\n            document_uris = parse_document_claims.document_uris_from_highwire_doi(\n                highwire_dict,\n                claimant='http://example.com/example.html',\n            )\n\n            assert [d['uri'] for d in document_uris] == ['doi:foo']\n\n\nclass TestDocumentURIsFromDC(object):\n\n    def test_dc_identifiers_produce_dc_doi_document_uris(self):\n        \"\"\"Each 'identifier' list item in the 'dc' dict becomes a doc URI.\"\"\"\n        dc_dict = {\n            'identifier': [\n                'doi:10.10.1038/nphys1170',\n                'doi:10.1002/0470841559.ch1',\n                'doi:10.1594/PANGAEA.726855'\n            ]\n        }\n\n        document_uris = parse_document_claims.document_uris_from_dc(\n            dc_dict,\n            claimant='http://example.com/example.html',\n        )\n\n        for doi in dc_dict['identifier']:\n            document_uri = one([d for d in document_uris\n                                if d.get('uri') == doi])\n            assert document_uri == {\n                'claimant': 'http://example.com/example.html',\n                'uri': doi,\n                'type': 'dc-doi',\n                'content_type': '',\n            }\n\n    def test_doi_is_prepended_to_dc_identifiers(self):\n        \"\"\"If a dc identifier doesn't begin with 'doi:' it is prepended.\"\"\"\n        dc_dict = {'identifier': ['10.10.1038/nphys1170']}\n\n        document_uris = parse_document_claims.document_uris_from_dc(\n            dc_dict,\n            claimant='http://example.com/example.html',\n        )\n\n        expected_uri = 'doi:' + dc_dict['identifier'][0]\n        one([d for d in document_uris if d.get('uri') == expected_uri])\n\n    def test_empty_string_dois_are_ignored(self):\n        for doi in ('', 'doi:'):\n            dc_dict = {'identifier': [doi]}\n\n            document_uris = parse_document_claims.document_uris_from_dc(\n                dc_dict,\n                claimant='http://example.com/example.html',\n            )\n\n            assert document_uris == []\n\n    def test_whitespace_only_dois_are_ignored(self):\n        for doi in (' ', 'doi: '):\n            dc_dict = {'identifier': [doi]}\n\n            document_uris = parse_document_claims.document_uris_from_dc(\n                dc_dict,\n                claimant='http://example.com/example.html',\n            )\n\n            assert document_uris == []\n\n    def test_whitespace_is_stripped_from_dois(self):\n        for doi in (' foo ', 'doi: foo ', ' doi:foo ', ' doi: foo '):\n            dc_dict = {'identifier': [doi]}\n\n            document_uris = parse_document_claims.document_uris_from_dc(\n                dc_dict,\n                claimant='http://example.com/example.html',\n            )\n\n            assert [d['uri'] for d in document_uris] == ['doi:foo']\n\n\nclass TestDocumentURISelfClaim(object):\n\n    def test_document_uri_self_claim(self):\n        claimant = 'http://localhost:5000/docs/help'\n\n        document_uri = parse_document_claims.document_uri_self_claim(\n            claimant)\n\n        assert document_uri == {\n            'claimant': claimant,\n            'uri': claimant,\n            'type': 'self-claim',\n            'content_type': '',\n        }\n\n\n@pytest.mark.usefixtures('document_uris_from_dc',\n                         'document_uris_from_highwire_doi',\n                         'document_uris_from_highwire_pdf',\n                         'document_uris_from_links',\n                         'document_uri_self_claim')\nclass TestDocumentURIsFromData(object):\n\n    def test_it_gets_document_uris_from_links(self, document_uris_from_links):\n        document_data = {\n            'link': [\n                # In production these would be link dicts not strings.\n                'link_dict_1',\n                'link_dict_2',\n                'link_dict_3',\n            ]\n\n        }\n        claimant = 'http://localhost:5000/docs/help'\n        document_uris_from_links.return_value = [\n            {'uri': 'uri_1'}, {'uri': 'uri_2'}, {'uri': 'uri_3'}]\n\n        document_uris = parse_document_claims.document_uris_from_data(\n            document_data=document_data,\n            claimant=claimant,\n        )\n\n        document_uris_from_links.assert_called_once_with(\n            document_data['link'], claimant)\n        for document_uri in document_uris_from_links.return_value:\n            assert document_uri in document_uris\n\n    def test_calling_document_uris_from_links_when_no_links(\n            self,\n            document_uris_from_links):\n        document_data = {}  # No 'link' key.\n        claimant = 'http://localhost:5000/docs/help'\n\n        parse_document_claims.document_uris_from_data(\n            document_data=document_data,\n            claimant=claimant,\n        )\n\n        document_uris_from_links.assert_called_once_with(\n            [], claimant)\n\n    def test_it_gets_documents_uris_from_highwire_pdf(\n            self,\n            document_uris_from_highwire_pdf):\n        document_data = {\n            'highwire': {\n                'pdf': [\n                    'pdf_1',\n                    'pdf_2',\n                    'pdf_3',\n                ]\n            }\n        }\n        claimant = 'http://localhost:5000/docs/help'\n        document_uris_from_highwire_pdf.return_value = [\n            {'uri': 'uri_1'}, {'uri': 'uri_2'}, {'uri': 'uri_3'}]\n\n        document_uris = parse_document_claims.document_uris_from_data(\n            document_data=document_data,\n            claimant=claimant,\n        )\n\n        document_uris_from_highwire_pdf.assert_called_once_with(\n            document_data['highwire'], claimant)\n        for document_uri in document_uris_from_highwire_pdf.return_value:\n            assert document_uri in document_uris\n\n    def test_calling_document_uris_from_highwire_pdf_when_no_highwire(\n            self,\n            document_uris_from_highwire_pdf):\n        document_data = {}  # No 'highwire' key.\n        claimant = 'http://localhost:5000/docs/help'\n\n        parse_document_claims.document_uris_from_data(\n            document_data=document_data,\n            claimant=claimant,\n        )\n\n        document_uris_from_highwire_pdf.assert_called_once_with(\n            {}, claimant)\n\n    def test_it_gets_documents_uris_from_highwire_doi(\n            self,\n            document_uris_from_highwire_doi):\n        document_data = {\n            'highwire': {\n                'doi': [\n                    'doi_1',\n                    'doi_2',\n                    'doi_3',\n                ]\n            }\n        }\n        claimant = 'http://localhost:5000/docs/help'\n        document_uris_from_highwire_doi.return_value = [\n            {'uri': 'uri_1'}, {'uri': 'uri_2'}, {'uri': 'uri_3'}]\n\n        document_uris = parse_document_claims.document_uris_from_data(\n            document_data=document_data,\n            claimant=claimant,\n        )\n\n        document_uris_from_highwire_doi.assert_called_once_with(\n            document_data['highwire'], claimant)\n        for document_uri in document_uris_from_highwire_doi.return_value:\n            assert document_uri in document_uris\n\n    def test_calling_document_uris_from_highwire_doi_when_no_highwire(\n            self,\n            document_uris_from_highwire_doi):\n        document_data = {}  # No 'highwire' key.\n        claimant = 'http://localhost:5000/docs/help'\n\n        parse_document_claims.document_uris_from_data(\n            document_data=document_data,\n            claimant=claimant,\n        )\n\n        document_uris_from_highwire_doi.assert_called_once_with(\n            {}, claimant)\n\n    def test_it_gets_documents_uris_from_dc(self,\n                                            document_uris_from_dc):\n        document_data = {\n            'dc': {\n                'identifier': [\n                    'doi_1',\n                    'doi_2',\n                    'doi_3',\n                ]\n            }\n        }\n        claimant = 'http://localhost:5000/docs/help'\n        document_uris_from_dc.return_value = [\n            {'uri': 'uri_1'}, {'uri': 'uri_2'}, {'uri': 'uri_3'}]\n\n        document_uris = parse_document_claims.document_uris_from_data(\n            document_data=document_data,\n            claimant=claimant,\n        )\n\n        document_uris_from_dc.assert_called_once_with(\n            document_data['dc'], claimant)\n        for document_uri in document_uris_from_dc.return_value:\n            assert document_uri in document_uris\n\n    def test_calling_document_uris_from_dc_when_no_dc(self,\n                                                      document_uris_from_dc):\n        document_data = {}  # No 'dc' key.\n        claimant = 'http://localhost:5000/docs/help'\n\n        parse_document_claims.document_uris_from_data(\n            document_data=document_data,\n            claimant=claimant,\n        )\n\n        document_uris_from_dc.assert_called_once_with(\n            {}, claimant)\n\n    def test_it_gets_self_claim_document_uris(self, document_uri_self_claim):\n        claimant = 'http://example.com/claimant'\n\n        document_uris = parse_document_claims.document_uris_from_data(\n            {}, claimant)\n\n        document_uri_self_claim.assert_called_once_with(claimant)\n        assert document_uri_self_claim.return_value in document_uris\n\n    def test_it_ignores_null_uris(self,\n                                  document_uris_from_links,\n                                  document_uris_from_highwire_pdf,\n                                  document_uris_from_highwire_doi,\n                                  document_uris_from_dc,\n                                  document_uri_self_claim):\n        document_uris_from_links.return_value = [{'uri': None}]\n        document_uris_from_highwire_pdf.return_value = [{'uri': None}]\n        document_uris_from_highwire_doi.return_value = [{'uri': None}]\n        document_uris_from_dc.return_value = [{'uri': None}]\n        document_uri_self_claim.return_value = {'uri': None}\n\n        document_uris = parse_document_claims.document_uris_from_data(\n            {}, 'http://example.com/claimant')\n\n        assert document_uris == []\n\n    def test_it_ignores_empty_string_uris(self,\n                                          document_uris_from_links,\n                                          document_uris_from_highwire_pdf,\n                                          document_uris_from_highwire_doi,\n                                          document_uris_from_dc,\n                                          document_uri_self_claim):\n        document_uris_from_links.return_value = [{'uri': ''}]\n        document_uris_from_highwire_pdf.return_value = [{'uri': ''}]\n        document_uris_from_highwire_doi.return_value = [{'uri': ''}]\n        document_uris_from_dc.return_value = [{'uri': ''}]\n        document_uri_self_claim.return_value = {'uri': ''}\n\n        document_uris = parse_document_claims.document_uris_from_data(\n            {}, 'http://example.com/claimant')\n\n        assert document_uris == []\n\n    def test_it_ignores_whitespace_only_self_claim_uris(\n            self, document_uri_self_claim):\n        for uri in (' ', '\\n ', '\\r\\n', ' \\t'):\n            document_uri_self_claim.return_value = {'uri': uri}\n\n            document_uris = parse_document_claims.document_uris_from_data(\n                {}, 'http://example.com/claimant')\n\n            assert document_uris == []\n\n    def test_it_ignores_whitespace_only_uris(self,\n                                             document_uris_from_links,\n                                             document_uris_from_highwire_pdf,\n                                             document_uris_from_highwire_doi,\n                                             document_uris_from_dc,\n                                             document_uri_self_claim):\n        uris = [' ', '\\n ', '\\r\\n', ' \\t']\n        document_uris_from_links.return_value = [{'uri': u} for u in uris]\n        document_uris_from_highwire_pdf.return_value = [{'uri': u} for u in uris]\n        document_uris_from_highwire_doi.return_value = [{'uri': u} for u in uris]\n        document_uris_from_dc.return_value = [{'uri': u} for u in uris]\n\n        document_uris = parse_document_claims.document_uris_from_data(\n            {}, 'http://example.com/claimant')\n\n        assert document_uris == [document_uri_self_claim.return_value]\n\n    def test_it_strips_whitespace_from_uris(self,\n                                            document_uris_from_links,\n                                            document_uris_from_highwire_pdf,\n                                            document_uris_from_highwire_doi,\n                                            document_uris_from_dc,\n                                            document_uri_self_claim,\n                                            matchers):\n        document_uris_from_links.return_value = [\n            {'uri': ' from_link_1'},\n            {'uri': 'from_link_2 '},\n            {'uri': ' from_link_3 '}\n        ]\n        document_uris_from_highwire_pdf.return_value = [\n            {'uri': ' highwire_1'},\n            {'uri': 'highwire_2 '},\n            {'uri': ' highwire_3 '}\n        ]\n        document_uris_from_highwire_doi.return_value = [\n            {'uri': ' doi_1'},\n            {'uri': 'doi_2 '},\n            {'uri': ' doi_3 '}\n        ]\n        document_uris_from_dc.return_value = [\n            {'uri': ' dc_1'},\n            {'uri': 'dc_2 '},\n            {'uri': ' dc_3 '}\n        ]\n\n        document_uris = parse_document_claims.document_uris_from_data(\n            {}, 'http://example.com/claimant')\n\n        assert document_uris == matchers.unordered_list([\n            {'uri': 'from_link_1'},\n            {'uri': 'from_link_2'},\n            {'uri': 'from_link_3'},\n            {'uri': 'highwire_1'},\n            {'uri': 'highwire_2'},\n            {'uri': 'highwire_3'},\n            {'uri': 'doi_1'},\n            {'uri': 'doi_2'},\n            {'uri': 'doi_3'},\n            {'uri': 'dc_1'},\n            {'uri': 'dc_2'},\n            {'uri': 'dc_3'},\n            document_uri_self_claim.return_value\n        ])\n\n    def test_it_strips_whitespace_from_self_claim_uris(\n            self, document_uris_from_links, document_uri_self_claim):\n        for uri in (' self_claim', 'self_claim ', ' self_claim '):\n            document_uris_from_links.return_value = []\n            document_uri_self_claim.return_value = {'uri': uri}\n\n            document_uris = parse_document_claims.document_uris_from_data(\n                {}, 'http://example.com/claimant')\n\n            assert document_uris == [{'uri': uri.strip()}]\n\n    @pytest.fixture\n    def document_uris_from_dc(self, patch):\n        return patch('memex.parse_document_claims.document_uris_from_dc', return_value=[])\n\n    @pytest.fixture\n    def document_uris_from_highwire_pdf(self, patch):\n        return patch('memex.parse_document_claims.document_uris_from_highwire_pdf', return_value=[])\n\n    @pytest.fixture\n    def document_uris_from_highwire_doi(self, patch):\n        return patch('memex.parse_document_claims.document_uris_from_highwire_doi', return_value=[])\n\n    @pytest.fixture\n    def document_uris_from_links(self, patch):\n        return patch('memex.parse_document_claims.document_uris_from_links', return_value=[])\n\n    @pytest.fixture\n    def document_uri_self_claim(self, patch):\n        return patch('memex.parse_document_claims.document_uri_self_claim')\n\n\ndef one(list_):\n    assert len(list_) == 1\n    return list_[0]\n"},{"size":4238,"relativepath":"tests/memex/cors_test.py","filename":"cors_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\nimport pytest\n\nfrom pyramid.request import Request\nfrom pyramid.httpexceptions import HTTPBadRequest\n\nfrom memex.cors import set_cors_headers\n\n\ndef test_cors_passes_through_non_preflight():\n    request = Request.blank('/')\n\n    resp = request.get_response(wsgi_testapp)\n    resp = set_cors_headers(request, resp)\n\n    assert resp.body == 'OK'\n    assert resp.status_code == 200\n\n\ndef test_cors_adds_allow_origin_header_for_non_preflight():\n    request = Request.blank('/', )\n\n    resp = request.get_response(wsgi_testapp)\n    set_cors_headers(request, resp)\n\n    assert resp.headers['Access-Control-Allow-Origin'] == '*'\n\n\ndef test_cors_400s_for_preflight_without_origin(headers):\n    del headers['Origin']\n    request = Request.blank('/', method='OPTIONS', headers=headers)\n\n    resp = request.get_response(wsgi_testapp)\n\n    with pytest.raises(HTTPBadRequest):\n        set_cors_headers(request, resp)\n\n\ndef test_cors_400s_for_preflight_without_reqmethod(headers):\n    del headers['Access-Control-Request-Method']\n    request = Request.blank('/', method='OPTIONS', headers=headers)\n\n    resp = request.get_response(wsgi_testapp)\n\n    with pytest.raises(HTTPBadRequest):\n        set_cors_headers(request, resp)\n\n\ndef test_cors_sets_allow_origin_for_preflight(headers):\n    request = Request.blank('/', method='OPTIONS', headers=headers)\n\n    resp = request.get_response(wsgi_testapp)\n    resp = set_cors_headers(request, resp)\n\n    assert resp.headers['Access-Control-Allow-Origin'] == 'http://example.com'\n\n\ndef test_cors_sets_allow_methods_OPTIONS_for_preflight(headers):\n    request = Request.blank('/', method='OPTIONS', headers=headers)\n\n    resp = request.get_response(wsgi_testapp)\n    resp = set_cors_headers(request, resp)\n\n    assert resp.headers['Access-Control-Allow-Methods'] == 'OPTIONS'\n\n\ndef test_cors_sets_allow_methods_for_preflight(headers):\n    request = Request.blank('/', method='OPTIONS', headers=headers)\n\n    resp = request.get_response(wsgi_testapp)\n    resp = set_cors_headers(request, resp, allow_methods=('PUT', 'DELETE'))\n    values = resp.headers['Access-Control-Allow-Methods'].split(', ')\n\n    assert sorted(values) == ['DELETE', 'OPTIONS', 'PUT']\n\n\ndef test_cors_sets_allow_credentials_for_preflight_when_set(headers):\n    request = Request.blank('/', method='OPTIONS', headers=headers)\n\n    resp = request.get_response(wsgi_testapp)\n    resp = set_cors_headers(request, resp, allow_credentials=True)\n\n    assert resp.headers['Access-Control-Allow-Credentials'] == 'true'\n\n\ndef test_cors_sets_allow_headers_for_preflight_when_set(headers):\n    request = Request.blank('/', method='OPTIONS', headers=headers)\n\n    resp = request.get_response(wsgi_testapp)\n    resp = set_cors_headers(request, resp, allow_headers=('Foo', 'X-Bar'))\n    values = resp.headers['Access-Control-Allow-Headers'].split(', ')\n\n    assert sorted(values) == ['Foo', 'X-Bar']\n\n\ndef test_cors_sets_expose_headers_for_preflight_when_set(headers):\n    request = Request.blank('/', method='OPTIONS', headers=headers)\n\n    resp = request.get_response(wsgi_testapp)\n    resp = set_cors_headers(request, resp, expose_headers=('Foo', 'X-Bar'))\n    values = resp.headers['Access-Control-Expose-Headers'].split(', ')\n\n    assert sorted(values) == ['Foo', 'X-Bar']\n\n\ndef test_cors_sets_max_age_default_for_preflight(headers):\n    request = Request.blank('/', method='OPTIONS', headers=headers)\n\n    resp = request.get_response(wsgi_testapp)\n    resp = set_cors_headers(request, resp)\n\n    assert resp.headers['Access-Control-Max-Age'] == '86400'\n\n\ndef test_cors_sets_max_age_for_preflight_when_set(headers):\n    request = Request.blank('/', method='OPTIONS', headers=headers)\n\n    resp = request.get_response(wsgi_testapp)\n    resp = set_cors_headers(request, resp, max_age=42)\n\n    assert resp.headers['Access-Control-Max-Age'] == '42'\n\n\n# A tiny WSGI application used for testing the middleware\ndef wsgi_testapp(environ, start_response):\n    start_response('200 OK', [('Content-Type', 'text/plain')])\n    return ['OK']\n\n\n@pytest.fixture\ndef headers():\n    return {\n        'Origin': 'http://example.com',\n        'Access-Control-Request-Method': 'PUT',\n        'Access-Control-Request-Headers': 'Authorization',\n    }\n"},{"size":5088,"relativepath":"tests/memex/db/types_test.py","filename":"types_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\nimport pytest\n\nfrom sqlalchemy.dialects.postgresql import dialect\n\nfrom memex.db import types\n\nUUID_FIXTURES = [\n    # 16 byte UUIDv4s\n    ('OHFscuRvTmiwpOHWfrbzxw', '38716c72e46f4e68b0a4e1d67eb6f3c7'),\n    ('JCfVA8bARx6wdjQq-vp9VA', '2427d503c6c0471eb076342afafa7d54'),\n    ('3AlOaWxzQBKYjRtK3_Uyvw', 'dc094e696c734012988d1b4adff532bf'),\n\n    # 15-byte ElasticSearch flake IDs\n    ('AVGwR1YD8sFu_DXLVRKw',   '0151b0475603ef2c516efc35cb5512b0'),\n    ('AVGy6_TM8sFu_DXLVRfp',   '0151b2ebf4ccef2c516efc35cb5517e9'),\n    ('AVGM9RGq8sFu_DXLVN2l',   '01518cf511aaef2c516efc35cb54dda5'),\n\n    # Null values\n    (None, None),\n]\n\nUUID_FIXTURES_INVALID = [\n    # Incorrect type\n    123,\n    [1, 2, 3],\n    # 20 bytes of not-base64-encoded data\n    '!!!@@@^abcdef&@@@!!!',\n    # 22 bytes of not-base64-encoded data\n    '!!!@@@^^abcdef&&@@@!!!',\n    # short data\n    'MDEyMzQ1Njc4OTAxMjM=',\n    'MDEyMzQ1Njc4OTAxMjM0==',\n    # long data\n    'MDEyMzQ1Njc4OTAxMjM0NTY=',\n    'YWxsIGtpbmRzIG9mIHdlaXJkIHN0dWZmIGdvaW5nIG9u',\n]\n\n\n@pytest.mark.parametrize('app,db', UUID_FIXTURES)\ndef test_uuid_serialize(app, db):\n    t = types.URLSafeUUID()\n    assert t.process_bind_param(app, dialect) == db\n\n\n@pytest.mark.parametrize('data', UUID_FIXTURES_INVALID)\ndef test_uuid_serialize_non_base64_data(data):\n    t = types.URLSafeUUID()\n    with pytest.raises(types.InvalidUUID):\n        t.process_bind_param(data, dialect)\n\n\n@pytest.mark.parametrize('app,db', UUID_FIXTURES)\ndef test_uuid_deserialize(app, db):\n    t = types.URLSafeUUID()\n    assert t.process_result_value(db, dialect) == app\n\n\ndef test_annotation_selector_serialize():\n    t = types.AnnotationSelectorJSONB()\n    selectors = [{\n        'type': 'TextQuoteSelector',\n        'prefix': u'\\u0000Lorem ipsum ',\n        'exact': u'dolor sit amet,\\u0000 ',\n        'suffix': u'consectetur\\u0000 adipiscing elit.'\n    }]\n\n    value = t.process_bind_param(selectors, dialect)\n    assert value[0]['prefix'] == u'\\\\u0000Lorem ipsum '\n    assert value[0]['exact'] == 'dolor sit amet,\\\\u0000 '\n    assert value[0]['suffix'] == 'consectetur\\\\u0000 adipiscing elit.'\n\n\ndef test_annotation_selector_serialize_missing_text_quote_selector():\n    t = types.AnnotationSelectorJSONB()\n    selectors = [{\n        'type': 'RangeSelector',\n        'startContainer': '/div[1]/div[2]',\n        'endContainer': '/div[1]/div[3]',\n        'startOffset': 39,\n        'endoffset': 1\n    }]\n    assert t.process_bind_param(selectors, dialect) == selectors\n\n\ndef test_annotation_selector_deserialize():\n    t = types.AnnotationSelectorJSONB()\n    selectors = [{\n        'type': 'TextQuoteSelector',\n        'prefix': u'\\\\u0000Lorem ipsum ',\n        'exact': u'dolor sit amet,\\\\u0000 ',\n        'suffix': u'consectetur\\\\u0000 adipiscing elit.'\n    }]\n\n    value = t.process_result_value(selectors, dialect)\n    assert value[0]['prefix'] == u'\\u0000Lorem ipsum '\n    assert value[0]['exact'] == u'dolor sit amet,\\u0000 '\n    assert value[0]['suffix'] == u'consectetur\\u0000 adipiscing elit.'\n\n\ndef test_annotation_selector_deserialize_missing_text_quote_selector():\n    t = types.AnnotationSelectorJSONB()\n    selectors = [{\n        'type': 'RangeSelector',\n        'startContainer': '/div[1]/div[2]',\n        'endContainer': '/div[1]/div[3]',\n        'startOffset': 39,\n        'endoffset': 1\n    }]\n    assert t.process_result_value(selectors, dialect) == selectors\n\n\nclass TestMutableList(object):\n\n    @mock.patch.object(types.Mutable, 'changed')\n    @pytest.mark.parametrize('operation', [\n        lambda l: l.__setitem__(0, 'value'),\n        lambda l: l.__setslice__(1, 3, ['a', 'b']),\n        lambda l: l.__delitem__(0),\n        lambda l: l.__delslice__(1, 3),\n        lambda l: l.append('value'),\n        lambda l: l.insert(0, 'value'),\n        lambda l: l.extend(['value']),\n        lambda l: l.pop(),\n        lambda l: l.remove(1),\n        lambda l: l.sort(),\n        lambda l: l.reverse(),\n    ])\n    def test_it_calls_changed(self, changed, operation):\n        list_ = types.MutableList([1, 2, 3])\n        assert not changed.called\n\n        operation(list_)\n\n        changed.assert_called_once_with()\n\n    @pytest.mark.parametrize('operation,expected_result', [\n        (lambda l: l.__setitem__(0, 'value'), ['value', 3, 2]),\n        (lambda l: l.__setslice__(1, 3, ['a', 'b']), [1, 'a', 'b']),\n        (lambda l: l.__delitem__(0), [3, 2]),\n        (lambda l: l.__delslice__(1, 3), [1]),\n        (lambda l: l.append('value'), [1, 3, 2, 'value']),\n        (lambda l: l.insert(0, 'value'), ['value', 1, 3, 2]),\n        (lambda l: l.extend(['value']), [1, 3, 2, 'value']),\n        (lambda l: l.pop(), [1, 3]),\n        (lambda l: l.remove(1), [3, 2]),\n        (lambda l: l.sort(), [1, 2, 3]),\n        (lambda l: l.reverse(), [2, 3, 1]),\n    ])\n    def test_it_mutates_the_list(self, operation, expected_result):\n        list_ = types.MutableList([1, 3, 2])\n\n        operation(list_)\n\n        assert list_ == expected_result\n\n    def test_pop_returns_the_popped_value(self):\n        assert types.MutableList(['value']).pop() == 'value'\n"},{"size":16478,"relativepath":"tests/memex/storage_test.py","filename":"storage_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport copy\n\nimport pytest\nimport mock\n\nfrom memex import storage\nfrom memex import schemas\nfrom memex.models.annotation import Annotation\nfrom memex.models.document import Document, DocumentURI, DocumentMeta\n\n\nclass TestFetchAnnotation(object):\n\n    def test_it_fetches_and_returns_the_annotation(self, db_session, factories):\n        annotation = factories.Annotation()\n\n        actual = storage.fetch_annotation(db_session, annotation.id)\n        assert annotation == actual\n\n    def test_it_does_not_crash_if_id_is_invalid(self, db_session):\n        assert storage.fetch_annotation(db_session, 'foo') is None\n\n\nclass TestFetchOrderedAnnotations(object):\n\n    def test_it_returns_annotations_for_ids_in_the_same_order(self, db_session, factories):\n        ann_1 = factories.Annotation(userid='luke')\n        ann_2 = factories.Annotation(userid='luke')\n\n        assert [ann_2, ann_1] == storage.fetch_ordered_annotations(db_session,\n                                                                   [ann_2.id, ann_1.id])\n        assert [ann_1, ann_2] == storage.fetch_ordered_annotations(db_session,\n                                                                   [ann_1.id, ann_2.id])\n\n    def test_it_allows_to_change_the_query(self, db_session, factories):\n        ann_1 = factories.Annotation(userid='luke')\n        ann_2 = factories.Annotation(userid='maria')\n\n        def only_maria(query):\n            return query.filter(Annotation.userid == 'maria')\n\n        assert [ann_2] == storage.fetch_ordered_annotations(db_session,\n                                                            [ann_2.id, ann_1.id],\n                                                            query_processor=only_maria)\n\n\nclass TestExpandURI(object):\n\n    def test_expand_uri_no_document(self, db_session):\n        actual = storage.expand_uri(db_session, 'http://example.com/')\n        assert actual == ['http://example.com/']\n\n    def test_expand_uri_document_doesnt_expand_canonical_uris(self, db_session):\n        document = Document(document_uris=[\n            DocumentURI(uri='http://foo.com/', claimant='http://example.com'),\n            DocumentURI(uri='http://bar.com/', claimant='http://example.com'),\n            DocumentURI(uri='http://example.com/', type='rel-canonical',\n                        claimant='http://example.com'),\n        ])\n        db_session.add(document)\n        db_session.flush()\n\n        assert storage.expand_uri(db_session, \"http://example.com/\") == [\n            \"http://example.com/\"]\n\n    def test_expand_uri_document_uris(self, db_session):\n        document = Document(document_uris=[\n            DocumentURI(uri='http://foo.com/', claimant='http://bar.com'),\n            DocumentURI(uri='http://bar.com/', claimant='http://bar.com'),\n        ])\n        db_session.add(document)\n        db_session.flush()\n\n        assert storage.expand_uri(db_session, 'http://foo.com/') == [\n            'http://foo.com/',\n            'http://bar.com/'\n        ]\n\n\n@pytest.mark.usefixtures('models')\nclass TestCreateAnnotation(object):\n\n    def test_it_fetches_parent_annotation_for_replies(self,\n                                                      fetch_annotation,\n                                                      pyramid_config,\n                                                      pyramid_request):\n\n        # Make the annotation's parent belong to 'test-group'.\n        fetch_annotation.return_value.groupid = 'test-group'\n\n        # The request will need permission to write to 'test-group'.\n        pyramid_config.testing_securitypolicy('acct:foo@example.com',\n                                              groupids=['group:test-group'])\n\n        data = self.annotation_data()\n\n        # The annotation is a reply.\n        data['references'] = ['parent_annotation_id']\n\n        storage.create_annotation(pyramid_request, data)\n\n        fetch_annotation.assert_called_once_with(pyramid_request.db,\n                                                 'parent_annotation_id')\n\n    def test_it_sets_group_for_replies(self,\n                                       fetch_annotation,\n                                       models,\n                                       pyramid_config,\n                                       pyramid_request):\n        # Make the annotation's parent belong to 'test-group'.\n        fetch_annotation.return_value.groupid = 'test-group'\n\n        # The request will need permission to write to 'test-group'.\n        pyramid_config.testing_securitypolicy('acct:foo@example.com',\n                                              groupids=['group:test-group'])\n\n        data = self.annotation_data()\n        assert data['groupid'] != 'test-group'\n\n        # The annotation is a reply.\n        data['references'] = ['parent_annotation_id']\n\n        storage.create_annotation(pyramid_request, data)\n\n        assert models.Annotation.call_args[1]['groupid'] == 'test-group'\n\n    def test_it_raises_if_parent_annotation_does_not_exist(self,\n                                                           fetch_annotation,\n                                                           pyramid_request):\n        fetch_annotation.return_value = None\n\n        data = self.annotation_data()\n\n        # The annotation is a reply.\n        data['references'] = ['parent_annotation_id']\n\n        with pytest.raises(schemas.ValidationError) as exc:\n            storage.create_annotation(pyramid_request, data)\n\n        assert str(exc.value).startswith('references.0: ')\n\n    def test_it_raises_if_user_does_not_have_permissions_for_group(self, pyramid_request):\n        data = self.annotation_data()\n        data['groupid'] = 'foo-group'\n\n        with pytest.raises(schemas.ValidationError) as exc:\n            storage.create_annotation(pyramid_request, data)\n\n        assert str(exc.value).startswith('group: ')\n\n    def test_it_inits_an_Annotation_model(self, models, pyramid_request):\n        data = self.annotation_data()\n\n        storage.create_annotation(pyramid_request, copy.deepcopy(data))\n\n        del data['document']\n        models.Annotation.assert_called_once_with(**data)\n\n    def test_it_adds_the_annotation_to_the_database(self, models, pyramid_request):\n        storage.create_annotation(pyramid_request, self.annotation_data())\n\n        assert models.Annotation.return_value in pyramid_request.db.added\n\n    def test_it_updates_the_document_metadata_from_the_annotation(self,\n                                                                  models,\n                                                                  pyramid_request,\n                                                                  datetime):\n        annotation_data = self.annotation_data()\n        annotation_data['document']['document_meta_dicts'] = (\n            mock.sentinel.document_meta_dicts)\n        annotation_data['document']['document_uri_dicts'] = (\n            mock.sentinel.document_uri_dicts)\n\n        storage.create_annotation(pyramid_request, annotation_data)\n\n        models.update_document_metadata.assert_called_once_with(\n            pyramid_request.db,\n            models.Annotation.return_value.target_uri,\n            mock.sentinel.document_meta_dicts,\n            mock.sentinel.document_uri_dicts,\n            created=datetime.utcnow(),\n            updated=datetime.utcnow(),\n        )\n\n    def test_it_sets_the_annotations_document_id(self,\n                                                 models,\n                                                 pyramid_request):\n        annotation_data = self.annotation_data()\n\n        document = mock.Mock()\n        models.update_document_metadata.return_value = document\n\n        ann = storage.create_annotation(pyramid_request, annotation_data)\n\n        assert ann.document == document\n\n    def test_it_returns_the_annotation(self, models, pyramid_request):\n        annotation = storage.create_annotation(pyramid_request,\n                                               self.annotation_data())\n\n        assert annotation == models.Annotation.return_value\n\n    def test_it_does_not_crash_if_target_selectors_is_empty(self, pyramid_request):\n        # Page notes have [] for target_selectors.\n        data = self.annotation_data()\n        data['target_selectors'] = []\n\n        storage.create_annotation(pyramid_request, data)\n\n    def test_it_does_not_crash_if_no_text_or_tags(self, pyramid_request):\n        # Highlights have no text or tags.\n        data = self.annotation_data()\n        data['text'] = data['tags'] = ''\n\n        storage.create_annotation(pyramid_request, data)\n\n    def annotation_data(self):\n        return {\n            'userid': 'acct:test@localhost',\n            'text': 'text',\n            'tags': ['one', 'two'],\n            'shared': False,\n            'target_uri': 'http://www.example.com/example.html',\n            'groupid': '__world__',\n            'references': [],\n            'target_selectors': ['selector_one', 'selector_two'],\n            'document': {\n                'document_uri_dicts': [],\n                'document_meta_dicts': [],\n            }\n        }\n\n\n@pytest.mark.usefixtures('models')\nclass TestUpdateAnnotation(object):\n\n    def test_it_gets_the_annotation_model(self,\n                                          annotation_data,\n                                          models,\n                                          session):\n        storage.update_annotation(session,\n                                  'test_annotation_id',\n                                  annotation_data)\n\n        session.query.assert_called_once_with(models.Annotation)\n        session.query.return_value.get.assert_called_once_with(\n            'test_annotation_id')\n\n    def test_it_adds_new_extras(self, annotation_data, session):\n        annotation = session.query.return_value.get.return_value\n        annotation.extra = {}\n        annotation_data['extra'] = {'foo': 'bar'}\n\n        storage.update_annotation(session,\n                                  'test_annotation_id',\n                                  annotation_data)\n\n        assert annotation.extra == {'foo': 'bar'}\n\n    def test_it_overwrites_existing_extras(self,\n                                           annotation_data,\n                                           session):\n        annotation = session.query.return_value.get.return_value\n        annotation.extra = {'foo': 'original_value'}\n        annotation_data['extra'] = {'foo': 'new_value'}\n\n        storage.update_annotation(session,\n                                  'test_annotation_id',\n                                  annotation_data)\n\n        assert annotation.extra == {'foo': 'new_value'}\n\n    def test_it_does_not_change_extras_that_are_not_sent(self,\n                                                         annotation_data,\n                                                         session):\n        annotation = session.query.return_value.get.return_value\n        annotation.extra = {\n            'one': 1,\n            'two': 2,\n        }\n        annotation_data['extra'] = {'two': 22}\n\n        storage.update_annotation(session,\n                                  'test_annotation_id',\n                                  annotation_data)\n\n        assert annotation.extra['one'] == 1\n\n    def test_it_does_not_change_extras_if_none_are_sent(self,\n                                                        annotation_data,\n                                                        session):\n        annotation = session.query.return_value.get.return_value\n        annotation.extra = {'one': 1, 'two': 2}\n        assert not annotation_data.get('extra')\n\n        storage.update_annotation(session,\n                                  'test_annotation_id',\n                                  annotation_data)\n\n        assert annotation.extra == {'one': 1, 'two': 2}\n\n    def test_it_changes_the_updated_timestamp(self, annotation_data, session, datetime):\n        annotation = storage.update_annotation(session,\n                                               'test_annotation_id',\n                                               annotation_data)\n\n        assert annotation.updated == datetime.utcnow()\n\n    def test_it_updates_the_annotation(self, annotation_data, session):\n        annotation = session.query.return_value.get.return_value\n\n        storage.update_annotation(session,\n                                  'test_annotation_id',\n                                  annotation_data)\n\n        for key, value in annotation_data.items():\n            assert getattr(annotation, key) == value\n\n    def test_it_updates_the_document_metadata_from_the_annotation(\n            self,\n            annotation_data,\n            session,\n            models,\n            datetime):\n        annotation = session.query.return_value.get.return_value\n        annotation_data['document']['document_meta_dicts'] = (\n            mock.sentinel.document_meta_dicts)\n        annotation_data['document']['document_uri_dicts'] = (\n            mock.sentinel.document_uri_dicts)\n\n        storage.update_annotation(session,\n                                  'test_annotation_id',\n                                  annotation_data)\n\n        models.update_document_metadata.assert_called_once_with(\n            session,\n            annotation.target_uri,\n            mock.sentinel.document_meta_dicts,\n            mock.sentinel.document_uri_dicts,\n            updated=datetime.utcnow()\n        )\n\n    def test_it_updates_the_annotations_document_id(self,\n                                                    annotation_data,\n                                                    session,\n                                                    models):\n        annotation = session.query.return_value.get.return_value\n        document = mock.Mock()\n        models.update_document_metadata.return_value = document\n\n        storage.update_annotation(session,\n                                  'test_annotation_id',\n                                  annotation_data)\n        assert annotation.document == document\n\n    def test_it_returns_the_annotation(self, annotation_data, session):\n        annotation = storage.update_annotation(session,\n                                               'test_annotation_id',\n                                               annotation_data)\n\n        assert annotation == session.query.return_value.get.return_value\n\n    def test_it_does_not_crash_if_no_document_in_data(self,\n                                                      session):\n        storage.update_annotation(session, 'test_annotation_id', {})\n\n    def test_it_does_not_call_update_document_meta_if_no_document_in_data(\n            self,\n            session,\n            models):\n\n        storage.update_annotation(session, 'test_annotation_id', {})\n\n        assert not models.update_document_metadata.called\n\n    @pytest.fixture\n    def annotation_data(self):\n        return {\n            'userid': 'acct:test@localhost',\n            'text': 'text',\n            'tags': ['one', 'two'],\n            'shared': False,\n            'target_uri': 'http://www.example.com/example.html',\n            'groupid': '__world__',\n            'references': [],\n            'target_selectors': ['selector_one', 'selector_two'],\n            'document': {\n                'document_uri_dicts': [],\n                'document_meta_dicts': [],\n            },\n            'extra': {},\n        }\n\n\nclass TestDeleteAnnotation(object):\n\n    def test_it_deletes_the_annotation(self, db_session, factories):\n        ann_1, ann_2 = (factories.Annotation(), factories.Annotation())\n\n        storage.delete_annotation(db_session, ann_1.id)\n        db_session.commit()\n\n        assert db_session.query(Annotation).get(ann_1.id) is None\n        assert db_session.query(Annotation).get(ann_2.id) == ann_2\n\n\n@pytest.fixture\ndef fetch_annotation(patch):\n    return patch('memex.storage.fetch_annotation')\n\n\n@pytest.fixture\ndef models(patch):\n    models = patch('memex.storage.models', autospec=False)\n    models.Annotation.return_value.is_reply = False\n    return models\n\n\n@pytest.fixture\ndef pyramid_request(fake_db_session, pyramid_request):\n    pyramid_request.db = fake_db_session\n    return pyramid_request\n\n\n@pytest.fixture\ndef session(db_session):\n    session = mock.Mock(spec=db_session)\n    session.query.return_value.get.return_value.extra = {}\n    return session\n\n\n@pytest.fixture\ndef datetime(patch):\n    return patch('memex.storage.datetime')\n"},{"size":4740,"relativepath":"tests/memex/conftest.py","filename":"conftest.py","extension":".py","content":"# -*- coding: utf-8 -*-\n# pylint: disable=no-self-use\n\"\"\"\nThe `conftest` module is automatically loaded by py.test and serves as a place\nto put fixture functions that are useful application-wide.\n\"\"\"\n\nimport functools\nimport os\n\nimport mock\nimport pytest\n\nimport sqlalchemy\nfrom pyramid import testing\nfrom pyramid.request import apply_request_extensions\nfrom sqlalchemy.orm import sessionmaker\n\nfrom memex import db\n\nTEST_DATABASE_URL = os.environ.get('TEST_DATABASE_URL',\n                                   'postgresql://postgres@localhost/htest')\n\nSession = sessionmaker()\n\n\nclass DummyFeature(object):\n\n    \"\"\"\n    A dummy feature flag looker-upper.\n\n    Because we're probably testing all feature-flagged functionality, this\n    feature client defaults every flag to *True*, which is the exact opposite\n    of what happens outside of testing.\n    \"\"\"\n\n    def __init__(self):\n        self.flags = {}\n\n    def __call__(self, name, *args, **kwargs):\n        return self.flags.get(name, True)\n\n\nclass DummySession(object):\n\n    \"\"\"\n    A dummy database session.\n    \"\"\"\n\n    def __init__(self):\n        self.added = []\n        self.deleted = []\n        self.flushed = False\n\n    def add(self, obj):\n        self.added.append(obj)\n\n    def delete(self, obj):\n        self.deleted.append(obj)\n\n    def flush(self):\n        self.flushed = True\n\n\ndef autopatcher(request, target, **kwargs):\n    \"\"\"Patch and cleanup automatically. Wraps :py:func:`mock.patch`.\"\"\"\n    options = {'autospec': True}\n    options.update(kwargs)\n    patcher = mock.patch(target, **options)\n    obj = patcher.start()\n    request.addfinalizer(patcher.stop)\n    return obj\n\n\n@pytest.fixture(scope='session')\ndef db_engine():\n    \"\"\"Set up the database connection and create tables.\"\"\"\n    engine = sqlalchemy.create_engine(TEST_DATABASE_URL)\n    db.init(engine, should_create=True, should_drop=True)\n    return engine\n\n\n@pytest.yield_fixture\ndef db_session(db_engine):\n    \"\"\"\n    Prepare the SQLAlchemy session object.\n\n    We enable fast repeatable database tests by setting up the database only\n    once per session (see :func:`db_engine`) and then wrapping each test\n    function in a transaction that is rolled back.\n\n    Additionally, we set a SAVEPOINT before entering the test, and if we\n    detect that the test has committed (i.e. released the savepoint) we\n    immediately open another. This has the effect of preventing test code from\n    committing the outer transaction.\n    \"\"\"\n    conn = db_engine.connect()\n    trans = conn.begin()\n    session = Session(bind=conn)\n    session.begin_nested()\n\n    @sqlalchemy.event.listens_for(session, \"after_transaction_end\")\n    def restart_savepoint(session, transaction):\n        if transaction.nested and not transaction._parent.nested:\n            session.begin_nested()\n\n    try:\n        yield session\n    finally:\n        session.close()\n        trans.rollback()\n        conn.close()\n\n\n@pytest.yield_fixture\ndef factories(db_session):\n    from . import factories\n    factories.SESSION = db_session\n    yield factories\n    factories.SESSION = None\n\n\n@pytest.fixture\ndef fake_feature():\n    return DummyFeature()\n\n\n@pytest.fixture\ndef fake_db_session():\n    return DummySession()\n\n\n@pytest.fixture\ndef matchers():\n    from ..common import matchers\n    return matchers\n\n\n@pytest.fixture\ndef notify(pyramid_config, request):\n    patcher = mock.patch.object(pyramid_config.registry, 'notify', autospec=True)\n    request.addfinalizer(patcher.stop)\n    return patcher.start()\n\n\n@pytest.fixture\ndef patch(request):\n    return functools.partial(autopatcher, request)\n\n\n@pytest.yield_fixture\ndef pyramid_config(pyramid_settings, pyramid_request):\n    \"\"\"Pyramid configurator object.\"\"\"\n    with testing.testConfig(request=pyramid_request,\n                            settings=pyramid_settings) as config:\n        # Include pyramid_services so it's easy to set up fake services in tests\n        config.include('pyramid_services')\n        apply_request_extensions(pyramid_request)\n\n        yield config\n\n\n@pytest.fixture\ndef pyramid_request(db_session, fake_feature, pyramid_settings):\n    \"\"\"Dummy Pyramid request object.\"\"\"\n    request = testing.DummyRequest(db=db_session, feature=fake_feature)\n    request.auth_domain = request.domain\n    request.create_form = mock.Mock()\n    request.registry.settings = pyramid_settings\n    return request\n\n\n@pytest.fixture\ndef pyramid_csrf_request(pyramid_request):\n    \"\"\"Dummy Pyramid request object with a valid CSRF token.\"\"\"\n    pyramid_request.headers['X-CSRF-Token'] = pyramid_request.session.get_csrf_token()\n    return pyramid_request\n\n\n@pytest.fixture\ndef pyramid_settings():\n    \"\"\"Default app settings.\"\"\"\n    return {\n        'sqlalchemy.url': TEST_DATABASE_URL\n    }\n"},{"size":2384,"relativepath":"tests/h/links_test.py","filename":"links_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport pytest\n\nfrom h import links\n\n\nclass FakeAnnotation(object):\n    def __init__(self):\n        self.thread_root_id = '123'\n        self.references = None\n        self.target_uri = 'http://example.com/foo/bar'\n        self.document = None\n\n\nclass FakeDocumentURI(object):\n    def __init__(self):\n        self.uri = 'http://example.com/foo.pdf'\n\n\nclass FakeDocument(object):\n    def __init__(self):\n        self.document_uris = []\n\n\ndef test_incontext_link(pyramid_request):\n    annotation = FakeAnnotation()\n\n    link = links.incontext_link(pyramid_request, annotation)\n\n    assert link == 'https://hyp.is/123/example.com/foo/bar'\n\n\n@pytest.mark.parametrize('target_uri,expected', [\n    ('', 'https://hyp.is/123'),\n    ('something_not_a_url', 'https://hyp.is/123'),\n    ('ftp://not_http', 'https://hyp.is/123'),\n    ('http://example.com/foo/bar', 'https://hyp.is/123/example.com/foo/bar'),\n    ('https://safari.org/giraffes', 'https://hyp.is/123/safari.org/giraffes'),\n])\ndef test_incontext_link_appends_schemaless_uri_if_present(pyramid_request,\n                                                          target_uri,\n                                                          expected):\n    annotation = FakeAnnotation()\n    annotation.target_uri = target_uri\n\n    link = links.incontext_link(pyramid_request, annotation)\n\n    assert link == expected\n\n\ndef test_incontext_link_appends_first_schemaless_uri_for_pdfs_with_document(pyramid_request):\n    doc = FakeDocument()\n    docuri1 = FakeDocumentURI()\n    docuri1.uri = 'http://example.com/foo.pdf'\n    docuri2 = FakeDocumentURI()\n    docuri2.uri = 'http://example.com/bar.pdf'\n\n    doc.document_uris = [docuri1, docuri2]\n\n    annotation = FakeAnnotation()\n    annotation.document = doc\n    annotation.target_uri = 'urn:x-pdf:the-fingerprint'\n\n    link = links.incontext_link(pyramid_request, annotation)\n\n    assert link == 'https://hyp.is/123/example.com/foo.pdf'\n\n\ndef test_incontext_link_skips_uri_for_pdfs_with_no_document(pyramid_request):\n    annotation = FakeAnnotation()\n    annotation.target_uri = 'urn:x-pdf:the-fingerprint'\n\n    link = links.incontext_link(pyramid_request, annotation)\n\n    assert link == 'https://hyp.is/123'\n\n\n@pytest.fixture\ndef pyramid_settings(pyramid_settings):\n    pyramid_settings.update({\n        'h.bouncer_url': 'https://hyp.is',\n    })\n    return pyramid_settings\n"},{"size":2408,"relativepath":"tests/h/mailer_test.py","filename":"mailer_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom smtplib import SMTPServerDisconnected\n\nimport mock\n\nfrom h import mailer\n\n\n@mock.patch('h.mailer.celery', autospec=True)\n@mock.patch('h.mailer.pyramid_mailer', autospec=True)\ndef test_send_creates_email_message(pyramid_mailer, celery):\n    celery.request = mock.sentinel.request\n\n    mailer.send(recipients=['foo@example.com'],\n                subject='My email subject',\n                body='Some text body')\n\n    pyramid_mailer.message.Message.assert_called_once_with(\n        subject='My email subject',\n        recipients=['foo@example.com'],\n        body='Some text body',\n        html=None)\n\n\n@mock.patch('h.mailer.celery', autospec=True)\n@mock.patch('h.mailer.pyramid_mailer', autospec=True)\ndef test_send_creates_email_message_with_html_body(pyramid_mailer, celery):\n    celery.request = mock.sentinel.request\n\n    mailer.send(recipients=['foo@example.com'],\n                subject='My email subject',\n                body='Some text body',\n                html='<p>An HTML body</p>')\n\n    pyramid_mailer.message.Message.assert_called_once_with(\n        subject='My email subject',\n        recipients=['foo@example.com'],\n        body='Some text body',\n        html='<p>An HTML body</p>')\n\n\n@mock.patch('h.mailer.celery', autospec=True)\n@mock.patch('h.mailer.pyramid_mailer', autospec=True)\ndef test_send_dispatches_email_using_request_mailer(pyramid_mailer, celery):\n    celery.request = mock.sentinel.request\n    request_mailer = pyramid_mailer.get_mailer.return_value\n    message = pyramid_mailer.message.Message.return_value\n\n    mailer.send(recipients=['foo@example.com'],\n                subject='My email subject',\n                body='Some text body')\n\n    pyramid_mailer.get_mailer.assert_called_once_with(mock.sentinel.request)\n    request_mailer.send_immediately.assert_called_once_with(message)\n\n\n@mock.patch('h.mailer.celery', autospec=True)\n@mock.patch('h.mailer.pyramid_mailer', autospec=True)\ndef test_send_retries_if_mailing_fails(pyramid_mailer, celery):\n    celery.request = mock.sentinel.request\n    request_mailer = pyramid_mailer.get_mailer.return_value\n    request_mailer.send_immediately.side_effect = SMTPServerDisconnected()\n\n    mailer.send.retry = mock.Mock(spec_set=[])\n    mailer.send(recipients=['foo@example.com'],\n                subject='My email subject',\n                body='Some text body')\n\n    assert mailer.send.retry.called\n"},{"size":790,"relativepath":"tests/h/security_test.py","filename":"security_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom passlib.context import CryptContext\nfrom hypothesis import strategies as st\nfrom hypothesis import given\n\nfrom h._compat import text_type\nfrom h.security import password_context\nfrom h.security import token_urlsafe\n\n\ndef test_password_context():\n    assert isinstance(password_context, CryptContext)\n    assert len(password_context.schemes()) > 0\n\n\n@given(nbytes=st.integers(min_value=1, max_value=64))\ndef test_token_urlsafe(nbytes):\n    tok = token_urlsafe(nbytes)\n\n    # Should be text\n    assert isinstance(tok, text_type)\n    # Always at least nbytes of data\n    assert len(tok) > nbytes\n\n\ndef test_token_urlsafe_no_args():\n    tok = token_urlsafe()\n\n    assert isinstance(tok, text_type)\n    assert len(tok) > 32\n"},{"size":5549,"relativepath":"tests/h/features/client_test.py","filename":"client_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\nimport pytest\n\nfrom h.auth import role\nfrom h.models import Feature, FeatureCohort, User\nfrom h.features.client import Client\nfrom h.features.client import UnknownFeatureError\n\n\nclass TestClient(object):\n    def test_init_stores_the_request(self, client, pyramid_request):\n        assert client.request == pyramid_request\n\n    def test_enabled_loads_features(self, client, fetcher, pyramid_request):\n        client.enabled('foo')\n\n        fetcher.assert_called_once_with(pyramid_request.db)\n\n    def test_enabled_caches_features(self, client, fetcher, pyramid_request):\n        client.enabled('foo')\n        client.enabled('bar')\n\n        fetcher.assert_called_once_with(pyramid_request.db)\n\n    def test_enabled_caches_empty_result_sets(self, client, fetcher, pyramid_request):\n        \"\"\"Even an empty result set from the fetcher should be cached.\"\"\"\n        fetcher.return_value = []\n        try:\n            client.enabled('foo')\n        except UnknownFeatureError:\n            pass\n        try:\n            client.enabled('bar')\n        except UnknownFeatureError:\n            pass\n\n        fetcher.assert_called_once_with(pyramid_request.db)\n\n    def test_enabled_raises_for_unknown_features(self, client):\n        with pytest.raises(UnknownFeatureError):\n            client.enabled('wibble')\n\n    def test_enabled_true_if_feature_query_param_set(self, client, pyramid_request):\n        pyramid_request.GET['__feature__[foo]'] = ''\n\n        assert client.enabled('foo') is True\n\n    def test_enabled_false_if_everyone_false(self, client):\n        assert client.enabled('foo') is False\n\n    def test_enabled_true_if_everyone_true(self, client):\n        assert client.enabled('on-for-everyone') is True\n\n    def test_enabled_false_when_admins_true_normal_request(self, client):\n        assert client.enabled('on-for-admins') is False\n\n    def test_enabled_true_when_admins_true_admin_request(self, client, pyramid_config):\n        pyramid_config.testing_securitypolicy('acct:foo@example.com',\n                                              groupids=[role.Admin])\n        assert client.enabled('on-for-admins') is True\n\n    def test_enabled_false_when_staff_true_normal_request(self, client):\n        assert client.enabled('on-for-staff') is False\n\n    def test_enabled_true_when_staff_true_staff_request(self, client, pyramid_config):\n        pyramid_config.testing_securitypolicy('acct:foo@example.com',\n                                              groupids=[role.Staff])\n        assert client.enabled('on-for-staff') is True\n\n    def test_call_false_if_everyone_false(self, client):\n        assert client('foo') is False\n\n    def test_call_true_if_everyone_true(self, client):\n        assert client('on-for-everyone') is True\n\n    def test_call_false_if_cohort_disabled(self, client):\n        assert client('on-for-cohort') is False\n\n    def test_call_true_if_cohort_enabled(self, patch, client, user, cohort):\n        user.cohorts = [cohort]\n        assert client('on-for-cohort') is True\n\n    def test_call_false_if_unauthenticated_user(self, patch, client, pyramid_request):\n        pyramid_request.authenticated_user = None\n        assert client('on-for-cohort') is False\n\n    def test_all_loads_features(self, client, fetcher, pyramid_request):\n        client.all()\n\n        fetcher.assert_called_once_with(pyramid_request.db)\n\n    def test_all_caches_features(self, client, fetcher, pyramid_request):\n        client.all()\n        client.all()\n\n        fetcher.assert_called_once_with(pyramid_request.db)\n\n    def test_all_caches_empty_result_sets(self, client, fetcher, pyramid_request):\n        \"\"\"Even an empty result set from the fetcher should be cached.\"\"\"\n        fetcher.return_value = []\n        client.all()\n        client.all()\n\n        fetcher.assert_called_once_with(pyramid_request.db)\n\n    def test_all_returns_feature_dictionary(self, client, pyramid_config):\n        pyramid_config.testing_securitypolicy('acct:foo@example.com',\n                                              groupids=[role.Staff])\n\n        result = client.all()\n\n        assert result == {\n            'foo': False,\n            'bar': False,\n            'on-for-everyone': True,\n            'on-for-staff': True,\n            'on-for-admins': False,\n            'on-for-cohort': False,\n        }\n\n    def test_clear_resets_cache(self, client, fetcher):\n        result = client.enabled('foo')\n        client.clear()\n\n        assert fetcher.call_count == 1\n        assert result is False\n\n        fetcher.return_value[0].everyone = True\n        result = client.enabled('foo')\n\n        assert fetcher.call_count == 2\n        assert result is True\n\n    @pytest.fixture\n    def fetcher(self, cohort):\n        return mock.Mock(spec_set=[], return_value=[\n            Feature(name='foo'),\n            Feature(name='bar'),\n            Feature(name='on-for-everyone', everyone=True),\n            Feature(name='on-for-staff', staff=True),\n            Feature(name='on-for-admins', admins=True),\n            Feature(name='on-for-cohort', cohorts=[cohort])\n        ])\n\n    @pytest.fixture\n    def user(self):\n        return User(username='foo', email='foo@example.com')\n\n    @pytest.fixture\n    def cohort(self):\n        return FeatureCohort(name='cohort')\n\n    @pytest.fixture\n    def client(self, pyramid_request, fetcher):\n        return Client(pyramid_request, fetcher)\n\n    @pytest.fixture\n    def pyramid_request(self, pyramid_request, user):\n        pyramid_request.authenticated_user = user\n        return pyramid_request\n"},{"size":2071,"relativepath":"tests/h/features/subscribers_test.py","filename":"subscribers_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\nfrom mock import patch\n\nfrom pyramid.registry import Registry\nfrom pyramid.events import ApplicationCreated, NewRequest\n\nfrom h.features.subscribers import preload_flags, remove_old_flags\n\n\nclass TestPreloadFlags(object):\n    def test_preloads_feature_flags(self, pyramid_request):\n        event = NewRequest(pyramid_request)\n\n        preload_flags(event)\n\n        assert event.request.feature.loaded\n\n    @pytest.mark.parametrize('path', [\n        '/assets/some/style.css',\n        '/_debug_toolbar/foo123',\n    ])\n    def test_does_not_preload_for_opted_out_requests(self, path, pyramid_request):\n        pyramid_request.path = path\n        event = NewRequest(pyramid_request)\n\n        preload_flags(event)\n\n        assert not event.request.feature.loaded\n\n\nclass TestRemoveOldFlags(object):\n    def test_removes_flags(self, patch):\n        db = patch('h.features.subscribers.db')\n        Feature = patch('h.features.subscribers.Feature')\n        event = ApplicationCreated(DummyApp())\n\n        remove_old_flags(event)\n\n        Feature.remove_old_flags.assert_called_once_with(db.Session.return_value)\n\n    def test_cleans_up_database_session_and_connection(self, patch):\n        db = patch('h.features.subscribers.db')\n        patch('h.features.subscribers.Feature')\n        event = ApplicationCreated(DummyApp())\n\n        remove_old_flags(event)\n\n        db.Session.return_value.close.assert_called_once_with()\n        db.make_engine.return_value.dispose.assert_called_once_with()\n\n    @patch.dict('os.environ', {'H_SCRIPT': '1'})\n    def test_does_nothing_when_in_script(self, patch):\n        patch('h.features.subscribers.db')\n        Feature = patch('h.features.subscribers.Feature')\n        event = ApplicationCreated(DummyApp())\n\n        remove_old_flags(event)\n\n        assert not Feature.remove_old_flags.called\n\n\nclass DummyApp(object):\n    def __init__(self):\n        self.registry = Registry('testing')\n        self.registry.settings = {'sqlalchemy.url': 'sqlite:///:memory:'}\n"},{"size":1765,"relativepath":"tests/h/jinja_extension_test.py","filename":"jinja_extension_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport datetime\n\nfrom jinja2 import Markup\nimport pytest\n\nfrom h import jinja_extensions as ext\n\n@pytest.mark.parametrize(\"value_in,json_out\", [\n    ({\"foo\": 42}, \"{\\\"foo\\\": 42}\")\n])\ndef test_to_json(value_in, json_out):\n    result = str(ext.to_json(value_in))\n\n    assert result == json_out\n\n\n@pytest.mark.parametrize(\"timestamp_in,string_out\", [\n    # Basic format for recent timestamps\n    (datetime.datetime(2016, 4, 14, 16, 45, 36, 529730),\n     '14 April at 16:45'),\n    # For times more than a year ago, add the year\n    (datetime.datetime(2012, 4, 14, 16, 45, 36, 529730),\n     '14 April 2012 at 16:45'),\n])\ndef test_human_timestamp(timestamp_in, string_out):\n    result = ext.human_timestamp(\n        timestamp_in, now=lambda: datetime.datetime(2016, 4, 14))\n\n    assert result == string_out\n\n\ndef test_svg_icon_loads_icon():\n    def read_icon(name):\n        return '<svg id=\"{}\"></svg>'.format(name)\n\n    result = ext.svg_icon(read_icon, 'settings')\n\n    assert result == Markup('<svg id=\"settings\" />')\n\n\ndef test_svg_icon_removes_title():\n    def read_icon(name):\n        return '<svg xmlns=\"http://www.w3.org/2000/svg\"><title>foo</title></svg>'\n\n    assert (ext.svg_icon(read_icon, 'icon') ==\n        Markup('<svg xmlns=\"http://www.w3.org/2000/svg\" />'))\n\n\ndef test_svg_icon_strips_default_xml_namespace():\n    def read_icon(name):\n        return '<svg xmlns=\"http://www.w3.org/2000/svg\"></svg>'\n\n    assert (ext.svg_icon(read_icon, 'icon') ==\n        Markup('<svg xmlns=\"http://www.w3.org/2000/svg\" />'))\n\n\ndef test_svg_icon_sets_css_class():\n    def read_icon(name):\n        return '<svg></svg>'\n\n    result = ext.svg_icon(read_icon, 'icon', css_class='fancy-icon')\n\n    assert result == Markup('<svg class=\"fancy-icon\" />')\n"},{"size":2537,"relativepath":"tests/h/emails/signup_test.py","filename":"signup_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\n\nfrom h.emails.signup import generate\n\n\n@pytest.mark.usefixtures('routes')\nclass TestGenerate(object):\n\n    def test_calls_renderers_with_appropriate_context(self,\n                                                      pyramid_request,\n                                                      html_renderer,\n                                                      text_renderer):\n        generate(pyramid_request,\n                 id=1234,\n                 email='foo@example.com',\n                 activation_code='abcd4567')\n\n        expected_context = {\n            'activate_link': 'http://example.com/activate/1234/abcd4567',\n        }\n        html_renderer.assert_(**expected_context)\n        text_renderer.assert_(**expected_context)\n\n    def test_appropriate_return_values(self,\n                                       pyramid_request,\n                                       html_renderer,\n                                       text_renderer):\n        html_renderer.string_response = 'HTML output'\n        text_renderer.string_response = 'Text output'\n\n        recipients, subject, text, html = generate(pyramid_request,\n                                                   id=1234,\n                                                   email='foo@example.com',\n                                                   activation_code='abcd4567')\n\n        assert recipients == ['foo@example.com']\n        assert subject == 'Please activate your account'\n        assert html == 'HTML output'\n        assert text == 'Text output'\n\n    def test_jinja_templates_render(self,\n                                    pyramid_config,\n                                    pyramid_request):\n        \"\"\"Ensure that the jinja templates don't contain syntax errors\"\"\"\n        pyramid_config.include('pyramid_jinja2')\n        pyramid_config.add_jinja2_extension('h.jinja_extensions.Filters')\n\n        generate(pyramid_request,\n                 id=1234,\n                 email='foo@example.com',\n                 activation_code='abcd4567')\n\n    @pytest.fixture\n    def html_renderer(self, pyramid_config):\n        return pyramid_config.testing_add_renderer('h:templates/emails/signup.html.jinja2')\n\n    @pytest.fixture\n    def routes(self, pyramid_config):\n        pyramid_config.add_route('activate', '/activate/{id}/{code}')\n\n    @pytest.fixture\n    def text_renderer(self, pyramid_config):\n        return pyramid_config.testing_add_renderer('h:templates/emails/signup.txt.jinja2')\n"},{"size":8552,"relativepath":"tests/h/emails/reply_notification_test.py","filename":"reply_notification_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport datetime\n\nimport mock\nimport pytest\n\nfrom h.emails.reply_notification import generate\nfrom h.models import Annotation\nfrom h.models import Document, DocumentMeta\nfrom h.notification.reply import Notification\n\n\n@pytest.mark.usefixtures('routes',\n                         'token_serializer',\n                         'html_renderer',\n                         'text_renderer')\nclass TestGenerate(object):\n\n    def test_gets_in_context_link(self, notification, links, pyramid_request):\n        generate(pyramid_request, notification)\n\n        links.incontext_link.assert_called_once_with(pyramid_request,\n                                                     notification.reply)\n\n    def test_calls_renderers_with_appropriate_context(self,\n                                                      notification,\n                                                      parent_user,\n                                                      pyramid_request,\n                                                      reply_user,\n                                                      html_renderer,\n                                                      text_renderer,\n                                                      links):\n        generate(pyramid_request, notification)\n\n        expected_context = {\n            'document_title': 'My fascinating page',\n            'document_url': 'http://example.org/',\n            'parent': notification.parent,\n            'parent_user': parent_user,\n            'parent_user_url': 'http://example.com/stream/user/patricia',\n            'reply': notification.reply,\n            'reply_url': links.incontext_link.return_value,\n            'reply_user': reply_user,\n            'reply_user_url': 'http://example.com/stream/user/ron',\n            'unsubscribe_url': 'http://example.com/unsub/FAKETOKEN',\n        }\n        html_renderer.assert_(**expected_context)\n        text_renderer.assert_(**expected_context)\n\n    def test_falls_back_to_target_uri_for_document_title(self,\n                                                         notification,\n                                                         pyramid_request,\n                                                         html_renderer,\n                                                         text_renderer):\n        notification.document.title = None\n\n        generate(pyramid_request, notification)\n\n        html_renderer.assert_(document_title='http://example.org/')\n        text_renderer.assert_(document_title='http://example.org/')\n\n    def test_falls_back_to_individual_page_if_no_bouncer(self,\n                                                         notification,\n                                                         parent_user,\n                                                         pyramid_request,\n                                                         reply_user,\n                                                         html_renderer,\n                                                         text_renderer,\n                                                         links):\n        \"\"\"\n        It link to individual pages if bouncer isn't available.\n\n        If bouncer isn't enabled direct links in reply notification emails\n        should fall back to linking to the reply's individual page, instead of\n        the bouncer direct link.\n\n        \"\"\"\n        # incontext_link() returns None if bouncer isn't available.\n        links.incontext_link.return_value = None\n\n        generate(pyramid_request, notification)\n\n        expected_context = {\n            'document_title': 'My fascinating page',\n            'document_url': 'http://example.org/',\n            'parent': notification.parent,\n            'parent_user': parent_user,\n            'reply_user_url': 'http://example.com/stream/user/patricia',\n            'reply': notification.reply,\n            'reply_url': 'http://example.com/ann/bar456',\n            'reply_user': reply_user,\n            'reply_user_url': 'http://example.com/stream/user/ron',\n            'unsubscribe_url': 'http://example.com/unsub/FAKETOKEN',\n        }\n        html_renderer.assert_(**expected_context)\n        text_renderer.assert_(**expected_context)\n\n    def test_returns_text_and_body_results_from_renderers(self,\n                                                          notification,\n                                                          pyramid_request,\n                                                          html_renderer,\n                                                          text_renderer):\n        html_renderer.string_response = 'HTML output'\n        text_renderer.string_response = 'Text output'\n\n        _, _, text, html = generate(pyramid_request, notification)\n\n        assert html == 'HTML output'\n        assert text == 'Text output'\n\n    def test_returns_subject_with_reply_username(self, notification, pyramid_request):\n        _, subject, _, _ = generate(pyramid_request, notification)\n\n        assert subject == 'ron has replied to your annotation'\n\n    def test_returns_parent_email_as_recipients(self, notification, pyramid_request):\n        recipients, _, _, _ = generate(pyramid_request, notification)\n\n        assert recipients == ['pat@ric.ia']\n\n    def test_calls_token_serializer_with_correct_arguments(self,\n                                                           notification,\n                                                           pyramid_request,\n                                                           token_serializer):\n        generate(pyramid_request, notification)\n\n        token_serializer.dumps.assert_called_once_with({\n            'type': 'reply',\n            'uri': 'acct:patricia@example.com',\n        })\n\n    def test_jinja_templates_render(self,\n                                    notification,\n                                    pyramid_config,\n                                    pyramid_request):\n        \"\"\"Ensure that the jinja templates don't contain syntax errors\"\"\"\n        pyramid_config.include('pyramid_jinja2')\n        pyramid_config.add_jinja2_extension('h.jinja_extensions.Filters')\n\n        generate(pyramid_request, notification)\n\n    @pytest.fixture\n    def document(self, db_session):\n        doc = Document(title='My fascinating page')\n        db_session.add(doc)\n        db_session.flush()\n        return doc\n\n    @pytest.fixture\n    def html_renderer(self, pyramid_config):\n        return pyramid_config.testing_add_renderer('h:templates/emails/reply_notification.html.jinja2')\n\n    @pytest.fixture\n    def links(self, patch):\n        return patch('h.emails.reply_notification.links')\n\n    @pytest.fixture\n    def notification(self, reply, reply_user, parent, parent_user, document):\n        return Notification(reply=reply,\n                            reply_user=reply_user,\n                            parent=parent,\n                            parent_user=parent_user,\n                            document=document)\n\n    @pytest.fixture\n    def parent(self):\n        common = {\n            'id': 'foo123',\n            'created': datetime.datetime.utcnow(),\n            'updated': datetime.datetime.utcnow(),\n            'text': 'Foo is true',\n        }\n        return Annotation(target_uri='http://example.org/', **common)\n\n    @pytest.fixture\n    def parent_user(self, factories):\n        return factories.User(username='patricia', email='pat@ric.ia')\n\n    @pytest.fixture\n    def reply(self):\n        common = {\n            'id': 'bar456',\n            'created': datetime.datetime.utcnow(),\n            'updated': datetime.datetime.utcnow(),\n            'text': 'No it is not!',\n        }\n        return Annotation(target_uri='http://example.org/', **common)\n\n    @pytest.fixture\n    def reply_user(self, factories):\n        return factories.User(username='ron', email='ron@thesmiths.com')\n\n    @pytest.fixture\n    def routes(self, pyramid_config):\n        pyramid_config.add_route('annotation', '/ann/{id}')\n        pyramid_config.add_route('stream.user_query', '/stream/user/{user}')\n        pyramid_config.add_route('unsubscribe', '/unsub/{token}')\n\n    @pytest.fixture\n    def text_renderer(self, pyramid_config):\n        return pyramid_config.testing_add_renderer('h:templates/emails/reply_notification.txt.jinja2')\n\n    @pytest.fixture\n    def token_serializer(self, pyramid_config):\n        serializer = mock.Mock(spec_set=['dumps'])\n        serializer.dumps.return_value = 'FAKETOKEN'\n        pyramid_config.registry.notification_serializer = serializer\n        return serializer\n"},{"size":784,"relativepath":"tests/h/exceptions_test.py","filename":"exceptions_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom h.exceptions import APIError, ClientUnauthorized\n\n\nclass TestAPIError(object):\n    def test_message(self):\n        exc = APIError('some message')\n\n        assert exc.message == 'some message'\n\n    def test_default_status_code(self):\n        exc = APIError('some message')\n\n        assert exc.status_code == 500\n\n    def test_custom_status_code(self):\n        exc = APIError('some message', status_code=418)\n\n        assert exc.status_code == 418\n\n\nclass TestClientUnauthorized(object):\n    def test_message(self):\n        exc = ClientUnauthorized()\n\n        assert 'credentials are invalid' in exc.message\n\n    def test_status_code(self):\n        exc = ClientUnauthorized()\n\n        assert exc.status_code == 403\n"},{"size":11879,"relativepath":"tests/h/views/groups_test.py","filename":"groups_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport deform\nimport mock\nimport pytest\nfrom pyramid.httpexceptions import (HTTPMovedPermanently, HTTPNoContent,\n                                    HTTPSeeOther)\n\nfrom h.views import groups as views\nfrom h.models import (Group, User)\n\n\n@pytest.mark.usefixtures('groups_service', 'handle_form_submission', 'routes')\nclass TestGroupCreateController(object):\n\n    def test_get_renders_form(self, controller):\n        controller.form = form_validating_to({})\n\n        result = controller.get()\n\n        assert result == {'form': 'valid form'}\n\n    def test_post_calls_handle_form_submission(self,\n                                               controller,\n                                               handle_form_submission,\n                                               matchers):\n        controller.post()\n\n        handle_form_submission.assert_called_once_with(\n            controller.request,\n            controller.form,\n            matchers.any_callable(),\n            matchers.any_callable(),\n        )\n\n    def test_post_returns_handle_form_submission(self,\n                                                 controller,\n                                                 handle_form_submission):\n        assert controller.post() == handle_form_submission.return_value\n\n    def test_post_creates_new_group_if_form_valid(self,\n                                                  controller,\n                                                  groups_service,\n                                                  handle_form_submission,\n                                                  pyramid_config):\n        pyramid_config.testing_securitypolicy('ariadna')\n\n        # If the form submission is valid then handle_form_submission() should\n        # call on_success() with the appstruct.\n        def call_on_success(request, form, on_success, on_failure):\n            on_success({'name': 'my_new_group', 'description': 'foobar'})\n        handle_form_submission.side_effect = call_on_success\n\n        controller.post()\n\n        assert groups_service.created == [('my_new_group', 'ariadna', 'foobar')]\n\n    def test_post_creates_new_group_if_legacy_form_valid(self,\n                                                         controller,\n                                                         groups_service,\n                                                         handle_form_submission,\n                                                         pyramid_config):\n        pyramid_config.testing_securitypolicy('ariadna')\n\n        # If the form submission is valid then handle_form_submission() should\n        # call on_success() with the appstruct.\n        def call_on_success(request, form, on_success, on_failure):\n            on_success({'name': 'my_new_group'})\n        handle_form_submission.side_effect = call_on_success\n\n        controller.post()\n\n        assert groups_service.created == [('my_new_group', 'ariadna', None)]\n\n    def test_post_redirects_if_form_valid(self,\n                                          controller,\n                                          handle_form_submission,\n                                          matchers):\n        # If the form submission is valid then handle_form_submission() should\n        # return the redirect that on_success() returns.\n        def return_on_success(request, form, on_success, on_failure):\n            return on_success({'name': 'my_new_group'})\n        handle_form_submission.side_effect = return_on_success\n\n        assert controller.post() == matchers.redirect_303_to(\n            '/g/abc123/fake-group')\n\n    def test_post_does_not_create_group_if_form_invalid(self,\n                                                        controller,\n                                                        groups_service,\n                                                        handle_form_submission):\n        # If the form submission is invalid then handle_form_submission() should\n        # call on_failure().\n        def call_on_failure(request, form, on_success, on_failure):\n            on_failure()\n        handle_form_submission.side_effect = call_on_failure\n\n        controller.post()\n\n        assert groups_service.created == []\n\n    def test_post_returns_template_data_if_form_invalid(self,\n                                                        controller,\n                                                        handle_form_submission):\n        # If the form submission is invalid then handle_form_submission() should\n        # return the template data that on_failure() returns.\n        def return_on_failure(request, form, on_success, on_failure):\n            return on_failure()\n        handle_form_submission.side_effect = return_on_failure\n\n        assert controller.post() == {'form': controller.form.render.return_value}\n\n    @pytest.fixture\n    def controller(self, pyramid_request):\n        return views.GroupCreateController(pyramid_request)\n\n    @pytest.fixture\n    def handle_form_submission(self, patch):\n        return patch('h.views.groups.form.handle_form_submission')\n\n\n@pytest.mark.usefixtures('routes')\nclass TestGroupEditController(object):\n\n    def test_get_reads_group_properties(self, pyramid_request):\n        pyramid_request.create_form.return_value = FakeForm()\n\n        creator = User(username='luke', authority='example.org')\n        group = Group(name='Birdwatcher Community',\n                      description='We watch birds all day long',\n                      creator=creator)\n        group.pubid = 'the-test-pubid'\n\n        result = views.GroupEditController(group, pyramid_request).get()\n\n        assert result == {\n            'form': {\n                'name': 'Birdwatcher Community',\n                'description': 'We watch birds all day long',\n            },\n            'group_path': '/g/the-test-pubid/birdwatcher-community'\n        }\n\n    def test_post_sets_group_properties(self, form_validating_to, pyramid_request):\n        creator = User(username='luke', authority='example.org')\n        group = Group(name='Birdwatcher Community',\n                      description='We watch birds all day long',\n                      creator=creator)\n        group.pubid = 'the-test-pubid'\n\n        controller = views.GroupEditController(group, pyramid_request)\n        controller.form = form_validating_to({\n            'name': 'Alligatorwatcher Comm.',\n            'description': 'We are all about the alligators now',\n        })\n        controller.post()\n\n        assert group.name == 'Alligatorwatcher Comm.'\n        assert group.description == 'We are all about the alligators now'\n\n\n@pytest.mark.usefixtures('groups_service', 'routes')\nclass TestGroupRead(object):\n    def test_redirects_if_slug_incorrect(self, pyramid_request):\n        group = FakeGroup('abc123', 'some-slug')\n        pyramid_request.matchdict['slug'] = 'another-slug'\n\n        with pytest.raises(HTTPMovedPermanently) as exc:\n            views.read(group, pyramid_request)\n\n        assert exc.value.location == '/g/abc123/some-slug'\n\n    def test_returns_template_context(self, patch, pyramid_request):\n        group = FakeGroup('abc123', 'some-slug')\n        group.documents = lambda: ['d1', 'd2']\n        link = patch('h.presenters.DocumentHTMLPresenter.link',\n                     autospec=None,\n                     new_callable=mock.PropertyMock)\n        link.side_effect = ['link1', 'link2']\n        pyramid_request.matchdict['slug'] = 'some-slug'\n\n        result = views.read(group, pyramid_request)\n\n        assert result['group'] == group\n        assert result['document_links'] == ['link1', 'link2']\n\n    def test_renders_join_template_if_not_member(self,\n                                                 pyramid_config,\n                                                 pyramid_request):\n        group = FakeGroup('abc123', 'some-slug')\n        pyramid_config.testing_securitypolicy('bohus', permissive=False)\n        pyramid_request.matchdict['slug'] = 'some-slug'\n\n        result = views.read(group, pyramid_request)\n\n        assert 'join.html' in pyramid_request.override_renderer\n        assert result == {'group': group}\n\n\n@pytest.mark.usefixtures('routes')\nclass TestGroupReadUnauthenticated(object):\n    def test_redirects_if_slug_incorrect(self, pyramid_request):\n        group = FakeGroup('abc123', 'some-slug')\n        pyramid_request.matchdict['slug'] = 'another-slug'\n\n        with pytest.raises(HTTPMovedPermanently) as exc:\n            views.read_unauthenticated(group, pyramid_request)\n\n        assert exc.value.location == '/g/abc123/some-slug'\n\n    def test_returns_template_context(self, pyramid_request):\n        group = FakeGroup('abc123', 'some-slug')\n        pyramid_request.matchdict['slug'] = 'some-slug'\n\n        result = views.read_unauthenticated(group, pyramid_request)\n\n        assert result == {'group': group}\n\n\n@pytest.mark.usefixtures('routes')\ndef test_read_noslug_redirects(pyramid_request):\n    group = FakeGroup('abc123', 'some-slug')\n\n    with pytest.raises(HTTPMovedPermanently) as exc:\n        views.read_noslug(group, pyramid_request)\n\n    assert exc.value.location == '/g/abc123/some-slug'\n\n\n@pytest.mark.usefixtures('groups_service', 'routes')\nclass TestGroupJoin(object):\n    def test_joins_group(self,\n                         groups_service,\n                         pyramid_config,\n                         pyramid_request):\n        group = FakeGroup('abc123', 'some-slug')\n        pyramid_config.testing_securitypolicy('gentiana')\n\n        views.join(group, pyramid_request)\n\n        assert (group, 'gentiana') in groups_service.joined\n\n    def test_redirects_to_group_page(self, pyramid_request):\n        group = FakeGroup('abc123', 'some-slug')\n\n        result = views.join(group, pyramid_request)\n\n        assert isinstance(result, HTTPSeeOther)\n        assert result.location == '/g/abc123/some-slug'\n\n\n@pytest.mark.usefixtures('groups_service', 'routes')\nclass TestGroupLeave(object):\n    def test_leaves_group(self,\n                          groups_service,\n                          pyramid_config,\n                          pyramid_request):\n        group = FakeGroup('abc123', 'some-slug')\n        pyramid_config.testing_securitypolicy('marcela')\n\n        views.leave(group, pyramid_request)\n\n        assert (group, 'marcela') in groups_service.left\n\n    def test_returns_nocontent(self, pyramid_request):\n        group = FakeGroup('abc123', 'some-slug')\n\n        result = views.leave(group, pyramid_request)\n\n        assert isinstance(result, HTTPNoContent)\n\n\nclass FakeGroup(object):\n    def __init__(self, pubid, slug):\n        self.pubid = pubid\n        self.slug = slug\n\n\nclass FakeGroupsService(object):\n    def __init__(self):\n        self.created = []\n        self.joined = []\n        self.left = []\n\n    def create(self, name, userid, description):\n        self.created.append((name, userid, description))\n        return FakeGroup('abc123', 'fake-group')\n\n    def member_join(self, group, userid):\n        self.joined.append((group, userid))\n\n    def member_leave(self, group, userid):\n        self.left.append((group, userid))\n\n\nclass FakeForm(object):\n    def set_appstruct(self, appstruct):\n        self.appstruct = appstruct\n\n    def render(self):\n        return self.appstruct\n\n\ndef form_validating_to(appstruct):\n    form = mock.Mock()\n    form.validate.return_value = appstruct\n    form.render.return_value = 'valid form'\n    return form\n\n\ndef invalid_form():\n    form = mock.Mock()\n    form.validate.side_effect = deform.ValidationFailure(None, None, None)\n    form.render.return_value = 'invalid form'\n    return form\n\n\n@pytest.fixture\ndef groups_service(pyramid_config):\n    service = FakeGroupsService()\n    pyramid_config.register_service(service, name='groups')\n    return service\n\n\n@pytest.fixture\ndef routes(pyramid_config):\n    pyramid_config.add_route('group_read', '/g/{pubid}/{slug}')\n"},{"size":4569,"relativepath":"tests/h/views/api_users_test.py","filename":"api_users_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\nfrom mock import Mock\n\nfrom h.accounts.services import UserSignupService\nfrom h.exceptions import ClientUnauthorized\nfrom h.views.api_users import create\n\n\n@pytest.mark.usefixtures('auth_client',\n                         'basic_auth_creds',\n                         'user_signup_service')\nclass TestCreate(object):\n\n    def test_returns_user_object(self,\n                                 auth_client,\n                                 basic_auth_creds,\n                                 factories,\n                                 pyramid_request,\n                                 user_signup_service,\n                                 valid_payload):\n        basic_auth_creds.return_value = (auth_client.id, auth_client.secret)\n        pyramid_request.json_body = valid_payload\n        user_signup_service.signup.return_value = factories.User(**valid_payload)\n\n        result = create(pyramid_request)\n\n        assert result == {\n            'userid': 'acct:jeremy@weylandindustries.com',\n            'username': 'jeremy',\n            'email': 'jeremy@weylandtech.com',\n            'authority': 'weylandindustries.com',\n        }\n\n    def test_signs_up_user(self,\n                           auth_client,\n                           basic_auth_creds,\n                           factories,\n                           pyramid_request,\n                           user_signup_service,\n                           valid_payload):\n        basic_auth_creds.return_value = (auth_client.id, auth_client.secret)\n        pyramid_request.json_body = valid_payload\n        user_signup_service.signup.return_value = factories.User(**valid_payload)\n\n        create(pyramid_request)\n\n        user_signup_service.signup.assert_called_once_with(\n            require_activation=False,\n            authority='weylandindustries.com',\n            username='jeremy',\n            email='jeremy@weylandtech.com')\n\n    def test_raises_when_no_creds(self, pyramid_request, valid_payload):\n        pyramid_request.json_body = valid_payload\n\n        with pytest.raises(ClientUnauthorized):\n            create(pyramid_request)\n\n    def test_raises_when_malformed_client_id(self,\n                                             basic_auth_creds,\n                                             pyramid_request,\n                                             valid_payload):\n        basic_auth_creds.return_value = ('foobar', 'somerandomsecret')\n        pyramid_request.json_body = valid_payload\n\n        with pytest.raises(ClientUnauthorized):\n            create(pyramid_request)\n\n    def test_raises_when_no_client(self,\n                                   basic_auth_creds,\n                                   pyramid_request,\n                                   valid_payload):\n        basic_auth_creds.return_value = ('C69BA868-5089-4EE4-ABB6-63A1C38C395B',\n                                         'somerandomsecret')\n        pyramid_request.json_body = valid_payload\n\n        with pytest.raises(ClientUnauthorized):\n            create(pyramid_request)\n\n    def test_raises_when_client_secret_invalid(self,\n                                               auth_client,\n                                               basic_auth_creds,\n                                               pyramid_request,\n                                               valid_payload):\n        basic_auth_creds.return_value = (auth_client.id, 'incorrectsecret')\n        pyramid_request.json_body = valid_payload\n\n        with pytest.raises(ClientUnauthorized):\n            create(pyramid_request)\n\n\n@pytest.fixture\ndef auth_client(factories):\n    return factories.AuthClient(authority='weylandindustries.com')\n\n\n@pytest.fixture\ndef basic_auth_creds(patch):\n    basic_auth_creds = patch('h.views.api_users.basic_auth_creds')\n    basic_auth_creds.return_value = None\n    return basic_auth_creds\n\n\n@pytest.fixture\ndef user_signup_service(db_session, factories, pyramid_config):\n    service = Mock(spec_set=UserSignupService(default_authority='example.com',\n                                              mailer=None,\n                                              session=None,\n                                              signup_email=None,\n                                              stats=None))\n    pyramid_config.register_service(service, name='user_signup')\n    return service\n\n\n@pytest.fixture\ndef valid_payload():\n    return {\n        'authority': 'weylandindustries.com',\n        'email': 'jeremy@weylandtech.com',\n        'username': 'jeremy',\n    }\n"},{"size":41698,"relativepath":"tests/h/views/accounts_test.py","filename":"accounts_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n# pylint: disable=no-self-use\n\nimport mock\nimport pytest\n\nimport deform\nfrom pyramid import httpexceptions\n\nfrom h import accounts\nfrom h.views import accounts as views\n\n\nclass FakeForm(object):\n    def set_appstruct(self, appstruct):\n        self.appstruct = appstruct\n\n    def render(self):\n        return self.appstruct\n\n\nclass FakeSubscription(object):\n    def __init__(self, type_, active):\n        self.type = type_\n        self.active = active\n\n\nclass FakeSerializer(object):\n    def dumps(self, obj):\n        return 'faketoken'\n\n    def loads(self, token):\n        return {'username': 'foo@bar.com'}\n\n\n@pytest.mark.usefixtures('routes')\nclass TestBadCSRFTokenHTML(object):\n    def test_it_returns_login_with_root_next_as_default(self, pyramid_request):\n        pyramid_request.referer = None\n        result = views.bad_csrf_token_html(None, pyramid_request)\n\n        assert result['login_path'] == '/login?next=%2F'\n\n    def test_it_returns_login_with_referer_path_as_next(self, pyramid_request):\n        pyramid_request.referer = 'http://' + \\\n                                  pyramid_request.domain + \\\n                                  '/account/settings'\n\n        result = views.bad_csrf_token_html(None, pyramid_request)\n\n        assert result['login_path'] == '/login?next=%2Faccount%2Fsettings'\n\n    def test_it_returns_login_with_root_when_hostnames_are_different(self, pyramid_request):\n        pyramid_request.domain = 'example.org'\n        pyramid_request.referer = 'http://example.com/account/settings'\n\n        result = views.bad_csrf_token_html(None, pyramid_request)\n\n        assert result['login_path'] == '/login?next=%2F'\n\n    @pytest.fixture\n    def routes(self, pyramid_config):\n        pyramid_config.add_route('login', '/login')\n\n\n@pytest.mark.usefixtures('routes')\nclass TestAuthController(object):\n\n    def test_post_redirects_when_logged_in(self, pyramid_config, pyramid_request):\n        pyramid_config.testing_securitypolicy(\"acct:jane@doe.org\")\n\n        with pytest.raises(httpexceptions.HTTPFound):\n            views.AuthController(pyramid_request).post()\n\n    def test_post_redirects_to_next_param_when_logged_in(self, pyramid_config, pyramid_request):\n        pyramid_request.params = {'next': '/foo/bar'}\n        pyramid_config.testing_securitypolicy(\"acct:jane@doe.org\")\n\n        with pytest.raises(httpexceptions.HTTPFound) as e:\n            views.AuthController(pyramid_request).post()\n\n        assert e.value.location == '/foo/bar'\n\n    def test_post_returns_form_when_validation_fails(self,\n                                                     invalid_form,\n                                                     pyramid_config,\n                                                     pyramid_request):\n        pyramid_config.testing_securitypolicy(None)  # Logged out\n        controller = views.AuthController(pyramid_request)\n        controller.form = invalid_form()\n\n        result = controller.post()\n\n        assert result == {'form': 'invalid form'}\n\n    @mock.patch('h.views.accounts.LoginEvent', autospec=True)\n    def test_post_no_event_when_validation_fails(self,\n                                                 loginevent,\n                                                 invalid_form,\n                                                 notify,\n                                                 pyramid_config,\n                                                 pyramid_request):\n        pyramid_config.testing_securitypolicy(None)  # Logged out\n        controller = views.AuthController(pyramid_request)\n        controller.form = invalid_form()\n\n        controller.post()\n\n        assert not loginevent.called\n        assert not notify.called\n\n    def test_post_redirects_when_validation_succeeds(self,\n                                                     factories,\n                                                     form_validating_to,\n                                                     pyramid_config,\n                                                     pyramid_request):\n        pyramid_config.testing_securitypolicy(None)  # Logged out\n        controller = views.AuthController(pyramid_request)\n        controller.form = form_validating_to({\"user\": factories.User(username='cara')})\n\n        result = controller.post()\n\n        assert isinstance(result, httpexceptions.HTTPFound)\n\n    def test_post_redirects_to_next_param_when_validation_succeeds(self,\n                                                                   factories,\n                                                                   form_validating_to,\n                                                                   pyramid_config,\n                                                                   pyramid_request):\n        pyramid_request.params = {'next': '/foo/bar'}\n        pyramid_config.testing_securitypolicy(None)  # Logged out\n        controller = views.AuthController(pyramid_request)\n        controller.form = form_validating_to({\"user\": factories.User(username='cara')})\n\n        result = controller.post()\n\n        assert isinstance(result, httpexceptions.HTTPFound)\n        assert result.location == '/foo/bar'\n\n    @mock.patch('h.views.accounts.LoginEvent', autospec=True)\n    def test_post_event_when_validation_succeeds(self,\n                                                 loginevent,\n                                                 factories,\n                                                 form_validating_to,\n                                                 notify,\n                                                 pyramid_config,\n                                                 pyramid_request):\n        pyramid_config.testing_securitypolicy(None)  # Logged out\n        elephant = factories.User(username='avocado')\n        controller = views.AuthController(pyramid_request)\n        controller.form = form_validating_to({\"user\": elephant})\n\n        controller.post()\n\n        loginevent.assert_called_with(pyramid_request, elephant)\n        notify.assert_called_with(loginevent.return_value)\n\n    @mock.patch('h.views.accounts.LogoutEvent', autospec=True)\n    def test_logout_event(self, logoutevent, notify, pyramid_config, pyramid_request):\n        pyramid_config.testing_securitypolicy(\"acct:jane@doe.org\")\n\n        views.AuthController(pyramid_request).logout()\n\n        logoutevent.assert_called_with(pyramid_request)\n        notify.assert_called_with(logoutevent.return_value)\n\n    def test_logout_invalidates_session(self, pyramid_config, pyramid_request):\n        pyramid_request.session[\"foo\"] = \"bar\"\n        pyramid_config.testing_securitypolicy(\"acct:jane@doe.org\")\n\n        views.AuthController(pyramid_request).logout()\n\n        assert \"foo\" not in pyramid_request.session\n\n    def test_logout_redirects(self, pyramid_request):\n        result = views.AuthController(pyramid_request).logout()\n\n        assert isinstance(result, httpexceptions.HTTPFound)\n\n    def test_logout_response_has_forget_headers(self, pyramid_config, pyramid_request):\n        pyramid_config.testing_securitypolicy(forget_result={\n            'x-erase-fingerprints': 'on the hob'\n        })\n\n        result = views.AuthController(pyramid_request).logout()\n\n        assert result.headers['x-erase-fingerprints'] == 'on the hob'\n\n    @pytest.fixture\n    def routes(self, pyramid_config):\n        pyramid_config.add_route('forgot_password', '/forgot')\n        pyramid_config.add_route('index', '/index')\n        pyramid_config.add_route('stream', '/stream')\n\n\n@pytest.mark.usefixtures('session')\nclass TestAjaxAuthController(object):\n\n    def test_login_returns_status_okay_when_validation_succeeds(self,\n                                                                factories,\n                                                                form_validating_to,\n                                                                pyramid_request):\n        pyramid_request.json_body = {}\n        controller = views.AjaxAuthController(pyramid_request)\n        controller.form = form_validating_to({'user': factories.User(username='bob')})\n\n        result = controller.login()\n\n        assert result['status'] == 'okay'\n\n    def test_login_raises_JSONError_on_non_json_body(self, pyramid_request):\n        type(pyramid_request).json_body = {}\n        with mock.patch.object(type(pyramid_request),\n                               'json_body',\n                               new_callable=mock.PropertyMock) as json_body:\n            json_body.side_effect = ValueError()\n\n            controller = views.AjaxAuthController(pyramid_request)\n\n            with pytest.raises(accounts.JSONError) as exc_info:\n                controller.login()\n                assert exc_info.value.message.startswith(\n                    'Could not parse request body as JSON: ')\n\n    def test_login_raises_JSONError_on_non_object_json(self, pyramid_request):\n        pyramid_request.authenticated_user = mock.Mock(groups=[])\n        pyramid_request.json_body = 'foo'\n\n        controller = views.AjaxAuthController(pyramid_request)\n        expected_message = 'Request JSON body must have a top-level object'\n\n        with pytest.raises(accounts.JSONError) as exc_info:\n            controller.login()\n\n        assert exc_info.value.message == expected_message\n\n    def test_login_converts_non_string_usernames_to_strings(self, pyramid_csrf_request):\n        for input_, expected_output in ((None, ''),\n                                        (23, '23'),\n                                        (True, 'True')):\n            pyramid_csrf_request.json_body = {'username': input_,\n                                              'password': 'pass'}\n            controller = views.AjaxAuthController(pyramid_csrf_request)\n            controller.form.validate = mock.Mock(\n                return_value={'user': mock.Mock()})\n\n            controller.login()\n\n            assert controller.form.validate.called\n            pstruct = controller.form.validate.call_args[0][0]\n            assert sorted(pstruct) == sorted([('username', expected_output),\n                                              ('password', 'pass')])\n\n    def test_login_converts_non_string_passwords_to_strings(self, pyramid_csrf_request):\n        for input_, expected_output in ((None, ''),\n                                        (23, '23'),\n                                        (True, 'True')):\n            pyramid_csrf_request.json_body = {'username': 'user',\n                                              'password': input_}\n            controller = views.AjaxAuthController(pyramid_csrf_request)\n            controller.form.validate = mock.Mock(\n                return_value={'user': mock.Mock()})\n\n            controller.login()\n\n            assert controller.form.validate.called\n            pstruct = controller.form.validate.call_args[0][0]\n            assert sorted(pstruct) == sorted([('username', 'user'),\n                                              ('password', expected_output)])\n\n    def test_login_raises_ValidationFailure_on_ValidationFailure(self,\n                                                                 invalid_form,\n                                                                 pyramid_request):\n        pyramid_request.json_body = {}\n        controller = views.AjaxAuthController(pyramid_request)\n        controller.form = invalid_form({'password': 'too short'})\n\n        with pytest.raises(deform.ValidationFailure) as exc_info:\n            controller.login()\n\n        assert exc_info.value.error.asdict() == {'password': 'too short'}\n\n    def test_logout_returns_status_okay(self, pyramid_request):\n        result = views.AjaxAuthController(pyramid_request).logout()\n\n        assert result['status'] == 'okay'\n\n\n@pytest.mark.usefixtures('activation_model',\n                         'mailer',\n                         'routes')\nclass TestForgotPasswordController(object):\n\n    def test_post_returns_form_when_validation_fails(self,\n                                                     invalid_form,\n                                                     pyramid_request):\n        controller = views.ForgotPasswordController(pyramid_request)\n        controller.form = invalid_form()\n\n        result = controller.post()\n\n        assert result == {'form': 'invalid form'}\n\n    def test_post_creates_no_activations_when_validation_fails(self,\n                                                               activation_model,\n                                                               invalid_form,\n                                                               pyramid_request):\n        controller = views.ForgotPasswordController(pyramid_request)\n        controller.form = invalid_form()\n\n        controller.post()\n\n        assert activation_model.call_count == 0\n\n    @mock.patch('h.views.accounts.account_reset_link')\n    def test_post_generates_reset_link(self,\n                                       reset_link,\n                                       factories,\n                                       form_validating_to,\n                                       pyramid_request):\n        pyramid_request.registry.password_reset_serializer = FakeSerializer()\n        user = factories.User(username='giraffe', email='giraffe@thezoo.org')\n        controller = views.ForgotPasswordController(pyramid_request)\n        controller.form = form_validating_to({\"user\": user})\n\n        controller.post()\n\n        reset_link.assert_called_with(pyramid_request, \"faketoken\")\n\n    @mock.patch('h.views.accounts.account_reset_email')\n    @mock.patch('h.views.accounts.account_reset_link')\n    def test_post_generates_mail(self,\n                                 reset_link,\n                                 reset_mail,\n                                 activation_model,\n                                 factories,\n                                 form_validating_to,\n                                 pyramid_request):\n        pyramid_request.registry.password_reset_serializer = FakeSerializer()\n        user = factories.User(username='giraffe', email='giraffe@thezoo.org')\n        controller = views.ForgotPasswordController(pyramid_request)\n        controller.form = form_validating_to({\"user\": user})\n        reset_link.return_value = \"http://example.com\"\n        reset_mail.return_value = {\n            'recipients': [],\n            'subject': '',\n            'body': ''\n        }\n\n        controller.post()\n\n        reset_mail.assert_called_with(user, \"faketoken\", \"http://example.com\")\n\n    @mock.patch('h.views.accounts.account_reset_email')\n    def test_post_sends_mail(self,\n                             reset_mail,\n                             factories,\n                             form_validating_to,\n                             mailer,\n                             pyramid_request):\n        pyramid_request.registry.password_reset_serializer = FakeSerializer()\n        user = factories.User(username='giraffe', email='giraffe@thezoo.org')\n        controller = views.ForgotPasswordController(pyramid_request)\n        controller.form = form_validating_to({\"user\": user})\n        reset_mail.return_value = {\n            'recipients': ['giraffe@thezoo.org'],\n            'subject': 'subject',\n            'body': 'body'\n        }\n\n        controller.post()\n\n        mailer.send.delay.assert_called_once_with(recipients=['giraffe@thezoo.org'],\n                                                  subject='subject',\n                                                  body='body')\n\n    def test_post_redirects_on_success(self,\n                                       factories,\n                                       form_validating_to,\n                                       pyramid_request):\n        pyramid_request.registry.password_reset_serializer = FakeSerializer()\n        user = factories.User(username='giraffe', email='giraffe@thezoo.org')\n        controller = views.ForgotPasswordController(pyramid_request)\n        controller.form = form_validating_to({\"user\": user})\n\n        result = controller.post()\n\n        assert isinstance(result, httpexceptions.HTTPRedirection)\n\n    def test_get_redirects_when_logged_in(self, pyramid_config, pyramid_request):\n        pyramid_config.testing_securitypolicy(\"acct:jane@doe.org\")\n\n        with pytest.raises(httpexceptions.HTTPFound):\n            views.ForgotPasswordController(pyramid_request).get()\n\n    @pytest.fixture\n    def routes(self, pyramid_config):\n        pyramid_config.add_route('index', '/index')\n        pyramid_config.add_route('account_reset', '/account/reset')\n        pyramid_config.add_route('account_reset_with_code', '/account/reset-with-code')\n\n\n@pytest.mark.usefixtures('routes')\nclass TestResetController(object):\n\n    def test_post_returns_form_when_validation_fails(self,\n                                                     invalid_form,\n                                                     pyramid_request):\n        controller = views.ResetController(pyramid_request)\n        controller.form = invalid_form()\n\n        result = controller.post()\n\n        assert result == {'form': 'invalid form'}\n\n    def test_post_sets_user_password_from_form(self,\n                                               factories,\n                                               form_validating_to,\n                                               pyramid_request):\n        elephant = factories.User(password='password1')\n        controller = views.ResetController(pyramid_request)\n        controller.form = form_validating_to({'user': elephant,\n                                              'password': 's3cure!'})\n\n        controller.post()\n\n        assert elephant.check_password('s3cure!')\n\n    @mock.patch('h.views.accounts.PasswordResetEvent', autospec=True)\n    def test_post_emits_event(self,\n                              event,\n                              factories,\n                              form_validating_to,\n                              notify,\n                              pyramid_request):\n        user = factories.User(password='password1')\n        controller = views.ResetController(pyramid_request)\n        controller.form = form_validating_to({'user': user,\n                                              'password': 's3cure!'})\n\n        controller.post()\n\n        event.assert_called_with(pyramid_request, user)\n        notify.assert_called_with(event.return_value)\n\n    def test_post_redirects_on_success(self,\n                                       factories,\n                                       form_validating_to,\n                                       pyramid_request):\n        user = factories.User(password='password1')\n        controller = views.ResetController(pyramid_request)\n        controller.form = form_validating_to({'user': user,\n                                              'password': 's3cure!'})\n\n        result = controller.post()\n\n        assert isinstance(result, httpexceptions.HTTPRedirection)\n\n    @pytest.fixture\n    def routes(self, pyramid_config):\n        pyramid_config.add_route('index', '/index')\n        pyramid_config.add_route('login', '/login')\n        pyramid_config.add_route('account_reset', '/reset')\n        pyramid_config.add_route('account_reset_with_code', '/reset-with-code')\n\n\n@pytest.mark.usefixtures('pyramid_config',\n                         'routes',\n                         'user_signup_service')\nclass TestSignupController(object):\n\n    def test_post_returns_errors_when_validation_fails(self,\n                                                       invalid_form,\n                                                       pyramid_request):\n        controller = views.SignupController(pyramid_request)\n        controller.form = invalid_form()\n\n        result = controller.post()\n\n        assert result == {\"form\": \"invalid form\"}\n\n    def test_post_creates_user_from_form_data(self,\n                                              form_validating_to,\n                                              pyramid_request,\n                                              user_signup_service):\n        controller = views.SignupController(pyramid_request)\n        controller.form = form_validating_to({\n            \"username\": \"bob\",\n            \"email\": \"bob@example.com\",\n            \"password\": \"s3crets\",\n            \"random_other_field\": \"something else\",\n        })\n\n        controller.post()\n\n        user_signup_service.signup.assert_called_with(username=\"bob\",\n                                                      email=\"bob@example.com\",\n                                                      password=\"s3crets\")\n\n    def test_post_does_not_create_user_when_validation_fails(self,\n                                                             invalid_form,\n                                                             pyramid_request,\n                                                             user_signup_service):\n        controller = views.SignupController(pyramid_request)\n        controller.form = invalid_form()\n\n        controller.post()\n\n        assert not user_signup_service.signup.called\n\n    def test_post_redirects_on_success(self,\n                                       form_validating_to,\n                                       pyramid_request):\n        controller = views.SignupController(pyramid_request)\n        controller.form = form_validating_to({\n            \"username\": \"bob\",\n            \"email\": \"bob@example.com\",\n            \"password\": \"s3crets\",\n        })\n\n        result = controller.post()\n\n        assert isinstance(result, httpexceptions.HTTPRedirection)\n\n    def test_get_redirects_when_logged_in(self, pyramid_config, pyramid_request):\n        pyramid_config.testing_securitypolicy(\"acct:jane@doe.org\")\n        controller = views.SignupController(pyramid_request)\n\n        with pytest.raises(httpexceptions.HTTPRedirection):\n            controller.get()\n\n    @pytest.fixture\n    def routes(self, pyramid_config):\n        pyramid_config.add_route('index', '/index')\n        pyramid_config.add_route('stream', '/stream')\n\n\n@pytest.mark.usefixtures('ActivationEvent',\n                         'activation_model',\n                         'notify',\n                         'routes',\n                         'user_model')\nclass TestActivateController(object):\n\n    def test_get_when_not_logged_in_404s_if_id_not_int(self, pyramid_request):\n        pyramid_request.matchdict = {'id': 'abc',  # Not an int.\n                                     'code': 'abc456'}\n\n        with pytest.raises(httpexceptions.HTTPNotFound):\n            views.ActivateController(pyramid_request).get_when_not_logged_in()\n\n    def test_get_when_not_logged_in_looks_up_activation_by_code(\n            self,\n            activation_model,\n            pyramid_request,\n            user_model):\n        pyramid_request.matchdict = {'id': '123', 'code': 'abc456'}\n        user_model.get_by_activation.return_value.id = 123\n\n        views.ActivateController(pyramid_request).get_when_not_logged_in()\n\n        activation_model.get_by_code.assert_called_with(pyramid_request.db, 'abc456')\n\n    def test_get_when_not_logged_in_redirects_if_activation_not_found(\n            self,\n            activation_model,\n            pyramid_request):\n        \"\"\"\n\n        If the activation code doesn't match any activation then we redirect to\n        the front page and flash a message suggesting that they may already be\n        activated and can log in.\n\n        This happens if a user clicks on an activation link from an email after\n        they've already been activated, for example.\n\n        (This also happens if users visit a bogus activation URL, but we're\n        happy to do this same redirect in that edge case.)\n\n        \"\"\"\n        pyramid_request.matchdict = {'id': '123', 'code': 'abc456'}\n        activation_model.get_by_code.return_value = None\n\n        result = views.ActivateController(pyramid_request).get_when_not_logged_in()\n        error_flash = pyramid_request.session.peek_flash('error')\n\n        assert isinstance(result, httpexceptions.HTTPFound)\n        assert error_flash\n        assert error_flash[0].startswith(\"We didn't recognize that activation link.\")\n\n    def test_get_when_not_logged_in_looks_up_user_by_activation(\n            self,\n            activation_model,\n            pyramid_request,\n            user_model):\n        pyramid_request.matchdict = {'id': '123', 'code': 'abc456'}\n        user_model.get_by_activation.return_value.id = 123\n\n        views.ActivateController(pyramid_request).get_when_not_logged_in()\n\n        user_model.get_by_activation.assert_called_once_with(\n            pyramid_request.db,\n            activation_model.get_by_code.return_value)\n\n    def test_get_when_not_logged_in_404s_if_user_not_found(self, pyramid_request, user_model):\n        pyramid_request.matchdict = {'id': '123', 'code': 'abc456'}\n        user_model.get_by_activation.return_value = None\n\n        with pytest.raises(httpexceptions.HTTPNotFound):\n            views.ActivateController(pyramid_request).get_when_not_logged_in()\n\n    def test_get_when_not_logged_in_404s_if_user_id_does_not_match_hash(\n            self,\n            pyramid_request,\n            user_model):\n        \"\"\"\n\n        We don't want to let a user with a valid hash activate a different\n        user's account!\n\n        \"\"\"\n        pyramid_request.matchdict = {'id': '123', 'code': 'abc456'}\n        user_model.get_by_activation.return_value.id = 2  # Not the same id.\n\n        with pytest.raises(httpexceptions.HTTPNotFound):\n            views.ActivateController(pyramid_request).get_when_not_logged_in()\n\n    def test_get_when_not_logged_in_successful_activates_user(\n            self,\n            pyramid_request,\n            user_model):\n        pyramid_request.matchdict = {'id': '123', 'code': 'abc456'}\n        pyramid_request.db.delete = mock.create_autospec(pyramid_request.db.delete,\n                                                         return_value=None)\n        user_model.get_by_activation.return_value.id = 123\n\n        views.ActivateController(pyramid_request).get_when_not_logged_in()\n\n        user_model.get_by_activation.return_value.activate.assert_called_once_with()\n\n    def test_get_when_not_logged_in_successful_flashes_message(self,\n                                                               pyramid_request,\n                                                               user_model):\n        pyramid_request.matchdict = {'id': '123', 'code': 'abc456'}\n        user_model.get_by_activation.return_value.id = 123\n\n        views.ActivateController(pyramid_request).get_when_not_logged_in()\n        success_flash = pyramid_request.session.peek_flash('success')\n\n        assert success_flash\n        assert success_flash[0].startswith(\"Your account has been activated\")\n\n    def test_get_when_not_logged_in_successful_creates_ActivationEvent(\n            self,\n            pyramid_request,\n            user_model,\n            ActivationEvent):\n        pyramid_request.matchdict = {'id': '123', 'code': 'abc456'}\n        user_model.get_by_activation.return_value.id = 123\n\n        views.ActivateController(pyramid_request).get_when_not_logged_in()\n\n        ActivationEvent.assert_called_once_with(\n            pyramid_request, user_model.get_by_activation.return_value)\n\n    def test_get_when_not_logged_in_successful_notifies(self,\n                                                        notify,\n                                                        pyramid_request,\n                                                        user_model,\n                                                        ActivationEvent):\n        pyramid_request.matchdict = {'id': '123', 'code': 'abc456'}\n        user_model.get_by_activation.return_value.id = 123\n\n        views.ActivateController(pyramid_request).get_when_not_logged_in()\n\n        notify.assert_called_once_with(ActivationEvent.return_value)\n\n    def test_get_when_logged_in_already_logged_in_when_id_not_an_int(self, pyramid_request):\n        pyramid_request.authenticated_user = mock.Mock(id=123, spec=['id'])\n        pyramid_request.matchdict = {'id': 'abc',  # Not an int.\n                                     'code': 'abc456'}\n\n        with pytest.raises(httpexceptions.HTTPNotFound):\n            views.ActivateController(pyramid_request).get_when_logged_in()\n\n    def test_get_when_logged_in_already_logged_in_to_same_account(self, pyramid_request):\n        pyramid_request.authenticated_user = mock.Mock(id=123, spec=['id'])\n        pyramid_request.matchdict = {'id': '123',\n                                     'code': 'abc456'}\n\n        result = views.ActivateController(pyramid_request).get_when_logged_in()\n        success_flash = pyramid_request.session.peek_flash('success')\n\n        assert isinstance(result, httpexceptions.HTTPFound)\n        assert success_flash\n        assert success_flash[0].startswith(\n            \"Your account has been activated and you're logged in\")\n\n    def test_get_when_logged_in_already_logged_in_to_different_account(self, pyramid_request):\n        pyramid_request.authenticated_user = mock.Mock(id=124, spec=['id'])\n        pyramid_request.matchdict = {'id': '123',\n                                     'code': 'abc456'}\n\n        result = views.ActivateController(pyramid_request).get_when_logged_in()\n        error_flash = pyramid_request.session.peek_flash('error')\n\n        assert isinstance(result, httpexceptions.HTTPFound)\n        assert error_flash\n        assert error_flash[0].startswith(\n            \"You're already logged in to a different account\")\n\n    @pytest.fixture\n    def routes(self, pyramid_config):\n        pyramid_config.add_route('index', '/index')\n        pyramid_config.add_route('login', '/login')\n        pyramid_config.add_route('logout', '/logout')\n\n\n@pytest.mark.usefixtures('routes')\nclass TestAccountController(object):\n\n    def test_post_email_form_with_valid_data_changes_email(self,\n                                                           form_validating_to,\n                                                           pyramid_request):\n        controller = views.AccountController(pyramid_request)\n        controller.forms['email'] = form_validating_to({\n            'email': 'new_email_address'})\n\n        controller.post_email_form()\n\n        assert pyramid_request.authenticated_user.email == 'new_email_address'\n\n    def test_post_email_form_with_invalid_data_does_not_change_email(\n            self, invalid_form, pyramid_request):\n        controller = views.AccountController(pyramid_request)\n        controller.forms['email'] = invalid_form()\n        original_email = pyramid_request.authenticated_user.email\n\n        controller.post_email_form()\n\n        assert pyramid_request.authenticated_user.email == original_email\n\n    def test_post_email_form_with_invalid_data_returns_template_data(\n            self, invalid_form, pyramid_request):\n        controller = views.AccountController(pyramid_request)\n        controller.forms['email'] = invalid_form()\n\n        result = controller.post_email_form()\n\n        assert result == {\n            'email': pyramid_request.authenticated_user.email,\n            'email_form': controller.forms['email'].render(),\n            'password_form': controller.forms['password'].render(),\n        }\n\n    def test_post_password_form_with_valid_data_changes_password(\n            self, form_validating_to, pyramid_request):\n        controller = views.AccountController(pyramid_request)\n        controller.forms['password'] = form_validating_to({\n            'new_password': 'my_new_password'})\n\n        controller.post_password_form()\n\n        assert pyramid_request.authenticated_user.check_password('my_new_password')\n\n    def test_post_password_form_with_invalid_data_does_not_change_password(\n            self, invalid_form, pyramid_request):\n        user = pyramid_request.authenticated_user\n        user.password = 'original password'\n        controller = views.AccountController(pyramid_request)\n        controller.forms['password'] = invalid_form()\n\n        controller.post_password_form()\n\n        assert user.check_password('original password')\n\n    def test_post_password_form_with_invalid_data_returns_template_data(\n            self, invalid_form, pyramid_request):\n        controller = views.AccountController(pyramid_request)\n        controller.forms['password'] = invalid_form()\n\n        result = controller.post_password_form()\n\n        assert result == {\n            'email': pyramid_request.authenticated_user.email,\n            'email_form': controller.forms['email'].render(),\n            'password_form': controller.forms['password'].render(),\n        }\n\n    @pytest.fixture\n    def pyramid_request(self, factories, pyramid_request):\n        pyramid_request.POST = {}\n        pyramid_request.authenticated_user = factories.User()\n        return pyramid_request\n\n    @pytest.fixture\n    def routes(self, pyramid_config):\n        pyramid_config.add_route('account', '/my/account')\n\n\n@pytest.mark.usefixtures('pyramid_config',\n                         'routes',\n                         'subscriptions_model')\nclass TestNotificationsController(object):\n\n    def test_get_sets_subscriptions_data_in_form(self,\n                                                 form_validating_to,\n                                                 pyramid_config,\n                                                 pyramid_request,\n                                                 subscriptions_model):\n        pyramid_config.testing_securitypolicy('fiona')\n        subscriptions_model.get_subscriptions_for_uri.return_value = [\n            FakeSubscription('reply', True),\n            FakeSubscription('foo', False),\n        ]\n        controller = views.NotificationsController(pyramid_request)\n        controller.form = form_validating_to({})\n\n        controller.get()\n\n        controller.form.set_appstruct.assert_called_once_with({\n            'notifications': set(['reply']),\n        })\n\n    def test_post_with_invalid_data_returns_form(self,\n                                                 invalid_form,\n                                                 pyramid_config,\n                                                 pyramid_request):\n        pyramid_request.POST = {}\n        pyramid_config.testing_securitypolicy('jerry')\n        controller = views.NotificationsController(pyramid_request)\n        controller.form = invalid_form()\n\n        result = controller.post()\n\n        assert 'form' in result\n\n    def test_post_with_valid_data_updates_subscriptions(self,\n                                                        form_validating_to,\n                                                        pyramid_config,\n                                                        pyramid_request,\n                                                        subscriptions_model):\n        pyramid_request.POST = {}\n        pyramid_config.testing_securitypolicy('fiona')\n        subs = [\n            FakeSubscription('reply', True),\n            FakeSubscription('foo', False),\n        ]\n        subscriptions_model.get_subscriptions_for_uri.return_value = subs\n        controller = views.NotificationsController(pyramid_request)\n        controller.form = form_validating_to({'notifications': set(['foo'])})\n\n        controller.post()\n\n        assert subs[0].active is False\n        assert subs[1].active is True\n\n    def test_post_with_valid_data_redirects(self,\n                                            form_validating_to,\n                                            pyramid_config,\n                                            pyramid_request,\n                                            subscriptions_model):\n        pyramid_request.POST = {}\n        pyramid_config.testing_securitypolicy('fiona')\n        subscriptions_model.get_subscriptions_for_uri.return_value = []\n        controller = views.NotificationsController(pyramid_request)\n        controller.form = form_validating_to({})\n\n        result = controller.post()\n\n        assert isinstance(result, httpexceptions.HTTPFound)\n\n    @pytest.fixture\n    def routes(self, pyramid_config):\n        pyramid_config.add_route('account_notifications', '/p/notifications')\n\n\nclass TestEditProfileController(object):\n\n    def test_get_reads_user_properties(self, pyramid_request):\n        pyramid_request.authenticated_user = mock.Mock()\n        pyramid_request.create_form.return_value = FakeForm()\n        user = pyramid_request.authenticated_user\n        user.display_name = 'Jim Smith'\n        user.description = 'Job Description'\n        user.orcid = 'ORCID ID'\n        user.uri = 'http://foo.org'\n        user.location = 'Paris'\n\n        result = views.EditProfileController(pyramid_request).get()\n\n        assert result == {\n            'form': {\n                'display_name': 'Jim Smith',\n                'description': 'Job Description',\n                'orcid': 'ORCID ID',\n                'link': 'http://foo.org',\n                'location': 'Paris',\n            }\n        }\n\n    def test_post_sets_user_properties(self, form_validating_to, pyramid_request):\n        pyramid_request.authenticated_user = mock.Mock()\n        user = pyramid_request.authenticated_user\n\n        ctrl = views.EditProfileController(pyramid_request)\n        ctrl.form = form_validating_to({\n            'display_name': 'Jim Smith',\n            'description': 'Job Description',\n            'orcid': 'ORCID ID',\n            'link': 'http://foo.org',\n            'location': 'Paris',\n        })\n        ctrl.post()\n\n        assert user.display_name == 'Jim Smith'\n        assert user.description == 'Job Description'\n        assert user.orcid == 'ORCID ID'\n        assert user.uri == 'http://foo.org'\n        assert user.location == 'Paris'\n\n\n@pytest.mark.usefixtures('models')\nclass TestDeveloperController(object):\n\n    def test_get_gets_token_for_authenticated_userid(self, models, pyramid_request):\n        views.DeveloperController(pyramid_request).get()\n\n        models.Token.get_dev_token_by_userid.assert_called_once_with(\n            pyramid_request.db,\n            pyramid_request.authenticated_userid)\n\n    def test_get_returns_token(self, models, pyramid_request):\n        models.Token.get_dev_token_by_userid.return_value.value = u'abc123'\n\n        data = views.DeveloperController(pyramid_request).get()\n\n        assert data.get('token') == u'abc123'\n\n    def test_get_with_no_token(self, models, pyramid_request):\n        models.Token.get_dev_token_by_userid.return_value = None\n\n        result = views.DeveloperController(pyramid_request).get()\n\n        assert result == {}\n\n    def test_post_gets_token_for_authenticated_userid(self, models, pyramid_request):\n        views.DeveloperController(pyramid_request).post()\n\n        models.Token.get_dev_token_by_userid.assert_called_once_with(\n            pyramid_request.db,\n            pyramid_request.authenticated_userid)\n\n    def test_post_calls_regenerate(self, models, pyramid_request):\n        \"\"\"If the user already has a token it should regenerate it.\"\"\"\n        views.DeveloperController(pyramid_request).post()\n\n        models.Token.get_dev_token_by_userid.return_value.regenerate.assert_called_with()\n\n    def test_post_inits_new_token_for_authenticated_userid(self, models, pyramid_request):\n        \"\"\"If the user doesn't have a token yet it should generate one.\"\"\"\n        models.Token.get_dev_token_by_userid.return_value = None\n\n        views.DeveloperController(pyramid_request).post()\n\n        models.Token.assert_called_once_with(userid=pyramid_request.authenticated_userid)\n\n    def test_post_adds_new_token_to_db(self, models, pyramid_request):\n        \"\"\"If the user doesn't have a token yet it should add one to the db.\"\"\"\n        models.Token.get_dev_token_by_userid.return_value = None\n\n        views.DeveloperController(pyramid_request).post()\n\n        assert models.Token.return_value in pyramid_request.db.added\n\n        models.Token.assert_called_once_with(userid=pyramid_request.authenticated_userid)\n\n    def test_post_returns_token_after_regenerating(self, models, pyramid_request):\n        \"\"\"After regenerating a token it should return its new value.\"\"\"\n        data = views.DeveloperController(pyramid_request).post()\n\n        assert data['token'] == models.Token.get_dev_token_by_userid.return_value.value\n\n    def test_post_returns_token_after_generating(self, models, pyramid_request):\n        \"\"\"After generating a new token it should return its value.\"\"\"\n        models.Token.get_dev_token_by_userid.return_value = None\n\n        data = views.DeveloperController(pyramid_request).post()\n\n        assert data['token'] == models.Token.return_value.value\n\n    @pytest.fixture\n    def pyramid_request(self, pyramid_request, fake_db_session):\n        # Override the database session with a fake session implementation.\n        # FIXME: don't mock models...\n        pyramid_request.db = fake_db_session\n        return pyramid_request\n\n\n@pytest.fixture\ndef session(patch):\n    return patch('h.views.accounts.session')\n\n\n@pytest.fixture\ndef subscriptions_model(patch):\n    return patch('h.models.Subscriptions')\n\n\n@pytest.fixture\ndef user_model(patch):\n    return patch('h.models.User')\n\n\n@pytest.fixture\ndef activation_model(patch):\n    return patch('h.models.Activation')\n\n\n@pytest.fixture\ndef ActivationEvent(patch):\n    return patch('h.views.accounts.ActivationEvent')\n\n\n@pytest.fixture\ndef mailer(patch):\n    return patch('h.views.accounts.mailer')\n\n\n@pytest.fixture\ndef models(patch):\n    return patch('h.views.accounts.models')\n\n\n@pytest.fixture\ndef user_signup_service(pyramid_config):\n    service = mock.Mock(spec_set=['signup'])\n    pyramid_config.register_service(service, name='user_signup')\n    return service\n"},{"size":1422,"relativepath":"tests/h/views/client_test.py","filename":"client_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\nfrom pyramid import exceptions\nfrom pyramid import httpexceptions\n\nfrom h.views import client\n\nannotator_token_fixtures = pytest.mark.usefixtures('generate_jwt', 'session')\n\n\n@annotator_token_fixtures\ndef test_annotator_token_calls_check_csrf_token(pyramid_request, session):\n    client.annotator_token(pyramid_request)\n\n    session.check_csrf_token.assert_called_once_with(pyramid_request)\n\n\n@annotator_token_fixtures\ndef test_annotator_token_raises_Unauthorized_if_check_csrf_token_raises(\n        pyramid_request,\n        session):\n    session.check_csrf_token.side_effect = exceptions.BadCSRFToken\n\n    with pytest.raises(httpexceptions.HTTPUnauthorized):\n        client.annotator_token(pyramid_request)\n\n\n@annotator_token_fixtures\ndef test_annotator_token_calls_generate_jwt(generate_jwt, pyramid_request):\n    client.annotator_token(pyramid_request)\n\n    generate_jwt.assert_called_once_with(pyramid_request, 3600)\n\n\n@annotator_token_fixtures\ndef test_annotator_token_returns_token(generate_jwt, pyramid_request):\n    result = client.annotator_token(pyramid_request)\n\n    assert result == generate_jwt.return_value\n\n\n@pytest.fixture\ndef generate_jwt(patch):\n    func = patch('h.views.client.generate_jwt')\n    func.return_value = 'abc123'\n    return func\n\n\n@pytest.fixture\ndef session(patch):\n    return patch('h.views.client.session')\n"},{"size":513,"relativepath":"tests/h/views/exceptions_test.py","filename":"exceptions_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom h.views.exceptions import notfound, error\n\n\ndef test_notfound_view(pyramid_request):\n    result = notfound(pyramid_request)\n\n    assert pyramid_request.response.status_int == 404\n    assert result == {}\n\n\ndef test_error_view(patch, pyramid_request):\n    handle_exception = patch('h.views.exceptions.handle_exception')\n\n    result = error(pyramid_request)\n\n    handle_exception.assert_called_once_with(pyramid_request)\n    assert result == {}\n"},{"size":1019,"relativepath":"tests/h/views/help_test.py","filename":"help_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\nimport mock\nfrom pyramid import httpexceptions\n\nfrom h.views import help\n\n\n@pytest.mark.usefixtures('routes')\ndef test_welcome_page_redirects_to_new_url(pyramid_request):\n    result = help.onboarding_page({}, pyramid_request)\n    assert isinstance(result, httpexceptions.HTTPFound)\n\n\n@pytest.mark.usefixtures('routes')\ndef test_help_page_returns_is_help_true(pyramid_request):\n    result = help.help_page({}, pyramid_request)\n    assert result['is_help']\n\n\n@pytest.mark.usefixtures('routes')\ndef test_custom_welcome_page(pyramid_request):\n    result = help.custom_onboarding_page({}, pyramid_request)\n    assert not result['is_help']\n    assert result['is_onboarding']\n\n\n@pytest.fixture\ndef routes(pyramid_config):\n    pyramid_config.add_route('help', '/docs/help')\n    pyramid_config.add_route('onboarding', '/welcome/')\n    pyramid_config.add_route('custom_onboarding', '/welcome/{slug}')\n    pyramid_config.add_route('embed', '/embed')\n"},{"size":3475,"relativepath":"tests/h/views/panels_test.py","filename":"panels_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom mock import Mock\nfrom mock import PropertyMock\nimport pytest\n\nfrom h.views import panels\n\n\n@pytest.mark.usefixtures('routes')\nclass TestNavbar(object):\n    def test_it_sets_null_username_when_logged_out(self, req):\n        result = panels.navbar({}, req)\n        assert result['username'] is None\n\n    def test_it_sets_username_when_logged_in(self, req, authenticated_user):\n        req.authenticated_user = authenticated_user\n        result = panels.navbar({}, req)\n\n        assert result['username'] == 'vannevar'\n\n    def test_it_lists_groups_when_logged_in(self, req, authenticated_user):\n        req.authenticated_user = authenticated_user\n        result = panels.navbar({}, req)\n\n        titles = [group.name for group in authenticated_user.groups]\n\n        assert result['groups_menu_items'] == [\n            {'title': titles[0], 'link': 'http://example.com/groups/id1/first'},\n            {'title': titles[1], 'link': 'http://example.com/groups/id2/second'},\n        ]\n\n    def test_username_url_when_logged_in(self, req, authenticated_user):\n        req.authenticated_user = authenticated_user\n        result = panels.navbar({}, req)\n\n        assert result['username_url'] == 'http://example.com/search?q=user:vannevar'\n\n    def test_it_includes_search_query(self, req):\n        req.params['q'] = 'tag:question'\n        result = panels.navbar({}, req)\n\n        assert result['q'] == 'tag:question'\n\n    def test_it_includes_search_url_when_on_user_search(self, req):\n        type(req.matched_route).name = PropertyMock(return_value='activity.user_search')\n        req.matchdict = {'username': 'luke'}\n\n        result = panels.navbar({}, req)\n        assert result['search_url'] == 'http://example.com/users/luke/search'\n\n    def test_it_includes_search_url_when_on_group_search(self, req):\n        type(req.matched_route).name = PropertyMock(return_value='activity.group_search')\n        req.matchdict = {'pubid': 'foobar'}\n\n        result = panels.navbar({}, req)\n        assert result['search_url'] == 'http://example.com/groups/foobar/search'\n\n    def test_it_includes_default_search_url(self, req):\n        result = panels.navbar({}, req)\n        assert result['search_url'] == 'http://example.com/search'\n\n    @pytest.fixture\n    def routes(self, pyramid_config):\n        pyramid_config.add_route('account', '/account')\n        pyramid_config.add_route('account_profile', '/account/profile')\n        pyramid_config.add_route('account_notifications', '/account/notifications')\n        pyramid_config.add_route('account_developer', '/account/developer')\n        pyramid_config.add_route('activity.search', '/search')\n        pyramid_config.add_route('activity.user_search', '/users/{username}/search')\n        pyramid_config.add_route('activity.group_search', '/groups/{pubid}/search')\n        pyramid_config.add_route('group_create', '/groups/new')\n        pyramid_config.add_route('group_read', '/groups/:pubid/:slug')\n        pyramid_config.add_route('logout', '/logout')\n\n    @pytest.fixture\n    def authenticated_user(self):\n        groups = [\n            Mock(pubid='id1', slug='first'),\n            Mock(pubid='id2', slug='second'),\n        ]\n        authenticated_user = Mock(username='vannevar', groups=groups)\n        return authenticated_user\n\n    @pytest.fixture\n    def req(self, pyramid_request):\n        pyramid_request.authenticated_user = None\n        return pyramid_request\n"},{"size":2771,"relativepath":"tests/h/views/activity_test.py","filename":"activity_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport pytest\n\nimport mock\nfrom pyramid import httpexceptions\n\nfrom h.views.activity import PAGE_SIZE\nfrom h.views.activity import search\n\n\n# The search view is just a skeleton at the moment, the only part we should\n# test at the moment is that it returns a 404 response when the feature flag\n# is turned off.\nclass TestSearch(object):\n    def test_it_returns_404_when_feature_turned_off(self, pyramid_request):\n        pyramid_request.feature.flags['search_page'] = False\n\n        with pytest.raises(httpexceptions.HTTPNotFound):\n            search(pyramid_request)\n\n    def test_it_checks_for_redirects(self, pyramid_request, query):\n        pyramid_request.feature.flags['search_page'] = True\n\n        search(pyramid_request)\n\n        query.check_url.assert_called_once_with(pyramid_request,\n                                                query.extract.return_value)\n\n    def test_it_executes_a_search_query(self, pyramid_request, query):\n        pyramid_request.feature.flags['search_page'] = True\n\n        search(pyramid_request)\n\n        query.execute.assert_called_once_with(pyramid_request,\n                                              query.extract.return_value,\n                                              page_size=PAGE_SIZE)\n\n    def test_it_allows_to_specify_the_page_size(self, pyramid_request, query):\n        pyramid_request.feature.flags['search_page'] = True\n\n        pyramid_request.params['page_size'] = 100\n        search(pyramid_request)\n\n        query.execute.assert_called_once_with(pyramid_request,\n                                              query.extract.return_value,\n                                              page_size=100)\n\n    def test_it_uses_default_page_size_when_value_is_a_string(self, pyramid_request, query):\n        pyramid_request.feature.flags['search_page'] = True\n\n        pyramid_request.params['page_size'] = 'foobar'\n        search(pyramid_request)\n\n        query.execute.assert_called_once_with(pyramid_request,\n                                              query.extract.return_value,\n                                              page_size=PAGE_SIZE)\n\n    @pytest.mark.usefixtures('query')\n    def test_is_uses_passed_in_page_size_for_pagination(self, pyramid_request, paginate):\n        pyramid_request.feature.flags['search_page'] = True\n\n        pyramid_request.params['page_size'] = 100\n        search(pyramid_request)\n\n        paginate.assert_called_once_with(pyramid_request,\n                                         mock.ANY,\n                                         page_size=100)\n\n    @pytest.fixture\n    def query(self, patch):\n        return patch('h.views.activity.query')\n\n    @pytest.fixture\n    def paginate(self, patch):\n        return patch('h.views.activity.paginate')\n"},{"size":2646,"relativepath":"tests/h/views/notification_test.py","filename":"notification_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\nimport pytest\n\nfrom h.models import Subscriptions\nfrom h.views.notification import unsubscribe\n\n\n@pytest.mark.usefixtures('subscriptions', 'token_serializer')\nclass TestUnsubscribe(object):\n\n    def test_deserializes_token(self, pyramid_request, token_serializer):\n        pyramid_request.matchdict = {'token': 'wibble'}\n\n        unsubscribe(pyramid_request)\n\n        token_serializer.loads.assert_called_once_with('wibble')\n\n    def test_successfully_unsubscribes_user(self, pyramid_request, subscriptions, token_serializer):\n        sub1, _, _ = subscriptions\n        pyramid_request.matchdict = {'token': 'wibble'}\n        token_serializer.loads.return_value = {'type': 'reply', 'uri': 'acct:foo@example.com'}\n\n        unsubscribe(pyramid_request)\n\n        assert not sub1.active\n\n    def test_ignores_other_subscriptions(self, pyramid_request, subscriptions, token_serializer):\n        _, sub2, sub3 = subscriptions\n        pyramid_request.matchdict = {'token': 'wibble'}\n        token_serializer.loads.return_value = {'type': 'reply', 'uri': 'acct:foo@example.com'}\n\n        unsubscribe(pyramid_request)\n\n        assert sub2.active\n        assert sub3.active\n\n    def test_multiple_calls_ok(self, pyramid_request, subscriptions, token_serializer):\n        sub1, _, _ = subscriptions\n        pyramid_request.matchdict = {'token': 'wibble'}\n        token_serializer.loads.return_value = {'type': 'reply', 'uri': 'acct:foo@example.com'}\n\n        unsubscribe(pyramid_request)\n        unsubscribe(pyramid_request)\n\n        assert not sub1.active\n\n    def test_raises_not_found_if_token_invalue(self, pyramid_request, token_serializer):\n        from pyramid.exceptions import HTTPNotFound\n        pyramid_request.matchdict = {'token': 'wibble'}\n        token_serializer.loads.side_effect = ValueError('token invalid')\n\n        with pytest.raises(HTTPNotFound):\n            unsubscribe(pyramid_request)\n\n    @pytest.fixture\n    def subscriptions(self, db_session):\n        subs = [\n            Subscriptions(type='reply', uri='acct:foo@example.com', active=True),\n            Subscriptions(type='dingo', uri='acct:foo@example.com', active=True),\n            Subscriptions(type='reply', uri='acct:bar@example.com', active=True),\n        ]\n        db_session.add_all(subs)\n        db_session.flush()\n        return subs\n\n    @pytest.fixture\n    def token_serializer(self, pyramid_config):\n        serializer = mock.Mock(spec_set=['loads'])\n        serializer.loads.return_value = {'type': 'matches', 'uri': 'nothing'}\n        pyramid_config.registry.notification_serializer = serializer\n        return serializer\n"},{"size":1317,"relativepath":"tests/h/views/badge_test.py","filename":"badge_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\nimport mock\n\nfrom pyramid import httpexceptions\n\nfrom h.views.badge import badge\n\n\nbadge_fixtures = pytest.mark.usefixtures('models', 'search_lib')\n\n\n@badge_fixtures\ndef test_badge_returns_number_from_search(models, search_run):\n    request = mock.Mock(params={'uri': 'test_uri'})\n    models.Blocklist.is_blocked.return_value = False\n    search_run.return_value = mock.Mock(total=29)\n\n    result = badge(request)\n\n    search_run.assert_called_once_with({'uri': 'test_uri', 'limit': 0})\n    assert result == {'total': 29}\n\n\n@badge_fixtures\ndef test_badge_returns_0_if_blocked(models, search_run):\n    request = mock.Mock(params={'uri': 'test_uri'})\n    models.Blocklist.is_blocked.return_value = True\n    search_run.return_value = {'total': 29}\n\n    result = badge(request)\n\n    assert not search_run.called\n    assert result == {'total': 0}\n\n\n@badge_fixtures\ndef test_badge_raises_if_no_uri():\n    with pytest.raises(httpexceptions.HTTPBadRequest):\n        badge(mock.Mock(params={}))\n\n\n@pytest.fixture\ndef models(patch):\n    return patch('h.views.badge.models')\n\n\n@pytest.fixture\ndef search_lib(patch):\n    return patch('h.views.badge.search')\n\n\n@pytest.fixture\ndef search_run(search_lib):\n    return search_lib.Search.return_value.run\n"},{"size":982,"relativepath":"tests/h/views/api_exceptions_test.py","filename":"api_exceptions_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom h.exceptions import APIError\nfrom h.views.api_exceptions import api_notfound, api_error, json_error\n\n\ndef test_api_notfound_view(pyramid_request):\n    result = api_notfound(pyramid_request)\n\n    assert pyramid_request.response.status_int == 404\n    assert result['status'] == 'failure'\n    assert result['reason']\n\n\ndef test_api_error_view(pyramid_request):\n    context = APIError(message='asplosions!', status_code=418)\n\n    result = api_error(context, pyramid_request)\n\n    assert pyramid_request.response.status_code == 418\n    assert result['status'] == 'failure'\n    assert result['reason'] == 'asplosions!'\n\n\ndef test_json_error_view(patch, pyramid_request):\n    handle_exception = patch('h.views.api_exceptions.handle_exception')\n\n    result = json_error(pyramid_request)\n\n    handle_exception.assert_called_once_with(pyramid_request)\n    assert result['status'] == 'failure'\n    assert result['reason']\n"},{"size":3415,"relativepath":"tests/h/views/feeds_test.py","filename":"feeds_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport mock\nimport pytest\n\nfrom h.views.feeds import stream_atom, stream_rss\n\n\n@pytest.mark.usefixtures('fetch_ordered_annotations',\n                         'render_atom',\n                         'search_run',\n                         'routes')\nclass TestStreamAtom(object):\n\n    def test_renders_atom(self, pyramid_request, render_atom):\n        stream_atom(pyramid_request)\n\n        render_atom.assert_called_once_with(request=pyramid_request,\n                                            annotations=mock.sentinel.fetched_annotations,\n                                            atom_url='http://example.com/thestream.atom',\n                                            html_url='http://example.com/thestream',\n                                            title='Some feed',\n                                            subtitle='It contains stuff')\n\n    def test_returns_rendered_atom(self, pyramid_request, render_atom):\n        result = stream_atom(pyramid_request)\n\n        assert result == render_atom.return_value\n\n\n@pytest.mark.usefixtures('fetch_ordered_annotations',\n                         'render_rss',\n                         'search_run',\n                         'routes')\nclass TestStreamRSS(object):\n\n    def test_renders_rss(self, pyramid_request, render_rss):\n        stream_rss(pyramid_request)\n\n        render_rss.assert_called_once_with(request=pyramid_request,\n                                           annotations=mock.sentinel.fetched_annotations,\n                                           rss_url='http://example.com/thestream.rss',\n                                           html_url='http://example.com/thestream',\n                                           title='Some feed',\n                                           description='Stuff and things')\n\n    def test_returns_rendered_rss(self, pyramid_request, render_rss):\n        result = stream_rss(pyramid_request)\n\n        assert result == render_rss.return_value\n\n\n@pytest.fixture\ndef fetch_ordered_annotations(patch):\n    fetch_ordered_annotations = patch('h.views.feeds.fetch_ordered_annotations')\n    fetch_ordered_annotations.return_value = mock.sentinel.fetched_annotations\n    return fetch_ordered_annotations\n\n\n@pytest.fixture\ndef pyramid_settings(pyramid_settings):\n    settings = {}\n    settings.update(pyramid_settings)\n    settings.update({\n        'h.feed.title': 'Some feed',\n        'h.feed.subtitle': 'It contains stuff',\n        'h.feed.description': 'Stuff and things',\n    })\n    return settings\n\n\n@pytest.fixture\ndef render_atom(patch):\n    return patch('h.views.feeds.render_atom')\n\n\n@pytest.fixture\ndef render_rss(patch):\n    return patch('h.views.feeds.render_rss')\n\n\n@pytest.fixture\ndef routes(pyramid_config):\n    pyramid_config.add_route('stream_atom', '/thestream.atom')\n    pyramid_config.add_route('stream_rss', '/thestream.rss')\n    pyramid_config.add_route('stream', '/thestream')\n\n\n@pytest.fixture\ndef search(patch):\n    return patch('h.views.feeds.search')\n\n\n@pytest.fixture\ndef search_run(search):\n    from memex.search.core import SearchResult\n    result = SearchResult(total=123,\n                          annotation_ids=['foo', 'bar'],\n                          reply_ids=[],\n                          aggregations={})\n    search_run = search.Search.return_value.run\n    search_run.return_value = result\n    return search_run\n"},{"size":489,"relativepath":"tests/h/feeds/util_test.py","filename":"util_test.py","extension":".py","content":"import datetime\n\nimport mock\n\nfrom h.feeds import util\n\n\ndef test_tag_uri_for_annotation(factories):\n    \"\"\"Entry IDs should be tag URIs based on domain, day and annotation ID.\"\"\"\n    annotation = factories.Annotation(\n        created=datetime.datetime(year=2015, month=3, day=19))\n\n    tag_uri = util.tag_uri_for_annotation(\n        annotation,\n        annotation_url=mock.Mock(return_value=\"http://example.com/a/12345\"))\n\n    assert tag_uri == \"tag:example.com,2015-09:\" + annotation.id\n"},{"size":6970,"relativepath":"tests/h/feeds/atom_test.py","filename":"atom_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n# pylint: disable=protected-access\n\"\"\"Unit tests for h/atom.py.\"\"\"\nfrom datetime import datetime\nimport mock\n\nfrom memex import models\nfrom h.feeds import atom\n\n\ndef _annotation(**kwargs):\n    args = {\n        'userid': 'acct:janebloggs@hypothes.is',\n        'created': datetime.utcnow(),\n        'updated': datetime.utcnow(),\n        'target_selectors': [],\n        'document': models.Document(),\n    }\n    args.update(kwargs)\n    return models.Annotation(**args)\n\n\ndef test_feed_id():\n    feed = atom.feed_from_annotations([], 'atom_url', mock.Mock())\n\n    assert feed['id'] == 'atom_url'\n\n\ndef test_feed_title():\n    feed = atom.feed_from_annotations([], mock.Mock(), mock.Mock(),\n                                      title='foo')\n\n    assert feed['title'] == 'foo'\n\n\ndef test_feed_subtitle():\n    feed = atom.feed_from_annotations([], mock.Mock(), mock.Mock(),\n                                      subtitle='bar')\n\n    assert feed['subtitle'] == 'bar'\n\n\n@mock.patch('h.feeds.atom._feed_entry_from_annotation')\ndef test_feed_contains_entries(_feed_entry_from_annotation, factories):\n    \"\"\"The feed should contain an entry for each annotation.\"\"\"\n    annotations = [\n        factories.Annotation(), factories.Annotation(), factories.Annotation()]\n    annotations_url_function = mock.Mock()\n    annotations_api_url_function = mock.Mock()\n    entries = [\n        \"feed entry for annotation 1\",\n        \"feed entry for annotation 2\",\n        \"feed entry for annotation 3\"\n    ]\n    def pop(*args, **kwargs):\n        return entries.pop(0)\n    _feed_entry_from_annotation.side_effect = pop\n\n    feed = atom.feed_from_annotations(\n        annotations, annotations_url_function, annotations_api_url_function)\n\n    assert feed['entries'] == [\n        \"feed entry for annotation 1\",\n        \"feed entry for annotation 2\",\n        \"feed entry for annotation 3\"\n    ]\n\n\ndef test_atom_url_link():\n    \"\"\"The feed should contain a link to its Atom URL.\"\"\"\n    feed = atom.feed_from_annotations([], 'atom_url', mock.Mock())\n\n    assert feed['links'][0] == {\n        'rel': 'self', 'type': 'application/atom+xml', 'href': 'atom_url'}\n\n\ndef test_html_url_link():\n    \"\"\"The feed should contain a link to its corresponding HTML page.\"\"\"\n    feed = atom.feed_from_annotations(\n        [], mock.Mock(), mock.Mock(), html_url='html_url')\n\n    assert feed['links'][1] == {\n        'rel': 'alternate', 'type': 'text/html', 'href': 'html_url'}\n\n\n@mock.patch(\"h.feeds.util\")\ndef test_entry_id(util, factories):\n    \"\"\"The ids of feed entries should come from tag_uri_for_annotation().\"\"\"\n    annotation = factories.Annotation()\n    annotations_url_function = lambda annotation: \"annotation url\"\n\n    feed = atom.feed_from_annotations(\n        [annotation], \"atom_url\", annotations_url_function)\n\n    util.tag_uri_for_annotation.assert_called_once_with(\n        annotation, annotations_url_function)\n    assert feed['entries'][0]['id'] == util.tag_uri_for_annotation.return_value\n\n\ndef test_entry_author(factories):\n    \"\"\"The authors of entries should come from the annotation usernames.\"\"\"\n    annotation = factories.Annotation(userid='acct:nobu@hypothes.is')\n\n    feed = atom.feed_from_annotations(\n        [annotation], \"atom_url\", lambda annotation: \"annotation url\")\n\n    assert feed['entries'][0]['author']['name'] == 'nobu'\n\n\ndef test_entry_title(factories):\n    \"\"\"The titles of feed entries should come from annotation.title.\"\"\"\n    with mock.patch(\"h.feeds.atom.presenters.AnnotationHTMLPresenter.title\",\n                    new_callable=mock.PropertyMock) as mock_title:\n        annotation = factories.Annotation()\n\n        feed = atom.feed_from_annotations(\n            [annotation], \"atom_url\", lambda annotation: \"annotation url\")\n\n        mock_title.assert_called_once_with()\n        assert feed['entries'][0]['title'] == mock_title.return_value\n\n\ndef test_entry_updated():\n    \"\"\"The updated times of entries should come from the annotations.\"\"\"\n    annotation = _annotation(\n        updated=datetime(year=2016, month=2, day=29, hour=16, minute=39, second=12, microsecond=537626))\n\n    feed = atom.feed_from_annotations(\n        [annotation], \"atom_url\", lambda annotation: \"annotation url\")\n\n    assert feed['entries'][0]['updated'] == '2016-02-29T16:39:12.537626+00:00'\n\n\ndef test_entry_published():\n    \"\"\"The published times of entries should come from the annotations.\"\"\"\n    annotation = _annotation(\n        created=datetime(year=2016, month=5, day=31, hour=12, minute=15, second=45, microsecond=537626))\n\n    feed = atom.feed_from_annotations(\n        [annotation], \"atom_url\", lambda annotation: \"annotation url\")\n\n    assert feed['entries'][0]['published'] == '2016-05-31T12:15:45.537626+00:00'\n\n\ndef test_entry_content(factories):\n    \"\"\"The contents of entries come from annotation.description.\"\"\"\n    with mock.patch(\n            \"h.feeds.atom.presenters.AnnotationHTMLPresenter.description\",\n            new_callable=mock.PropertyMock) as mock_description:\n        annotation = factories.Annotation()\n\n        feed = atom.feed_from_annotations(\n            [annotation], \"atom_url\", lambda annotation: \"annotation url\")\n\n        mock_description.assert_called_once_with()\n        assert feed['entries'][0]['content'] == mock_description.return_value\n\n\n@mock.patch('h.feeds.util')\ndef test_annotation_url_links(_, factories):\n    \"\"\"Entries should contain links to the HTML pages for the annotations.\"\"\"\n    annotation = factories.Annotation()\n    annotation_url = mock.Mock()\n\n    feed = atom.feed_from_annotations(\n        [annotation], \"atom_url\", annotation_url)\n\n    annotation_url.assert_called_once_with(annotation)\n    assert feed['entries'][0]['links'][0] == {\n        'rel': 'alternate', 'type': 'text/html',\n        'href': annotation_url.return_value\n    }\n\n\n@mock.patch('h.feeds.util')\ndef test_annotation_api_url_links(_, factories):\n    \"\"\"Entries should contain links to the JSON pages for the annotations.\"\"\"\n    annotation = factories.Annotation()\n    annotation_api_url = mock.Mock()\n\n    feed = atom.feed_from_annotations(\n        [annotation], \"atom_url\", mock.Mock(),\n        annotation_api_url=annotation_api_url)\n\n    annotation_api_url.assert_called_once_with(annotation)\n    assert feed['entries'][0]['links'][1] == {\n        'rel': 'alternate', 'type': 'application/json',\n        'href': annotation_api_url.return_value\n    }\n\n\ndef test_feed_updated():\n    annotations = [\n        _annotation(updated=datetime(year=2015, month=3, day=11, hour=10, minute=45, second=54, microsecond=537626)),\n        _annotation(updated=datetime(year=2015, month=2, day=11, hour=10, minute=43, second=54, microsecond=537626)),\n        _annotation(updated=datetime(year=2015, month=1, day=11, hour=10, minute=43, second=54, microsecond=537626))\n    ]\n\n    feed = atom.feed_from_annotations(\n        annotations, \"atom_url\", lambda annotation: \"annotation url\")\n\n    assert feed['updated'] == '2015-03-11T10:45:54.537626+00:00'\n"},{"size":5537,"relativepath":"tests/h/feeds/rss_test.py","filename":"rss_test.py","extension":".py","content":"import datetime\n\nimport mock\n\nfrom h import models\nfrom h.feeds import rss\n\n\ndef _annotation_url():\n    \"\"\"Return a mock annotation_url() function.\n\n    It just returns a hard-coded URL, enough to make the code that calls this\n    function not crash.\n\n    \"\"\"\n    return mock.Mock(return_value='https://hypothes.is/a/id')\n\n\ndef _annotation(**kwargs):\n    args = {\n        'userid': 'acct:janebloggs@hypothes.is',\n        'target_selectors': [],\n        'created': datetime.datetime.utcnow(),\n        'updated': datetime.datetime.utcnow(),\n        'document': models.Document(),\n    }\n    args.update(**kwargs)\n    return models.Annotation(**args)\n\n\ndef test_feed_from_annotations_item_author():\n    \"\"\"Feed items should include the annotation's author.\"\"\"\n    annotation = _annotation()\n\n    feed = rss.feed_from_annotations(\n        [annotation], _annotation_url(), mock.Mock(), '', '', '')\n\n    assert feed['entries'][0]['author'] == {'name': 'janebloggs'}\n\n\ndef test_feed_annotations_pubDate():\n    \"\"\"It should render the pubDates of annotations correctly.\"\"\"\n    ann = _annotation(created=datetime.datetime(year=2015, month=3, day=11, hour=10, minute=43, second=54))\n\n    feed = rss.feed_from_annotations(\n        [ann], _annotation_url(), mock.Mock(), '', '', '')\n\n    assert feed['entries'][0]['pubDate'] == 'Wed, 11 Mar 2015 10:43:54 +0000'\n\n\ndef test_feed_from_annotations_html_links(factories):\n    \"\"\"Items should include links to the annotations' HTML pages.\"\"\"\n    annotation_url = _annotation_url()\n\n    feed = rss.feed_from_annotations(\n        [factories.Annotation()], annotation_url, mock.Mock(), '', '', '')\n\n    item = feed['entries'][0]\n    assert item['link'] == annotation_url.return_value\n\n\ndef test_feed_from_annotations_item_titles(factories):\n    \"\"\"Feed items should include the annotation's document's title.\"\"\"\n    document = factories.Document(title='Hello, World')\n    annotation = factories.Annotation(document=document)\n\n    feed = rss.feed_from_annotations(\n        [annotation], _annotation_url(), mock.Mock(), '', '', '')\n\n    assert feed['entries'][0]['title'] == annotation.document.title\n\n\ndef test_feed_from_annotations_item_descriptions(factories):\n    \"\"\"Feed items should include a description of the annotation.\"\"\"\n    with mock.patch(\n            \"h.feeds.rss.presenters.AnnotationHTMLPresenter.description\",\n            new_callable=mock.PropertyMock) as description:\n        feed = rss.feed_from_annotations(\n            [factories.Annotation()], _annotation_url(), mock.Mock(), '', '', '')\n\n        assert feed['entries'][0]['description'] == (\n            description.return_value)\n\n\ndef test_feed_from_annotations_item_guid(factories):\n    \"\"\"Feed items should use the annotation's HTML URL as their GUID.\"\"\"\n    annotation = factories.Annotation(\n        created=datetime.datetime(year=2015, month=3, day=11))\n\n    feed = rss.feed_from_annotations(\n        [annotation], _annotation_url(), mock.Mock(), '', '', '')\n\n    assert feed['entries'][0]['guid'] == (\n        'tag:hypothes.is,2015-09:' + annotation.id)\n\n\ndef test_feed_from_annotations_title():\n    \"\"\"The feed should use the given title for its title field.\"\"\"\n    feed = rss.feed_from_annotations(\n        [], _annotation_url(), mock.Mock(), '', 'Hypothesis Stream', '')\n\n    assert feed['title'] == 'Hypothesis Stream'\n\n\ndef test_feed_from_annotations_link():\n    \"\"\"The feed should use the given html_url for its html_url field.\"\"\"\n    feed = rss.feed_from_annotations(\n        [], _annotation_url(), mock.Mock(), 'http://Hypothes.is/stream', '',\n        '')\n\n    assert feed['html_url'] == 'http://Hypothes.is/stream'\n\n\ndef test_feed_from_annotations_description():\n    \"\"\"The feed should use the given description for its description field.\"\"\"\n    feed = rss.feed_from_annotations(\n        [], _annotation_url(), mock.Mock(), '', '', 'The Web. Annotated')\n\n    assert feed['description'] == 'The Web. Annotated'\n\n\ndef test_feed_from_annotations_with_0_annotations():\n    \"\"\"If there are no annotations it should return [] for entries.\"\"\"\n    feed = rss.feed_from_annotations(\n        [], _annotation_url(), mock.Mock(), '', '', '')\n\n    assert feed['entries'] == []\n\n\ndef test_feed_from_annotations_with_1_annotation(factories):\n    \"\"\"If there's 1 annotation it should return 1 entry.\"\"\"\n    feed = rss.feed_from_annotations(\n        [factories.Annotation()], _annotation_url(), mock.Mock(), '', '', '')\n\n    assert len(feed['entries']) == 1\n\n\ndef test_feed_from_annotations_with_3_annotations(factories):\n    \"\"\"If there are 3 annotations it should return 3 entries.\"\"\"\n    annotations = [factories.Annotation(), factories.Annotation(),\n                   factories.Annotation()]\n\n    feed = rss.feed_from_annotations(\n        annotations, _annotation_url(), mock.Mock(), '', '', '')\n\n    assert len(feed['entries']) == 3\n\n\ndef test_feed_from_annotations_pubDate():\n    \"\"\"The pubDate should be the updated time of the most recent annotation.\"\"\"\n    annotations = [\n        _annotation(updated=datetime.datetime(year=2015, month=3, day=11, hour=10, minute=45, second=54, microsecond=537626)),\n        _annotation(updated=datetime.datetime(year=2015, month=2, day=11, hour=10, minute=43, second=54, microsecond=537626)),\n        _annotation(updated=datetime.datetime(year=2015, month=1, day=11, hour=10, minute=43, second=54, microsecond=537626))\n    ]\n\n    feed = rss.feed_from_annotations(\n        annotations, _annotation_url(), mock.Mock(), '', '', '')\n\n    assert feed['pubDate'] == 'Wed, 11 Mar 2015 10:45:54 UTC'\n"},{"size":8934,"relativepath":"tests/h/models/groups_test.py","filename":"groups_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\nimport pytest\n\nfrom pyramid import security\n\nimport memex\nfrom h import models\n\n\ndef test_init(db_session, factories):\n    name = \"My Hypothesis Group\"\n    description = \"This group is awesome\"\n    user = factories.User()\n\n    group = models.Group(name=name, creator=user, description=description)\n    db_session.add(group)\n    db_session.flush()\n\n    assert group.id\n    assert group.name == name\n    assert group.description == description\n    assert group.created\n    assert group.updated\n    assert group.creator == user\n    assert group.creator_id == user.id\n    assert group.members == [user]\n\n\ndef test_with_short_name(factories):\n    \"\"\"Should raise ValueError if name shorter than 4 characters.\"\"\"\n    with pytest.raises(ValueError):\n        models.Group(name=\"abc\", creator=factories.User())\n\n\ndef test_with_long_name(factories):\n    \"\"\"Should raise ValueError if name longer than 25 characters.\"\"\"\n    with pytest.raises(ValueError):\n        models.Group(name=\"abcdefghijklmnopqrstuvwxyz\",\n                     creator=factories.User())\n\n\ndef test_slug(db_session, factories):\n    name = \"My Hypothesis Group\"\n    user = factories.User()\n\n    group = models.Group(name=name, creator=user)\n    db_session.add(group)\n    db_session.flush()\n\n    assert group.slug == \"my-hypothesis-group\"\n\n\ndef test_repr(db_session, factories):\n    name = \"My Hypothesis Group\"\n    user = factories.User()\n\n    group = models.Group(name=name, creator=user)\n    db_session.add(group)\n    db_session.flush()\n\n    assert repr(group) == \"<Group: my-hypothesis-group>\"\n\n\ndef test_created_by(db_session, factories):\n    name_1 = \"My first group\"\n    name_2 = \"My second group\"\n    user = factories.User()\n\n    group_1 = models.Group(name=name_1, creator=user)\n    group_2 = models.Group(name=name_2, creator=user)\n\n    db_session.add(group_1, group_2)\n    db_session.flush()\n\n    assert models.Group.created_by(db_session, user).all() == [group_1, group_2]\n\n\n@pytest.mark.usefixtures('documents')\ndef test_documents_returns_groups_annotated_documents(db_session, group):\n    # Three different documents each with a shared annotation in the group.\n    document_1 = document(db_session, 'http://example.com/document_1')\n    annotation(db_session, document_1, groupid='test-group', shared=True)\n    document_2 = document(db_session, 'http://example.com/document_2')\n    annotation(db_session, document_2, groupid='test-group', shared=True)\n    document_3 = document(db_session, 'http://example.com/document_3')\n    annotation(db_session, document_3, groupid='test-group', shared=True)\n\n    # In this test we don't care about other annotated documents that the\n    # documents fixture might have created before we created our own.\n    # We only care  that the first 3 documents returned are the 3 that we\n    # created, in the right order.\n    assert group.documents()[:3] == [document_3, document_2, document_1]\n\n\ndef test_documents_does_not_return_same_document_twice(documents, group):\n    assert group.documents().count(\n        documents['multiple_shared_annotations']) == 1\n\n\ndef test_documents_does_not_return_privately_annotated_documents(documents,\n                                                                 group):\n    returned_documents = group.documents()\n\n    assert documents['only_private_annotations'] not in returned_documents\n\n\ndef test_documents_returns_documents_both_private_and_shared_annotations(\n        documents, group):\n    returned_documents = group.documents()\n\n    assert documents['private_and_shared_annotations'] in returned_documents\n\n\ndef test_documents_does_not_return_other_groups_documents(documents, group):\n    returned_documents = group.documents()\n\n    assert documents['annotated_by_other_group'] not in returned_documents\n\n\ndef test_documents_returns_documents_annotated_by_this_group_and_another(\n        documents, group):\n    returned = group.documents()\n\n    assert documents['annotated_by_this_group_and_another_group'] in returned\n\n\ndef test_documents_does_not_return_more_than_25_documents(db_session, group):\n    for i in range(50):\n        annotation(db_session,\n                   document(db_session,\n                            'http://example.com/document_' + str(i)),\n                   groupid='test-group',\n                   shared=True)\n\n    assert len(group.documents()) == 25\n\n\ndef test_documents_passing_in_a_custom_limit(db_session, group):\n    \"\"\"It should obey a custom limit if one is passed in.\"\"\"\n    for i in range(50):\n        annotation(db_session,\n                   document(db_session,\n                            'http://example.com/document_' + str(i)),\n                   groupid='test-group',\n                   shared=True)\n\n    for limit in (10, 40):\n        assert len(group.documents(limit=limit)) == limit\n\n\ndef test_documents_when_group_has_no_documents(group):\n    assert group.documents() == []\n\n\ndef test_acl(group, factories):\n    group.pubid = 'testing-pubid'\n    group.creator = factories.User(username='luke', authority='foobar.org')\n\n    assert group.__acl__() == [\n        (security.Allow, 'group:testing-pubid', 'read'),\n        (security.Allow, 'acct:luke@foobar.org', 'admin'),\n        security.DENY_ALL,\n    ]\n\n\ndef annotation(session, document_, groupid, shared):\n    \"\"\"Add a new annotation of the given document to the db and return it.\"\"\"\n    annotation_ = memex.models.Annotation(\n        userid=u'fred', groupid=groupid, shared=shared,\n        target_uri=document_.document_uris[0].uri,\n        document_id=document_.id)\n    session.add(annotation_)\n    return annotation_\n\n\ndef document(session, uri):\n    \"\"\"Add a new Document for the given uri to the db and return it.\"\"\"\n    document_ = memex.models.Document()\n    session.add(document_)\n\n    # Flush the session so that document.id gets generated.\n    session.flush()\n\n    session.add(memex.models.DocumentURI(\n        claimant=uri, document_id=document_.id, uri=uri))\n\n    return document_\n\n\n@pytest.fixture\ndef documents(db_session):\n    \"\"\"Add diverse annotated documents to the db and return them.\"\"\"\n    # Document with one shared annotation.\n    one_shared_annotation = document(db_session,\n                                     'http://example.com/one_shared_annotation')\n    annotation(db_session,\n               one_shared_annotation,\n               groupid='test-group',\n               shared=True)\n\n    # Document with multiple shared annotations.\n    multiple_shared_annotations = document(db_session,\n                                           'http://example.com/multiple_shared_annotations')\n    for _ in range(3):\n        annotation(db_session,\n                   multiple_shared_annotations,\n                   groupid='test-group',\n                   shared=True)\n\n    # Document with only private annotations.\n    only_private_annotations = document(db_session,\n                                        'http://example.com/only_private_annotations')\n    annotation(db_session,\n               only_private_annotations,\n               groupid='test-group',\n               shared=False)\n\n    # Document with both private and shared annotations.\n    private_and_shared_annotations = document(db_session,\n                                              'http://example.com/private_and_shared_annotations')\n    for shared in [True, False]:\n        annotation(db_session,\n                   private_and_shared_annotations,\n                   groupid='test-group',\n                   shared=shared)\n\n    # Document annotated by other group.\n    annotated_by_other_group = document(db_session,\n                                        'http://example.com/annotated_by_other_group')\n    annotation(db_session,\n               annotated_by_other_group,\n               groupid='other-group',\n               shared=True)\n\n    # Document annotated by both this group and another group.\n    annotated_by_this_group_and_another_group = document(db_session,\n                                                         'http://example.com/annotated_by_this_group_and_another_group')\n    for groupid in ['test-group', 'other-group']:\n        annotation(db_session,\n                   annotated_by_this_group_and_another_group,\n                   groupid=groupid,\n                   shared=True)\n\n    return dict(\n        one_shared_annotation=one_shared_annotation,\n        multiple_shared_annotations=multiple_shared_annotations,\n        only_private_annotations=only_private_annotations,\n        private_and_shared_annotations=private_and_shared_annotations,\n        annotated_by_other_group=annotated_by_other_group,\n        annotated_by_this_group_and_another_group=annotated_by_this_group_and_another_group,\n    )\n\n\n@pytest.fixture\ndef group(db_session, factories):\n    \"\"\"Add a new group to the db and return it.\"\"\"\n    group_ = models.Group(name='test-group', creator=factories.User())\n    db_session.add(group_)\n    group_.pubid = 'test-group'\n    return group_\n"},{"size":462,"relativepath":"tests/h/models/auth_client_test.py","filename":"auth_client_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nimport pytest\n\nfrom h.models import AuthClient\n\n\nclass TestAuthClient(object):\n\n    def test_has_id(self, client):\n        assert client.id\n\n    def test_has_secret(self, client):\n        assert client.secret\n\n    @pytest.fixture\n    def client(self, db_session):\n        client = AuthClient(authority='example.com')\n        db_session.add(client)\n        db_session.flush()\n        return client\n"},{"size":1081,"relativepath":"tests/h/models/token_test.py","filename":"token_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom h.models import Token\n\n\nclass TestToken(object):\n    def test_init_generates_value(self):\n        assert Token().value\n\n    def test_get_dev_token_by_userid_filters_by_userid(self, db_session, factories):\n        token_1 = factories.Token(userid='acct:vanessa@example.org', authclient=None)\n        token_2 = factories.Token(userid='acct:david@example.org', authclient=None)\n\n        assert Token.get_dev_token_by_userid(db_session, token_2.userid) == token_2\n\n    def test_get_dev_token_by_userid_only_returns_the_latest_token(self, db_session, factories):\n        token_1 = factories.Token(authclient=None)\n        token_2 = factories.Token(userid=token_1.userid, authclient=None)\n\n        assert Token.get_dev_token_by_userid(db_session, token_1.userid) == token_2\n\n    def test_get_dev_token_by_userid_filters_out_non_dev_tokens(self, db_session, factories):\n        token = factories.Token(authclient=factories.AuthClient())\n\n        assert Token.get_dev_token_by_userid(db_session, token.userid) is None\n"},{"size":2606,"relativepath":"tests/h/models/feature_test.py","filename":"feature_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\nimport pytest\n\nfrom h.models import Feature\n\n\n@pytest.mark.usefixtures('features_override',\n                         'features_pending_removal_override')\nclass TestFeature(object):\n    def test_description_returns_hardcoded_description(self):\n        feat = Feature(name='notification')\n\n        assert feat.description == 'A test flag for testing with.'\n\n    def test_all_creates_annotations_that_dont_exist(self, db_session):\n        features = Feature.all(db_session)\n\n        assert len(features) == 1\n        assert features[0].name == 'notification'\n\n    def test_all_only_returns_current_flags(self, db_session):\n        \"\"\"The .all() method should only return named current feature flags.\"\"\"\n        new, pending, old = [Feature(name='notification'),\n                             Feature(name='abouttoberemoved'),\n                             Feature(name='somethingelse')]\n        db_session.add_all([new, pending, old])\n        db_session.flush()\n\n        features = Feature.all(db_session)\n\n        assert len(features) == 1\n        assert features[0].name == 'notification'\n\n    def test_remove_old_flag_removes_old_flags(self, db_session):\n        \"\"\"\n        The remove_old_flags function should remove unknown flags.\n\n        New flags and flags pending removal should be left alone, but completely\n        unknown flags should be removed.\n        \"\"\"\n        new, pending, old = [Feature(name='notification'),\n                             Feature(name='abouttoberemoved'),\n                             Feature(name='somethingelse')]\n        db_session.add_all([new, pending, old])\n        db_session.flush()\n\n        Feature.remove_old_flags(db_session)\n\n        remaining = set([f.name for f in db_session.query(Feature).all()])\n        assert remaining == {'abouttoberemoved', 'notification'}\n\n    @pytest.fixture\n    def features_override(self, request):\n        # Replace the primary FEATURES dictionary for the duration of testing...\n        patcher = mock.patch.dict('h.models.feature.FEATURES', {\n            'notification': \"A test flag for testing with.\"\n        }, clear=True)\n        patcher.start()\n        request.addfinalizer(patcher.stop)\n\n    @pytest.fixture\n    def features_pending_removal_override(self, request):\n        # And configure 'abouttoberemoved' as a feature pending removal...\n        patcher = mock.patch.dict('h.models.feature.FEATURES_PENDING_REMOVAL', {\n            'abouttoberemoved': \"A test flag that's about to be removed.\"\n        }, clear=True)\n        patcher.start()\n        request.addfinalizer(patcher.stop)\n"},{"size":5988,"relativepath":"tests/h/models/user_test.py","filename":"user_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nimport pytest\nfrom sqlalchemy import exc\n\nfrom h import models\nfrom h.security import password_context\n\n\ndef test_cannot_create_dot_variant_of_user(db_session):\n    fred = models.User(authority='example.com',\n                       username='fredbloggs',\n                       email='fred@example.com')\n    fred2 = models.User(authority='example.com',\n                        username='fred.bloggs',\n                        email='fred@example.org')\n\n    db_session.add(fred)\n    db_session.add(fred2)\n    with pytest.raises(exc.IntegrityError):\n        db_session.flush()\n\n\ndef test_cannot_create_case_variant_of_user(db_session):\n    bob = models.User(authority='example.com',\n                      username='BobJones',\n                      email='bob@example.com')\n    bob2 = models.User(authority='example.com',\n                       username='bobjones',\n                       email='bob@example.org')\n\n    db_session.add(bob)\n    db_session.add(bob2)\n    with pytest.raises(exc.IntegrityError):\n        db_session.flush()\n\n\ndef test_userid_derived_from_username_and_authority():\n    fred = models.User(authority='example.net',\n                       username='fredbloggs',\n                       email='fred@example.com')\n\n    assert fred.userid == 'acct:fredbloggs@example.net'\n\n\ndef test_userid_as_class_property(db_session):\n    fred = models.User(authority='example.net',\n                       username='fredbloggs',\n                       email='fred@example.com')\n    db_session.add(fred)\n    db_session.flush()\n\n    result = (db_session.query(models.User)\n              .filter_by(userid='acct:fredbloggs@example.net')\n              .one())\n\n    assert result == fred\n\n\ndef test_userid_as_class_property_invalid_userid(db_session):\n    # This is to ensure that we don't expose the ValueError that could\n    # potentially be thrown by split_user.\n\n    result = (db_session.query(models.User)\n              .filter_by(userid='fredbloggsexample.net')\n              .all())\n\n    assert result == []\n\n\ndef test_cannot_create_user_with_too_short_username():\n    with pytest.raises(ValueError):\n        models.User(username='aa')\n\n\ndef test_cannot_create_user_with_too_long_username():\n    with pytest.raises(ValueError):\n        models.User(username='1234567890123456789012345678901')\n\n\ndef test_cannot_create_user_with_invalid_chars():\n    with pytest.raises(ValueError):\n        models.User(username='foo-bar')\n\n\ndef test_cannot_create_user_with_too_long_email():\n    with pytest.raises(ValueError):\n        models.User(email='bob@b' + 'o'*100 +'b.com')\n\n\ndef test_cannot_create_user_with_too_short_password():\n    with pytest.raises(ValueError):\n        models.User(password='a')\n\n\ndef test_check_password_false_with_null_password():\n    user = models.User(username='barnet')\n\n    assert not user.check_password('anything')\n\n\ndef test_check_password_false_with_empty_password():\n    user = models.User(username='barnet')\n    user._password = ''\n\n    assert not user.check_password('')\n\n\ndef test_check_password_true_with_matching_password():\n    user = models.User(username='barnet', password='s3cr37')\n\n    assert user.check_password('s3cr37')\n\n\ndef test_check_password_false_with_incorrect_password():\n    user = models.User(username='barnet', password='s3cr37')\n\n    assert not user.check_password('somethingelse')\n\n\ndef test_check_password_validates_old_style_passwords():\n    user = models.User(username='barnet')\n    user.salt = 'somesalt'\n    # Generated with passlib.hash.bcrypt.encrypt('foobar' + 'somesalt', rounds=10)\n    user._password = '$2a$10$il7Mi/T5WtvbqP5m3dbjeeohDf5XeDx35N5tdwyJ8uRB35NnIlozy'\n\n    assert user.check_password('foobar')\n    assert not user.check_password('somethingelse')\n\n\ndef test_check_password_upgrades_old_style_passwords():\n    user = models.User(username='barnet')\n    user.salt = 'somesalt'\n    # Generated with passlib.hash.bcrypt.encrypt('foobar' + 'somesalt', rounds=10)\n    user._password = '$2a$10$il7Mi/T5WtvbqP5m3dbjeeohDf5XeDx35N5tdwyJ8uRB35NnIlozy'\n\n    user.check_password('foobar')\n\n    assert user.salt is None\n    assert not password_context.needs_update(user._password)\n\n\ndef test_check_password_only_upgrades_when_password_is_correct():\n    user = models.User(username='barnet')\n    user.salt = 'somesalt'\n    # Generated with passlib.hash.bcrypt.encrypt('foobar' + 'somesalt', rounds=10)\n    user._password = '$2a$10$il7Mi/T5WtvbqP5m3dbjeeohDf5XeDx35N5tdwyJ8uRB35NnIlozy'\n\n    user.check_password('donkeys')\n\n    assert user.salt is not None\n    assert password_context.needs_update(user._password)\n\n\ndef test_check_password_works_after_upgrade():\n    user = models.User(username='barnet')\n    user.salt = 'somesalt'\n    # Generated with passlib.hash.bcrypt.encrypt('foobar' + 'somesalt', rounds=10)\n    user._password = '$2a$10$il7Mi/T5WtvbqP5m3dbjeeohDf5XeDx35N5tdwyJ8uRB35NnIlozy'\n\n    user.check_password('foobar')\n\n    assert user.check_password('foobar')\n\n\ndef test_check_password_upgrades_new_style_passwords():\n    user = models.User(username='barnet')\n    # Generated with passlib.hash.bcrypt.encrypt('foobar', rounds=4, ident='2b')\n    user._password = '$2b$04$L2j.vXxlLt9JJNHHsy0EguslcaphW7vssSpHbhqCmf9ECsMiuTd1y'\n\n    user.check_password('foobar')\n\n    assert not password_context.needs_update(user._password)\n\n\ndef test_setting_password_unsets_salt():\n    user = models.User(username='barnet')\n    user.salt = 'somesalt'\n    user._password = 'whatever'\n\n    user.password = 'flibble'\n\n    assert user.salt is None\n    assert user.check_password('flibble')\n\n\ndef test_User_activate_activates_user(db_session):\n    user = models.User(authority='example.com',\n                       username='kiki',\n                       email='kiki@kiki.com')\n    activation = models.Activation()\n    user.activation = activation\n    db_session.add(user)\n    db_session.flush()\n\n    user.activate()\n    db_session.commit()\n\n    assert user.is_activated\n"},{"size":869,"relativepath":"tests/h/models/blocklist_test.py","filename":"blocklist_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom h import models\n\n\ndef test_is_blocked(db_session):\n    db_session.add(models.Blocklist(uri=\"http://example.com\"))\n    db_session.add(models.Blocklist(uri=\"http://example.com/bar\"))\n    db_session.flush()\n\n    assert models.Blocklist.is_blocked(db_session, \"http://example.com\")\n    assert models.Blocklist.is_blocked(db_session, \"http://example.com/bar\")\n    assert not models.Blocklist.is_blocked(db_session, \"http://example.com/foo\")\n\n\ndef test_is_blocked_with_wildcards(db_session):\n    db_session.add(models.Blocklist(uri=\"%//example.com%\"))\n    db_session.flush()\n\n    assert models.Blocklist.is_blocked(db_session, \"http://example.com/\")\n    assert models.Blocklist.is_blocked(db_session, \"http://example.com/bar\")\n    assert models.Blocklist.is_blocked(db_session, \"http://example.com/foo\")\n"},{"size":287,"relativepath":"tests/h/models/activation_test.py","filename":"activation_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nimport re\n\nfrom h.models import Activation\n\n\ndef test_activation_has_asciinumeric_code(db_session):\n    act = Activation()\n\n    db_session.add(act)\n    db_session.flush()\n\n    assert re.match(r'[A-Za-z0-9]{12}', act.code)\n"},{"size":16330,"relativepath":"tests/h/presenters_test.py","filename":"presenters_test.py","extension":".py","content":"import datetime\n\nimport pytest\nimport mock\nimport jinja2\n\nfrom h import presenters\n\n\nclass TestAnnotationHTMLPresenter(object):\n\n    def _annotation(self, annotation=None, **kwargs):\n        \"\"\"Return an AnnotationHTMLPresenter for the given annotation.\n\n        If no annotation is given a mock will be used, and any keyword\n        arguments will be forwarded to the mock.Mock() constructor.\n\n        \"\"\"\n        return presenters.AnnotationHTMLPresenter(\n            annotation or mock.Mock(**kwargs))\n\n    def test_uri_is_escaped(self):\n        spam_link = '<a href=\"http://example.com/rubies\">Buy rubies!!!</a>'\n\n        uri = self._annotation(target_uri='http://</a>' + spam_link).uri\n\n        assert jinja2.escape(spam_link) in uri\n        for char in ['<', '>', '\"', \"'\"]:\n            assert char not in uri\n\n    def test_uri_returns_Markup(self):\n        assert isinstance(self._annotation(target_uri=\"http://foo.com\").uri,\n                          jinja2.Markup)\n\n    def test_quote(self):\n        annotation = self._annotation(\n            annotation=mock.Mock(\n                target_selectors=[{'exact': 'selected text'}],\n                text=\"entered text\"\n            )\n        )\n\n        assert annotation.quote == (\"selected text\")\n\n    def test_username(self):\n        annotation = self._annotation(\n            annotation=mock.Mock(\n                userid=\"acct:jdoe@hypothes.is\"\n            )\n        )\n\n        assert annotation.username == (\"jdoe\")\n\n    def test_text_rendered(self):\n        annotation = self._annotation(\n            annotation=mock.Mock()\n        )\n\n        assert annotation.text_rendered == annotation.annotation.text_rendered\n\n    def test_description(self):\n        annotation = self._annotation(\n            annotation=mock.Mock(\n                target_selectors=[{'exact': 'selected text'}],\n                text=\"entered text\"\n            )\n        )\n\n        assert annotation.description == (\n            \"&lt;blockquote&gt;selected text&lt;/blockquote&gt;entered text\")\n\n    def test_created_day_string_from_annotation(self):\n        annotation = self._annotation(\n            annotation=mock.Mock(\n                created=datetime.datetime(2015, 9, 4, 17, 37, 49, 517852))\n            )\n        assert annotation.created_day_string == '2015-09-04'\n\n    def test_it_does_not_crash_when_annotation_has_no_document(self):\n        annotation = mock.Mock(document=None)\n        presenter = presenters.AnnotationHTMLPresenter(annotation)\n\n        # Some AnnotationHTMLPresenter properties rely on the annotation's\n        # document. Call them all to make sure that none of them crash when\n        # the document is None.\n        # pylint: disable=pointless-statement\n        presenter.document_link\n        presenter.hostname_or_filename\n        presenter.href\n        presenter.link_text\n        presenter.title\n\n    @mock.patch('h.presenters.DocumentHTMLPresenter')\n    def test_it_does_not_init_DocumentHTMLPresenter_if_no_document(\n            self, DocumentHTMLPresenter):\n        \"\"\"\n        It shouldn't init DocumentHTMLPresenter if document is None.\n\n        We don't want DocumentHTMLPresenter to be initialized with None for\n        a document, so make sure that AnnotationHTMLPresenter doesn't do so.\n\n        \"\"\"\n        annotation = mock.Mock(document=None)\n        presenter = presenters.AnnotationHTMLPresenter(annotation)\n\n        # Call all these as well to make sure that none of them cause a\n        # DocumentHTMLPresenter to be initialized.\n        # pylint: disable=pointless-statement\n        presenter.document_link\n        presenter.hostname_or_filename\n        presenter.href\n        presenter.link_text\n        presenter.title\n\n        assert not DocumentHTMLPresenter.called\n\n\nclass TestDocumentHTMLPresenter(object):\n\n    def test_filename_with_http_uri(self):\n        presenter = self.presenter(\n            document_uris=[mock.Mock(uri=\"http://example.com/example.html\")])\n\n        assert presenter.filename == ''\n\n    def test_filename_with_file_uri(self):\n        presenter = self.presenter(\n            document_uris=[mock.Mock(uri=\"file:///home/seanh/MyFile.pdf\")])\n\n        assert presenter.filename == \"MyFile.pdf\"\n\n    def test_filename_returns_Markup(self):\n        presenter = self.presenter(\n            document_uris=[mock.Mock(uri=\"file:///home/seanh/MyFile.pdf\")])\n\n        assert isinstance(presenter.filename, jinja2.Markup)\n\n    def test_filename_with_FILE_uri(self):\n        presenter = self.presenter(\n            document_uris=[mock.Mock(uri=\"FILE:///home/seanh/MyFile.pdf\")])\n\n        assert presenter.filename == \"MyFile.pdf\"\n\n    def test_filename_with_folder(self):\n        presenter = self.presenter(document_uris=[\n            mock.Mock(uri=\"file:///home/seanh/My%20Documents/\")\n        ])\n\n        assert presenter.filename == \"\"\n\n    def test_filename_with_no_uri(self):\n        # self.uri should always be unicode, the worst it should ever be is an\n        # empty string.\n        presenter = self.presenter(document_uris=[mock.Mock(uri=u\"\")])\n\n        assert presenter.filename == \"\"\n\n    def test_filename_with_nonsense_uri(self):\n        presenter = self.presenter(document_uris=[mock.Mock(uri=u\"foobar\")])\n\n        assert presenter.filename == \"\"\n\n    def test_href_returns_web_uri_if_document_has_one(self):\n        web_uri = \"http://www.example.com/example.html\"\n\n        assert self.presenter(web_uri=web_uri).href == web_uri\n\n    def test_href_returns_empty_string_for_document_with_no_web_uri(self):\n        assert self.presenter(web_uri=None).href == \"\"\n\n    def test_href_returns_Markup(self):\n        web_uri = \"http://www.example.com/example.html\"\n\n        assert isinstance(self.presenter(web_uri=web_uri).href, jinja2.Markup)\n\n    link_text_fixtures = pytest.mark.usefixtures('title')\n\n    @link_text_fixtures\n    def test_link_text_with_non_http_title(self, title):\n        \"\"\"If .title doesn't start with http(s) it should just use it.\"\"\"\n        title.return_value = \"Example Document\"\n\n        assert self.presenter().link_text == \"Example Document\"\n\n    @link_text_fixtures\n    def test_link_text_with_http_title(self, title):\n        \"\"\"If .title is an http URI .link_test should use it.\n\n        This happens when an annotation's document has no title, so .title\n        falls back on the URI instead.\n\n        \"\"\"\n        title.return_value = \"http://www.example.com/example.html\"\n\n        assert self.presenter().link_text == \"www.example.com/example.html\"\n\n    @link_text_fixtures\n    def test_link_text_with_https_title(self, title):\n        \"\"\"If .title is an https URI .link_test should use it.\n\n        This happens when an annotation's document has no title, so .title\n        falls back on the URI instead.\n\n        \"\"\"\n        title.return_value = \"https://www.example.com/example.html\"\n\n        assert self.presenter().link_text == \"www.example.com/example.html\"\n\n    @link_text_fixtures\n    def test_link_text_returns_Markup_if_title_returns_Markup(self, title):\n        for title_ in (jinja2.Markup(\"Example Document\"),\n                       jinja2.Markup(\"http://www.example.com/example.html\"),\n                       jinja2.Markup(\"https://www.example.com/example.html\")):\n            title.return_value = title_\n            assert isinstance(self.presenter().link_text, jinja2.Markup)\n\n    hostname_or_filename_fixtures = pytest.mark.usefixtures('uri', 'filename')\n\n    @hostname_or_filename_fixtures\n    def test_hostname_or_filename_returns_filename_for_files(self, filename):\n        filename.return_value = \"MyFile.pdf\"\n\n        assert self.presenter().hostname_or_filename == \"MyFile.pdf\"\n\n    @hostname_or_filename_fixtures\n    def test_hostname_or_filename_returns_Markup_if_filename_does(self,\n                                                                  filename):\n        filename.return_value = jinja2.Markup(\"MyFile.pdf\")\n\n        assert isinstance(self.presenter().hostname_or_filename, jinja2.Markup)\n\n    @hostname_or_filename_fixtures\n    def test_hostname_or_filename_unquotes_filenames(self, filename):\n        filename.return_value = \"My%20File.pdf\"\n\n        assert self.presenter().hostname_or_filename == \"My File.pdf\"\n\n    @hostname_or_filename_fixtures\n    def test_hostname_or_filename_returns_hostname_for_non_files(self,\n                                                                 uri,\n                                                                 filename):\n        filename.return_value = \"\"\n        uri.return_value = \"http://www.example.com/example.html\"\n\n        assert self.presenter().hostname_or_filename == \"www.example.com\"\n\n    @hostname_or_filename_fixtures\n    def test_hostname_or_filename_returns_Markup_when_uri_does(self,\n                                                               uri,\n                                                               filename):\n        filename.return_value = \"\"\n        uri.return_value = jinja2.Markup(\"http://www.example.com/example.html\")\n\n        assert isinstance(self.presenter().hostname_or_filename, jinja2.Markup)\n\n    @hostname_or_filename_fixtures\n    def test_hostname_or_filename_with_empty_string_for_uri(self,\n                                                            uri,\n                                                            filename):\n        filename.return_value = \"\"\n        uri.return_value = u\"\"\n\n        assert isinstance(self.presenter().hostname_or_filename, unicode)\n\n    @hostname_or_filename_fixtures\n    def test_hostname_or_filename_with_nonsense_uri(self, uri, filename):\n        filename.return_value = \"\"\n\n        # urlparse.urlparse(u\"foobar\").hostname is None, make sure this doesn't\n        # trip up .hostname_or_filename.\n        uri.return_value = u\"foobar\"\n\n        assert isinstance(self.presenter().hostname_or_filename, unicode)\n\n    title_fixtures = pytest.mark.usefixtures('uri', 'filename')\n\n    @title_fixtures\n    def test_title_with_a_document_that_has_a_title(self):\n        \"\"\"If the document has a title it should use it.\"\"\"\n        title = 'document title'\n\n        assert self.presenter(title=title).title == title\n\n    @title_fixtures\n    def test_title_escapes_html_in_document_titles(self):\n        spam_link = '<a href=\"http://example.com/rubies\">Buy rubies!!!</a>'\n\n        title = self.presenter(title=spam_link).title\n\n        assert jinja2.escape(spam_link) in title\n        for char in ['<', '>', '\"', \"'\"]:\n            assert char not in title\n        assert isinstance(title, jinja2.Markup)\n\n    @title_fixtures\n    def test_title_with_file_uri(self, filename):\n        \"\"\"If the document has no title and the annotation has a file:// uri\n        then it should return the filename part only.\"\"\"\n        filename.return_value = \"MyFile.pdf\"\n\n        assert self.presenter(title=None).title == \"MyFile.pdf\"\n\n    @title_fixtures\n    def test_title_returns_Markup_when_filename_returns_Markup(self, filename):\n        filename.return_value = jinja2.Markup(\"MyFile.pdf\")\n\n        assert isinstance(self.presenter(title=None).title, jinja2.Markup)\n\n    @title_fixtures\n    def test_title_unquotes_uris(self, uri, filename):\n        filename.return_value = \"\"  # This is not a file:// URI.\n        uri.return_value = \"http://example.com/example%201.html\"\n\n        assert self.presenter(title=None).title == (\n            \"http://example.com/example 1.html\")\n\n    @title_fixtures\n    def test_title_returns_Markup_when_uri_returns_Markup(self, uri, filename):\n        filename.return_value = \"\"  # This is not a file:// URI.\n        uri.return_value = jinja2.Markup(\"http://example.com/example.html\")\n\n        assert isinstance(self.presenter(title=None).title, jinja2.Markup)\n\n    @title_fixtures\n    def test_title_when_document_has_None_for_title(self, uri, filename):\n        \"\"\"If title is None for its title it should use the uri instead.\"\"\"\n        uri.return_value = \"http://example.com/example.html\"\n        filename.return_value = \"\"  # This is not a file:// URI.\n\n        assert self.presenter(title=None).title == (\n            \"http://example.com/example.html\")\n\n    @title_fixtures\n    @pytest.mark.parametrize('title', [\n        23, 23.7, False, {'foo': 'bar'}, [1, 2, 3]\n    ])\n    def test_title_when_document_title_is_not_a_string(self,\n                                                       uri,\n                                                       filename,\n                                                       title):\n        \"\"\"If title is None it should use the uri instead.\"\"\"\n        uri.return_value = u\"http://example.com/example.html\"\n        filename.return_value = \"\"  # This is not a file:// URI.\n\n        assert isinstance(self.presenter(title=title).title, unicode)\n\n    @title_fixtures\n    def test_title_when_document_has_empty_string_for_title(self,\n                                                            uri,\n                                                            filename):\n        \"\"\"If title is \"\" it should use the uri instead.\"\"\"\n        uri.return_value = \"http://example.com/example.html\"\n        filename.return_value = \"\"  # This is not a file:// URI.\n\n        assert self.presenter(title=\"\").title == (\n            \"http://example.com/example.html\")\n\n    @title_fixtures\n    def test_title_when_no_document_title_no_filename_and_no_uri(self,\n                                                                 uri,\n                                                                 filename):\n        uri.return_value = \"\"\n        filename.return_value = \"\"\n\n        assert self.presenter(title=None).title == \"\"\n\n    def test_web_uri_returns_document_web_uri(self):\n        \"\"\"\n        It just returns Document.web_uri for non-via web_uris.\n\n        If Document.web_uri is a string that doesn't start with\n        https://via.hypothes.is/ then DocumentHTMLPresenter.web_uri should\n        just return Document.web_uri.\n\n        \"\"\"\n        non_via_uri = 'http://example.com/page'\n\n        assert self.presenter(web_uri=non_via_uri).web_uri == non_via_uri\n\n    def test_web_uri_returns_None_if_document_web_uri_is_None(self):\n        assert self.presenter(web_uri=None).web_uri is None\n\n    @pytest.mark.parametrize('via_url', (\n                             'https://via.hypothes.is',\n                             'https://via.hypothes.is/'))\n    def test_web_uri_returns_via_front_page(self, via_url):\n        \"\"\"It doesn't strip https://via.hypothes.is if that's the entire URL.\"\"\"\n        assert self.presenter(web_uri=via_url).web_uri == via_url\n\n    def test_web_uri_does_not_strip_http_via(self):\n        \"\"\"\n        It doesn't strip non-SSL http://via.hypothes.is.\n\n        Since http://via.hypothes.is redirects to https://via.hypothes.is\n        anyway, and we don't currently have any http://via.hypothes.is\n        URIs in our production DB, DocumentHTMLPresenter.web_uri only strips\n        https://via.hypothes.is/ and ignores http://via.hypothes.is/.\n        \"\"\"\n        uri = 'http://via.hypothes.is/http://example.com/page'\n\n        assert self.presenter(web_uri=uri).web_uri == uri\n\n    @pytest.mark.parametrize('path', ('foo', 'http://example.com'))\n    def test_web_uri_strips_via(self, path):\n        \"\"\"\n        It strips any https://via.hypothes.is/ prefix from Document.web_uri.\n\n        If Document.web_uri is https://via.hypothes.is/<path>, for any <path>\n        (whether path is a URL or not), DocumentHTMLPresenter.web_uri just\n        returns <path> with the https://via.hypothes.is/ prefix removed.\n\n        \"\"\"\n        uri = 'https://via.hypothes.is/' + path\n\n        assert self.presenter(web_uri=uri).web_uri == path\n\n    def presenter(self, **kwargs):\n        return presenters.DocumentHTMLPresenter(mock.Mock(**kwargs))\n\n    @pytest.fixture\n    def filename(self, patch):\n        return patch('h.presenters.DocumentHTMLPresenter.filename',\n                     autospec=None,\n                     new_callable=mock.PropertyMock)\n\n    @pytest.fixture\n    def title(self, patch):\n        return patch('h.presenters.DocumentHTMLPresenter.title',\n                     autospec=None,\n                     new_callable=mock.PropertyMock)\n\n    @pytest.fixture\n    def uri(self, patch):\n        return patch('h.presenters.DocumentHTMLPresenter.uri',\n                     autospec=None,\n                     new_callable=mock.PropertyMock)\n"},{"size":5348,"relativepath":"tests/h/subscribers_test.py","filename":"subscribers_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nimport mock\nimport pytest\n\nfrom h import subscribers\nfrom memex.events import AnnotationEvent\n\n\nclass FakeMailer(object):\n    def __init__(self):\n        self.lastcall = None\n\n    def __call__(self, recipients, subject, body, html):\n        self.lastcall = (recipients, subject, body, html)\n\n\nclass TestPublishAnnotationEvent:\n\n    def test_it_publishes_the_realtime_event(self, event):\n        event.request.headers = {'X-Client-Id': 'client_id'}\n\n        subscribers.publish_annotation_event(event)\n\n        event.request.realtime.publish_annotation.assert_called_once_with({\n            'action': event.action,\n            'annotation_id': event.annotation_id,\n            'src_client_id': 'client_id'\n        })\n\n    def test_it_adds_annotation_dict_to_realtime_event(self, event):\n        annotation_dict = mock.Mock()\n        type(event).annotation_dict = mock.PropertyMock(return_value=annotation_dict)\n        event.request.headers = {'X-Client-Id': 'client_id'}\n\n        subscribers.publish_annotation_event(event)\n\n        event.request.realtime.publish_annotation.assert_called_once_with({\n            'action': event.action,\n            'annotation_id': event.annotation_id,\n            'src_client_id': 'client_id',\n            'annotation_dict': annotation_dict\n        })\n\n    @pytest.fixture\n    def event(self, pyramid_request):\n        pyramid_request.realtime = mock.Mock()\n        event = AnnotationEvent(pyramid_request,\n                                'test_annotation_id',\n                                'create')\n        type(event).annotation_dict = mock.PropertyMock(return_value=None)\n        return event\n\n\n@pytest.mark.usefixtures('fetch_annotation')\nclass TestSendReplyNotifications(object):\n    def test_calls_get_notification_with_request_annotation_and_action(self, fetch_annotation):\n        send = FakeMailer()\n        get_notification = mock.Mock(spec_set=[], return_value=None)\n        generate_mail = mock.Mock(spec_set=[], return_value=[])\n        event = AnnotationEvent(mock.sentinel.request,\n                                mock.sentinel.annotation_id,\n                                mock.sentinel.action)\n        mock.sentinel.request.db = mock.Mock()\n\n        subscribers.send_reply_notifications(event,\n                                             get_notification=get_notification,\n                                             generate_mail=generate_mail,\n                                             send=send)\n\n        fetch_annotation.assert_called_once_with(mock.sentinel.request.db,\n                                                 mock.sentinel.annotation_id)\n\n        get_notification.assert_called_once_with(mock.sentinel.request,\n                                                 fetch_annotation.return_value,\n                                                 mock.sentinel.action)\n\n    def test_generates_and_sends_mail_for_any_notification(self):\n        s = mock.sentinel\n        send = FakeMailer()\n        get_notification = mock.Mock(spec_set=[], return_value=s.notification)\n        generate_mail = mock.Mock(spec_set=[])\n        generate_mail.return_value = (['foo@example.com'], 'Your email', 'Text body', 'HTML body')\n        event = AnnotationEvent(s.request, None, None)\n        s.request.db = mock.Mock()\n\n        subscribers.send_reply_notifications(event,\n                                             get_notification=get_notification,\n                                             generate_mail=generate_mail,\n                                             send=send)\n\n        generate_mail.assert_called_once_with(s.request, s.notification)\n        assert send.lastcall == (['foo@example.com'], 'Your email', 'Text body', 'HTML body')\n\n    def test_catches_exceptions_and_reports_to_sentry(self, pyramid_request):\n        send = FakeMailer()\n        get_notification = mock.Mock(spec_set=[], side_effect=RuntimeError('asplode!'))\n        generate_mail = mock.Mock(spec_set=[], return_value=[])\n        pyramid_request.debug = False\n        pyramid_request.sentry = mock.Mock()\n        event = AnnotationEvent(pyramid_request, None, None)\n\n        subscribers.send_reply_notifications(event,\n                                             get_notification=get_notification,\n                                             generate_mail=generate_mail,\n                                             send=send)\n\n        event.request.sentry.captureException.assert_called_once_with()\n\n    def test_reraises_exceptions_in_debug_mode(self, pyramid_request):\n        send = FakeMailer()\n        get_notification = mock.Mock(spec_set=[], side_effect=RuntimeError('asplode!'))\n        generate_mail = mock.Mock(spec_set=[], return_value=[])\n        pyramid_request.debug = True\n        pyramid_request.sentry = mock.Mock()\n        event = AnnotationEvent(pyramid_request, None, None)\n\n        with pytest.raises(RuntimeError):\n            subscribers.send_reply_notifications(event,\n                                                 get_notification=get_notification,\n                                                 generate_mail=generate_mail,\n                                                 send=send)\n\n    @pytest.fixture\n    def fetch_annotation(self, patch):\n        return patch('h.subscribers.storage.fetch_annotation')\n"},{"size":3572,"relativepath":"tests/h/routes_test.py","filename":"routes_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom mock import Mock, call\n\nfrom h.routes import includeme\n\n\ndef test_includeme():\n    config = Mock(spec_set=['add_route'])\n\n    includeme(config)\n\n    # This may look like a ridiculous test, but the cost of keeping it\n    # up-to-date is hopefully pretty low (run the tests with -vv, copy the new\n    # expected value) and it serves as a check to ensure that any changes made\n    # to the routes were intended.\n    assert config.add_route.mock_calls == [\n        call('index', '/'),\n        call('robots', '/robots.txt'),\n        call('via_redirect', '/via'),\n        call('login', '/login'),\n        call('logout', '/logout'),\n        call('signup', '/signup'),\n        call('activate', '/activate/{id}/{code}'),\n        call('forgot_password', '/forgot-password'),\n        call('account_reset', '/account/reset'),\n        call('account_reset_with_code', '/account/reset/{code}'),\n        call('account', '/account/settings'),\n        call('account_profile', '/account/profile'),\n        call('account_notifications', '/account/settings/notifications'),\n        call('account_developer', '/account/developer'),\n        call('claim_account_legacy', '/claim_account/{token}'),\n        call('dismiss_sidebar_tutorial', '/app/dismiss_sidebar_tutorial'),\n        call('activity.search', '/search'),\n        call('activity.group_search', '/groups/{pubid}/search'),\n        call('activity.user_search', '/users/{username}/search'),\n        call('admin_index', '/admin/'),\n        call('admin_admins', '/admin/admins'),\n        call('admin_badge', '/admin/badge'),\n        call('admin_features', '/admin/features'),\n        call('admin_cohorts', '/admin/features/cohorts'),\n        call('admin_cohorts_edit', '/admin/features/cohorts/{id}'),\n        call('admin_groups', '/admin/groups'),\n        call('admin_groups_csv', '/admin/groups.csv'),\n        call('admin_nipsa', '/admin/nipsa'),\n        call('admin_staff', '/admin/staff'),\n        call('admin_users', '/admin/users'),\n        call('admin_users_activate', '/admin/users/activate'),\n        call('admin_users_delete', '/admin/users/delete'),\n        call('admin_users_rename', '/admin/users/rename'),\n        call('annotation', '/a/{id}', factory='memex.resources:AnnotationFactory', traverse='/{id}'),\n        call('stream', '/stream'),\n        call('stream.user_query', '/u/{user}'),\n        call('stream.tag_query', '/t/{tag}'),\n        call('assets_client', '/assets/client/*subpath'),\n        call('assets', '/assets/*subpath'),\n        call('badge', '/api/badge'),\n        call('token', '/api/token'),\n        call('api.users', '/api/users'),\n        call('session', '/app'),\n        call('widget', '/app.html'),\n        call('embed', '/embed.js'),\n        call('stream_atom', '/stream.atom'),\n        call('stream_rss', '/stream.rss'),\n        call('group_create', '/groups/new'),\n        call('group_edit', '/groups/{pubid}/edit', factory='h.models.group:GroupFactory', traverse='/{pubid}'),\n        call('group_leave', '/groups/{pubid}/leave', factory='h.models.group:GroupFactory', traverse='/{pubid}'),\n        call('group_read', '/groups/{pubid}/{slug:[^/]*}', factory='h.models.group:GroupFactory', traverse='/{pubid}'),\n        call('group_read_noslug', '/groups/{pubid}', factory='h.models.group:GroupFactory', traverse='/{pubid}'),\n        call('help', '/docs/help'),\n        call('onboarding', '/welcome/'),\n        call('custom_onboarding', '/welcome/{slug}'),\n        call('unsubscribe', '/notification/unsubscribe/{token}'),\n    ]\n"},{"size":1028,"relativepath":"tests/h/accounts/util_test.py","filename":"util_test.py","extension":".py","content":"import pytest\n\nfrom h.accounts.util import validate_orcid, validate_url\n\ndef test_validate_url_rejects_urls_without_domains():\n    with pytest.raises(ValueError):\n        validate_url('http:///path')\n\n\ndef test_validate_url_adds_http_prefix():\n    assert validate_url('github.com/jimsmith') == 'http://github.com/jimsmith'\n\n\ndef test_validate_url_accepts_http_urls():\n    validate_url('http://github.com/jimsmith')\n\n\ndef test_validate_url_rejects_non_http_urls():\n    with pytest.raises(ValueError):\n        validate_url('mailto:jim@smith.org')\n\n\n@pytest.mark.parametrize('orcid_id', [\n    '0000-0002-1825-0097',\n    '0000-0001-5109-3700',\n    '0000-0002-1694-233X',\n])\ndef test_validate_orcid_accepts_valid_ids(orcid_id):\n    assert validate_orcid(orcid_id)\n\n\ndef test_validate_orcid_rejects_malformed_ids():\n    with pytest.raises(ValueError):\n        validate_orcid('not-an-orcid')\n\n\ndef test_validate_orcid_rejects_mismatching_check_digit():\n    with pytest.raises(ValueError):\n        validate_orcid('1000-0002-1825-0097')\n"},{"size":23197,"relativepath":"tests/h/accounts/schemas_test.py","filename":"schemas_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\nimport colander\nimport pytest\nfrom mock import Mock\nfrom pyramid.exceptions import BadCSRFToken\nfrom itsdangerous import BadData, SignatureExpired\n\nfrom h.accounts import schemas\nfrom h.accounts.services import UserNotActivated, UserNotKnown, UserService\n\n\nclass TestUnblacklistedUsername(object):\n\n    def test(self, dummy_node):\n        blacklist = set(['admin', 'root', 'postmaster'])\n\n        # Should not raise for valid usernames\n        schemas.unblacklisted_username(dummy_node, \"john\", blacklist)\n        schemas.unblacklisted_username(dummy_node, \"Abigail\", blacklist)\n        # Should raise for usernames in blacklist\n        pytest.raises(colander.Invalid,\n                      schemas.unblacklisted_username,\n                      dummy_node,\n                      \"admin\",\n                      blacklist)\n        # Should raise for case variants of usernames in blacklist\n        pytest.raises(colander.Invalid,\n                      schemas.unblacklisted_username,\n                      dummy_node,\n                      \"PostMaster\",\n                      blacklist)\n\n\n@pytest.mark.usefixtures('user_model')\nclass TestUniqueEmail(object):\n\n    def test_it_looks_up_user_by_email(self,\n                                       dummy_node,\n                                       pyramid_request,\n                                       user_model):\n        with pytest.raises(colander.Invalid):\n            schemas.unique_email(dummy_node, \"foo@bar.com\")\n\n        user_model.get_by_email.assert_called_with(pyramid_request.db,\n                                                   \"foo@bar.com\")\n\n    def test_it_is_invalid_when_user_exists(self, dummy_node):\n        pytest.raises(colander.Invalid,\n                      schemas.unique_email,\n                      dummy_node,\n                      \"foo@bar.com\")\n\n    def test_it_is_invalid_when_user_does_not_exist(self,\n                                                    dummy_node,\n                                                    user_model):\n        user_model.get_by_email.return_value = None\n\n        assert schemas.unique_email(dummy_node, \"foo@bar.com\") is None\n\n    def test_it_is_valid_when_authorized_users_email(self,\n                                                     dummy_node,\n                                                     pyramid_config,\n                                                     user_model):\n        \"\"\"\n        If the given email is the authorized user's current email it's valid.\n\n        This is so that we don't get a \"That email is already taken\" validation\n        error when a user tries to change their email address to the same email\n        address that they already have it set to.\n\n        \"\"\"\n        pyramid_config.testing_securitypolicy('acct:elliot@hypothes.is')\n        user_model.get_by_email.return_value = Mock(\n            spec_set=('userid',),\n            userid='acct:elliot@hypothes.is')\n\n        schemas.unique_email(dummy_node, \"elliot@bar.com\")\n\n\n@pytest.mark.usefixtures('user_model')\nclass TestRegisterSchema(object):\n\n    def test_it_is_invalid_when_password_too_short(self, pyramid_request):\n        schema = schemas.RegisterSchema().bind(request=pyramid_request)\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\"password\": \"a\"})\n        assert exc.value.asdict()['password'] == (\n            \"Must be 2 characters or more.\")\n\n    def test_it_is_invalid_when_username_too_short(self,\n                                                   pyramid_request,\n                                                   user_model):\n        schema = schemas.RegisterSchema().bind(request=pyramid_request)\n        user_model.get_by_username.return_value = None\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\"username\": \"a\"})\n        assert exc.value.asdict()['username'] == (\n            \"Must be 3 characters or more.\")\n\n    def test_it_is_invalid_when_username_too_long(self,\n                                                  pyramid_request,\n                                                  user_model):\n        schema = schemas.RegisterSchema().bind(request=pyramid_request)\n        user_model.get_by_username.return_value = None\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\"username\": \"a\" * 500})\n        assert exc.value.asdict()['username'] == (\n            \"Must be 30 characters or less.\")\n\n    def test_it_is_invalid_with_invalid_characters_in_username(self,\n                                                               pyramid_request,\n                                                               user_model):\n        user_model.get_by_username.return_value = None\n        schema = schemas.RegisterSchema().bind(request=pyramid_request)\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\"username\": \"Fred Flintstone\"})\n        assert exc.value.asdict()['username'] == (\"Must have only letters, \"\n                                                  \"numbers, periods, and \"\n                                                  \"underscores.\")\n\n\n@pytest.mark.usefixtures('user_service')\nclass TestLoginSchema(object):\n\n    def test_passes_username_and_password_to_user_service(self,\n                                                          factories,\n                                                          pyramid_csrf_request,\n                                                          user_service):\n        user = factories.User(username='jeannie')\n        user_service.login.return_value = user\n        schema = schemas.LoginSchema().bind(request=pyramid_csrf_request)\n\n        schema.deserialize({\n            'username': 'jeannie',\n            'password': 'cake',\n        })\n\n        user_service.login.assert_called_once_with(username_or_email='jeannie',\n                                                   password='cake')\n\n    def test_it_returns_user_when_valid(self,\n                                        factories,\n                                        pyramid_csrf_request,\n                                        user_service):\n        user = factories.User(username='jeannie')\n        user_service.login.return_value = user\n        schema = schemas.LoginSchema().bind(request=pyramid_csrf_request)\n\n        result = schema.deserialize({\n            'username': 'jeannie',\n            'password': 'cake',\n        })\n\n        assert result['user'] is user\n\n    def test_invalid_with_bad_csrf(self, pyramid_request, user_service):\n        schema = schemas.LoginSchema().bind(request=pyramid_request)\n\n        with pytest.raises(BadCSRFToken):\n            schema.deserialize({\n                'username': 'jeannie',\n                'password': 'cake',\n            })\n\n    def test_invalid_with_inactive_user(self,\n                                        pyramid_csrf_request,\n                                        user_service):\n        schema = schemas.LoginSchema().bind(request=pyramid_csrf_request)\n        user_service.login.side_effect = UserNotActivated()\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\n                'username': 'jeannie',\n                'password': 'cake',\n            })\n        errors = exc.value.asdict()\n\n        assert 'username' in errors\n        assert 'activate your account' in errors['username']\n\n    def test_invalid_with_unknown_user(self,\n                                       pyramid_csrf_request,\n                                       user_service):\n        schema = schemas.LoginSchema().bind(request=pyramid_csrf_request)\n        user_service.login.side_effect = UserNotKnown()\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\n                'username': 'jeannie',\n                'password': 'cake',\n            })\n        errors = exc.value.asdict()\n\n        assert 'username' in errors\n        assert 'does not exist' in errors['username']\n\n\n    def test_invalid_with_bad_password(self,\n                                       pyramid_csrf_request,\n                                       user_service):\n        user_service.login.return_value = None\n        schema = schemas.LoginSchema().bind(request=pyramid_csrf_request)\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\n                'username': 'jeannie',\n                'password': 'cake',\n            })\n        errors = exc.value.asdict()\n\n        assert 'password' in errors\n        assert 'Wrong password' in errors['password']\n\n\n@pytest.mark.usefixtures('user_model')\nclass TestForgotPasswordSchema(object):\n\n    def test_it_is_invalid_with_no_user(self,\n                                        pyramid_csrf_request,\n                                        user_model):\n        schema = schemas.ForgotPasswordSchema().bind(\n            request=pyramid_csrf_request)\n        user_model.get_by_email.return_value = None\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({'email': 'rapha@example.com'})\n\n        assert 'email' in exc.value.asdict()\n        assert exc.value.asdict()['email'] == 'Unknown email address.'\n\n    def test_it_returns_user_when_valid(self,\n                                        pyramid_csrf_request,\n                                        user_model):\n        schema = schemas.ForgotPasswordSchema().bind(\n            request=pyramid_csrf_request)\n        user = user_model.get_by_email.return_value\n\n        appstruct = schema.deserialize({'email': 'rapha@example.com'})\n\n        assert appstruct['user'] == user\n\n\n@pytest.mark.usefixtures('user_model')\nclass TestResetPasswordSchema(object):\n\n    def test_it_is_invalid_with_password_too_short(self, pyramid_csrf_request):\n        schema = schemas.ResetPasswordSchema().bind(\n            request=pyramid_csrf_request)\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\"password\": \"a\"})\n        assert \"password\" in exc.value.asdict()\n\n    def test_it_is_invalid_with_invalid_user_token(self, pyramid_csrf_request):\n        pyramid_csrf_request.registry.password_reset_serializer = (\n            self.FakeInvalidSerializer())\n        schema = schemas.ResetPasswordSchema().bind(\n            request=pyramid_csrf_request)\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\n                'user': 'abc123',\n                'password': 'secret',\n            })\n\n        assert 'user' in exc.value.asdict()\n        assert 'Wrong reset code.' in exc.value.asdict()['user']\n\n    def test_it_is_invalid_with_expired_token(self, pyramid_csrf_request):\n        pyramid_csrf_request.registry.password_reset_serializer = (\n            self.FakeExpiredSerializer())\n        schema = schemas.ResetPasswordSchema().bind(\n            request=pyramid_csrf_request)\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\n                'user': 'abc123',\n                'password': 'secret',\n            })\n\n        assert 'user' in exc.value.asdict()\n        assert 'Reset code has expired.' in exc.value.asdict()['user']\n\n    def test_it_is_invalid_if_user_has_already_reset_their_password(\n            self, pyramid_csrf_request, user_model):\n        pyramid_csrf_request.registry.password_reset_serializer = (\n            self.FakeSerializer())\n        schema = schemas.ResetPasswordSchema().bind(\n            request=pyramid_csrf_request)\n        user = user_model.get_by_username.return_value\n        user.password_updated = 2\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\n                'user': 'abc123',\n                'password': 'secret',\n            })\n\n        assert 'user' in exc.value.asdict()\n        assert 'This reset code has already been used.' in exc.value.asdict()['user']\n\n    def test_it_returns_user_when_valid(self,\n                                        pyramid_csrf_request,\n                                        user_model):\n        pyramid_csrf_request.registry.password_reset_serializer = (\n            self.FakeSerializer())\n        schema = schemas.ResetPasswordSchema().bind(\n            request=pyramid_csrf_request)\n        user = user_model.get_by_username.return_value\n        user.password_updated = 0\n\n        appstruct = schema.deserialize({\n            'user': 'abc123',\n            'password': 'secret',\n        })\n\n        assert appstruct['user'] == user\n\n    class FakeSerializer(object):\n        def dumps(self, obj):\n            return 'faketoken'\n\n        def loads(self, token, max_age=0, return_timestamp=False):\n            payload = {'username': 'foo@bar.com'}\n            if return_timestamp:\n                return payload, 1\n            return payload\n\n    class FakeExpiredSerializer(FakeSerializer):\n        def loads(self, token, max_age=0, return_timestamp=False):\n            raise SignatureExpired(\"Token has expired\")\n\n    class FakeInvalidSerializer(FakeSerializer):\n        def loads(self, token, max_age=0, return_timestamp=False):\n            raise BadData(\"Invalid token\")\n\n\n@pytest.mark.usefixtures('user_model')\nclass TestLegacyEmailChangeSchema(object):\n\n    def test_it_is_invalid_if_emails_dont_match(self,\n                                                pyramid_csrf_request,\n                                                user_model):\n        user = Mock()\n        pyramid_csrf_request.authenticated_user = user\n        schema = schemas.LegacyEmailChangeSchema().bind(\n            request=pyramid_csrf_request)\n        # The email isn't taken\n        user_model.get_by_email.return_value = None\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({'email': 'foo@bar.com',\n                                'email_confirm': 'foo@baz.com',\n                                'password': 'flibble'})\n\n        assert 'email_confirm' in exc.value.asdict()\n\n    def test_it_is_invalid_if_password_wrong(self,\n                                             pyramid_csrf_request,\n                                             user_model):\n        user = Mock()\n        pyramid_csrf_request.authenticated_user = user\n        schema = schemas.LegacyEmailChangeSchema().bind(\n            request=pyramid_csrf_request)\n        # The email isn't taken\n        user_model.get_by_email.return_value = None\n        # The password does not check out\n        user.check_password.return_value = False\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({'email': 'foo@bar.com',\n                                'email_confirm': 'foo@bar.com',\n                                'password': 'flibble'})\n\n        user.check_password.assert_called_once_with('flibble')\n        assert 'password' in exc.value.asdict()\n\n\n@pytest.mark.usefixtures('models')\nclass TestEmailChangeSchema(object):\n\n    # The user's password.\n    PASSWORD = 'flibble'\n\n    def test_it_returns_the_new_email_when_valid(self, schema):\n        appstruct = schema.deserialize({\n            'email': 'foo@bar.com',\n            'password': self.PASSWORD,\n        })\n\n        assert appstruct['email'] == 'foo@bar.com'\n\n    def test_it_is_valid_if_email_same_as_users_existing_email(self,\n                                                               schema,\n                                                               user,\n                                                               models,\n                                                               pyramid_config):\n        \"\"\"\n        It is valid if the new email is the same as the user's existing one.\n\n        Trying to change your email to what your email already is should not\n        return an error.\n\n        \"\"\"\n        models.User.get_by_email.return_value = Mock(spec_set=['userid'],\n                                                      userid=user.userid)\n        pyramid_config.testing_securitypolicy(user.userid)\n\n        schema.deserialize({'email': user.email, 'password': self.PASSWORD})\n\n    def test_it_is_invalid_if_csrf_token_missing(self,\n                                                 pyramid_request,\n                                                 schema):\n        del pyramid_request.headers['X-CSRF-Token']\n\n        with pytest.raises(BadCSRFToken):\n            schema.deserialize({\n                'email': 'foo@bar.com',\n                'password': self.PASSWORD,\n            })\n\n    def test_it_is_invalid_if_csrf_token_wrong(self, pyramid_request, schema):\n        pyramid_request.headers['X-CSRF-Token'] = 'WRONG'\n\n        with pytest.raises(BadCSRFToken):\n            schema.deserialize({\n                'email': 'foo@bar.com',\n                'password': self.PASSWORD,\n            })\n\n    def test_it_is_invalid_if_password_wrong(self, schema):\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\n                'email': 'foo@bar.com',\n                'password': 'WRONG'  # Not the correct password!\n            })\n\n        assert exc.value.asdict() == {'password': 'Wrong password.'}\n\n    def test_it_returns_incorrect_password_error_if_password_too_short(\n            self, schema):\n        \"\"\"\n        The schema should be invalid if the password is too short.\n\n        Test that this returns a \"that was not the right password\" error rather\n        than a \"that password is too short error\" as it used to (the user is\n        entering their current password for authentication, they aren't\n        choosing a new password).\n\n        \"\"\"\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\n                'email': 'foo@bar.com',\n                'password': 'a'  # Too short to be a valid password.\n            })\n\n        assert exc.value.asdict() == {'password': 'Wrong password.'}\n\n    def test_it_is_invalid_if_email_too_long(self, schema):\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\n                'email': 'a' * 100 + '@bar.com',\n                'password': self.PASSWORD,\n            })\n\n        assert exc.value.asdict() == {\n            'email': 'Must be 100 characters or less.'}\n\n    def test_it_is_invalid_if_email_not_a_valid_email_address(self, schema):\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\n                'email': 'this is not a valid email address',\n                'password': self.PASSWORD,\n            })\n\n        assert exc.value.asdict() == {'email': 'Invalid email address.'}\n\n    def test_it_is_invalid_if_email_already_taken(self, models, schema):\n        models.User.get_by_email.return_value = Mock(spec_set=['userid'])\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({\n                'email': 'foo@bar.com',\n                'password': self.PASSWORD,\n            })\n\n        assert exc.value.asdict() == {'email': 'Sorry, an account with this '\n                                               'email address already exists.'}\n\n    @pytest.fixture\n    def pyramid_request(self, pyramid_csrf_request, user):\n        pyramid_csrf_request.authenticated_user = user\n        return pyramid_csrf_request\n\n    @pytest.fixture\n    def schema(self, pyramid_request):\n        return schemas.EmailChangeSchema().bind(request=pyramid_request)\n\n    @pytest.fixture\n    def user(self, factories):\n        return factories.User(password=self.PASSWORD)\n\n    @pytest.fixture\n    def models(self, patch):\n        models = patch('h.accounts.schemas.models')\n\n        # By default there isn't already an account with the email address that\n        # we're trying to change to.\n        models.User.get_by_email.return_value = None\n\n        return models\n\n\nclass TestPasswordChangeSchema(object):\n\n    def test_it_is_invalid_if_passwords_dont_match(self, pyramid_csrf_request):\n        user = Mock()\n        pyramid_csrf_request.authenticated_user = user\n        schema = schemas.PasswordChangeSchema().bind(\n            request=pyramid_csrf_request)\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({'new_password': 'wibble',\n                                'new_password_confirm': 'wibble!',\n                                'password': 'flibble'})\n\n        assert 'new_password_confirm' in exc.value.asdict()\n\n    def test_it_is_invalid_if_current_password_is_wrong(self,\n                                                        pyramid_csrf_request):\n        user = Mock()\n        pyramid_csrf_request.authenticated_user = user\n        schema = schemas.PasswordChangeSchema().bind(\n            request=pyramid_csrf_request)\n        # The password does not check out\n        user.check_password.return_value = False\n\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({'new_password': 'wibble',\n                                'new_password_confirm': 'wibble',\n                                'password': 'flibble'})\n\n        user.check_password.assert_called_once_with('flibble')\n        assert 'password' in exc.value.asdict()\n\n\nclass TestEditProfileSchema(object):\n    def test_accepts_valid_input(self, pyramid_csrf_request):\n        schema = schemas.EditProfileSchema().bind(request=pyramid_csrf_request)\n        appstruct = schema.deserialize({\n            'display_name': 'Michael Granitzer',\n            'description': 'Professor at University of Passau',\n            'link': 'http://mgrani.github.io/',\n            'location': 'Bavaria, Germany',\n            'orcid': '0000-0003-3566-5507',\n        })\n\n    def test_rejects_invalid_orcid(self, pyramid_csrf_request, validate_orcid):\n        validate_orcid.side_effect = ValueError('Invalid ORCID')\n        schema = schemas.EditProfileSchema().bind(request=pyramid_csrf_request)\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({'orcid': 'abcdef'})\n        assert exc.value.asdict()['orcid'] == 'Invalid ORCID'\n\n    def test_rejects_invalid_url(self, pyramid_csrf_request, validate_url):\n        validate_url.side_effect = ValueError('Invalid URL')\n        schema = schemas.EditProfileSchema().bind(request=pyramid_csrf_request)\n        with pytest.raises(colander.Invalid) as exc:\n            schema.deserialize({'link': '\"invalid URL\"'})\n        assert exc.value.asdict()['link'] == 'Invalid URL'\n\n\n@pytest.fixture\ndef validate_url(patch):\n    return patch('h.accounts.schemas.util.validate_url')\n\n\n@pytest.fixture\ndef validate_orcid(patch):\n    return patch('h.accounts.schemas.util.validate_orcid')\n\n\n@pytest.fixture\ndef dummy_node(pyramid_request):\n    class DummyNode(object):\n        def __init__(self, request):\n            self.bindings = {\n                'request': request\n            }\n    return DummyNode(pyramid_request)\n\n\n@pytest.fixture\ndef user_model(patch):\n    return patch('h.accounts.schemas.models.User')\n\n\n@pytest.fixture\ndef user_service(db_session, pyramid_config):\n    service = Mock(spec_set=UserService(default_authority='example.com',\n                                        session=db_session))\n    service.login.return_value = None\n    pyramid_config.register_service(service, name='user')\n    return service\n"},{"size":8854,"relativepath":"tests/h/accounts/services_test.py","filename":"services_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport mock\nimport pytest\n\nfrom h.accounts.services import (\n    UserNotActivated,\n    UserNotKnown,\n    UserService,\n    UserSignupService,\n    user_service_factory,\n    user_signup_service_factory,\n)\nfrom h.models import Activation, Subscriptions, User\n\n\n@pytest.mark.usefixtures('users')\nclass TestUserService(object):\n\n    def test_fetch_retrieves_user_by_userid(self, svc):\n        result = svc.fetch('acct:jacqui@foo.com')\n\n        assert isinstance(result, User)\n\n    def test_fetch_caches_fetched_users(self, db_session, svc, users):\n        jacqui, _, _ = users\n\n        svc.fetch('acct:jacqui@foo.com')\n        db_session.delete(jacqui)\n        db_session.flush()\n        user = svc.fetch('acct:jacqui@foo.com')\n\n        assert user is not None\n        assert user.username == 'jacqui'\n\n    def test_flushes_cache_on_session_commit(self, db_session, svc, users):\n        jacqui, _, _ = users\n\n        svc.fetch('acct:jacqui@foo.com')\n        db_session.delete(jacqui)\n        db_session.commit()\n        user = svc.fetch('acct:jacqui@foo.com')\n\n        assert user is None\n\n    def test_login_by_username(self, svc, users):\n        _, steve, _ = users\n        assert svc.login('steve', 'stevespassword') is steve\n\n    def test_login_by_email(self, svc, users):\n        _, steve, _ = users\n        assert svc.login('steve@steveo.com', 'stevespassword') is steve\n\n    def test_login_bad_password(self, svc):\n        assert svc.login('steve', 'incorrect') is None\n        assert svc.login('steve@steveo.com', 'incorrect') is None\n\n    def test_login_by_username_wrong_authority(self, svc):\n        with pytest.raises(UserNotKnown):\n            svc.login('jacqui', 'jacquispassword')\n\n    def test_login_by_email_wrong_authority(self, svc):\n        with pytest.raises(UserNotKnown):\n            svc.login('jacqui@jj.com', 'jacquispassword')\n\n    def test_login_by_username_not_activated(self, svc):\n        with pytest.raises(UserNotActivated):\n            svc.login('mirthe', 'mirthespassword')\n\n    def test_login_by_email_not_activated(self, svc, users):\n        with pytest.raises(UserNotActivated):\n            svc.login('mirthe@deboer.com', 'mirthespassword')\n\n    @pytest.fixture\n    def svc(self, db_session):\n        return UserService(default_authority='example.com', session=db_session)\n\n    @pytest.fixture\n    def users(self, db_session, factories):\n        users = [factories.User(username='jacqui',\n                                email='jacqui@jj.com',\n                                authority='foo.com',\n                                password='jacquispassword'),\n                 factories.User(username='steve',\n                                email='steve@steveo.com',\n                                authority='example.com',\n                                password='stevespassword'),\n                 factories.User(username='mirthe',\n                                email='mirthe@deboer.com',\n                                authority='example.com',\n                                password='mirthespassword',\n                                inactive=True)]\n        db_session.add_all(users)\n        db_session.flush()\n        return users\n\n\nclass TestUserSignupService(object):\n    def test_signup_returns_user(self, svc):\n        user = svc.signup(username='foo', email='foo@bar.com')\n\n        assert isinstance(user, User)\n\n    def test_signup_creates_user_in_db(self, db_session, svc):\n        svc.signup(username='foo', email='foo@bar.com')\n\n        db_session.commit()\n        db_session.close()\n\n        user = db_session.query(User).filter_by(username='foo').one_or_none()\n\n        assert user is not None\n\n    def test_signup_creates_activation_for_user(self, svc):\n        user = svc.signup(username='foo', email='foo@bar.com')\n\n        assert isinstance(user.activation, Activation)\n\n    def test_signup_does_not_create_activation_for_user_when_activation_not_required(self, svc):\n        user = svc.signup(require_activation=False,\n                          username='foo',\n                          email='foo@bar.com')\n\n        assert user.activation is None\n\n    def test_signup_sets_default_authority(self, svc):\n        user = svc.signup(username='foo', email='foo@bar.com')\n\n        assert user.authority == 'example.org'\n\n    def test_signup_allows_authority_override(self, svc):\n        user = svc.signup(username='foo',\n                          email='foo@bar.com',\n                          authority='bar-client.com')\n\n        assert user.authority == 'bar-client.com'\n\n    def test_passes_user_info_to_signup_email(self, svc, signup_email):\n        user = svc.signup(username='foo', email='foo@bar.com')\n\n        signup_email.assert_called_once_with(id=user.id,\n                                             email='foo@bar.com',\n                                             activation_code=user.activation.code)\n\n    def test_signup_sends_email(self, mailer, svc):\n        svc.signup(username='foo', email='foo@bar.com')\n\n        mailer.send.delay.assert_called_once_with(['test@example.com'],\n                                                  'My subject',\n                                                  'Text',\n                                                  '<p>HTML</p>')\n\n    def test_signup_does_not_send_email_when_activation_not_required(self, mailer, svc):\n        svc.signup(require_activation=False,\n                   username='foo',\n                   email='foo@bar.com')\n\n        assert not mailer.send.delay.called\n\n    def test_signup_creates_reply_notification_subscription(self, db_session, svc):\n        svc.signup(username='foo', email='foo@bar.com')\n\n        sub = (db_session.query(Subscriptions)\n               .filter_by(uri='acct:foo@example.org')\n               .one_or_none())\n\n        assert sub.active\n\n    def test_signup_records_stats_if_present(self, svc, stats):\n        svc.stats = stats\n\n        svc.signup(username='foo', email='foo@bar.com')\n\n        stats.incr.assert_called_once_with('auth.local.register')\n\n    @pytest.fixture\n    def svc(self, db_session, mailer, signup_email):\n        return UserSignupService(default_authority='example.org',\n                                 mailer=mailer,\n                                 session=db_session,\n                                 signup_email=signup_email)\n\n    @pytest.fixture\n    def mailer(self):\n        return mock.Mock(spec_set=['send'])\n\n    @pytest.fixture\n    def signup_email(self):\n        signup_email = mock.Mock(spec_set=[])\n        signup_email.return_value = (['test@example.com'], 'My subject', 'Text', '<p>HTML</p>')\n        return signup_email\n\n    @pytest.fixture\n    def stats(self):\n        return mock.Mock(spec_set=['incr'])\n\n\nclass TestUserServiceFactory(object):\n    def test_returns_user_service(self, pyramid_request):\n        svc = user_service_factory(None, pyramid_request)\n\n        assert isinstance(svc, UserService)\n\n    def test_provides_request_auth_domain_as_default_authority(self, pyramid_request):\n        svc = user_service_factory(None, pyramid_request)\n\n        assert svc.default_authority == pyramid_request.auth_domain\n\n    def test_provides_request_db_as_session(self, pyramid_request):\n        svc = user_service_factory(None, pyramid_request)\n\n        assert svc.session == pyramid_request.db\n\n\nclass TestUserSignupServiceFactory(object):\n    def test_returns_user_signup_service(self, pyramid_request):\n        svc = user_signup_service_factory(None, pyramid_request)\n\n        assert isinstance(svc, UserSignupService)\n\n    def test_provides_request_auth_domain_as_default_authority(self, pyramid_request):\n        svc = user_signup_service_factory(None, pyramid_request)\n\n        assert svc.default_authority == pyramid_request.auth_domain\n\n    def test_provides_request_db_as_session(self, pyramid_request):\n        svc = user_signup_service_factory(None, pyramid_request)\n\n        assert svc.session == pyramid_request.db\n\n    def test_wraps_email_module_as_signup_email(self, patch, pyramid_request):\n        signup_email = patch('h.emails.signup.generate')\n        svc = user_signup_service_factory(None, pyramid_request)\n\n        svc.signup_email(id=123, email='foo@bar.com', activation_code='abc456')\n\n        signup_email.assert_called_once_with(pyramid_request,\n                                             id=123,\n                                             email='foo@bar.com',\n                                             activation_code='abc456')\n\n    def test_provides_request_stats_as_stats(self, pyramid_request):\n        svc = user_signup_service_factory(None, pyramid_request)\n\n        assert svc.stats == pyramid_request.stats\n\n\n@pytest.fixture\ndef pyramid_request(pyramid_request):\n    pyramid_request.stats = mock.Mock(spec_set=['incr'])\n    return pyramid_request\n"},{"size":1923,"relativepath":"tests/h/accounts/__init___test.py","filename":"__init___test.py","extension":".py","content":"# -*- coding: utf-8 -*-\nimport mock\nimport pytest\n\nfrom h import accounts\n\n\n@pytest.mark.usefixtures('user_service')\nclass TestAuthenticatedUser(object):\n    def test_fetches_user_using_service(self,\n                                        factories,\n                                        pyramid_config,\n                                        pyramid_request,\n                                        user_service):\n        pyramid_config.testing_securitypolicy('userid')\n        user_service.fetch.return_value = factories.User()\n\n        accounts.authenticated_user(pyramid_request)\n\n        user_service.fetch.assert_called_once_with('userid')\n\n    def test_does_not_invalidate_session_if_not_authenticated(self,\n                                                              pyramid_config,\n                                                              pyramid_request):\n        \"\"\"\n        If authenticated_userid is None it shouldn't invalidate the session.\n\n        Even though the user with id None obviously won't exist in the db.\n\n        This also tests that it doesn't raise a redirect in this case.\n\n        \"\"\"\n        pyramid_request.session.invalidate = mock.Mock()\n\n        accounts.authenticated_user(pyramid_request)\n\n        assert not pyramid_request.session.invalidate.called\n\n    def test_returns_user(self,\n                          factories,\n                          pyramid_config,\n                          pyramid_request,\n                          user_service):\n        pyramid_config.testing_securitypolicy('userid')\n        user = user_service.fetch.return_value = factories.User()\n\n        result = accounts.authenticated_user(pyramid_request)\n\n        assert result == user\n\n\n@pytest.fixture\ndef user_service(pyramid_config):\n    service = mock.Mock(spec_set=['fetch'])\n    service.fetch.return_value = None\n    pyramid_config.register_service(service, name='user')\n    return service\n"},{"size":6869,"relativepath":"tests/h/notification/reply_test.py","filename":"reply_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\nimport mock\n\nfrom h.models import Annotation\nfrom h.models import Document, DocumentMeta\nfrom h.models import Subscriptions\nfrom h.models import User\nfrom h.notification.reply import Notification\nfrom h.notification.reply import get_notification\n\nFIXTURE_DATA = {\n    'reply': {\n        'id': 'OECV3AmDEeaAtTt8rjCjIg',\n        'groupid': '__world__',\n        'shared': True,\n        'userid': 'acct:elephant@safari.net',\n    },\n    'parent': {\n        'id': 'SucHcAmDEeaAtf_ZeH-rhA',\n        'groupid': '__world__',\n        'shared': True,\n        'userid': 'acct:giraffe@safari.net',\n    },\n}\n\n\n@pytest.mark.usefixtures('authz_policy', 'fetch_annotation', 'subscription', 'user_service')\nclass TestGetNotification(object):\n    def test_returns_correct_params_when_subscribed(self,\n                                                    parent,\n                                                    pyramid_request,\n                                                    reply,\n                                                    user_service):\n        result = get_notification(pyramid_request, reply, 'create')\n\n        assert isinstance(result, Notification)\n        assert result.reply == reply\n        assert result.parent == parent\n        assert result.reply_user == user_service.fetch(reply.userid)\n        assert result.parent_user == user_service.fetch(parent.userid)\n        assert result.document == reply.document\n\n    def test_returns_none_when_action_is_not_create(self, pyramid_request, reply):\n        assert get_notification(pyramid_request, reply, 'update') is None\n        assert get_notification(pyramid_request, reply, 'delete') is None\n        assert get_notification(pyramid_request, reply, 'frobnicate') is None\n\n    def test_returns_none_when_annotation_is_not_reply(self, pyramid_request, reply):\n        reply.references = None\n\n        result = get_notification(pyramid_request, reply, 'create')\n\n        assert result is None\n\n    def test_returns_none_when_parent_does_not_exist(self,\n                                                     annotations,\n                                                     parent,\n                                                     pyramid_request,\n                                                     reply):\n        del annotations[parent.id]\n\n        result = get_notification(pyramid_request, reply, 'create')\n\n        assert result is None\n\n    def test_returns_none_when_parent_user_does_not_exist(self, pyramid_request, reply, user_service):\n        users = {\n            'acct:elephant@safari.net': User(username='elephant')\n        }\n        user_service.fetch.side_effect = users.get\n\n        result = get_notification(pyramid_request, reply, 'create')\n\n        assert result is None\n\n    def test_returns_none_when_reply_user_does_not_exist(self, pyramid_request, reply, user_service):\n        \"\"\"\n        Don't send a reply if somehow the replying user ceased to exist.\n\n        It's not clear when or why this would ever happen, but we can't\n        construct the reply email without the user who replied existing. We log\n        a warning if this happens.\n        \"\"\"\n        users = {\n            'acct:giraffe@safari.net': User(username='giraffe')\n        }\n        user_service.fetch.side_effect = users.get\n\n        result = get_notification(pyramid_request, reply, 'create')\n\n        assert result is None\n\n    def test_returns_none_when_reply_by_same_user(self, parent, pyramid_request, reply):\n        parent.userid = 'acct:elephant@safari.net'\n\n        result = get_notification(pyramid_request, reply, 'create')\n\n        assert result is None\n\n    def test_returns_none_when_parent_user_cannot_read_reply(self, pyramid_request, reply):\n        reply.shared = False\n\n        result = get_notification(pyramid_request, reply, 'create')\n\n        assert result is None\n\n    def test_returns_none_when_subscription_inactive(self, pyramid_request, reply, subscription):\n        subscription.active = False\n\n        result = get_notification(pyramid_request, reply, 'create')\n\n        assert result is None\n\n    def test_returns_none_when_subscription_absent(self,\n                                                   db_session,\n                                                   parent,\n                                                   pyramid_request,\n                                                   reply):\n        db_session.query(Subscriptions).delete()\n\n        result = get_notification(pyramid_request, reply, 'create')\n\n        assert result is None\n\n    @pytest.fixture\n    def annotations(self):\n        return {}\n\n    @pytest.fixture\n    def authz_policy(self, pyramid_config):\n        from pyramid.authorization import ACLAuthorizationPolicy\n        pyramid_config.set_authorization_policy(ACLAuthorizationPolicy())\n\n    @pytest.fixture\n    def fetch_annotation(self, patch, annotations):\n        fetch_annotation = patch('h.notification.reply.storage.fetch_annotation')\n        fetch_annotation.side_effect = lambda _, id: annotations.get(id)\n        return fetch_annotation\n\n    @pytest.fixture\n    def parent(self, annotations):\n        parent = Annotation(**FIXTURE_DATA['parent'])\n        annotations[parent.id] = parent\n        return parent\n\n    @pytest.fixture\n    def reply(self, annotations, db_session, parent):\n        # We need to create a document object to provide the title, and\n        # ensure it is associated with the annotation through the\n        # annotation's `target_uri`\n        doc = Document.find_or_create_by_uris(db_session,\n                                              claimant_uri='http://example.net/foo',\n                                              uris=[]).one()\n        doc.meta.append(DocumentMeta(type='title',\n                                     value=['Some document'],\n                                     claimant='http://example.com/foo'))\n        reply = Annotation(**FIXTURE_DATA['reply'])\n        reply.target_uri = 'http://example.net/foo'\n        reply.references = [parent.id]\n        reply.document = doc\n        db_session.add(reply)\n        db_session.flush()\n        annotations[reply.id] = reply\n        return reply\n\n    @pytest.fixture\n    def subscription(self, db_session):\n        sub = Subscriptions(type='reply', active=True, uri='acct:giraffe@safari.net')\n        db_session.add(sub)\n        db_session.flush()\n        return sub\n\n    @pytest.fixture\n    def user_service(self, pyramid_config):\n        users = {\n            'acct:giraffe@safari.net': User(username='giraffe'),\n            'acct:elephant@safari.net': User(username='elephant'),\n        }\n        service = mock.Mock(spec_set=['fetch'])\n        service.fetch.side_effect = users.get\n        pyramid_config.register_service(service, name='user')\n        return service\n"},{"size":4227,"relativepath":"tests/h/cli/commands/shell_test.py","filename":"shell_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport sys\n\nimport mock\nimport pytest\n\nfrom h.cli.commands import shell\n\n\nclass TestAutoDetect(object):\n\n    def test_bpython(self, monkeypatch):\n        monkeypatch.setitem(sys.modules, 'bpython', mock.sentinel.bpython)\n        assert shell.autodetect() == 'bpython'\n\n    def test_bpython_over_ipython(self, monkeypatch):\n        monkeypatch.setitem(sys.modules, 'bpython', mock.sentinel.bpython)\n        monkeypatch.setitem(sys.modules, 'IPython', mock.sentinel.bpython)\n        assert shell.autodetect() == 'bpython'\n\n    def test_ipython(self, monkeypatch):\n        monkeypatch.setitem(sys.modules, 'IPython', mock.sentinel.bpython)\n        assert shell.autodetect() == 'ipython'\n\n    def test_plain(self):\n        assert shell.autodetect() == 'plain'\n\n\n@pytest.mark.usefixtures('banner')\nclass TestShells(object):\n\n    def test_bpython(self, monkeypatch):\n        fake_bpython = mock.Mock(spec_set=['embed'])\n        monkeypatch.setitem(sys.modules, 'bpython', fake_bpython)\n\n        shell.bpython(foo='bar', baz='qux')\n\n        fake_bpython.embed.assert_called_once_with({'foo': 'bar', 'baz': 'qux'},\n                                                   banner='custom banner!')\n\n    def test_ipython(self, monkeypatch):\n        fake_ipython = mock.Mock(spec_set=['start_ipython'])\n        monkeypatch.setitem(sys.modules, 'IPython', fake_ipython)\n        fake_traitlets = mock.Mock(spec_set=['config'])\n        fake_traitlets_config = mock.Mock(spec_set=['get_config'])\n        monkeypatch.setitem(sys.modules, 'traitlets', fake_traitlets)\n        monkeypatch.setitem(sys.modules, 'traitlets.config', fake_traitlets_config)\n\n        shell.ipython(foo='bar', baz='qux')\n\n        _, kwargs = fake_ipython.start_ipython.call_args\n\n        assert kwargs['argv'] == []\n        assert kwargs['user_ns'] == {'foo': 'bar', 'baz': 'qux'}\n        assert kwargs['config'].TerminalInteractiveShell.banner2 == 'custom banner!'\n\n    def test_plain(self, monkeypatch):\n        fake_code = mock.Mock(spec_set=['interact'])\n        monkeypatch.setitem(sys.modules, 'code', fake_code)\n\n        shell.plain(foo='bar', baz='qux')\n\n        fake_code.interact.assert_called_once_with(banner='custom banner!',\n                                                   local={'foo': 'bar',\n                                                          'baz': 'qux'})\n\n    @pytest.fixture\n    def banner(self, monkeypatch):\n        monkeypatch.setattr(shell, 'BANNER', 'custom banner!')\n\n\n@pytest.mark.usefixtures('code', 'models')\nclass TestShellCommand(object):\n\n    def test_runs_bootstrap(self, cli):\n        config = {'bootstrap': mock.Mock(spec_set=[])}\n\n        cli.invoke(shell.shell, obj=config)\n\n        config['bootstrap'].assert_called_once_with()\n\n    def test_can_select_shell_manually(self, cli, monkeypatch):\n        config = {'bootstrap': mock.Mock(spec_set=[])}\n        fake_bpython = mock.Mock(spec_set=['embed'])\n        monkeypatch.setitem(sys.modules, 'bpython', fake_bpython)\n\n        cli.invoke(shell.shell, ['--type', 'bpython'], obj=config)\n\n        assert fake_bpython.embed.called\n\n    def test_passes_useful_locals(self, cli, code, models):\n        bootstrap = mock.Mock(spec_set=[])\n        request = bootstrap.return_value\n        config = {'bootstrap': bootstrap}\n\n        cli.invoke(shell.shell, obj=config)\n\n        _, kwargs = code.interact.call_args\n        locals_ = kwargs['local']\n\n        assert locals_ == {\n            'm': models,\n            'models': models,\n            'registry': request.registry,\n            'request': request,\n            'session': request.db,\n        }\n\n    def test_error_if_shell_not_found(self, cli):\n        config = {'bootstrap': mock.Mock(spec_set=[])}\n\n        result = cli.invoke(shell.shell, ['--type', 'bpython'], obj=config)\n\n        assert result.exit_code != 0\n\n    @pytest.fixture\n    def code(self, monkeypatch):\n        code = mock.Mock(spec_set=['interact'])\n        monkeypatch.setitem(sys.modules, 'code', code)\n        return code\n\n    @pytest.fixture\n    def models(self, monkeypatch):\n        h = mock.Mock(spec_set=['models'])\n        h.models = mock.sentinel.models\n        monkeypatch.setitem(sys.modules, 'h', h)\n        return h.models\n"},{"size":7531,"relativepath":"tests/h/cli/commands/normalize_uris_test.py","filename":"normalize_uris_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport mock\nimport pytest\n\nfrom memex import models\nfrom h.cli.commands import normalize_uris\n\n\ndef test_it_normalizes_document_uris_uri(req):\n    docuri_1 = models.DocumentURI(_claimant='http://example.org/',\n                                  _claimant_normalized='http://example.org',\n                                  _uri='http://example.org/',\n                                  _uri_normalized='http://example.org',\n                                  type='self-claim')\n    docuri_2 = models.DocumentURI(_claimant='http://example.org/',\n                                  _claimant_normalized='http://example.org',\n                                  _uri='https://example.org/',\n                                  _uri_normalized='https://example.org',\n                                  type='rel-canonical')\n\n    req.db.add(models.Document(document_uris=[docuri_1, docuri_2]))\n    req.db.flush()\n\n    normalize_uris.normalize_document_uris(req)\n\n    assert docuri_1.uri_normalized == 'httpx://example.org'\n    assert docuri_2.uri_normalized == 'httpx://example.org'\n\n\ndef test_it_normalizes_document_uris_claimant(req):\n    docuri_1 = models.DocumentURI(_claimant='http://example.org/',\n                                  _claimant_normalized='http://example.org',\n                                  _uri='http://example.org/',\n                                  _uri_normalized='http://example.org',\n                                  type='self-claim')\n    docuri_2 = models.DocumentURI(_claimant='http://example.org/',\n                                  _claimant_normalized='http://example.org',\n                                  _uri='https://example.org/',\n                                  _uri_normalized='https://example.org',\n                                  type='rel-canonical')\n\n    req.db.add(models.Document(document_uris=[docuri_1, docuri_2]))\n    req.db.flush()\n\n    normalize_uris.normalize_document_uris(req)\n\n    assert docuri_1.claimant_normalized == 'httpx://example.org'\n    assert docuri_2.claimant_normalized == 'httpx://example.org'\n\n\ndef test_it_deletes_duplicate_document_uri_objects(req):\n    docuri_1 = models.DocumentURI(_claimant='http://example.org/',\n                                  _claimant_normalized='http://example.org',\n                                  _uri='http://example.org/',\n                                  _uri_normalized='http://example.org',\n                                  type='self-claim')\n    docuri_2 = models.DocumentURI(_claimant='https://example.org/',\n                                  _claimant_normalized='https://example.org',\n                                  _uri='https://example.org/',\n                                  _uri_normalized='https://example.org',\n                                  type='self-claim')\n\n    req.db.add(models.Document(document_uris=[docuri_1, docuri_2]))\n    req.db.flush()\n\n    normalize_uris.normalize_document_uris(req)\n\n    assert req.db.query(models.DocumentURI).count() == 1\n\n\ndef test_it_merges_documents_when_duplicates_found(req):\n    docuri_1 = models.DocumentURI(claimant='http://example.org/',\n                                  uri='http://example.org/',\n                                  type='self-claim')\n    docuri_2 = models.DocumentURI(claimant='https://example.net/',\n                                  uri='https://example.org/',\n                                  type='rel-canonical')\n\n    req.db.add_all([\n        models.Document(document_uris=[docuri_1]),\n        models.Document(document_uris=[docuri_2]),\n    ])\n    req.db.flush()\n\n    normalize_uris.normalize_document_uris(req)\n\n    assert req.db.query(models.Document).count() == 1\n\n\ndef test_it_normalizes_document_meta_claimant(req):\n    docmeta_1 = models.DocumentMeta(_claimant='http://example.org/',\n                                    _claimant_normalized='http://example.org',\n                                    type='title',\n                                    value=['Test Title'])\n    docmeta_2 = models.DocumentMeta(_claimant='http://example.net/',\n                                    _claimant_normalized='http://example.net',\n                                    type='title',\n                                    value=['Test Title'])\n\n    req.db.add(models.Document(meta=[docmeta_1, docmeta_2]))\n    req.db.flush()\n\n    normalize_uris.normalize_document_meta(req)\n\n    assert docmeta_1.claimant_normalized == 'httpx://example.org'\n    assert docmeta_2.claimant_normalized == 'httpx://example.net'\n\n\ndef test_it_deletes_duplicate_document_meta_objects(req):\n    docmeta_1 = models.DocumentMeta(_claimant='http://example.org/',\n                                    type='title',\n                                    value=['Test Title'])\n    docmeta_1._claimant_normalized = 'http://example.org'\n    docmeta_2 = models.DocumentMeta(_claimant='https://example.org/',\n                                    type='title',\n                                    value=['Test Title'])\n    docmeta_2._claimant_normalized = 'https://example.org'\n\n    req.db.add_all([\n        models.Document(meta=[docmeta_1]),\n        models.Document(meta=[docmeta_2]),\n    ])\n    req.db.flush()\n\n    normalize_uris.normalize_document_meta(req)\n\n    assert req.db.query(models.DocumentMeta).count() == 1\n\n\n@pytest.mark.usefixtures('index')\ndef test_it_normalizes_annotation_target_uri(req, factories, db_session):\n    annotation_1 = factories.Annotation(userid='luke', target_uri='http://example.org/')\n    annotation_1._target_uri_normalized = 'http://example.org'\n    annotation_2 = factories.Annotation(userid='luke', target_uri='http://example.net/')\n    annotation_2._target_uri_normalized = 'http://example.net'\n    db_session.flush()\n\n    normalize_uris.normalize_annotations(req)\n\n    assert annotation_1.target_uri_normalized == 'httpx://example.org'\n    assert annotation_2.target_uri_normalized == 'httpx://example.net'\n\n\ndef test_it_reindexes_changed_annotations(req, index, factories, db_session):\n    annotation_1 = factories.Annotation(userid='luke',\n                                        target_uri='http://example.org/')\n    annotation_1._target_uri_normalized = 'http://example.org'\n    annotation_2 = factories.Annotation(userid='luke',\n                                        target_uri='http://example.net/')\n    annotation_2._target_uri_normalized='http://example.net'\n    db_session.flush()\n\n    indexer = index.BatchIndexer.return_value\n    indexer.index.return_value = None\n\n    normalize_uris.normalize_annotations(req)\n\n    indexer.index.assert_called_once_with(set([annotation_1.id, annotation_2.id]))\n\n\ndef test_it_skips_reindexing_unaltered_annotations(req, index, factories, db_session):\n    annotation_1 = factories.Annotation(userid='luke',\n                                        target_uri='http://example.org/')\n    annotation_2 = factories.Annotation(userid='luke',\n                                        target_uri='http://example.net/')\n    annotation_2._target_uri_normalized = 'http://example.net'\n    db_session.flush()\n\n    indexer = index.BatchIndexer.return_value\n    indexer.index.return_value = None\n\n    normalize_uris.normalize_annotations(req)\n\n    indexer.index.assert_called_once_with(set([annotation_2.id]))\n\n\n@pytest.fixture\ndef req(pyramid_request):\n    pyramid_request.tm = mock.MagicMock()\n    pyramid_request.es = mock.MagicMock()\n    return pyramid_request\n\n\n@pytest.fixture\ndef index(patch):\n    return patch('h.cli.commands.normalize_uris.index')\n"},{"size":397,"relativepath":"tests/h/config_test.py","filename":"config_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom h.config import configure\n\n\ndef test_configure_generates_secret_key_if_missing():\n    config = configure(environ={}, settings={})\n\n    assert 'secret_key' in config.registry.settings\n\n\ndef test_configure_doesnt_override_secret_key():\n    config = configure(environ={}, settings={'secret_key': 'foobar'})\n\n    assert config.registry.settings['secret_key'] == 'foobar'\n"},{"size":6894,"relativepath":"tests/h/auth/policy_test.py","filename":"policy_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\nimport pytest\n\nfrom pyramid.interfaces import IAuthenticationPolicy\n\nfrom h.auth.policy import AuthenticationPolicy\nfrom h.auth.policy import TokenAuthenticationPolicy\n\nAPI_PATHS = (\n    '/api',\n    '/api/foo',\n    '/api/annotations/abc123',\n)\n\nNONAPI_PATHS = (\n    '/login',\n    '/account/settings',\n    '/api/badge',\n    '/api/token',\n)\n\n\nclass TestAuthenticationPolicy(object):\n\n    @pytest.fixture(autouse=True)\n    def policy(self):\n        self.api_policy = mock.Mock(spec_set=list(IAuthenticationPolicy))\n        self.fallback_policy = mock.Mock(spec_set=list(IAuthenticationPolicy))\n        self.policy = AuthenticationPolicy(api_policy=self.api_policy,\n                                           fallback_policy=self.fallback_policy)\n\n        self.fallback_policy.remember.return_value = [('Cookie', 'auth=foobar')]\n\n    # api_request and nonapi_request are parametrized fixtures, which will\n    # take on each value in the passed `params` sequence in turn. This is a\n    # quick and easy way to generate a named fixture which takes multiple\n    # values and can be used by multiple tests.\n    @pytest.fixture(params=API_PATHS)\n    def api_request(self, request, pyramid_request):\n        pyramid_request.path = request.param\n        return pyramid_request\n\n    @pytest.fixture(params=NONAPI_PATHS)\n    def nonapi_request(self, request, pyramid_request):\n        pyramid_request.path = request.param\n        return pyramid_request\n\n    def test_authenticated_userid_uses_fallback_policy_for_nonapi_paths(self, nonapi_request):\n        result = self.policy.authenticated_userid(nonapi_request)\n\n        self.fallback_policy.authenticated_userid.assert_called_once_with(nonapi_request)\n        assert result == self.fallback_policy.authenticated_userid.return_value\n\n    def test_authenticated_userid_uses_api_policy_for_api_paths(self, api_request):\n        result = self.policy.authenticated_userid(api_request)\n\n        self.api_policy.authenticated_userid.assert_called_once_with(api_request)\n        assert result == self.api_policy.authenticated_userid.return_value\n\n    def test_unauthenticated_userid_uses_fallback_policy_for_nonapi_paths(self, nonapi_request):\n        result = self.policy.unauthenticated_userid(nonapi_request)\n\n        self.fallback_policy.unauthenticated_userid.assert_called_once_with(nonapi_request)\n        assert result == self.fallback_policy.unauthenticated_userid.return_value\n\n    def test_unauthenticated_userid_uses_api_policy_for_api_paths(self, api_request):\n        result = self.policy.unauthenticated_userid(api_request)\n\n        self.api_policy.unauthenticated_userid.assert_called_once_with(api_request)\n        assert result == self.api_policy.unauthenticated_userid.return_value\n\n    def test_effective_principals_uses_fallback_policy_for_nonapi_paths(self, nonapi_request):\n        result = self.policy.effective_principals(nonapi_request)\n\n        self.fallback_policy.effective_principals.assert_called_once_with(nonapi_request)\n        assert result == self.fallback_policy.effective_principals.return_value\n\n    def test_effective_principals_uses_api_policy_for_api_paths(self, api_request):\n        result = self.policy.effective_principals(api_request)\n\n        self.api_policy.effective_principals.assert_called_once_with(api_request)\n        assert result == self.api_policy.effective_principals.return_value\n\n    def test_remember_uses_fallback_policy_for_nonapi_paths(self, nonapi_request):\n        result = self.policy.remember(nonapi_request, 'foo', bar='baz')\n\n        self.fallback_policy.remember.assert_called_once_with(nonapi_request, 'foo', bar='baz')\n        assert result == self.fallback_policy.remember.return_value\n\n    def test_remember_uses_api_policy_for_api_paths(self, api_request):\n        result = self.policy.remember(api_request, 'foo', bar='baz')\n\n        self.api_policy.remember.assert_called_once_with(api_request, 'foo', bar='baz')\n        assert result == self.api_policy.remember.return_value\n\n    def test_forget_uses_fallback_policy_for_nonapi_paths(self, nonapi_request):\n        result = self.policy.forget(nonapi_request)\n\n        self.fallback_policy.forget.assert_called_once_with(nonapi_request)\n        assert result == self.fallback_policy.forget.return_value\n\n    def test_forget_uses_api_policy_for_api_paths(self, api_request):\n        result = self.policy.forget(api_request)\n\n        self.api_policy.forget.assert_called_once_with(api_request)\n        assert result == self.api_policy.forget.return_value\n\n\nclass TestTokenAuthenticationPolicy(object):\n    def test_remember_does_nothing(self, pyramid_request):\n        policy = TokenAuthenticationPolicy()\n\n        assert policy.remember(pyramid_request, 'foo') == []\n\n    def test_forget_does_nothing(self, pyramid_request):\n        policy = TokenAuthenticationPolicy()\n\n        assert policy.forget(pyramid_request) == []\n\n    def test_unauthenticated_userid_is_none_if_no_token(self, pyramid_request):\n        policy = TokenAuthenticationPolicy()\n\n        assert policy.unauthenticated_userid(pyramid_request) is None\n\n    def test_unauthenticated_userid_returns_userid_from_token(self, fake_token, pyramid_request):\n        policy = TokenAuthenticationPolicy()\n        pyramid_request.auth_token = fake_token\n\n        result = policy.unauthenticated_userid(pyramid_request)\n\n        assert result == 'acct:foo@example.com'\n\n    def test_unauthenticated_userid_returns_none_if_token_invalid(self, pyramid_request):\n        policy = TokenAuthenticationPolicy()\n        token = DummyToken(valid=False)\n        pyramid_request.auth_token = token\n\n        result = policy.unauthenticated_userid(pyramid_request)\n\n        assert result is None\n\n    def test_authenticated_userid_uses_callback(self, fake_token, pyramid_request):\n        def callback(userid, request):\n            return None\n        policy = TokenAuthenticationPolicy(callback=callback)\n        pyramid_request.auth_token = fake_token\n\n        result = policy.authenticated_userid(pyramid_request)\n\n        assert result is None\n\n    def test_effective_principals_uses_callback(self, fake_token, pyramid_request):\n        def callback(userid, request):\n            return [userid + '.foo', 'group:donkeys']\n        policy = TokenAuthenticationPolicy(callback=callback)\n        pyramid_request.auth_token = fake_token\n\n        result = policy.effective_principals(pyramid_request)\n\n        assert set(result) > set(['acct:foo@example.com',\n                                  'acct:foo@example.com.foo',\n                                  'group:donkeys'])\n\n    @pytest.fixture\n    def fake_token(self):\n        return DummyToken()\n\n\nclass DummyToken(object):\n    def __init__(self, userid='acct:foo@example.com', valid=True):\n        self.userid = userid\n        self._valid = valid\n\n    def is_valid(self):\n        return self._valid\n"},{"size":6095,"relativepath":"tests/h/auth/util_test.py","filename":"util_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport base64\nfrom collections import namedtuple\n\nimport pytest\nimport mock\nfrom hypothesis import strategies as st\nfrom hypothesis import given\n\nfrom pyramid import security\n\nfrom h.auth import role\nfrom h.auth import util\n\n\nFakeUser = namedtuple('FakeUser', ['admin', 'staff', 'groups'])\nFakeGroup = namedtuple('FakeGroup', ['pubid'])\n\n# The most recent standard covering the 'Basic' HTTP Authentication scheme is\n# RFC 7617. It defines the allowable characters in usernames and passwords as\n# follows:\n#\n#     The user-id and password MUST NOT contain any control characters (see\n#     \"CTL\" in Appendix B.1 of [RFC5234]).\n#\n# RFC5234 defines CTL as:\n#\n#     CTL            =  %x00-1F / %x7F\n#\nCONTROL_CHARS = set(chr(n) for n in range(0x00, 0x1F+1)) | set('\\x7f')\n\n# Furthermore, from RFC 7617:\n#\n#     a user-id containing a colon character is invalid\n#\nINVALID_USERNAME_CHARS = CONTROL_CHARS | set(':')\n\n# The character encoding of the user-id and password is *undefined* by\n# specification for historical reasons:\n#\n#     The original definition of this authentication scheme failed to specify\n#     the character encoding scheme used to convert the user-pass into an\n#     octet sequence.  In practice, most implementations chose either a\n#     locale-specific encoding such as ISO-8859-1 ([ISO-8859-1]), or UTF-8\n#     ([RFC3629]).  For backwards compatibility reasons, this specification\n#     continues to leave the default encoding undefined, as long as it is\n#     compatible with US-ASCII (mapping any US-ASCII character to a single\n#     octet matching the US-ASCII character code).\n#\n# In particular, Firefox still does *very* special things if you provide\n# non-BMP characters in a username or password.\n#\n# There's not a lot we can do about this so we are going to assume UTF-8\n# encoding for the user-pass string, and these tests verify that we\n# successfully decode valid Unicode user-pass strings.\n#\nVALID_USERNAME_CHARS = st.characters(blacklist_characters=INVALID_USERNAME_CHARS)\nVALID_PASSWORD_CHARS = st.characters(blacklist_characters=CONTROL_CHARS)\n\n\nclass TestBasicAuthCreds(object):\n\n    @given(username=st.text(alphabet=VALID_USERNAME_CHARS),\n           password=st.text(alphabet=VALID_PASSWORD_CHARS))\n    def test_valid(self, username, password, pyramid_request):\n        user_pass = username + ':' + password\n        creds = ('Basic', base64.standard_b64encode(user_pass.encode('utf-8')))\n        pyramid_request.authorization = creds\n\n        assert util.basic_auth_creds(pyramid_request) == (username, password)\n\n    def test_missing(self, pyramid_request):\n        pyramid_request.authorization = None\n\n        assert util.basic_auth_creds(pyramid_request) is None\n\n    def test_no_password(self, pyramid_request):\n        creds = ('Basic', base64.standard_b64encode('foobar'.encode('utf-8')))\n        pyramid_request.authorization = creds\n\n        assert util.basic_auth_creds(pyramid_request) is None\n\n    def test_other_authorization_type(self, pyramid_request):\n        creds = ('Digest', base64.standard_b64encode('foo:bar'.encode('utf-8')))\n        pyramid_request.authorization = creds\n\n        assert util.basic_auth_creds(pyramid_request) is None\n\n\nclass TestGroupfinder(object):\n    def test_it_fetches_the_user(self, pyramid_request, user_service):\n        util.groupfinder('acct:bob@example.org', pyramid_request)\n        user_service.fetch.assert_called_once_with('acct:bob@example.org')\n\n    def test_it_returns_principals_for_user(self,\n                                            pyramid_request,\n                                            user_service,\n                                            principals_for_user):\n        result = util.groupfinder('acct:bob@example.org', pyramid_request)\n\n        principals_for_user.assert_called_once_with(user_service.fetch.return_value)\n        assert result == principals_for_user.return_value\n\n\n@pytest.mark.parametrize('user,principals', (\n    # User isn't found in the database: they're not authenticated at all\n    (None, None),\n    # User found but not staff, admin, or a member of any groups: no additional principals\n    (FakeUser(admin=False, staff=False, groups=[]),\n     []),\n    # User is admin: role.Admin should be in principals\n    (FakeUser(admin=True, staff=False, groups=[]),\n     [role.Admin]),\n    # User is staff: role.Staff should be in principals\n    (FakeUser(admin=False, staff=True, groups=[]),\n     [role.Staff]),\n    # User is admin and staff\n    (FakeUser(admin=True, staff=True, groups=[]),\n     [role.Admin, role.Staff]),\n    # User is a member of some groups\n    (FakeUser(admin=False, staff=False, groups=[FakeGroup('giraffe'), FakeGroup('elephant')]),\n     ['group:giraffe', 'group:elephant']),\n    # User is admin, staff, and a member of some groups\n    (FakeUser(admin=True, staff=True, groups=[FakeGroup('donkeys')]),\n     ['group:donkeys', role.Admin, role.Staff]),\n))\ndef test_principals_for_user(user, principals):\n    result = util.principals_for_user(user)\n\n    if principals is None:\n        assert result is None\n    else:\n        assert set(principals) == set(result)\n\n\n@pytest.mark.parametrize(\"p_in,p_out\", [\n    # The basics\n    ([], []),\n    (['acct:donna@example.com'], ['acct:donna@example.com']),\n    (['group:foo'], ['group:foo']),\n\n    # Remove pyramid principals\n    (['system.Everyone'], []),\n\n    # Remap annotatator principal names\n    (['group:__world__'], [security.Everyone]),\n\n    # Normalise multiple principals\n    (['me', 'myself', 'me', 'group:__world__', 'group:foo', 'system.Admins'],\n     ['me', 'myself', security.Everyone, 'group:foo']),\n])\ndef test_translate_annotation_principals(p_in, p_out):\n    result = util.translate_annotation_principals(p_in)\n\n    assert set(result) == set(p_out)\n\n\n@pytest.fixture\ndef user_service(pyramid_config):\n    service = mock.Mock(spec_set=['fetch'])\n    service.fetch.return_value = None\n    pyramid_config.register_service(service, name='user')\n    return service\n\n@pytest.fixture\ndef principals_for_user(patch):\n    return patch('h.auth.util.principals_for_user')\n"},{"size":2417,"relativepath":"tests/h/auth/worker_test.py","filename":"worker_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom datetime import (datetime, timedelta)\n\nimport pytest\n\nfrom h.auth import worker\nfrom h.models import (AuthTicket, Token)\n\n\n@pytest.mark.usefixtures('celery')\nclass TestDeleteExpiredAuthTickets(object):\n    def test_it_removes_expired_tickets(self, db_session, factories):\n        tickets = [\n            factories.AuthTicket(expires=datetime(2014, 5, 6, 7, 8, 9)),\n            factories.AuthTicket(expires=(datetime.utcnow() - timedelta(seconds=1))),\n        ]\n        db_session.add_all(tickets)\n\n        assert db_session.query(AuthTicket).count() == 2\n        worker.delete_expired_auth_tickets()\n        assert db_session.query(AuthTicket).count() == 0\n\n    def test_it_leaves_valid_tickets(self, db_session, factories):\n        tickets = [\n            factories.AuthTicket(expires=datetime(2014, 5, 6, 7, 8, 9)),\n            factories.AuthTicket(expires=(datetime.utcnow() + timedelta(hours=1))),\n        ]\n        db_session.add_all(tickets)\n\n        assert db_session.query(AuthTicket).count() == 2\n        worker.delete_expired_auth_tickets()\n        assert db_session.query(AuthTicket).count() == 1\n\n\n@pytest.mark.usefixtures('celery')\nclass TestDeleteExpiredTokens(object):\n    def test_it_removes_expired_tokens(self, db_session, factories):\n        factories.Token(expires=datetime(2014, 5, 6, 7, 8, 9))\n        factories.Token(expires=(datetime.utcnow() - timedelta(seconds=1)))\n\n        assert db_session.query(Token).count() == 2\n        worker.delete_expired_tokens()\n        assert db_session.query(Token).count() == 0\n\n    def test_it_leaves_valid_tickets(self, db_session, factories):\n        factories.Token(expires=datetime(2014, 5, 6, 7, 8, 9))\n        factories.Token(expires=(datetime.utcnow() + timedelta(hours=1)))\n\n        assert db_session.query(Token).count() == 2\n        worker.delete_expired_tokens()\n        assert db_session.query(Token).count() == 1\n\n    def test_it_leaves_tickets_without_an_expiration_date(self, db_session, factories):\n        factories.Token(expires=None)\n        factories.Token(expires=None)\n\n        assert db_session.query(Token).count() == 2\n        worker.delete_expired_tokens()\n        assert db_session.query(Token).count() == 2\n\n\n@pytest.fixture\ndef celery(patch, db_session):\n    cel = patch('h.auth.worker.celery', autospec=False)\n    cel.request.db = db_session\n    return cel\n"},{"size":19779,"relativepath":"tests/h/auth/services_test.py","filename":"services_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom datetime import (datetime, timedelta)\nfrom calendar import timegm\n\nimport jwt\nimport mock\nimport pytest\n\nfrom h import models\nfrom h.accounts.services import UserService\nfrom h.auth import services\nfrom h.exceptions import OAuthTokenError\nfrom h._compat import text_type\n\n\nclass TestAuthTicketService(object):\n    def test_userid_raises_when_ticket_has_not_been_loaded_yet(self, svc):\n        with pytest.raises(services.AuthTicketNotLoadedError) as exc:\n            svc.userid()\n        assert str(exc.value) == 'auth ticket is not loaded yet'\n\n    def test_userid_returns_the_users_userid(self, svc, ticket):\n        svc.usersvc.fetch.return_value = ticket.user\n\n        svc.verify_ticket(ticket.user_userid, ticket.id)\n\n        userid = svc.userid()\n        assert ticket.user.userid == userid\n\n    @pytest.mark.usefixtures('principals_for_user')\n    def test_groups_loads_the_user(self, svc, ticket):\n        svc.verify_ticket(ticket.user_userid, ticket.id)\n\n        svc.groups()\n\n        assert svc.usersvc.fetch.call_count == 1\n        svc.usersvc.fetch.assert_called_once_with(ticket.user_userid)\n\n    def test_groups_returns_principals_for_user(self, svc, principals_for_user, ticket):\n        principals_for_user.return_value = ['foo', 'bar', 'baz']\n        svc.usersvc.fetch.return_value = ticket.user\n        svc.verify_ticket(ticket.user_userid, ticket.id)\n\n        result = svc.groups()\n\n        principals_for_user.assert_called_once_with(ticket.user)\n        assert ['foo', 'bar', 'baz'] == result\n\n    def test_groups_raises_when_ticket_is_not_loaded(self, svc, ticket):\n        with pytest.raises(services.AuthTicketNotLoadedError) as exc:\n            svc.groups()\n        assert str(exc.value) == 'auth ticket is not loaded yet'\n\n    def test_verify_ticket_fails_when_id_is_None(self, svc):\n        assert svc.verify_ticket(self.principal, None) is False\n\n    def test_verify_ticket_fails_when_id_is_empty(self, svc):\n        assert svc.verify_ticket(self.principal, '') is False\n\n    @pytest.mark.usefixtures('ticket')\n    def test_verify_ticket_fails_when_ticket_cannot_be_found(self, svc, db_session):\n        assert svc.verify_ticket('foobar', 'bogus') is False\n\n    def test_verify_ticket_fails_when_ticket_user_does_not_match_principal(self, svc, db_session, ticket):\n        assert svc.verify_ticket('foobar', ticket.id) is False\n\n    def test_verify_ticket_fails_when_ticket_is_expired(self, svc, db_session, factories):\n        expires = datetime.utcnow() - timedelta(hours=3)\n        ticket = factories.AuthTicket(expires=expires)\n        db_session.flush()\n\n        assert svc.verify_ticket(ticket.user_userid, ticket.id) is False\n\n    def test_verify_ticket_succeeds_when_ticket_is_valid(self, svc, db_session, ticket):\n        assert svc.verify_ticket(ticket.user_userid, ticket.id) is True\n\n    def test_verify_ticket_skips_extending_expiration_when_within_refresh_interval(self, svc, db_session, factories):\n        ticket = factories.AuthTicket(updated=datetime.utcnow())\n        db_session.flush()\n\n        expires_before = ticket.expires\n\n        svc.verify_ticket(ticket.user_userid, ticket.id)\n        db_session.flush()\n\n        # Manually expire ticket, so that the data will be reloaded from the\n        # database.\n        db_session.expire(ticket)\n        assert expires_before == ticket.expires\n\n    def test_verify_ticket_extends_expiration_when_over_refresh_interval(self, svc, db_session, factories):\n        ticket = factories.AuthTicket(updated=(datetime.utcnow() - services.TICKET_REFRESH_INTERVAL))\n        db_session.flush()\n\n        expires_before = ticket.expires\n\n        svc.verify_ticket(ticket.user_userid, ticket.id)\n        db_session.flush()\n\n        # Manually expire ticket, so that the data will be reloaded from the\n        # database.\n        db_session.expire(ticket)\n        assert expires_before < ticket.expires\n\n    def test_add_ticket_raises_when_user_cannot_be_found(self, svc):\n        svc.usersvc.fetch.return_value = None\n\n        with pytest.raises(ValueError) as exc:\n            svc.add_ticket('bogus', 'foobar')\n\n        assert str(exc.value) == 'Cannot find user with userid bogus'\n\n    def test_add_ticket_stores_ticket(self, svc, db_session, user, utcnow):\n        svc.usersvc.fetch.return_value = user\n\n        utcnow.return_value = datetime(2016, 1, 1, 5, 23, 54)\n\n        svc.add_ticket(user.userid, 'the-ticket-id')\n\n        ticket = db_session.query(models.AuthTicket).first()\n        assert ticket.id == 'the-ticket-id'\n        assert ticket.user == user\n        assert ticket.user_userid == user.userid\n        assert ticket.expires == utcnow.return_value + services.TICKET_TTL\n\n    def test_add_ticket_caches_the_userid(self, svc, db_session, user):\n        svc.usersvc.fetch.return_value = user\n\n        assert svc._userid is None\n        svc.add_ticket(user.userid, 'the-ticket-id')\n        assert svc._userid == user.userid\n\n    @pytest.mark.usefixtures('ticket')\n    def test_remove_ticket_skips_deleting_when_id_is_None(self, svc, db_session):\n        assert db_session.query(models.AuthTicket).count() == 1\n        svc.remove_ticket(None)\n        assert db_session.query(models.AuthTicket).count() == 1\n\n    @pytest.mark.usefixtures('ticket')\n    def test_remove_ticket_skips_deleting_when_id_is_empty(self, svc, db_session):\n        assert db_session.query(models.AuthTicket).count() == 1\n        svc.remove_ticket('')\n        assert db_session.query(models.AuthTicket).count() == 1\n\n    def test_remove_ticket_deletes_ticket(self, svc, ticket, factories, db_session):\n        keep = factories.AuthTicket()\n\n        assert db_session.query(models.AuthTicket).count() == 2\n        svc.remove_ticket(ticket.id)\n        assert db_session.query(models.AuthTicket).get(keep.id) is not None\n        assert db_session.query(models.AuthTicket).get(ticket.id) is None\n\n    def test_remove_ticket_clears_userid_cache(self, svc, ticket):\n        svc.verify_ticket(ticket.user_userid, ticket.id)\n\n        assert svc._userid is not None\n        svc.remove_ticket(ticket.id)\n        assert svc._userid is None\n\n    @property\n    def principal(self):\n        return 'acct:bob@example.org'\n\n    @property\n    def ticket_id(self):\n        return 'test-ticket-id'\n\n    @pytest.fixture\n    def svc(self, db_session, user_service):\n        return services.AuthTicketService(db_session, user_service)\n\n    @pytest.fixture\n    def principals_for_user(self, patch):\n        return patch('h.auth.services.principals_for_user')\n\n    @pytest.fixture\n    def ticket(self, factories, user, db_session):\n        ticket = factories.AuthTicket(user=user, user_userid=user.userid)\n        db_session.flush()\n        return ticket\n\n    @pytest.fixture\n    def user(self, factories, db_session):\n        user = factories.User()\n        db_session.add(user)\n        db_session.flush()\n        return user\n\n\n@pytest.mark.usefixtures('user_service')\nclass TestAuthTicketServiceFactory(object):\n    def test_it_returns_auth_ticket_service(self, pyramid_request):\n        svc = services.auth_ticket_service_factory(None, pyramid_request)\n        assert isinstance(svc, services.AuthTicketService)\n\n    def test_it_provides_request_db_as_session(self, pyramid_request):\n        svc = services.auth_ticket_service_factory(None, pyramid_request)\n        assert svc.session == pyramid_request.db\n\n    def test_it_provides_user_service(self, pyramid_request, user_service):\n        svc = services.auth_ticket_service_factory(None, pyramid_request)\n        assert svc.usersvc == user_service\n\n\nclass TestOAuthServiceVerifyJWTBearer(object):\n    \"\"\" Tests for ``OAuthService.verify_jwt_bearer`` \"\"\"\n\n    def test_it_returns_the_user_and_authclient_from_the_jwt_token(self, svc, claims, authclient, user):\n        expected_user = user\n        tok = self.jwt_token(claims, authclient.secret)\n\n        result = svc.verify_jwt_bearer(assertion=tok,\n                                       grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert (expected_user, authclient) == result\n\n    def test_missing_grant_type(self, svc):\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion='jwt-token',\n                                  grant_type=None)\n\n        assert exc.value.type == 'unsupported_grant_type'\n        assert 'grant type is not supported' in exc.value.message\n\n    def test_unsupported_grant_type(self, svc):\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion='jwt-token',\n                                  grant_type='authorization_code')\n\n        assert exc.value.type == 'unsupported_grant_type'\n        assert 'grant type is not supported' in exc.value.message\n\n    def test_missing_assertion(self, svc):\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion=None,\n                                  grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert exc.value.type == 'invalid_request'\n        assert 'assertion parameter is missing' in exc.value.message\n\n    def test_non_jwt_assertion(self, svc):\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion='bogus',\n                                  grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert exc.value.type == 'invalid_grant'\n        assert 'invalid JWT signature' in exc.value.message\n\n    def test_missing_jwt_issuer(self, svc, claims, authclient):\n        del claims['iss']\n        tok = self.jwt_token(claims, authclient.secret)\n\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion=tok,\n                                  grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert exc.value.type == 'invalid_grant'\n        assert 'issuer is missing' in exc.value.message\n\n    def test_empty_jwt_issuer(self, svc, claims, authclient):\n        claims['iss'] = ''\n        tok = self.jwt_token(claims, authclient.secret)\n\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion=tok,\n                                  grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert exc.value.type == 'invalid_grant'\n        assert 'issuer is missing' in exc.value.message\n\n    def test_missing_authclient_with_given_jwt_issuer(self, svc, claims, authclient, db_session):\n        db_session.delete(authclient)\n        db_session.flush()\n\n        tok = self.jwt_token(claims, authclient.secret)\n\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion=tok,\n                                  grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert exc.value.type == 'invalid_grant'\n        assert 'issuer is invalid' in exc.value.message\n\n    def test_signed_with_different_secret(self, svc, claims):\n        tok = self.jwt_token(claims, 'different-secret')\n\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion=tok,\n                                  grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert exc.value.type == 'invalid_grant'\n        assert 'invalid JWT signature' in exc.value.message\n\n    def test_signed_with_unsupported_algorithm(self, svc, claims, authclient):\n        tok = self.jwt_token(claims, authclient.secret, algorithm='HS512')\n\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion=tok,\n                                  grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert exc.value.type == 'invalid_grant'\n        assert 'invalid JWT signature algorithm' in exc.value.message\n\n    def test_missing_jwt_audience(self, svc, claims, authclient):\n        del claims['aud']\n        tok = self.jwt_token(claims, authclient.secret)\n\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion=tok,\n                                  grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert exc.value.type == 'invalid_grant'\n        assert 'missing claim aud' in exc.value.message\n\n    def test_invalid_jwt_audience(self, svc, claims, authclient):\n        claims['aud'] = 'foobar.org'\n        tok = self.jwt_token(claims, authclient.secret)\n\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion=tok,\n                                  grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert exc.value.type == 'invalid_grant'\n        assert 'invalid JWT audience' in exc.value.message\n\n    def test_jwt_not_before_in_future(self, svc, claims, authclient):\n        claims['nbf'] = self.epoch(delta=timedelta(minutes=5))\n        tok = self.jwt_token(claims, authclient.secret)\n\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion=tok,\n                                  grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert exc.value.type == 'invalid_grant'\n        assert 'not before is in the future' in exc.value.message\n\n    def test_jwt_expires_with_leeway_in_the_past(self, svc, claims, authclient):\n        claims['exp'] = self.epoch(delta=timedelta(minutes=-2))\n        tok = self.jwt_token(claims, authclient.secret)\n\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion=tok,\n                                  grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert exc.value.type == 'invalid_grant'\n        assert 'token is expired' in exc.value.message\n\n    def test_jwt_issued_at_in_the_future(self, svc, claims, authclient):\n        claims['iat'] = self.epoch(delta=timedelta(minutes=2))\n        tok = self.jwt_token(claims, authclient.secret)\n\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion=tok,\n                                  grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert exc.value.type == 'invalid_grant'\n        assert 'issued at is in the future' in exc.value.message\n\n    def test_missing_jwt_subject(self, svc, claims, authclient):\n        del claims['sub']\n        tok = self.jwt_token(claims, authclient.secret)\n\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion=tok,\n                                  grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert exc.value.type == 'invalid_grant'\n        assert 'subject is missing' in exc.value.message\n\n    def test_empty_jwt_subject(self, svc, claims, authclient):\n        claims['sub'] = ''\n        tok = self.jwt_token(claims, authclient.secret)\n\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion=tok,\n                                  grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert exc.value.type == 'invalid_grant'\n        assert 'subject is missing' in exc.value.message\n\n    def test_user_not_found(self, svc, claims, authclient, user_service):\n        user_service.fetch.return_value = None\n\n        tok = self.jwt_token(claims, authclient.secret)\n\n        with pytest.raises(OAuthTokenError) as exc:\n            svc.verify_jwt_bearer(assertion=tok,\n                                  grant_type='urn:ietf:params:oauth:grant-type:jwt-bearer')\n\n        assert exc.value.type == 'invalid_grant'\n        assert 'user with userid described in subject could not be found' in exc.value.message\n\n    @pytest.fixture\n    def svc(self, pyramid_request, db_session, user_service):\n        return services.OAuthService(db_session, user_service, pyramid_request.domain)\n\n    @pytest.fixture\n    def claims(self, authclient, user, pyramid_request):\n        return {\n            'iss': authclient.id,\n            'sub': user.userid,\n            'aud': pyramid_request.domain,\n            'exp': self.epoch(delta=timedelta(minutes=10)),\n            'nbf': self.epoch(),\n            'iat': self.epoch(),\n        }\n\n    @pytest.fixture\n    def authclient(self, db_session):\n        client = models.AuthClient(authority='partner.org', secret='bogus')\n        db_session.add(client)\n        db_session.flush()\n        return client\n\n    @pytest.fixture\n    def user(self, factories, authclient, user_service):\n        user = factories.User(authority=authclient.authority)\n        user_service.fetch.return_value = user\n        return user\n\n    def jwt_token(self, claims, secret, algorithm='HS256'):\n        return text_type(jwt.encode(claims, secret, algorithm=algorithm))\n\n    def epoch(self, timestamp=None, delta=None):\n        if timestamp is None:\n            timestamp = datetime.utcnow()\n\n        if delta is not None:\n            timestamp = timestamp + delta\n\n        return timegm(timestamp.utctimetuple())\n\n\nclass TestOAuthServiceCreateToken(object):\n    \"\"\" Tests for ``OAuthService.create_token`` \"\"\"\n\n    def test_it_creates_a_token(self, svc, user, authclient, db_session):\n        query = db_session.query(models.Token).filter_by(userid=user.userid)\n\n        assert query.count() == 0\n        svc.create_token(user, authclient)\n        assert query.count() == 1\n\n    def test_it_returns_a_token(self, svc, user, authclient):\n        token = svc.create_token(user, authclient)\n        assert type(token) == models.Token\n\n    def test_new_token_expires_within_one_hour(self, svc, db_session, user, authclient, utcnow):\n        utcnow.return_value = datetime(2016, 1, 1, 3, 0, 0)\n\n        svc.create_token(user, authclient)\n\n        token = db_session.query(models.Token).filter_by(userid=user.userid).first()\n        assert token.expires == datetime(2016, 1, 1, 4, 0, 0)\n\n    def test_it_sets_the_passed_in_authclient(self, svc, user, authclient):\n        token = svc.create_token(user, authclient)\n        assert token.authclient == authclient\n\n    @pytest.fixture\n    def svc(self, pyramid_request, db_session, user_service):\n        return services.OAuthService(db_session, user_service, pyramid_request.domain)\n\n    @pytest.fixture\n    def user(self, db_session, factories):\n        user = factories.User()\n        db_session.add(user)\n        db_session.flush()\n        return user\n\n    @pytest.fixture\n    def authclient(self, db_session):\n        client = models.AuthClient(authority='partner.org', secret='bogus')\n        db_session.add(client)\n        db_session.flush()\n        return client\n\n\n@pytest.mark.usefixtures('user_service')\nclass TestOAuthServiceFactory(object):\n    def test_it_returns_oauth_service(self, pyramid_request):\n        svc = services.oauth_service_factory(None, pyramid_request)\n        assert isinstance(svc, services.OAuthService)\n\n    def test_it_provides_request_db_as_session(self, pyramid_request):\n        svc = services.oauth_service_factory(None, pyramid_request)\n        assert svc.session == pyramid_request.db\n\n    def test_it_provides_user_service(self, pyramid_request, user_service):\n        svc = services.oauth_service_factory(None, pyramid_request)\n        assert svc.usersvc == user_service\n\n    def test_it_provides_request_domain(self, pyramid_request):\n        pyramid_request.domain = 'example.org'\n        svc = services.oauth_service_factory(None, pyramid_request)\n        assert svc.domain == 'example.org'\n\n\n@pytest.fixture\ndef user_service(db_session, pyramid_config):\n    service = mock.Mock(spec=UserService(default_authority='example.com',\n                                         session=db_session))\n    pyramid_config.register_service(service, name='user')\n    return service\n\n\n@pytest.fixture\ndef utcnow(patch):\n    return patch('h.auth.services.utcnow')\n"},{"size":8350,"relativepath":"tests/h/auth/tokens_test.py","filename":"tokens_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport datetime\n\nimport jwt\nimport mock\n\nimport pytest\nfrom hypothesis import strategies as st\nfrom hypothesis import assume, given\n\nfrom h import models\nfrom h.auth import tokens\n\n\nclass TestToken(object):\n\n    def test_token_with_no_expiry_is_valid(self):\n        token = tokens.Token(mock.Mock(\n            expires=None, userid='acct:foo@example.com'))\n\n        assert token.is_valid()\n\n    def test_token_with_future_expiry_is_valid(self):\n        token = tokens.Token(mock.Mock(\n            userid='acct:foo@example.com', expires=_seconds_from_now(1800)))\n\n        assert token.is_valid()\n\n    def test_token_with_past_expiry_is_not_valid(self):\n        token = tokens.Token(mock.Mock(\n            userid='acct:foo@example.com', expires=_seconds_from_now(-1800)))\n\n        assert not token.is_valid()\n\n\nVALID_TOKEN_EXAMPLES = [\n    # Valid\n    lambda a, k: jwt.encode({'aud': a, 'exp': _seconds_from_now(3600)},\n                            key=k),\n\n    # Expired, but within leeway\n    lambda a, k: jwt.encode({'aud': a, 'exp': _seconds_from_now(-120)},\n                            key=k),\n]\n\nINVALID_TOKEN_EXAMPLES = [\n    # Expired 1 hour ago\n    lambda a, k: jwt.encode({'aud': a, 'exp': _seconds_from_now(-3600)},\n                            key=k),\n\n    # Issued in the future\n    lambda a, k: jwt.encode({'aud': a,\n                             'exp': _seconds_from_now(3600),\n                             'iat': _seconds_from_now(1800)},\n                            key=k),\n\n    # Incorrect audience\n    lambda a, k: jwt.encode({'aud': 'https://bar.com',\n                             'exp': _seconds_from_now(3600)},\n                            key=k),\n\n    # Incorrect encoding key\n    lambda a, k: jwt.encode({'aud': a, 'exp': _seconds_from_now(3600)},\n                            key='somethingelse'),\n]\n\n\nclass TestLegacyClientJWT(object):\n    @pytest.mark.parametrize('get_token', VALID_TOKEN_EXAMPLES)\n    def test_ok_for_valid_jwt(self, get_token):\n        token = get_token('http://example.com', 'secrets!')\n\n        result = tokens.LegacyClientJWT(token,\n                                        audience='http://example.com',\n                                        key='secrets!')\n\n        assert isinstance(result, tokens.LegacyClientJWT)\n\n    @pytest.mark.parametrize('get_token', INVALID_TOKEN_EXAMPLES)\n    def test_raises_for_invalid_jwt(self, get_token):\n        token = get_token('http://example.com', 'secrets!')\n\n        with pytest.raises(jwt.InvalidTokenError):\n            tokens.LegacyClientJWT(token,\n                                   audience='http://example.com',\n                                   key='secrets!')\n\n    def test_payload(self):\n        payload = {'aud': 'http://foo.com',\n                   'exp': _seconds_from_now(3600),\n                   'sub': 'foobar'}\n        token = jwt.encode(payload, key='s3cr37')\n\n        result = tokens.LegacyClientJWT(token,\n                                        audience='http://foo.com',\n                                        key='s3cr37')\n\n        assert result.payload == payload\n\n    def test_always_valid(self):\n        payload = {'aud': 'http://foo.com',\n                   'exp': _seconds_from_now(3600),\n                   'sub': 'foobar'}\n        token = jwt.encode(payload, key='s3cr37')\n\n        result = tokens.LegacyClientJWT(token,\n                                        audience='http://foo.com',\n                                        key='s3cr37')\n\n        assert result.is_valid()\n\n    def test_userid_gets_payload_sub(self):\n        payload = {'aud': 'http://foo.com',\n                   'exp': _seconds_from_now(3600),\n                   'sub': 'foobar'}\n        token = jwt.encode(payload, key='s3cr37')\n\n        result = tokens.LegacyClientJWT(token,\n                                        audience='http://foo.com',\n                                        key='s3cr37')\n\n        assert result.userid == 'foobar'\n\n    def test_userid_none_if_sub_missing(self):\n        payload = {'aud': 'http://foo.com',\n                   'exp': _seconds_from_now(3600)}\n        token = jwt.encode(payload, key='s3cr37')\n\n        result = tokens.LegacyClientJWT(token,\n                                        audience='http://foo.com',\n                                        key='s3cr37')\n\n        assert result.userid is None\n\n\ndef test_generate_jwt_calls_encode(jwt_, pyramid_config, pyramid_request):\n    \"\"\"It should pass the right arguments to encode().\"\"\"\n    pyramid_config.testing_securitypolicy('acct:testuser@hypothes.is')\n    before = datetime.datetime.utcnow()\n\n    tokens.generate_jwt(pyramid_request, 3600)\n\n    assert jwt_.encode.call_args[0][0]['sub'] == 'acct:testuser@hypothes.is', (\n        \"It should encode the userid as 'sub'\")\n    after = datetime.datetime.utcnow() + datetime.timedelta(seconds=3600)\n    assert before < jwt_.encode.call_args[0][0]['exp'] < after, (\n        \"It should encode the expiration time as 'exp'\")\n    assert jwt_.encode.call_args[0][0]['aud'] == pyramid_request.host_url, (\n        \"It should encode request.host_url as 'aud'\")\n    assert jwt_.encode.call_args[1]['algorithm'] == 'HS256', (\n        \"It should pass the right algorithm to encode()\")\n\n\ndef test_generate_jwt_when_authenticated_userid_is_None(jwt_, pyramid_request):\n    \"\"\"It should work when request.authenticated_userid is None.\"\"\"\n    tokens.generate_jwt(pyramid_request, 3600)\n\n    assert jwt_.encode.call_args[0][0]['sub'] is None\n\n\ndef test_generate_jwt_returns_token(jwt_, pyramid_request):\n    result = tokens.generate_jwt(pyramid_request, 3600)\n\n    assert result == jwt_.encode.return_value\n\n\n@pytest.mark.usefixtures('token')\nclass TestAuthToken(object):\n    def test_retrieves_token_for_request(self, pyramid_request, token):\n        pyramid_request.headers['Authorization'] = 'Bearer ' + token.value\n\n        result = tokens.auth_token(pyramid_request)\n\n        assert result.expires == token.expires\n        assert result.userid == token.userid\n\n    def test_returns_none_when_no_authz_header(self, pyramid_request, token):\n        result = tokens.auth_token(pyramid_request)\n\n        assert result is None\n\n    def test_returns_none_for_empty_token(self, pyramid_request, token):\n        pyramid_request.headers['Authorization'] = 'Bearer '\n\n        result = tokens.auth_token(pyramid_request)\n\n        assert result is None\n\n    def test_returns_none_for_malformed_header(self, pyramid_request, token):\n        pyramid_request.headers['Authorization'] = token.value\n\n        result = tokens.auth_token(pyramid_request)\n\n        assert result is None\n\n    @given(header=st.text())\n    @pytest.mark.fuzz\n    def test_returns_none_for_malformed_header_fuzz(self,\n                                                    header,\n                                                    pyramid_request,\n                                                    token):\n        assume(header != 'Bearer ' + token.value)\n        pyramid_request.headers['Authorization'] = header\n\n        result = tokens.auth_token(pyramid_request)\n\n        assert result is None\n\n    def test_returns_none_for_invalid_token(self, pyramid_request):\n        pyramid_request.headers['Authorization'] = 'Bearer abcd1234'\n\n        result = tokens.auth_token(pyramid_request)\n\n        assert result is None\n\n    @pytest.mark.usefixture('pyramid_settings')\n    def test_returns_legacy_client_jwt_when_jwt(self, pyramid_request):\n        token = jwt.encode({'aud': pyramid_request.host_url,\n                            'exp': _seconds_from_now(3600)},\n                           key='secret')\n        pyramid_request.headers['Authorization'] = 'Bearer ' + token\n\n        result = tokens.auth_token(pyramid_request)\n\n        assert isinstance(result, tokens.LegacyClientJWT)\n\n    @pytest.fixture\n    def token(self, db_session):\n        token = models.Token(userid='acct:foo@example.com')\n        db_session.add(token)\n        db_session.flush()\n        return token\n\n\n@pytest.fixture\ndef pyramid_settings(pyramid_settings):\n    pyramid_settings.update({\n        'h.client_id': 'id',\n        'h.client_secret': 'secret',\n    })\n    return pyramid_settings\n\n\n@pytest.fixture\ndef jwt_(patch):\n    return patch('h.auth.tokens.jwt')\n\n\ndef _seconds_from_now(seconds):\n    return datetime.datetime.utcnow() + datetime.timedelta(seconds=seconds)\n"},{"size":2154,"relativepath":"tests/h/assets_test.py","filename":"assets_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom sys import version_info\nfrom StringIO import StringIO\n\nfrom mock import patch\n\nfrom h.assets import Environment\n\nif version_info.major == 2:\n    open_target = '__builtin__.open'\nelse:\n    open_target = 'builtins.open'\n\nBUNDLE_INI = \\\n\"\"\"\n[bundles]\napp_js =\n  app.bundle.js\n  vendor.bundle.js\n\"\"\"\n\nMANIFEST_JSON = \\\n\"\"\"\n{\n    \"app.bundle.js\": \"app.bundle.js?abcdef\",\n    \"vendor.bundle.js\": \"vendor.bundle.js?1234\"\n}\n\"\"\"\n\n\ndef _fake_open(path):\n    if path == 'bundles.ini':\n        return StringIO(BUNDLE_INI)\n    elif path == 'manifest.json':\n        return StringIO(MANIFEST_JSON)\n\n\n@patch(open_target, _fake_open)\n@patch('os.path.getmtime')\ndef test_environment_lists_bundle_files(mtime):\n    env = Environment('/assets', 'bundles.ini', 'manifest.json')\n\n    assert env.files('app_js') == [\n        'app.bundle.js',\n        'vendor.bundle.js',\n    ]\n\n\n@patch(open_target, _fake_open)\n@patch('os.path.getmtime')\ndef test_environment_generates_bundle_urls(mtime):\n    env = Environment('/assets', 'bundles.ini', 'manifest.json')\n\n    assert env.urls('app_js') == [\n        '/assets/app.bundle.js?abcdef',\n        '/assets/vendor.bundle.js?1234',\n    ]\n\n\n@patch(open_target)\n@patch('os.path.getmtime')\ndef test_environment_reloads_manifest_on_change(mtime, open):\n    manifest_content = '{\"app.bundle.js\":\"app.bundle.js?oldhash\"}'\n    bundle_content = '[bundles]\\napp_js = \\n  app.bundle.js'\n\n    def _fake_open(path):\n        if path == 'bundles.ini':\n            return StringIO(bundle_content)\n        elif path == 'manifest.json':\n            return StringIO(manifest_content)\n\n    open.side_effect = _fake_open\n    mtime.return_value = 100\n    env = Environment('/assets', 'bundles.ini', 'manifest.json')\n\n    # An initial call to urls() should read and cache the manifest\n    env.urls('app_js')\n\n    manifest_content = '{\"app.bundle.js\":\"app.bundle.js?newhash\"}'\n    assert env.urls('app_js') == ['/assets/app.bundle.js?oldhash']\n\n    # Once the manifest's mtime changes, the Environment should re-read\n    # the manifest\n    mtime.return_value = 101\n    assert env.urls('app_js') == ['/assets/app.bundle.js?newhash']\n"},{"size":3904,"relativepath":"tests/h/indexer_test.py","filename":"indexer_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\nimport pytest\n\nfrom memex import events\nfrom h import indexer\n\n\n@pytest.mark.usefixtures('celery', 'index')\nclass TestAddAnnotation(object):\n\n    def test_it_fetches_the_annotation(self, fetch_annotation, celery):\n        id_ = 'test-annotation-id'\n\n        indexer.add_annotation(id_)\n\n        fetch_annotation.assert_called_once_with(celery.request.db, id_)\n\n    def test_it_calls_index_with_annotation(self, fetch_annotation, index, celery):\n        id_ = 'test-annotation-id'\n        annotation = mock.Mock(id=id_)\n        fetch_annotation.return_value = annotation\n\n        indexer.add_annotation(id_)\n\n        index.assert_called_once_with(celery.request.es, annotation, celery.request)\n\n    def test_it_skips_indexing_when_annotation_cannot_be_loaded(self, fetch_annotation, index, celery):\n        fetch_annotation.return_value = None\n\n        indexer.add_annotation('test-annotation-id')\n\n        assert index.called is False\n\n    @pytest.fixture\n    def index(self, patch):\n        return patch('h.indexer.index')\n\n    @pytest.fixture\n    def fetch_annotation(self, patch):\n        return patch('h.indexer.storage.fetch_annotation')\n\n\n@pytest.mark.usefixtures('celery', 'delete')\nclass TestDeleteAnnotation(object):\n\n    def test_it_deletes_from_index(self, delete, celery):\n        id_ = 'test-annotation-id'\n        indexer.delete_annotation(id_)\n\n        delete.assert_called_once_with(celery.request.es, id_)\n\n    @pytest.fixture\n    def delete(self, patch):\n        return patch('h.indexer.delete')\n\n\n@pytest.mark.usefixtures('celery')\nclass TestReindex(object):\n    def test_it_reindexes(self, celery, reindex):\n        indexer.reindex_annotations()\n\n        reindex.assert_called_once_with(\n            celery.request.db, celery.request.es, celery.request)\n\n    @pytest.fixture\n    def reindex(self, patch):\n        return patch('h.indexer.reindex')\n\n\n@pytest.mark.usefixtures('add_annotation', 'delete_annotation')\nclass TestSubscribeAnnotationEvent(object):\n\n    @pytest.mark.parametrize('action', ['create', 'update'])\n    def test_it_enqueues_add_annotation_celery_task(self,\n                                                    action,\n                                                    add_annotation,\n                                                    delete_annotation,\n                                                    pyramid_request):\n        event = events.AnnotationEvent(pyramid_request,\n                                       {'id': 'test_annotation_id'},\n                                       action)\n\n        indexer.subscribe_annotation_event(event)\n\n        add_annotation.delay.assert_called_once_with(event.annotation_id)\n        assert not delete_annotation.delay.called\n\n    def test_it_enqueues_delete_annotation_celery_task_for_delete(self,\n                                                                  add_annotation,\n                                                                  delete_annotation,\n                                                                  pyramid_request):\n        event = events.AnnotationEvent(pyramid_request,\n                                       {'id': 'test_annotation_id'},\n                                       'delete')\n\n        indexer.subscribe_annotation_event(event)\n\n        delete_annotation.delay.assert_called_once_with(event.annotation_id)\n        assert not add_annotation.delay.called\n\n    @pytest.fixture\n    def add_annotation(self, patch):\n        return patch('h.indexer.add_annotation')\n\n    @pytest.fixture\n    def delete_annotation(self, patch):\n        return patch('h.indexer.delete_annotation')\n\n\n@pytest.fixture\ndef celery(patch, pyramid_request):\n    cel = patch('h.indexer.celery')\n    cel.request = pyramid_request\n    return cel\n\n\n@pytest.fixture\ndef pyramid_request(pyramid_request):\n    pyramid_request.es = mock.Mock()\n    return pyramid_request\n"},{"size":19965,"relativepath":"tests/h/activity/query_test.py","filename":"query_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\nimport mock\n\nfrom pyramid.httpexceptions import HTTPFound\nfrom webob.multidict import MultiDict\n\nfrom h.activity.query import (\n    execute,\n    extract,\n    check_url,\n    fetch_annotations,\n)\n\n\nclass TestExtract(object):\n    def test_parses_param_value_with_parser(self, parse, pyramid_request):\n        pyramid_request.GET['q'] = 'giraffe'\n\n        extract(pyramid_request, parse=parse)\n\n        parse.assert_called_once_with('giraffe')\n\n    def test_returns_empty_results_when_q_param_is_missing(self, parse, pyramid_request):\n        result = extract(pyramid_request, parse=parse)\n        assert result == parse.return_value\n\n    def test_returns_parse_results(self, parse, pyramid_request):\n        parse.return_value = {'foo': 'bar'}\n        pyramid_request.GET['q'] = 'giraffe'\n\n        result = extract(pyramid_request, parse=parse)\n\n        assert result == {'foo': 'bar'}\n\n    def test_overrides_group_term_for_group_search_requests(self, parse, pyramid_request):\n        \"\"\"\n        If the query sent to a group search page includes a group, we override\n        it, because otherwise we'll display the union of the results for those\n        two groups, which makes no sense.\n        \"\"\"\n        parse.return_value = MultiDict({'foo': 'bar',\n                                        'group': 'whattheusersent'})\n        pyramid_request.matched_route.name = 'activity.group_search'\n        pyramid_request.matchdict['pubid'] = 'abcd1234'\n        pyramid_request.GET['q'] = 'giraffe'\n\n        result = extract(pyramid_request, parse=parse)\n\n        assert result.dict_of_lists() == {'foo': ['bar'],\n                                          'group': ['abcd1234']}\n\n    def test_overrides_user_term_for_user_search_requests(self, parse, pyramid_request):\n        \"\"\"\n        If the query sent to a user search page includes a user, we override\n        it, because otherwise we'll display the union of the results for those\n        two users, which makes no sense.\n        \"\"\"\n        parse.return_value = MultiDict({'foo': 'bar',\n                                        'user': 'whattheusersent'})\n        pyramid_request.matched_route.name = 'activity.user_search'\n        pyramid_request.matchdict['username'] = 'josiah'\n        pyramid_request.GET['q'] = 'giraffe'\n\n        result = extract(pyramid_request, parse=parse)\n\n        assert result.dict_of_lists() == {'foo': ['bar'],\n                                          'user': ['josiah']}\n\n    @pytest.fixture\n    def parse(self):\n        return mock.Mock(spec_set=[], return_value=MultiDict({'foo': 'bar'}))\n\n\n@pytest.mark.usefixtures('routes')\nclass TestCheckURL(object):\n    def test_redirects_to_group_search_page_if_one_group_in_query(self, pyramid_request, unparse):\n        query = MultiDict({'group': 'abcd1234'})\n\n        with pytest.raises(HTTPFound) as e:\n            check_url(pyramid_request, query, unparse=unparse)\n\n        assert e.value.location == '/act/groups/abcd1234?q=UNPARSED_QUERY'\n\n    def test_removes_group_term_from_query(self, pyramid_request, unparse):\n        query = MultiDict({'group': 'abcd1234'})\n\n        with pytest.raises(HTTPFound):\n            check_url(pyramid_request, query, unparse=unparse)\n\n        unparse.assert_called_once_with({})\n\n    def test_preserves_other_query_terms_for_group_search(self, pyramid_request, unparse):\n        query = MultiDict({'group': 'abcd1234', 'tag': 'foo'})\n\n        with pytest.raises(HTTPFound):\n            check_url(pyramid_request, query, unparse=unparse)\n\n        unparse.assert_called_once_with({'tag': 'foo'})\n\n    def test_redirects_to_user_search_page_if_one_group_in_query(self, pyramid_request, unparse):\n        query = MultiDict({'user': 'jose'})\n\n        with pytest.raises(HTTPFound) as e:\n            check_url(pyramid_request, query, unparse=unparse)\n\n        assert e.value.location == '/act/users/jose?q=UNPARSED_QUERY'\n\n    def test_removes_user_term_from_query(self, pyramid_request, unparse):\n        query = MultiDict({'user': 'jose'})\n\n        with pytest.raises(HTTPFound):\n            check_url(pyramid_request, query, unparse=unparse)\n\n        unparse.assert_called_once_with({})\n\n    def test_preserves_other_query_terms_for_user_search(self, pyramid_request, unparse):\n        query = MultiDict({'user': 'jose', 'tag': 'foo'})\n\n        with pytest.raises(HTTPFound):\n            check_url(pyramid_request, query, unparse=unparse)\n\n        unparse.assert_called_once_with({'tag': 'foo'})\n\n    def test_does_nothing_with_non_matching_queries(self, pyramid_request, unparse):\n        query = MultiDict({'tag': 'foo'})\n\n        result = check_url(pyramid_request, query, unparse=unparse)\n\n        assert result is None\n\n    def test_does_nothing_if_not_on_search_page(self, pyramid_request, unparse):\n        pyramid_request.matched_route.name = 'activity.group_search'\n        query = MultiDict({'group': 'abcd1234'})\n\n        result = check_url(pyramid_request, query, unparse=unparse)\n\n        assert result is None\n\n    @pytest.fixture\n    def unparse(self):\n        return mock.Mock(spec_set=[], return_value='UNPARSED_QUERY')\n\n\n@pytest.mark.usefixtures('fetch_annotations',\n                         '_fetch_groups',\n                         'bucketing',\n                         'presenters',\n                         'Search',\n                         'TagsAggregation',\n                         'UsersAggregation')\nclass TestExecute(object):\n\n    PAGE_SIZE = 23\n\n    def test_it_creates_a_search_query(self, pyramid_request, Search):\n        execute(pyramid_request, MultiDict(), self.PAGE_SIZE)\n\n        Search.assert_called_once_with(pyramid_request, separate_replies=True)\n\n    def test_it_adds_a_tags_aggregation_to_the_search_query(self,\n                                                            pyramid_request,\n                                                            search,\n                                                            TagsAggregation):\n        execute(pyramid_request, MultiDict(), self.PAGE_SIZE)\n\n        TagsAggregation.assert_called_once_with(limit=10)\n        search.append_aggregation.assert_called_with(\n            TagsAggregation.return_value)\n\n    def test_it_does_not_add_a_users_aggregation(self,\n                                                 pyramid_request,\n                                                 search,\n                                                 UsersAggregation):\n        \"\"\"On non-group pages there's no users aggregations.\"\"\"\n        execute(pyramid_request, MultiDict(), self.PAGE_SIZE)\n\n        assert not UsersAggregation.called\n\n    def test_on_group_pages_it_adds_a_users_aggregation_to_the_search_query(\n            self, pyramid_request, search, UsersAggregation):\n        \"\"\"If there's a single group facet it adds a users aggregation.\"\"\"\n        query = MultiDict(group='foo')\n\n        execute(pyramid_request, query, self.PAGE_SIZE)\n\n        UsersAggregation.assert_called_once_with(limit=10)\n        search.append_aggregation.assert_called_with(\n            UsersAggregation.return_value)\n\n    def test_it_limits_the_search_results_to_one_pages_worth(self,\n                                                             pyramid_request,\n                                                             search):\n        query = MultiDict()\n\n        execute(pyramid_request, query, self.PAGE_SIZE)\n\n        query = search.run.call_args[0][0]\n        assert query['limit'] == self.PAGE_SIZE\n\n    def test_it_gets_the_first_page_of_results_if_no_page_arg(self,\n                                                              pyramid_request,\n                                                              search):\n        query = MultiDict()\n        assert 'page' not in pyramid_request.params\n\n        execute(pyramid_request, query, self.PAGE_SIZE)\n\n        query = search.run.call_args[0][0]\n        assert query['offset'] == 0\n\n    def test_it_gets_the_first_page_of_results_if_page_arg_is_1(\n            self, pyramid_request, search):\n        query = MultiDict()\n        pyramid_request.params['page'] = '1'\n\n        execute(pyramid_request, query, self.PAGE_SIZE)\n\n        query = search.run.call_args[0][0]\n        assert query['offset'] == 0\n\n    @pytest.mark.parametrize('page,offset', [\n        ('2', 23),       # These expected offsets all assume a page size of 23.\n        ('12', 253),\n        ('1000', 22977),\n    ])\n    def test_it_gets_the_nth_page_of_results_if_page_arg_is_n(self,\n                                                              pyramid_request,\n                                                              search,\n                                                              page,\n                                                              offset):\n        query = MultiDict()\n        pyramid_request.params['page'] = page\n\n        execute(pyramid_request, query, self.PAGE_SIZE)\n\n        query = search.run.call_args[0][0]\n        assert query['offset'] == offset\n\n    @pytest.mark.parametrize('page', ('-1', '-3', '-2377'))\n    def test_it_gets_the_first_page_of_results_if_page_arg_is_negative(\n            self, pyramid_request, search, page):\n        query = MultiDict()\n        pyramid_request.params['page'] = page\n\n        execute(pyramid_request, query, self.PAGE_SIZE)\n\n        query = search.run.call_args[0][0]\n        assert query['offset'] == 0\n\n    @pytest.mark.parametrize('page', ('-23.7', 'foo'))\n    def test_it_gets_the_first_page_of_results_if_page_arg_is_not_an_int(\n            self, pyramid_request, search, page):\n        query = MultiDict()\n        pyramid_request.params['page'] = page\n\n        execute(pyramid_request, query, self.PAGE_SIZE)\n\n        query = search.run.call_args[0][0]\n        assert query['offset'] == 0\n\n    def test_it_passes_the_given_query_params_to_the_search(self,\n                                                            pyramid_request,\n                                                            search):\n        query = MultiDict(foo='bar')\n\n        execute(pyramid_request, query, self.PAGE_SIZE)\n\n        assert search.run.call_args[0][0]['foo'] == 'bar'\n\n    def test_it_returns_the_search_result_if_there_are_no_matches(\n            self, pyramid_request, search):\n        search.run.return_value.total = 0\n        search.run.return_value.annotation_ids = []\n\n        result = execute(pyramid_request, MultiDict(), self.PAGE_SIZE)\n\n        # This is what execute()'s result should look like if there are no\n        # annotations that match the given search query.\n        assert result.total == 0\n        assert result.aggregations == mock.sentinel.aggregations\n        assert result.timeframes == []\n\n    def test_it_fetches_the_annotations_from_the_database(self,\n                                                          fetch_annotations,\n                                                          pyramid_request,\n                                                          search):\n        execute(pyramid_request, MultiDict(), self.PAGE_SIZE)\n\n        fetch_annotations.assert_called_once_with(\n            pyramid_request.db,\n            search.run.return_value.annotation_ids,\n            search.run.return_value.reply_ids)\n\n    def test_it_buckets_the_annotations(self,\n                                        fetch_annotations,\n                                        bucketing,\n                                        pyramid_request,\n                                        search):\n        result = execute(pyramid_request, MultiDict(), self.PAGE_SIZE)\n\n        bucketing.bucket.assert_called_once_with(\n            fetch_annotations.return_value[0])\n        assert result.timeframes == bucketing.bucket.return_value\n\n    def test_it_fetches_the_groups_from_the_database(self,\n                                                     _fetch_groups,\n                                                     group_pubids,\n                                                     matchers,\n                                                     pyramid_request):\n        execute(pyramid_request, MultiDict(), self.PAGE_SIZE)\n\n        _fetch_groups.assert_called_once_with(\n            pyramid_request.db, matchers.unordered_list(group_pubids))\n\n    def test_it_returns_each_annotation_presented(self,\n                                                  annotations,\n                                                  pyramid_request):\n        result = execute(pyramid_request, MultiDict(), self.PAGE_SIZE)\n\n        presented_annotations = []\n        for timeframe in result.timeframes:\n            for bucket in timeframe.document_buckets.values():\n                presented_annotations.extend(bucket.annotations)\n\n        for annotation in annotations:\n            for presented_annotation in presented_annotations:\n                if presented_annotation['annotation'].annotation == annotation:\n                    break\n            else:\n                assert False\n\n    def test_it_returns_each_annotations_group(self,\n                                               _fetch_groups,\n                                               annotations,\n                                               group_pubids,\n                                               pyramid_request):\n        result = execute(pyramid_request, MultiDict(), self.PAGE_SIZE)\n\n        presented_annotations = []\n        for timeframe in result.timeframes:\n            for bucket in timeframe.document_buckets.values():\n                presented_annotations.extend(bucket.annotations)\n\n        for group in _fetch_groups.return_value:\n            for presented_annotation in presented_annotations:\n                if presented_annotation['group'] == group:\n                    break\n            else:\n                assert False\n\n    def test_it_returns_the_total_number_of_matching_annotations(\n            self, pyramid_request):\n        assert execute(pyramid_request, MultiDict(), self.PAGE_SIZE).total == 20\n\n    def test_it_returns_the_aggregations(self, pyramid_request):\n        result = execute(pyramid_request, MultiDict(), self.PAGE_SIZE)\n\n        assert result.aggregations == mock.sentinel.aggregations\n\n    @pytest.fixture\n    def fetch_annotations(self, patch):\n        func = patch('h.activity.query.fetch_annotations')\n        func.return_value = (mock.Mock(), mock.Mock())\n        return func\n\n    @pytest.fixture\n    def _fetch_groups(self, group_pubids, patch):\n        _fetch_groups = patch('h.activity.query._fetch_groups')\n        _fetch_groups.return_value = [mock.Mock(pubid=pubid)\n                                      for pubid in group_pubids]\n        return _fetch_groups\n\n    @pytest.fixture\n    def annotations(self, factories, group_pubids):\n        \"\"\"\n        Return the 20 annotations that bucket() will return.\n\n        Return a single flat list of all 20 annotations that will be\n        distributed among the timeframes and document buckets that our mock\n        bucketing.bucket() will return.\n\n        \"\"\"\n        return [\n            factories.Annotation.build(id='annotation_' + str(i),\n                                       groupid=group_pubid)\n            for i, group_pubid in enumerate(group_pubids)]\n\n    @pytest.fixture\n    def bucketing(self, document_buckets, patch):\n        bucketing = patch('h.activity.query.bucketing')\n\n        def timeframe(document_buckets):\n            \"\"\"Return a mock timeframe like the ones that bucket() returns.\"\"\"\n            return mock.Mock(\n                spec_set=['document_buckets'],\n                document_buckets=document_buckets)\n\n        timeframes = [\n            timeframe({\n                'Test Document 1': document_buckets[0],\n                'Test Document 2': document_buckets[1],\n                'Test Document 3': document_buckets[2],\n            }),\n            timeframe({\n                'Test Document 1': document_buckets[3],\n            }),\n            timeframe({\n                'Test Document 4': document_buckets[4],\n                'Test Document 3': document_buckets[5],\n                'Test Document 5': document_buckets[6],\n            }),\n        ]\n\n        bucketing.bucket.return_value = timeframes\n\n        return bucketing\n\n    @pytest.fixture\n    def document_buckets(self, annotations):\n        \"\"\"\n        Return the 7 document buckets that bucket() will return.\n\n        Return a single flat list of all 7 document buckets that will be\n        distributed among the timeframes that our mock bucketing.bucket() will\n        return.\n\n        \"\"\"\n        def document_bucket(annotations):\n            \"\"\"Return a mock document bucket like the ones bucket() returns.\"\"\"\n            return mock.Mock(spec_set=['annotations'], annotations=annotations)\n\n        return [\n            document_bucket(annotations[:3]),\n            document_bucket(annotations[3:7]),\n            document_bucket(annotations[7:12]),\n            document_bucket(annotations[12:13]),\n            document_bucket(annotations[13:15]),\n            document_bucket(annotations[15:18]),\n            document_bucket(annotations[18:]),\n        ]\n\n    @pytest.fixture\n    def group_pubids(self):\n        \"\"\"\n        Return a flat list of the pubids of all the annotations' groups.\n\n        Return a single flat list of all 20 pubids of the groups of the\n        annotations that our mock bucket() will return.\n\n        \"\"\"\n        return ['group_' + str(i) for i in range(20)]\n\n    @pytest.fixture\n    def presenters(self, patch):\n        presenters = patch('h.activity.query.presenters')\n        presenters.AnnotationHTMLPresenter = mock.Mock(\n            spec_set=['__call__'],\n            side_effect=lambda annotation: mock.Mock(annotation=annotation)\n        )\n        return presenters\n\n    @pytest.fixture\n    def search(self, annotations):\n        search = mock.Mock(\n            spec_set=['append_filter', 'append_aggregation', 'run'])\n        search.run.return_value = mock.Mock(\n            spec_set=['total', 'aggregations', 'annotation_ids', 'reply_ids'])\n        search.run.return_value.total = 20\n        search.run.return_value.aggregations = mock.sentinel.aggregations\n        search.run.return_value.annotation_ids = [\n            annotation.id for annotation in annotations]\n        return search\n\n    @pytest.fixture\n    def Search(self, patch, search):\n        return patch('h.activity.query.Search', return_value=search)\n\n    @pytest.fixture\n    def TagsAggregation(self, patch):\n        return patch('h.activity.query.TagsAggregation')\n\n    @pytest.fixture\n    def UsersAggregation(self, patch):\n        return patch('h.activity.query.UsersAggregation')\n\n\nclass TestFetchAnnotations(object):\n    def test_it_returns_annotations_by_ids(self, db_session, factories):\n        annotations = [factories.Annotation() for _ in xrange(3)]\n        ids = [a.id for a in annotations]\n\n        result, _ = fetch_annotations(db_session, ids, [])\n\n        assert annotations == result\n\n    def test_it_returns_empty_list_when_no_annotation_ids_provided(self, db_session):\n        result, _ = fetch_annotations(db_session, [], [])\n        assert result == []\n\n    def test_it_returns_replies_by_ids(self, db_session, factories):\n        replies = [factories.Annotation() for _ in xrange(3)]\n        ids = [a.id for a in replies]\n\n        _, result = fetch_annotations(db_session, [], ids)\n\n        assert replies == result\n\n    def test_it_returns_empty_list_when_no_reply_ids_provided(self, db_session):\n        _, result = fetch_annotations(db_session, [], [])\n        assert result == []\n\n\n@pytest.fixture\ndef pyramid_request(pyramid_request):\n    class DummyRoute(object):\n        name = 'activity.search'\n    pyramid_request.matched_route = DummyRoute()\n    return pyramid_request\n\n\n@pytest.fixture\ndef routes(pyramid_config):\n    pyramid_config.add_route('activity.group_search', '/act/groups/{pubid}')\n    pyramid_config.add_route('activity.user_search', '/act/users/{username}')\n"},{"size":13000,"relativepath":"tests/h/activity/bucketing_test.py","filename":"bucketing_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport datetime\nimport pytest\n\nfrom h.activity import bucketing\nfrom tests.common import factories\n\n\nUTCNOW = datetime.datetime(year=1970, month=2, day=21, hour=19, minute=30)\nFIVE_MINS_AGO = UTCNOW - datetime.timedelta(minutes=5)\nYESTERDAY = UTCNOW - datetime.timedelta(days=1)\nTHIRD_MARCH_1968 = datetime.datetime(year=1968, month=3, day=3)\nFIFTH_NOVEMBER_1969 = datetime.datetime(year=1969, month=11, day=5)\n\n\nclass timeframe_with(object):  # noqa: N801\n\n    def __init__(self, label, document_buckets):\n        self.label = label\n        self.document_buckets = document_buckets\n\n    def __eq__(self, timeframe):\n        return (self.label == timeframe.label and\n                self.document_buckets == timeframe.document_buckets)\n\n    def __repr__(self):\n        return '{class_} \"{label}\" with {n} document buckets'.format(\n            class_=self.__class__, label=self.label,\n            n=len(self.document_buckets))\n\n\n@pytest.mark.usefixtures('factories')\nclass TestDocumentBucket(object):\n    def test_init_sets_the_document_title(self, db_session, document):\n        title_meta = factories.DocumentMeta(type=\"title\",\n                                            value=[\"The Document Title\"],\n                                            document=document)\n        document.title = 'The Document Title'\n        db_session.add(title_meta)\n        db_session.flush()\n\n        bucket = bucketing.DocumentBucket(document)\n        assert bucket.title == 'The Document Title'\n\n    def test_init_uses_the_document_web_uri(self, db_session, document):\n        document.web_uri = 'http://example.com'\n\n        bucket = bucketing.DocumentBucket(document)\n        assert bucket.uri == 'http://example.com'\n\n    def test_init_sets_None_uri_when_no_http_or_https_can_be_found(self, db_session, document):\n        document.web_uri = None\n\n        bucket = bucketing.DocumentBucket(document)\n        assert bucket.uri is None\n\n    def test_init_sets_the_domain_from_the_extracted_uri(self, db_session, document):\n        document.web_uri = 'https://www.example.com/foobar.html'\n\n        bucket = bucketing.DocumentBucket(document)\n        assert bucket.domain == 'www.example.com'\n\n    def test_init_sets_domain_to_local_file_when_no_uri_is_set(self,\n                                                               db_session,\n                                                               document):\n        docuri_pdf = factories.DocumentURI(uri='urn:x-pdf:fingerprint',\n                                           document=document)\n        db_session.add(docuri_pdf)\n        db_session.flush()\n\n        bucket = bucketing.DocumentBucket(document)\n        assert bucket.domain == 'Local file'\n\n    def test_annotations_count_returns_count_of_annotations(self, db_session, document):\n        bucket = bucketing.DocumentBucket(document)\n\n        for _ in xrange(7):\n            annotation = factories.Annotation()\n            bucket.append(annotation)\n\n        assert bucket.annotations_count == 7\n\n    def test_append_appends_the_annotation(self, document):\n        bucket = bucketing.DocumentBucket(document)\n\n        annotations = []\n        for _ in xrange(7):\n            annotation = factories.Annotation()\n            annotations.append(annotation)\n            bucket.append(annotation)\n\n        assert bucket.annotations == annotations\n\n    def test_append_adds_unique_annotation_tag_to_bucket(self, document):\n        ann_1 = factories.Annotation(tags=['foo', 'bar'])\n        ann_2 = factories.Annotation(tags=['foo', 'baz'])\n\n        bucket = bucketing.DocumentBucket(document)\n        bucket.append(ann_1)\n        bucket.append(ann_2)\n        assert bucket.tags == set(['foo', 'bar', 'baz'])\n\n    def test_append_adds_unique_annotation_user_to_bucket(self, document):\n        ann_1 = factories.Annotation(userid='luke')\n        ann_2 = factories.Annotation(userid='alice')\n        ann_3 = factories.Annotation(userid='luke')\n\n        bucket = bucketing.DocumentBucket(document)\n        bucket.append(ann_1)\n        bucket.append(ann_2)\n        bucket.append(ann_3)\n        assert bucket.users == set(['luke', 'alice'])\n\n    def test_eq(self, document):\n        bucket_1 = bucketing.DocumentBucket(document)\n        bucket_2 = bucketing.DocumentBucket(document)\n\n        for _ in xrange(5):\n            annotation = factories.Annotation()\n            bucket_1.append(annotation)\n            bucket_2.append(annotation)\n\n        assert bucket_1 == bucket_2\n\n    def test_eq_annotations_mismatch(self, document):\n        bucket_1 = bucketing.DocumentBucket(document)\n        bucket_2 = bucketing.DocumentBucket(document)\n\n        bucket_1.annotations = [1, 2, 3]\n        bucket_2.annotations = [2, 3, 4]\n\n        assert not bucket_1 == bucket_2\n\n    def test_eq_tags_mismatch(self, document):\n        bucket_1 = bucketing.DocumentBucket(document)\n        bucket_2 = bucketing.DocumentBucket(document)\n\n        bucket_1.tags.update(['foo', 'bar'])\n        bucket_2.tags.update(['foo', 'baz'])\n\n        assert not bucket_1 == bucket_2\n\n    def test_eq_users_mismatch(self, document):\n        bucket_1 = bucketing.DocumentBucket(document)\n        bucket_2 = bucketing.DocumentBucket(document)\n\n        bucket_1.users.update(['alice', 'luke'])\n        bucket_2.users.update(['luke', 'paula'])\n\n        assert not bucket_1 == bucket_2\n\n    def test_eq_uri_mismatch(self, document):\n        bucket_1 = bucketing.DocumentBucket(document)\n        bucket_2 = bucketing.DocumentBucket(document)\n\n        bucket_1.uri = 'http://example.com'\n        bucket_2.uri = 'http://example.org'\n\n        assert not bucket_1 == bucket_2\n\n    def test_eq_domain_mismatch(self, document):\n        bucket_1 = bucketing.DocumentBucket(document)\n        bucket_2 = bucketing.DocumentBucket(document)\n\n        bucket_1.domain = 'example.com'\n        bucket_2.domain = 'example.org'\n\n        assert not bucket_1 == bucket_2\n\n    def test_eq_title_mismatch(self, document):\n        bucket_1 = bucketing.DocumentBucket(document)\n        bucket_2 = bucketing.DocumentBucket(document)\n\n        bucket_1.title = 'First Title'\n        bucket_2.title = 'Second Title'\n\n        assert not bucket_1 == bucket_2\n\n    @pytest.fixture\n    def document(self, db_session):\n        document = factories.Document()\n        db_session.add(document)\n        db_session.flush()\n        return document\n\n\n@pytest.mark.usefixtures('factories', 'utcnow')\nclass TestBucket(object):\n\n    def test_no_annotations(self):\n        assert bucketing.bucket([]) == []\n\n    @pytest.mark.parametrize('annotation_datetime,timeframe_label', [\n        (FIVE_MINS_AGO, 'Last 7 days'),\n        (THIRD_MARCH_1968, 'Mar 1968'),\n    ])\n    def test_one_annotation(self, annotation_datetime, timeframe_label):\n        document = factories.Document()\n        results = [factories.Annotation(document=document,\n                                        updated=annotation_datetime)]\n\n        timeframes = bucketing.bucket(results)\n\n        assert timeframes == [\n            timeframe_with(timeframe_label, {\n                document: bucketing.DocumentBucket(document, results)\n            })\n        ]\n\n    @pytest.mark.parametrize('annotation_datetime,timeframe_label', [\n        (FIVE_MINS_AGO, 'Last 7 days'),\n        (THIRD_MARCH_1968, 'Mar 1968'),\n    ])\n    def test_multiple_annotations_of_one_document_in_one_timeframe(\n            self, annotation_datetime, timeframe_label):\n        document = factories.Document()\n        results = [\n            factories.Annotation(document=document,\n                                 updated=annotation_datetime)\n            for _ in range(3)]\n\n        timeframes = bucketing.bucket(results)\n\n        assert timeframes == [\n            timeframe_with(timeframe_label, {\n                document: bucketing.DocumentBucket(document, results)\n            }),\n        ]\n\n    @pytest.mark.parametrize(\"annotation_datetime,timeframe_label\", [\n        (YESTERDAY, \"Last 7 days\"),\n        (THIRD_MARCH_1968, \"Mar 1968\"),\n    ])\n    def test_annotations_of_multiple_documents_in_one_timeframe(\n            self, annotation_datetime, timeframe_label):\n        document_1 = factories.Document()\n        document_2 = factories.Document()\n        document_3 = factories.Document()\n        results = [\n            factories.Annotation(document=document_1,\n                                 updated=annotation_datetime),\n            factories.Annotation(document=document_2,\n                                 updated=annotation_datetime),\n            factories.Annotation(document=document_3,\n                                 updated=annotation_datetime),\n        ]\n\n        timeframes = bucketing.bucket(results)\n\n        assert timeframes == [\n            timeframe_with(timeframe_label, {\n                document_1: bucketing.DocumentBucket(document_1, [results[0]]),\n                document_2: bucketing.DocumentBucket(document_2, [results[1]]),\n                document_3: bucketing.DocumentBucket(document_3, [results[2]]),\n            }),\n        ]\n\n    def test_annotations_of_the_same_document_in_different_timeframes(self):\n        document = factories.Document()\n        results = [\n            factories.Annotation(document=document),\n            factories.Annotation(document=document,\n                                 updated=FIFTH_NOVEMBER_1969),\n            factories.Annotation(document=document, updated=THIRD_MARCH_1968),\n        ]\n\n        timeframes = bucketing.bucket(results)\n\n        expected_bucket_1 = bucketing.DocumentBucket(document, [results[0]])\n        expected_bucket_2 = bucketing.DocumentBucket(document, [results[1]])\n        expected_bucket_3 = bucketing.DocumentBucket(document, [results[2]])\n\n        assert timeframes == [\n            timeframe_with('Last 7 days', {document: expected_bucket_1}),\n            timeframe_with('Nov 1969', {document: expected_bucket_2}),\n            timeframe_with('Mar 1968', {document: expected_bucket_3}),\n        ]\n\n    def test_recent_and_older_annotations_together(self):\n        document_1 = factories.Document()\n        document_2 = factories.Document()\n        document_3 = factories.Document()\n        document_4 = factories.Document()\n        document_5 = factories.Document()\n        document_6 = factories.Document()\n        results = [\n            factories.Annotation(document=document_1),\n            factories.Annotation(document=document_2),\n            factories.Annotation(document=document_3),\n            factories.Annotation(document=document_4,\n                                 updated=THIRD_MARCH_1968),\n            factories.Annotation(document=document_5,\n                                 updated=THIRD_MARCH_1968),\n            factories.Annotation(document=document_6,\n                                 updated=THIRD_MARCH_1968),\n        ]\n\n        timeframes = bucketing.bucket(results)\n\n        expected_bucket_1 = bucketing.DocumentBucket(document_1, [results[0]])\n        expected_bucket_2 = bucketing.DocumentBucket(document_2, [results[1]])\n        expected_bucket_3 = bucketing.DocumentBucket(document_3, [results[2]])\n        expected_bucket_4 = bucketing.DocumentBucket(document_4, [results[3]])\n        expected_bucket_5 = bucketing.DocumentBucket(document_5, [results[4]])\n        expected_bucket_6 = bucketing.DocumentBucket(document_6, [results[5]])\n\n        assert timeframes == [\n            timeframe_with('Last 7 days', {\n                document_1: expected_bucket_1,\n                document_2: expected_bucket_2,\n                document_3: expected_bucket_3,\n            }),\n            timeframe_with('Mar 1968', {\n                document_4: expected_bucket_4,\n                document_5: expected_bucket_5,\n                document_6: expected_bucket_6,\n            }),\n        ]\n\n    def test_annotations_from_different_days_in_same_month(self):\n        \"\"\"\n        Test bucketing multiple annotations from different days of same month.\n\n        Annotations from different days of the same month should go into one\n        bucket.\n\n        \"\"\"\n        document = factories.Document()\n        one_month_ago = UTCNOW - datetime.timedelta(days=30)\n        annotations = [\n            factories.Annotation(document=document, updated=one_month_ago),\n            factories.Annotation(document=document,\n                                 updated=one_month_ago - datetime.timedelta(days=1)),\n            factories.Annotation(document=document,\n                                 updated=one_month_ago - datetime.timedelta(days=2)),\n        ]\n\n        timeframes = bucketing.bucket(annotations)\n\n        expected_bucket = bucketing.DocumentBucket(document)\n        expected_bucket.update(annotations)\n\n        assert timeframes == [\n            timeframe_with('Jan 1970', {document: expected_bucket})]\n\n    @pytest.fixture\n    def utcnow(self, patch):\n        utcnow = patch('h.activity.bucketing.utcnow')\n        utcnow.return_value = UTCNOW\n        return utcnow\n"},{"size":4284,"relativepath":"tests/h/tweens_test.py","filename":"tweens_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\n\nfrom h import tweens\n\n\ndef test_tween_csp_noop_by_default(pyramid_request):\n    handler = mock.sentinel.HANDLER\n    result = tweens.content_security_policy_tween_factory(handler,\n                                                          pyramid_request.registry)\n\n    assert result == handler\n\n\ndef test_tween_csp_default_headers(pyramid_request):\n    pyramid_request.registry.settings['csp.enabled'] = True\n    tween = tweens.content_security_policy_tween_factory(\n        lambda req: req.response,\n        pyramid_request.registry)\n\n    response = tween(pyramid_request)\n\n    assert 'Content-Security-Policy-Report-Only' not in response.headers\n    assert 'Content-Security-Policy' in response.headers\n\n\ndef test_tween_csp_report_only_headers(pyramid_request):\n    pyramid_request.registry.settings.update({\n        'csp.enabled': True,\n        'csp.report_only': True,\n    })\n    tween = tweens.content_security_policy_tween_factory(\n        lambda req: req.response,\n        pyramid_request.registry)\n\n    response = tween(pyramid_request)\n\n    assert 'Content-Security-Policy-Report-Only' in response.headers\n    assert 'Content-Security-Policy' not in response.headers\n\n\ndef test_tween_csp_uri(pyramid_request):\n    pyramid_request.registry.settings.update({\n        'csp.enabled': True,\n        'csp.report_only': False,\n        'csp': {'report-uri': ['localhost']},\n    })\n    tween = tweens.content_security_policy_tween_factory(\n        lambda req: req.response,\n        pyramid_request.registry)\n\n    response = tween(pyramid_request)\n\n    expected = 'report-uri localhost'\n    assert expected == response.headers['Content-Security-Policy']\n\n\ndef test_tween_csp_header(pyramid_request):\n    pyramid_request.registry.settings.update({\n        \"csp.enabled\": True,\n        \"csp.report_only\": False,\n        \"csp\": {\n            \"font-src\": [\"'self'\", \"fonts.gstatic.com\"],\n            \"report-uri\": ['localhost'],\n            \"script-src\": [\"'self'\"],\n            \"style-src\": [\"'self'\", \"fonts.googleapis.com\"],\n        },\n    })\n    tween = tweens.content_security_policy_tween_factory(\n        lambda req: req.response,\n        pyramid_request.registry)\n\n    response = tween(pyramid_request)\n\n    expected = \"font-src 'self' fonts.gstatic.com; report-uri localhost; \" \\\n        \"script-src 'self'; style-src 'self' fonts.googleapis.com\"\n\n    assert expected == response.headers['Content-Security-Policy']\n\n\ndef test_tween_redirect_non_redirected_route(pyramid_request):\n    redirects = [('/foo', 'bar')]\n\n    pyramid_request.path = '/quux'\n\n    tween = tweens.redirect_tween_factory(\n        lambda req: req.response,\n        pyramid_request.registry,\n        redirects)\n\n    response = tween(pyramid_request)\n\n    assert response.status_code == 200\n\n\ndef test_tween_redirect_redirected_route(pyramid_request, pyramid_config):\n    redirects = [('/foo', 'bar')]\n\n    pyramid_config.add_route('bar', '/bar')\n\n    pyramid_request.path = '/foo'\n\n    tween = tweens.redirect_tween_factory(\n        lambda req: req.response,\n        pyramid_request.registry,\n        redirects)\n\n    response = tween(pyramid_request)\n\n    assert response.status_code == 301\n    assert response.location == 'http://example.com/bar'\n\n\ndef test_tween_redirect_matches_prefixes(pyramid_request, pyramid_config):\n    redirects = [('/foo', 'bar')]\n\n    pyramid_config.add_route('bar', '/bar')\n\n    pyramid_request.path = '/foo/baz'\n\n    tween = tweens.redirect_tween_factory(\n        lambda req: req.response,\n        pyramid_request.registry,\n        redirects)\n\n    response = tween(pyramid_request)\n\n    assert response.status_code == 301\n    assert response.location == 'http://example.com/bar/baz'\n\n\ndef test_tween_redirect_matches_in_order(pyramid_request, pyramid_config):\n    redirects = [\n        ('/foo/bar', 'bar'),\n        ('/foo', 'foonew'),\n    ]\n\n    pyramid_config.add_route('bar', '/bar')\n    pyramid_config.add_route('foonew', '/foonew')\n\n    pyramid_request.path = '/foo/bar'\n\n    tween = tweens.redirect_tween_factory(\n        lambda req: req.response,\n        pyramid_request.registry,\n        redirects)\n\n    response = tween(pyramid_request)\n\n    assert response.status_code == 301\n    assert response.location == 'http://example.com/bar'\n"},{"size":2315,"relativepath":"tests/h/celery_test.py","filename":"celery_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport logging\n\nimport mock\nimport pytest\n\nfrom h import celery\n\n\nclass TestCelery(object):\n\n    @pytest.fixture(autouse=True)\n    def register_signal(self, request):\n        return _patch('h.celery.register_signal', request)\n\n    @pytest.fixture(autouse=True)\n    def register_logger_signal(self, request):\n        return _patch('h.celery.register_logger_signal', request)\n\n    def test_bootstrap_worker_bootstraps_application(self):\n        sender = mock.Mock(spec=['app'])\n\n        celery.bootstrap_worker(sender)\n\n        sender.app.webapp_bootstrap.assert_called_once_with()\n\n    def test_bootstrap_worker_attaches_request_to_app(self):\n        sender = mock.Mock(spec=['app'])\n        request = sender.app.webapp_bootstrap.return_value\n\n        celery.bootstrap_worker(sender)\n\n        assert sender.app.request == request\n\n    def test_bootstrap_worker_configures_sentry_reporting(self,\n                                                          register_signal,\n                                                          register_logger_signal):\n        sender = mock.Mock(spec=['app'])\n        request = sender.app.webapp_bootstrap.return_value\n        request.sentry = mock.sentinel.sentry\n\n        celery.bootstrap_worker(sender)\n\n        register_signal.assert_called_once_with(mock.sentinel.sentry)\n        register_logger_signal.assert_called_once_with(mock.sentinel.sentry,\n                                                       loglevel=logging.ERROR)\n\n    def test_reset_feature_flags_resets_request_feature_flags(self):\n        sender = mock.Mock(spec=['app'])\n\n        celery.reset_feature_flags(sender)\n\n        sender.app.request.feature.clear.assert_called_once_with()\n\n    def test_transaction_commit_commits_request_transaction(self):\n        sender = mock.Mock(spec=['app'])\n\n        celery.transaction_commit(sender)\n\n        sender.app.request.tm.commit.assert_called_once_with()\n\n    def test_transaction_abort_aborts_request_transaction(self):\n        sender = mock.Mock(spec=['app'])\n\n        celery.transaction_abort(sender)\n\n        sender.app.request.tm.abort.assert_called_once_with()\n\n\ndef _patch(modulepath, request):\n    patcher = mock.patch(modulepath, autospec=True)\n    module = patcher.start()\n    request.addfinalizer(patcher.stop)\n    return module\n"},{"size":4264,"relativepath":"tests/h/nipsa/worker_test.py","filename":"worker_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\nimport mock\n\nfrom h.nipsa import worker\n\n\ndef test_add_nipsa_action():\n    action = worker.add_nipsa_action(\"foo\", {\"_id\": \"test_id\"})\n\n    assert action == {\n        \"_op_type\": \"update\",\n        \"_index\": \"foo\",\n        \"_type\": \"annotation\",\n        \"_id\": \"test_id\",\n        \"doc\": {\"nipsa\": True}\n    }\n\n\ndef test_remove_nipsa_action():\n    annotation = {\"_id\": \"test_id\", \"_source\": {\"nipsa\": True, \"foo\": \"bar\"}}\n    action = worker.remove_nipsa_action(\"bar\", annotation)\n\n    assert action == {\n        \"_op_type\": \"index\",\n        \"_index\": \"bar\",\n        \"_type\": \"annotation\",\n        \"_id\": \"test_id\",\n        \"_source\": {\"foo\": \"bar\"},\n    }\n\n\n@mock.patch(\"h.nipsa.worker.helpers\", autospec=True)\ndef test_bulk_update_annotations_scans_with_query(helpers):\n    client = mock.Mock(spec_set=['conn', 'index'])\n\n    worker.bulk_update_annotations(client=client,\n                                   query=mock.sentinel.query,\n                                   action=mock.sentinel.action)\n\n    helpers.scan.assert_called_once_with(client=client.conn,\n                                         index=client.index,\n                                         query=mock.sentinel.query)\n\n\n@mock.patch(\"h.nipsa.worker.helpers\", autospec=True)\ndef test_bulk_update_annotations_generates_actions_for_each_annotation(helpers):\n    action = mock.Mock(spec_set=[])\n    client = mock.Mock(spec_set=['conn', 'index'])\n    helpers.scan.return_value = [mock.sentinel.anno1,\n                                 mock.sentinel.anno2,\n                                 mock.sentinel.anno3]\n\n    worker.bulk_update_annotations(client=client,\n                                   query=mock.sentinel.query,\n                                   action=action)\n\n    assert action.call_args_list == [\n        mock.call(client.index, mock.sentinel.anno1),\n        mock.call(client.index, mock.sentinel.anno2),\n        mock.call(client.index, mock.sentinel.anno3),\n    ]\n\n\n@mock.patch(\"h.nipsa.worker.helpers\", autospec=True)\ndef test_bulk_update_annotations_calls_bulk_with_actions(helpers):\n    action = mock.Mock(spec_set=[], side_effect=[\n        mock.sentinel.action1,\n        mock.sentinel.action2,\n        mock.sentinel.action3,\n    ])\n    client = mock.Mock(spec_set=['conn', 'index'])\n    helpers.scan.return_value = [mock.sentinel.anno1,\n                                 mock.sentinel.anno2,\n                                 mock.sentinel.anno3]\n\n    worker.bulk_update_annotations(client=client,\n                                   query=mock.sentinel.query,\n                                   action=action)\n\n    helpers.bulk.assert_called_once_with(client=client.conn,\n                                         actions=[mock.sentinel.action1,\n                                                  mock.sentinel.action2,\n                                                  mock.sentinel.action3])\n\n\n@mock.patch(\"h.nipsa.worker.bulk_update_annotations\", autospec=True)\n@mock.patch(\"h.nipsa.worker.celery\", autospec=True)\n@mock.patch(\"h.nipsa.worker.search\", autospec=True)\nclass TestAddNipsa(object):\n    def test_calls_bulk_update_annotations(self, search, celery, bulk):\n        celery.request = mock.Mock(spec_set=['feature', 'es'])\n        celery.request.feature.return_value = True\n        expected_query = search.not_nipsad_annotations('acct:jeannie@example.com')\n\n        worker.add_nipsa('acct:jeannie@example.com')\n\n        bulk.assert_any_call(celery.request.es,\n                             expected_query,\n                             worker.add_nipsa_action)\n\n\n@mock.patch(\"h.nipsa.worker.bulk_update_annotations\", autospec=True)\n@mock.patch(\"h.nipsa.worker.celery\", autospec=True)\n@mock.patch(\"h.nipsa.worker.search\", autospec=True)\nclass TestRemoveNipsa(object):\n    def test_remove_nipsa_calls_bulk_update_annotations(self, search, celery, bulk):\n        celery.request = mock.Mock(spec_set=['feature', 'es'])\n        celery.request.feature.return_value = True\n        expected_query = search.nipsad_annotations('acct:jeannie@example.com')\n\n        worker.remove_nipsa('acct:jeannie@example.com')\n\n        bulk.assert_any_call(celery.request.es,\n                             expected_query,\n                             worker.remove_nipsa_action)\n"},{"size":2433,"relativepath":"tests/h/nipsa/services_test.py","filename":"services_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\n\nfrom h.nipsa.services import NipsaService\nfrom h.nipsa.services import nipsa_factory\n\n\n@pytest.mark.usefixtures('users', 'worker')\nclass TestNipsaService(object):\n    def test_flagged_user_returns_list_of_users(self, db_session, users):\n        svc = NipsaService(db_session)\n\n        assert set(svc.flagged_users) == set([users['renata'],\n                                              users['cecilia']])\n\n    def test_is_flagged_returns_true_for_flagged_users(self, db_session, users):\n        svc = NipsaService(db_session)\n\n        assert svc.is_flagged('acct:renata@example.com')\n        assert svc.is_flagged('acct:cecilia@example.com')\n\n    def test_is_flagged_returns_false_for_unflagged_users(self, db_session):\n        svc = NipsaService(db_session)\n\n        assert not svc.is_flagged('acct:dominic@example.com')\n        assert not svc.is_flagged('acct:romeo@example.com')\n\n    def test_flag_sets_nipsa_true(self, db_session, users):\n        svc = NipsaService(db_session)\n\n        svc.flag(users['dominic'])\n\n        assert users['dominic'].nipsa is True\n\n    def test_flag_triggers_add_nipsa_job(self, db_session, users, worker):\n        svc = NipsaService(db_session)\n\n        svc.flag(users['dominic'])\n\n        worker.add_nipsa.delay.assert_called_once_with('acct:dominic@example.com')\n\n    def test_unflag_sets_nipsa_false(self, db_session, users):\n        svc = NipsaService(db_session)\n\n        svc.unflag(users['renata'])\n\n        assert users['renata'].nipsa is False\n\n    def test_unflag_triggers_remove_nipsa_job(self, db_session, users, worker):\n        svc = NipsaService(db_session)\n\n        svc.unflag(users['renata'])\n\n        worker.remove_nipsa.delay.assert_called_once_with('acct:renata@example.com')\n\n\ndef test_nipsa_factory(pyramid_request):\n    svc = nipsa_factory(None, pyramid_request)\n\n    assert isinstance(svc, NipsaService)\n    assert svc.session == pyramid_request.db\n\n\n@pytest.fixture\ndef users(db_session, factories):\n    users = {\n        'renata': factories.User(username='renata', nipsa=True),\n        'cecilia': factories.User(username='cecilia', nipsa=True),\n        'dominic': factories.User(username='dominic', nipsa=False),\n    }\n    db_session.add_all([u for u in users.values()])\n    db_session.flush()\n    return users\n\n\n@pytest.fixture\ndef worker(patch):\n    return patch('h.nipsa.services.worker')\n"},{"size":946,"relativepath":"tests/h/nipsa/subscribers_test.py","filename":"subscribers_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom collections import namedtuple\n\nimport mock\nimport pytest\n\nfrom h.nipsa import subscribers\n\nFakeEvent = namedtuple('FakeEvent', ['request', 'annotation_dict'])\n\n\n@pytest.mark.usefixtures('nipsa_service')\n@pytest.mark.parametrize(\"ann,flagged\", [\n    ({\"user\": \"george\"}, True),\n    ({\"user\": \"georgia\"}, False),\n    ({}, False),\n])\ndef test_transform_annotation(ann, flagged, nipsa_service, pyramid_request):\n    nipsa_service.is_flagged.return_value = flagged\n    event = FakeEvent(request=pyramid_request,\n                      annotation_dict=ann)\n\n    subscribers.transform_annotation(event)\n\n    if flagged:\n        assert ann[\"nipsa\"] is True\n    else:\n        assert \"nipsa\" not in ann\n\n\n@pytest.fixture\ndef nipsa_service(pyramid_config):\n    service = mock.Mock(spec_set=['is_flagged'])\n    service.is_flagged.return_value = False\n    pyramid_config.register_service(service, name='nipsa')\n    return service\n"},{"size":1970,"relativepath":"tests/h/nipsa/search_test.py","filename":"search_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom h.nipsa import search\n\n\ndef test_nipsa_filter_filters_out_nipsad_annotations():\n    \"\"\"nipsa_filter() filters out annotations with \"nipsa\": True.\"\"\"\n    assert search.nipsa_filter() == {\n        \"bool\": {\n            \"should\": [\n                {'not': {'term': {'nipsa': True}}}\n            ]\n        }\n    }\n\n\ndef test_nipsa_filter_users_own_annotations_are_not_filtered():\n    filter_ = search.nipsa_filter(userid=\"fred\")\n\n    assert {'term': {'user': 'fred'}} in (\n        filter_[\"bool\"][\"should\"])\n\n\ndef test_nipsa_filter_coerces_userid_to_lowercase():\n    filter_ = search.nipsa_filter(userid=\"DonkeyNose\")\n\n    assert {'term': {'user': 'donkeynose'}} in (\n        filter_[\"bool\"][\"should\"])\n\n\ndef test_nipsad_annotations_filters_by_userid():\n    query = search.nipsad_annotations(\"test_userid\")\n\n    must_clauses = query[\"query\"][\"filtered\"][\"filter\"][\"bool\"][\"must\"]\n    assert {\"term\": {\"user\": \"test_userid\"}} in must_clauses\n\n\ndef test_nipsad_annotations_filters_by_lowercased_userid():\n    query = search.nipsad_annotations(\"SomethingWithUppercase\")\n\n    must_clauses = query[\"query\"][\"filtered\"][\"filter\"][\"bool\"][\"must\"]\n    assert {\"term\": {\"user\": \"somethingwithuppercase\"}} in must_clauses\n\n\ndef test_not_nipsad_annotatopns_filters_by_userid():\n    query = search.not_nipsad_annotations(\"test_userid\")\n\n    must_clauses = query[\"query\"][\"filtered\"][\"filter\"][\"bool\"][\"must\"]\n    assert {\"term\": {\"user\": \"test_userid\"}} in must_clauses\n\n\ndef test_nipsad_annotations_filters_by_nipsa():\n    query = search.nipsad_annotations(\"test_userid\")\n\n    must_clauses = query[\"query\"][\"filtered\"][\"filter\"][\"bool\"][\"must\"]\n    assert {\"term\": {\"nipsa\": True}} in must_clauses\n\n\ndef test_not_nipsad_annotations_filters_by_nipsa():\n    query = search.not_nipsad_annotations(\"test_userid\")\n\n    must_clauses = query[\"query\"][\"filtered\"][\"filter\"][\"bool\"][\"must\"]\n    assert {\"not\": {\"term\": {\"nipsa\": True}}} in (\n        must_clauses)\n"},{"size":3750,"relativepath":"tests/h/streamer/streamer_test.py","filename":"streamer_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\nfrom mock import call\nimport pytest\n\nfrom h.streamer import messages\nfrom h.streamer import streamer\nfrom h.streamer import websocket\n\n\ndef test_process_work_queue_sends_realtime_messages_to_messages_handle_message(session):\n    message = messages.Message(topic='foo', payload='bar')\n    queue = [message]\n\n    streamer.process_work_queue({}, queue, session_factory=lambda _: session)\n\n    messages.handle_message.assert_called_once_with(message,\n                                                    session,\n                                                    topic_handlers=mock.ANY)\n\n\ndef test_process_work_queue_uses_appropriate_topic_handlers_for_realtime_messages(session):\n    message = messages.Message(topic='user', payload='bar')\n    queue = [message]\n\n    streamer.process_work_queue({},\n                                queue,\n                                session_factory=lambda _: session)\n\n    topic_handlers = {\n        'annotation': messages.handle_annotation_event,\n        'user': messages.handle_user_event,\n    }\n\n    messages.handle_message.assert_called_once_with(mock.ANY,\n                                                    session,\n                                                    topic_handlers=topic_handlers)\n\n\ndef test_process_work_queue_sends_websocket_messages_to_websocket_handle_message(session):\n    message = websocket.Message(socket=mock.sentinel.SOCKET, payload='bar')\n    queue = [message]\n\n    streamer.process_work_queue({}, queue, session_factory=lambda _: session)\n\n    websocket.handle_message.assert_called_once_with(message, session)\n\n\ndef test_process_work_queue_commits_after_each_message(session):\n    message1 = websocket.Message(socket=mock.sentinel.SOCKET, payload='bar')\n    message2 = messages.Message(topic='user', payload='bar')\n    queue = [message1, message2]\n\n    streamer.process_work_queue({}, queue, session_factory=lambda _: session)\n\n    assert session.commit.call_count == 2\n\n\ndef test_process_work_queue_rolls_back_on_handler_exception(session):\n    message = messages.Message(topic='foo', payload='bar')\n    queue = [message]\n\n    messages.handle_message.side_effect = RuntimeError('explosion')\n\n    streamer.process_work_queue({}, queue, session_factory=lambda _: session)\n\n    session.commit.assert_not_called()\n    session.rollback.assert_called_once_with()\n\n\ndef test_process_work_queue_rolls_back_on_unknown_message_type(session):\n    message = 'something that is not a message'\n    queue = [message]\n\n    streamer.process_work_queue({}, queue, session_factory=lambda _: session)\n\n    session.commit.assert_not_called()\n    session.rollback.assert_called_once_with()\n\n\ndef test_process_work_queue_calls_close_after_commit(session):\n    message = messages.Message(topic='annotation', payload='bar')\n    queue = [message]\n\n    streamer.process_work_queue({}, queue, session_factory=lambda _: session)\n\n    assert session.method_calls[-2:] == [\n        call.commit(),\n        call.close()\n    ]\n\n\ndef test_process_work_queue_calls_close_after_rollback(session):\n    message = messages.Message(topic='foo', payload='bar')\n    queue = [message]\n\n    messages.handle_message.side_effect = RuntimeError('explosion')\n\n    streamer.process_work_queue({}, queue, session_factory=lambda _: session)\n\n    assert session.method_calls[-2:] == [\n        call.rollback(),\n        call.close()\n    ]\n\n\n@pytest.fixture\ndef session():\n    return mock.Mock(spec_set=['close', 'commit', 'execute', 'rollback'])\n\n\n@pytest.fixture(autouse=True)\ndef websocket_handle_message(patch):\n    return patch('h.streamer.websocket.handle_message')\n\n\n@pytest.fixture(autouse=True)\ndef messages_handle_message(patch):\n    return patch('h.streamer.messages.handle_message')\n"},{"size":17261,"relativepath":"tests/h/streamer/messages_test.py","filename":"messages_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\nimport pytest\nfrom gevent.queue import Queue\nfrom pyramid import security\nfrom pyramid import registry\n\nfrom h.streamer import messages\n\n\nclass FakeSocket(object):\n    client_id = None\n    filter = None\n    terminated = None\n\n    def __init__(self, client_id):\n        self.client_id = client_id\n        self.terminated = False\n        self.filter = mock.MagicMock()\n        self.send = mock.MagicMock()\n\n        self.authenticated_userid = None\n        self.effective_principals = [security.Everyone, 'group:__world__']\n        self.registry = registry.Registry('streamer_test')\n        self.registry.settings = {'h.app_url': 'http://streamer'}\n\n        self.send_json_payloads = []\n\n    def send_json(self, payload):\n        self.send_json_payloads.append(payload)\n\n\n@pytest.mark.usefixtures('fake_sentry', 'fake_stats')\nclass TestProcessMessages(object):\n    def test_creates_sentry_client(self, fake_sentry, fake_consumer, queue):\n        settings = {}\n\n        messages.process_messages(settings, 'foobar', queue, raise_error=False)\n\n        fake_sentry.get_client.assert_called_once_with(settings)\n\n    def test_passes_sentry_client_to_consumer(self, fake_sentry, fake_consumer, queue):\n        messages.process_messages({}, 'foobar', queue, raise_error=False)\n\n        fake_consumer.assert_called_once_with(connection=mock.ANY,\n                                              routing_key=mock.ANY,\n                                              handler=mock.ANY,\n                                              sentry_client=fake_sentry.get_client.return_value,\n                                              statsd_client=mock.ANY)\n\n    def test_creates_statsd_client(self, fake_stats, fake_consumer, queue):\n        settings = {}\n\n        messages.process_messages(settings, 'foobar', queue, raise_error=False)\n\n        fake_stats.get_client.assert_called_once_with(settings)\n\n    def test_passes_stats_client_to_consumer(self, fake_stats, fake_consumer, queue):\n        messages.process_messages({}, 'foobar', queue, raise_error=False)\n\n        fake_consumer.assert_called_once_with(connection=mock.ANY,\n                                              routing_key=mock.ANY,\n                                              handler=mock.ANY,\n                                              sentry_client=mock.ANY,\n                                              statsd_client=fake_stats.get_client.return_value)\n\n    def test_passes_routing_key_to_consumer(self, fake_consumer, queue):\n        messages.process_messages({}, 'foobar', queue, raise_error=False)\n\n        fake_consumer.assert_called_once_with(connection=mock.ANY,\n                                              routing_key='foobar',\n                                              handler=mock.ANY,\n                                              sentry_client=mock.ANY,\n                                              statsd_client=mock.ANY)\n\n    def test_initializes_new_connection(self, fake_realtime, fake_consumer, queue):\n        settings = {}\n        messages.process_messages(settings, 'foobar', queue, raise_error=False)\n\n        fake_realtime.get_connection.assert_called_once_with(settings)\n\n    def test_passes_connection_to_consumer(self, fake_realtime, fake_consumer, queue):\n        messages.process_messages({}, 'foobar', queue, raise_error=False)\n\n        fake_consumer.assert_called_once_with(connection=fake_realtime.get_connection.return_value,\n                                              routing_key=mock.ANY,\n                                              handler=mock.ANY,\n                                              sentry_client=mock.ANY,\n                                              statsd_client=mock.ANY)\n\n    def test_runs_consumer(self, fake_consumer, queue):\n        messages.process_messages({}, 'foobar', queue, raise_error=False)\n\n        consumer = fake_consumer.return_value\n        consumer.run.assert_called_once_with()\n\n    def test_message_handler_puts_message_on_queue(self, fake_consumer, queue):\n        messages.process_messages({}, 'foobar', queue, raise_error=False)\n        message_handler = fake_consumer.call_args[1]['handler']\n        message_handler({'foo': 'bar'})\n        result = queue.get_nowait()\n\n        assert result.topic == 'foobar'\n        assert result.payload == {'foo': 'bar'}\n\n    @pytest.fixture\n    def fake_sentry(self, patch):\n        return patch('h.sentry')\n\n    @pytest.fixture\n    def fake_stats(self, patch):\n        return patch('h.stats')\n\n    @pytest.fixture\n    def fake_consumer(self, patch):\n        return patch('h.streamer.messages.Consumer')\n\n    @pytest.fixture\n    def fake_realtime(self, patch):\n        return patch('h.streamer.messages.realtime')\n\n    @pytest.fixture\n    def queue(self):\n        return Queue()\n\n\nclass TestHandleMessage(object):\n    def test_calls_handler_with_list_of_sockets(self, websocket):\n        handler = mock.Mock(return_value=None)\n        session = mock.sentinel.db_session\n        message = messages.Message(topic='foo', payload={'foo': 'bar'})\n        websocket.instances = [FakeSocket('a'), FakeSocket('b')]\n\n        messages.handle_message(message, session, topic_handlers={'foo': handler})\n\n        handler.assert_called_once_with(message.payload, list(websocket.instances), session)\n\n    @pytest.fixture\n    def websocket(self, patch):\n        return patch('h.streamer.websocket.WebSocket')\n\n\n@pytest.mark.usefixtures('fetch_annotation', 'links_service', 'nipsa_service')\nclass TestHandleAnnotationEvent(object):\n    def test_it_fetches_the_annotation(self, fetch_annotation, presenter_asdict):\n        message = {\n            'annotation_id': 'panda',\n            'action': 'update',\n            'src_client_id': 'pigeon'\n        }\n        socket = FakeSocket('giraffe')\n        session = mock.sentinel.db_session\n        presenter_asdict.return_value = self.serialized_annotation()\n\n        messages.handle_annotation_event(message, [socket], session)\n\n        fetch_annotation.assert_called_once_with(session, 'panda')\n\n    def test_it_skips_notification_when_fetch_failed(self, fetch_annotation):\n        \"\"\"\n        When a create/update and a delete event happens in quick succession\n        we could fail to load the annotation, even though the event action is\n        update/create. This tests that in that case we silently abort and don't\n        sent a notification to the client.\n        \"\"\"\n        message = {\n            'annotation_id': 'panda',\n            'action': 'update',\n            'src_client_id': 'pigeon'\n        }\n        socket = FakeSocket('giraffe')\n        session = mock.sentinel.db_session\n        fetch_annotation.return_value = None\n\n        result = messages.handle_annotation_event(message, [socket], session)\n\n        assert result is None\n\n    def test_it_serializes_the_annotation(self,\n                                          fetch_annotation,\n                                          links_service,\n                                          presenters):\n        message = {'action': '_', 'annotation_id': '_', 'src_client_id': '_'}\n        socket = FakeSocket('giraffe')\n        session = mock.sentinel.db_session\n        presenters.AnnotationJSONPresenter.return_value.asdict.return_value = (\n            self.serialized_annotation())\n\n        messages.handle_annotation_event(message, [socket], session)\n\n        presenters.AnnotationJSONPresenter.assert_called_once_with(\n            fetch_annotation.return_value,\n            links_service.return_value)\n        assert presenters.AnnotationJSONPresenter.return_value.asdict.called\n\n    def test_notification_format(self, presenter_asdict):\n        \"\"\"Check the format of the returned notification in the happy case.\"\"\"\n        message = {\n            'annotation_id': 'panda',\n            'action': 'update',\n            'src_client_id': 'pigeon'\n        }\n        socket = FakeSocket('giraffe')\n        session = mock.sentinel.db_session\n        presenter_asdict.return_value = self.serialized_annotation()\n\n        messages.handle_annotation_event(message, [socket], session)\n\n        assert socket.send_json_payloads[0] == {\n            'payload': [self.serialized_annotation()],\n            'type': 'annotation-notification',\n            'options': {'action': 'update'},\n        }\n\n    def test_no_send_for_sender_socket(self, presenter_asdict):\n        \"\"\"Should return None if the socket's client_id matches the message's.\"\"\"\n        message = {'src_client_id': 'pigeon', 'annotation_id': '_', 'action': '_'}\n        socket = FakeSocket('pigeon')\n        session = mock.sentinel.db_session\n        presenter_asdict.return_value = self.serialized_annotation()\n\n        messages.handle_annotation_event(message, [socket], session)\n\n        assert socket.send_json_payloads == []\n\n    def test_no_send_if_no_socket_filter(self, presenter_asdict):\n        \"\"\"Should return None if the socket has no filter.\"\"\"\n        message = {'src_client_id': '_', 'annotation_id': '_', 'action': '_'}\n        socket = FakeSocket('giraffe')\n        socket.filter = None\n        session = mock.sentinel.db_session\n        presenter_asdict.return_value = self.serialized_annotation()\n\n        messages.handle_annotation_event(message, [socket], session)\n\n        assert socket.send_json_payloads == []\n\n    def test_no_send_if_action_is_read(self, presenter_asdict):\n        \"\"\"Should return None if the message action is 'read'.\"\"\"\n        message = {'action': 'read', 'src_client_id': '_', 'annotation_id': '_'}\n        socket = FakeSocket('giraffe')\n        session = mock.sentinel.db_session\n        presenter_asdict.return_value = self.serialized_annotation()\n\n        messages.handle_annotation_event(message, [socket], session)\n\n        assert socket.send_json_payloads == []\n\n    def test_no_send_if_filter_does_not_match(self, presenter_asdict):\n        \"\"\"Should return None if the socket filter doesn't match the message.\"\"\"\n        message = {'action': '_', 'src_client_id': '_', 'annotation_id': '_'}\n        socket = FakeSocket('giraffe')\n        socket.filter.match.return_value = False\n        session = mock.sentinel.db_session\n        presenter_asdict.return_value = self.serialized_annotation()\n\n        messages.handle_annotation_event(message, [socket], session)\n\n        assert socket.send_json_payloads == []\n\n    def test_no_send_if_annotation_nipsad(self, nipsa_service, presenter_asdict):\n        \"\"\"Should return None if the annotation is from a NIPSA'd user.\"\"\"\n        message = {'action': '_', 'src_client_id': '_', 'annotation_id': '_'}\n        socket = FakeSocket('giraffe')\n        session = mock.sentinel.db_session\n        presenter_asdict.return_value = self.serialized_annotation()\n        nipsa_service.return_value.is_flagged.return_value = True\n\n        messages.handle_annotation_event(message, [socket], session)\n\n        assert socket.send_json_payloads == []\n\n    def test_no_send_if_annotation_delete_nipsad(self, fetch_annotation, nipsa_service):\n        \"\"\"\n        Should return None if the annotation is a deletion from a NIPSA'd\n        user.\n        \"\"\"\n        message = {\n            'action': 'delete',\n            'src_client_id': '_',\n            'annotation_id': '_',\n            'annotation_dict': self.serialized_annotation({'user': 'geraldine'}),\n        }\n        fetch_annotation.return_value = None\n        socket = FakeSocket('giraffe')\n        session = mock.sentinel.db_session\n        def is_flagged(userid):\n            return userid == 'geraldine'\n        nipsa_service.return_value.is_flagged.side_effect = is_flagged\n\n        messages.handle_annotation_event(message, [socket], session)\n\n        assert socket.send_json_payloads == []\n\n    def test_sends_nipsad_annotations_to_owners(self, nipsa_service, presenter_asdict):\n        \"\"\"NIPSA'd users should see their own annotations.\"\"\"\n        message = {'action': '_', 'src_client_id': '_', 'annotation_id': '_'}\n        socket = FakeSocket('giraffe')\n        socket.authenticated_userid = 'fred'\n        session = mock.sentinel.db_session\n        presenter_asdict.return_value = self.serialized_annotation()\n        nipsa_service.return_value.is_flagged.return_value = True\n\n        messages.handle_annotation_event(message, [socket], session)\n\n        assert len(socket.send_json_payloads) == 1\n\n    def test_sends_nipsad_deletes_to_owners(self, fetch_annotation, nipsa_service):\n        \"\"\"NIPSA'd users should see their own deletions.\"\"\"\n        message = {\n            'action': 'delete',\n            'src_client_id': '_',\n            'annotation_id': '_',\n            'annotation_dict': self.serialized_annotation({'user': 'geraldine'}),\n        }\n        fetch_annotation.return_value = None\n        socket = FakeSocket('giraffe')\n        socket.authenticated_userid = 'geraldine'\n        session = mock.sentinel.db_session\n        def is_flagged(userid):\n            return userid == 'geraldine'\n        nipsa_service.return_value.is_flagged.side_effect = is_flagged\n\n        messages.handle_annotation_event(message, [socket], session)\n\n        assert len(socket.send_json_payloads) == 1\n\n    def test_sends_if_annotation_public(self, presenter_asdict):\n        \"\"\"\n        Everyone should see annotations which are public.\n\n        When logged-out, effective principals contains only\n        `pyramid.security.Everyone`. This test ensures that the system\n        principal is correctly equated with the annotation principal\n        'group:__world__', ensuring that everyone (including logged-out users)\n        receives all public annotations.\n        \"\"\"\n        message = {'action': '_', 'src_client_id': '_', 'annotation_id': '_'}\n        socket = FakeSocket('giraffe')\n        session = mock.sentinel.db_session\n        presenter_asdict.return_value = self.serialized_annotation()\n\n        messages.handle_annotation_event(message, [socket], session)\n\n        assert len(socket.send_json_payloads) == 1\n\n    def test_no_send_if_not_in_group(self, presenter_asdict):\n        \"\"\"Users shouldn't see annotations in groups they aren't members of.\"\"\"\n        message = {'action': '_', 'src_client_id': '_', 'annotation_id': '_'}\n        socket = FakeSocket('giraffe')\n        socket.authenticated_userid = 'fred'\n        session = mock.sentinel.db_session\n        presenter_asdict.return_value = self.serialized_annotation({\n            'permissions': {'read': ['group:private-group']}})\n\n        messages.handle_annotation_event(message, [socket], session)\n\n        assert socket.send_json_payloads == []\n\n    def test_sends_if_in_group(self, presenter_asdict):\n        \"\"\"Users should see annotations in groups they are members of.\"\"\"\n        message = {'action': '_', 'src_client_id': '_', 'annotation_id': '_'}\n        socket = FakeSocket('giraffe')\n        socket.authenticated_userid = 'fred'\n        socket.effective_principals.append('group:private-group')\n        session = mock.sentinel.db_session\n        presenter_asdict.return_value = self.serialized_annotation({\n            'permissions': {'read': ['group:private-group']}})\n\n        messages.handle_annotation_event(message, [socket], session)\n\n        assert len(socket.send_json_payloads) == 1\n\n    def serialized_annotation(self, data=None):\n        if data is None:\n            data = {}\n\n        serialized = {\n            'user': 'fred',\n            'permissions': {'read': ['group:__world__']}\n        }\n        serialized.update(data)\n\n        return serialized\n\n    @pytest.fixture\n    def fetch_annotation(self, patch):\n        return patch('h.streamer.messages.storage.fetch_annotation')\n\n    @pytest.fixture\n    def presenters(self, patch):\n        return patch('h.streamer.messages.presenters')\n\n    @pytest.fixture\n    def presenter_asdict(self, patch):\n        return patch('h.streamer.messages.presenters.AnnotationJSONPresenter.asdict')\n\n    @pytest.fixture\n    def links_service(self, patch):\n        return patch('h.streamer.messages.LinksService')\n\n    @pytest.fixture\n    def nipsa_service(self, patch):\n        service = patch('h.streamer.messages.NipsaService')\n        service.return_value.is_flagged.return_value = False\n        return service\n\n\nclass TestHandleUserEvent(object):\n    def test_sends_session_change_when_joining_or_leaving_group(self):\n        session_model = mock.Mock()\n        message = {\n            'type': 'group-join',\n            'userid': 'amy',\n            'group': 'groupid',\n            'session_model': session_model,\n        }\n        socket = FakeSocket('clientid')\n        socket.authenticated_userid = 'amy'\n\n        messages.handle_user_event(message, [socket], None)\n\n        assert socket.send_json_payloads[0] == {\n            'type': 'session-change',\n            'action': 'group-join',\n            'model': session_model,\n        }\n\n    def test_no_send_when_socket_is_not_event_users(self):\n        \"\"\"Don't send session-change events if the event user is not the socket user.\"\"\"\n        message = {\n            'type': 'group-join',\n            'userid': 'amy',\n            'group': 'groupid',\n        }\n        socket = FakeSocket('clientid')\n        socket.authenticated_userid = 'bob'\n\n        messages.handle_user_event(message, [socket], None)\n\n        assert socket.send_json_payloads == []\n"},{"size":2178,"relativepath":"tests/h/streamer/views_test.py","filename":"views_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\nimport pytest\n\nfrom h.streamer import views\nfrom h.streamer import streamer\n\n\ndef test_websocket_view_bad_origin(pyramid_request):\n    pyramid_request.registry.settings.update({'origins': ['http://good']})\n    pyramid_request.headers = {'Origin': 'http://bad'}\n    res = views.websocket_view(pyramid_request)\n    assert res.code == 403\n\n\ndef test_websocket_view_good_origin(pyramid_request):\n    pyramid_request.registry.settings.update({'origins': ['http://good']})\n    pyramid_request.headers = {'Origin': 'http://good'}\n    pyramid_request.get_response = lambda _: mock.sentinel.good_response\n    res = views.websocket_view(pyramid_request)\n    assert res == mock.sentinel.good_response\n\n\ndef test_websocket_view_same_origin(pyramid_request):\n    pyramid_request.get_response = lambda _: mock.sentinel.good_response\n    res = views.websocket_view(pyramid_request)\n    assert res == mock.sentinel.good_response\n\n\ndef test_websocket_view_adds_auth_state_to_environ(pyramid_config, pyramid_request):\n    pyramid_config.testing_securitypolicy('ragnar', groupids=['foo', 'bar'])\n    pyramid_request.get_response = lambda _: None\n\n    views.websocket_view(pyramid_request)\n    env = pyramid_request.environ\n\n    assert env['h.ws.authenticated_userid'] == 'ragnar'\n    assert env['h.ws.effective_principals'] == pyramid_request.effective_principals\n\n\ndef test_websocket_view_adds_registry_reference_to_environ(pyramid_request):\n    pyramid_request.get_response = lambda _: None\n\n    views.websocket_view(pyramid_request)\n    env = pyramid_request.environ\n\n    assert env['h.ws.registry'] == pyramid_request.registry\n\n\ndef test_websocket_view_adds_work_queue_to_environ(pyramid_request):\n    pyramid_request.get_response = lambda _: None\n\n    views.websocket_view(pyramid_request)\n    env = pyramid_request.environ\n\n    assert env['h.ws.streamer_work_queue'] == streamer.WORK_QUEUE\n\n\n@pytest.fixture\ndef pyramid_request(pyramid_request):\n    pyramid_request.registry.settings.update({'origins': []})\n    # example.com is the dummy request default host URL\n    pyramid_request.headers = {'Origin': 'http://example.com'}\n    return pyramid_request\n"},{"size":6069,"relativepath":"tests/h/streamer/websocket_test.py","filename":"websocket_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom collections import namedtuple\nimport json\n\nimport mock\nimport pytest\nfrom gevent.queue import Queue\nfrom pyramid import security\n\nfrom h.streamer import websocket\n\n\nFakeMessage = namedtuple('FakeMessage', ['data'])\n\n\ndef test_websocket_stores_instance_list(fake_environ):\n    socket = mock.Mock()\n    clients = [\n        websocket.WebSocket(socket, environ=fake_environ),\n        websocket.WebSocket(socket, environ=fake_environ)\n    ]\n\n    for c in clients:\n        assert c in websocket.WebSocket.instances\n\n\ndef test_websocket_removes_self_from_instance_list_when_closed(fake_environ):\n    socket = mock.Mock()\n    client1 = websocket.WebSocket(socket, environ=fake_environ)\n    client2 = websocket.WebSocket(socket, environ=fake_environ)\n\n    assert len(websocket.WebSocket.instances) == 2\n    client1.closed(1000)\n    assert client1 not in websocket.WebSocket.instances\n    client2.closed(1000)\n    assert client2 not in websocket.WebSocket.instances\n\n    # A second closure (however unusual) should not raise\n    client1.closed(1000)\n\n\ndef test_socket_enqueues_incoming_messages(fake_environ):\n    socket = mock.Mock()\n    client = websocket.WebSocket(socket, environ=fake_environ)\n    message = FakeMessage('client data')\n    queue = fake_environ['h.ws.streamer_work_queue']\n\n    client.received_message(message)\n    result = queue.get_nowait()\n\n    assert result.socket == client\n    assert result.payload == 'client data'\n\n\ndef test_socket_sets_auth_data_from_environ(fake_environ):\n    socket = mock.Mock()\n    client = websocket.WebSocket(socket, environ=fake_environ)\n\n    assert client.authenticated_userid == 'janet'\n    assert client.effective_principals == [\n        security.Everyone,\n        security.Authenticated,\n        'group:__world__',\n    ]\n\n\ndef test_socket_sets_registry_from_environ(fake_environ):\n    socket = mock.Mock()\n    client = websocket.WebSocket(socket, environ=fake_environ)\n\n    assert client.registry == mock.sentinel.registry\n\n\ndef test_socket_send_json(fake_environ, fake_json, fake_socket_send):\n    socket = mock.Mock()\n    client = websocket.WebSocket(socket, environ=fake_environ)\n\n    payload = {'foo': 'bar'}\n    client.send_json(payload)\n\n    fake_json.dumps.assert_called_once_with(payload)\n    fake_socket_send.assert_called_once_with(client, fake_json.dumps.return_value)\n\n\ndef test_socket_send_json_skips_when_terminated(fake_environ, fake_json, fake_socket_send, fake_socket_terminated):\n    socket = mock.Mock()\n    client = websocket.WebSocket(socket, environ=fake_environ)\n\n    fake_socket_terminated.return_value = True\n    client.send_json({'foo': 'bar'})\n\n    assert not fake_json.dumps.called\n    assert not fake_socket_send.called\n\n\ndef test_handle_message_sets_socket_client_id_for_client_id_messages():\n    socket = mock.Mock()\n    socket.client_id = None\n    message = websocket.Message(socket=socket, payload=json.dumps({\n        'messageType': 'client_id',\n        'value': 'abcd1234',\n    }))\n\n    websocket.handle_message(message)\n\n    assert socket.client_id == 'abcd1234'\n\n\ndef test_handle_message_sets_socket_filter_for_filter_messages():\n    socket = mock.Mock()\n    socket.filter = None\n    message = websocket.Message(socket=socket, payload=json.dumps({\n        'filter': {\n            'actions': {},\n            'match_policy': 'include_all',\n            'clauses': [{\n                'field': '/uri',\n                'operator': 'equals',\n                'value': 'http://example.com',\n            }],\n        }\n    }))\n\n    websocket.handle_message(message)\n\n    assert socket.filter is not None\n\n\n@mock.patch('memex.storage.expand_uri')\ndef test_handle_message_expands_uris_in_uri_filter_with_session(expand_uri):\n    expand_uri.return_value = ['http://example.com',\n                               'http://example.com/alter',\n                               'http://example.com/print']\n    session = mock.sentinel.db_session\n    socket = mock.Mock()\n    socket.filter = None\n    message = websocket.Message(socket=socket, payload=json.dumps({\n        'filter': {\n            'actions': {},\n            'match_policy': 'include_all',\n            'clauses': [{\n                'field': '/uri',\n                'operator': 'equals',\n                'value': 'http://example.com',\n            }],\n        }\n    }))\n\n    websocket.handle_message(message, session=session)\n\n    uri_filter = socket.filter.filter['clauses'][0]\n    uri_values = uri_filter['value']\n    assert len(uri_values) == 3\n    assert 'http://example.com' in uri_values\n    assert 'http://example.com/alter' in uri_values\n    assert 'http://example.com/print' in uri_values\n\n\n@mock.patch('memex.storage.expand_uri')\ndef test_handle_message_expands_uris_using_passed_session(expand_uri):\n    expand_uri.return_value = ['http://example.com', 'http://example.org/']\n    session = mock.sentinel.db_session\n    socket = mock.Mock()\n    socket.filter = None\n    message = websocket.Message(socket=socket, payload=json.dumps({\n        'filter': {\n            'actions': {},\n            'match_policy': 'include_all',\n            'clauses': [{\n                'field': '/uri',\n                'operator': 'equals',\n                'value': 'http://example.com',\n            }],\n        }\n    }))\n\n    websocket.handle_message(message, session=session)\n\n    expand_uri.assert_called_once_with(session, 'http://example.com')\n\n\n@pytest.fixture\ndef fake_environ():\n    return {\n        'h.ws.authenticated_userid': 'janet',\n        'h.ws.effective_principals': [security.Everyone,\n                                      security.Authenticated,\n                                      'group:__world__',],\n        'h.ws.registry': mock.sentinel.registry,\n        'h.ws.streamer_work_queue': Queue(),\n    }\n\n\n@pytest.fixture\ndef fake_json(patch):\n    return patch('h.streamer.websocket.json')\n\n\n@pytest.fixture\ndef fake_socket_send(patch):\n    return patch('h.streamer.websocket.WebSocket.send')\n\n\n@pytest.fixture\ndef fake_socket_terminated(patch):\n    return patch('h.streamer.websocket.WebSocket.terminated')\n"},{"size":3359,"relativepath":"tests/h/admin/views/nipsa_test.py","filename":"nipsa_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom pyramid import httpexceptions\nimport pytest\n\nfrom h.admin.views import nipsa as views\n\n\n@pytest.mark.usefixtures('nipsa_service', 'routes', 'users')\nclass TestNipsaIndex(object):\n    def test_lists_flagged_usernames(self, pyramid_request):\n        result = views.nipsa_index(pyramid_request)\n\n        assert set(result['usernames']) == set(['kiki', 'ursula', 'osono'])\n\n    def test_lists_flagged_usernames_no_results(self, nipsa_service, pyramid_request):\n        nipsa_service.flagged = set([])\n\n        result = views.nipsa_index(pyramid_request)\n\n        assert result['usernames'] == []\n\n\n@pytest.mark.usefixtures('nipsa_service', 'routes', 'users')\nclass TestNipsaAddRemove(object):\n    def test_add_flags_user(self, nipsa_service, pyramid_request, users):\n        pyramid_request.params = {\"add\": \"carl\"}\n\n        views.nipsa_add(pyramid_request)\n\n        assert users['carl'] in nipsa_service.flagged\n\n    @pytest.mark.parametrize('user', ['', 'donkeys', '\\x00'])\n    def test_add_raises_when_user_not_found(self, user, nipsa_service, pyramid_request):\n        pyramid_request.params = {\"add\": user}\n\n        with pytest.raises(views.UserNotFoundError):\n            views.nipsa_add(pyramid_request)\n\n    def test_add_redirects_to_index(self, pyramid_request):\n        pyramid_request.params = {\"add\": \"carl\"}\n\n        result = views.nipsa_add(pyramid_request)\n\n        assert isinstance(result, httpexceptions.HTTPSeeOther)\n        assert result.location == '/adm/nipsa'\n\n    def test_remove_unflags_user(self, nipsa_service, pyramid_request, users):\n        pyramid_request.params = {\"remove\": \"kiki\"}\n\n        views.nipsa_remove(pyramid_request)\n\n        assert users['kiki'] not in nipsa_service.flagged\n\n    @pytest.mark.parametrize('user', ['', 'donkeys', '\\x00'])\n    def test_remove_raises_when_user_not_found(self, user, nipsa_service, pyramid_request):\n        pyramid_request.params = {\"remove\": user}\n\n        with pytest.raises(views.UserNotFoundError):\n            views.nipsa_remove(pyramid_request)\n\n    def test_remove_redirects_to_index(self, pyramid_request):\n        pyramid_request.params = {\"remove\": \"kiki\"}\n\n        result = views.nipsa_remove(pyramid_request)\n\n        assert isinstance(result, httpexceptions.HTTPSeeOther)\n        assert result.location == '/adm/nipsa'\n\n\nclass FakeNipsaService(object):\n    def __init__(self, users):\n        self.flagged = set([u for u in users if u.nipsa])\n\n    @property\n    def flagged_users(self):\n        return list(self.flagged)\n\n    def flag(self, user):\n        self.flagged.add(user)\n\n    def unflag(self, user):\n        self.flagged.remove(user)\n\n\n@pytest.fixture\ndef nipsa_service(pyramid_config, users):\n    service = FakeNipsaService([u for u in users.values()])\n    pyramid_config.register_service(service, name='nipsa')\n    return service\n\n\n@pytest.fixture\ndef routes(pyramid_config):\n    pyramid_config.add_route('admin_nipsa', '/adm/nipsa')\n\n\n@pytest.fixture\ndef users(db_session, factories):\n    users = {\n        'carl': factories.User(username='carl'),\n        'kiki': factories.User(username='kiki', nipsa=True),\n        'ursula': factories.User(username='ursula', nipsa=True),\n        'osono': factories.User(username='osono', nipsa=True),\n    }\n    db_session.add_all([u for u in users.values()])\n    db_session.flush()\n    return users\n"},{"size":3893,"relativepath":"tests/h/admin/views/admins_test.py","filename":"admins_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport mock\nfrom pyramid import httpexceptions\nimport pytest\n\nfrom h.admin.views import admins as views\n\n\n@pytest.mark.usefixtures('routes')\nclass TestAdminsIndex(object):\n    def test_when_no_admins(self, pyramid_request):\n        result = views.admins_index(pyramid_request)\n\n        assert result[\"admin_users\"] == []\n\n    @pytest.mark.usefixtures('users')\n    def test_context_contains_admin_usernames(self, pyramid_request):\n        result = views.admins_index(pyramid_request)\n\n        assert set(result[\"admin_users\"]) == set([\"agnos\", \"bojan\", \"cristof\"])\n\n\n@pytest.mark.usefixtures('users', 'routes')\nclass TestAdminsAddRemove(object):\n\n    def test_add_makes_users_admins(self, pyramid_request, users):\n        pyramid_request.params = {\"add\": \"eva\"}\n\n        views.admins_add(pyramid_request)\n\n        assert users['eva'].admin\n\n    def test_add_is_idempotent(self, pyramid_request, users):\n        pyramid_request.params = {\"add\": \"agnos\"}\n\n        views.admins_add(pyramid_request)\n\n        assert users['agnos'].admin\n\n    def test_add_redirects_to_index(self, pyramid_request):\n        pyramid_request.params = {\"add\": \"eva\"}\n\n        result = views.admins_add(pyramid_request)\n\n        assert isinstance(result, httpexceptions.HTTPSeeOther)\n        assert result.location == '/adm/admins'\n\n    def test_add_redirects_to_index_when_user_not_found(self, pyramid_request):\n        pyramid_request.params = {\"add\": \"florp\"}\n\n        result = views.admins_add(pyramid_request)\n\n        assert isinstance(result, httpexceptions.HTTPSeeOther)\n        assert result.location == '/adm/admins'\n\n    def test_add_flashes_when_user_not_found(self, pyramid_request):\n        pyramid_request.params = {\"add\": \"florp\"}\n        pyramid_request.session.flash = mock.Mock()\n\n        views.admins_add(pyramid_request)\n\n        assert pyramid_request.session.flash.call_count == 1\n\n    def test_remove_makes_users_not_admins(self, pyramid_request, users):\n        pyramid_request.params = {\"remove\": \"cristof\"}\n\n        views.admins_remove(pyramid_request)\n\n        assert not users['cristof'].admin\n\n    def test_remove_is_idempotent(self, pyramid_request, users):\n        pyramid_request.params = {\"remove\": \"eva\"}\n\n        views.admins_remove(pyramid_request)\n\n        assert not users['eva'].admin\n\n    def test_remove_will_not_remove_last_admin(self, pyramid_request, users):\n        pyramid_request.params = {\"remove\": \"cristof\"}\n        views.admins_remove(pyramid_request)\n        pyramid_request.params = {\"remove\": \"bojan\"}\n        views.admins_remove(pyramid_request)\n        pyramid_request.params = {\"remove\": \"agnos\"}\n        views.admins_remove(pyramid_request)\n\n        assert users['agnos'].admin\n\n    def test_remove_redirects_to_index(self, pyramid_request):\n        pyramid_request.params = {\"remove\": \"agnos\"}\n\n        result = views.admins_remove(pyramid_request)\n\n        assert isinstance(result, httpexceptions.HTTPSeeOther)\n        assert result.location == '/adm/admins'\n\n    def test_remove_redirects_to_index_when_user_not_found(self, pyramid_request):\n        pyramid_request.params = {\"remove\": \"florp\"}\n\n        result = views.admins_remove(pyramid_request)\n\n        assert isinstance(result, httpexceptions.HTTPSeeOther)\n        assert result.location == '/adm/admins'\n\n\n@pytest.fixture\ndef routes(pyramid_config):\n    pyramid_config.add_route('admin_admins', '/adm/admins')\n\n\n@pytest.fixture\ndef users(db_session, factories):\n    admins = ['agnos', 'bojan', 'cristof']\n    nonadmins = ['david', 'eva', 'flora']\n\n    users = {}\n\n    for admin in admins:\n        users[admin] = factories.User(username=admin, admin=True)\n    for nonadmin in nonadmins:\n        users[nonadmin] = factories.User(username=nonadmin)\n\n    db_session.add_all(list(users.values()))\n    db_session.flush()\n\n    return users\n"},{"size":392,"relativepath":"tests/h/admin/views/index_test.py","filename":"index_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\nfrom h.admin.views import index as views\n\n\nclass TestIndex(object):\n    def test_release_info(self, pyramid_request):\n        result = views.index(pyramid_request)\n\n        assert 'release_info' in result\n        assert 'hostname' in result['release_info']\n        assert 'python_version' in result['release_info']\n        assert 'version' in result['release_info']\n"},{"size":6664,"relativepath":"tests/h/admin/views/features_test.py","filename":"features_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport pytest\nimport mock\n\nfrom h import models\nfrom h.admin.views import features as views\n\n\nclass DummyFeature(object):\n    def __init__(self, name):\n        self.name = name\n        self.everyone = False\n        self.admins = False\n        self.staff = False\n\n\nfeatures_save_fixtures = pytest.mark.usefixtures('Feature',\n                                                 'check_csrf_token')\n\n\n@features_save_fixtures\ndef test_features_save_sets_attributes_when_checkboxes_on(Feature, pyramid_request):\n    foo = DummyFeature(name='foo')\n    bar = DummyFeature(name='bar')\n    Feature.all.return_value = [foo, bar]\n    pyramid_request.POST = {'foo[everyone]': 'on',\n                            'foo[staff]': 'on',\n                            'bar[admins]': 'on'}\n\n    views.features_save(pyramid_request)\n\n    assert foo.everyone == foo.staff == bar.admins == True\n\n\n@features_save_fixtures\ndef test_features_save_sets_attributes_when_checkboxes_off(Feature, pyramid_request):\n    foo = DummyFeature(name='foo')\n    foo.everyone = True\n    foo.staff = True\n    Feature.all.return_value = [foo]\n    pyramid_request.POST = {}\n\n    views.features_save(pyramid_request)\n\n    assert foo.everyone == foo.staff == False\n\n\n@features_save_fixtures\ndef test_features_save_ignores_unknown_fields(Feature, pyramid_request):\n    foo = DummyFeature(name='foo')\n    Feature.all.return_value = [foo]\n    pyramid_request.POST = {'foo[wibble]': 'on',\n                            'foo[admins]': 'ignoreme'}\n\n    views.features_save(pyramid_request)\n\n    assert foo.admins == False\n\n\n@features_save_fixtures\ndef test_features_save_checks_csrf_token(Feature, check_csrf_token, pyramid_request):\n    Feature.all.return_value = []\n    pyramid_request.POST = {}\n\n    views.features_save(pyramid_request)\n\n    check_csrf_token.assert_called_with(pyramid_request)\n\n\ndef test_cohorts_index_without_cohorts(pyramid_request):\n    result = views.cohorts_index({}, pyramid_request)\n    assert result[\"results\"] == []\n\n\ndef test_cohorts_index_with_cohorts(pyramid_request):\n    cohort1 = models.FeatureCohort(name='cohort1')\n    cohort2 = models.FeatureCohort(name='cohort2')\n    pyramid_request.db.add(cohort1)\n    pyramid_request.db.add(cohort2)\n    pyramid_request.db.flush()\n\n    result = views.cohorts_index({}, pyramid_request)\n    assert len(result[\"results\"]) == 2\n\n\ndef test_cohorts_add_creates_cohort_with_no_members(pyramid_request):\n    pyramid_request.params['add'] = 'cohort'\n    views.cohorts_add(pyramid_request)\n\n    result = pyramid_request.db.query(models.FeatureCohort).filter_by(name='cohort').all()\n    assert len(result) == 1\n\n    cohort = result[0]\n    assert cohort.name == \"cohort\"\n    assert len(cohort.members) == 0\n\n\ndef test_cohorts_edit_add_user(factories, pyramid_request):\n    user = factories.User(username='benoit')\n    cohort = models.FeatureCohort(name='FractalCohort')\n\n    pyramid_request.db.add(user)\n    pyramid_request.db.add(cohort)\n    pyramid_request.db.flush()\n\n    pyramid_request.matchdict['id'] = cohort.id\n    pyramid_request.params['add'] = user.username\n    views.cohorts_edit_add(pyramid_request)\n\n    assert len(cohort.members) == 1\n    assert cohort.members[0].username == user.username\n\n\ndef test_cohorts_edit_remove_user(factories, pyramid_request):\n    user = factories.User(username='benoit')\n    cohort = models.FeatureCohort(name='FractalCohort')\n    cohort.members.append(user)\n\n    pyramid_request.db.add(user)\n    pyramid_request.db.add(cohort)\n    pyramid_request.db.flush()\n\n    assert len(cohort.members) == 1\n\n    pyramid_request.matchdict['id'] = cohort.id\n    pyramid_request.params['remove'] = user.username\n    views.cohorts_edit_remove(pyramid_request)\n\n    assert len(cohort.members) == 0\n\n\ndef test_cohorts_edit_with_no_users(pyramid_request):\n    cohort = models.FeatureCohort(name='FractalCohort')\n    pyramid_request.db.add(cohort)\n    pyramid_request.db.flush()\n\n    pyramid_request.matchdict['id'] = cohort.id\n    result = views.cohorts_edit({}, pyramid_request)\n\n    assert result['cohort'].id == cohort.id\n    assert len(result['cohort'].members) == 0\n\n\ndef test_cohorts_edit_with_users(factories, pyramid_request):\n    cohort = models.FeatureCohort(name='FractalCohort')\n    user1 = factories.User(username='benoit')\n    user2 = factories.User(username='emily')\n    cohort.members.append(user1)\n    cohort.members.append(user2)\n\n    pyramid_request.db.add(user1)\n    pyramid_request.db.add(user2)\n    pyramid_request.db.add(cohort)\n    pyramid_request.db.flush()\n\n    pyramid_request.matchdict['id'] = cohort.id\n    result = views.cohorts_edit({}, pyramid_request)\n\n    assert result['cohort'].id == cohort.id\n    assert len(result['cohort'].members) == 2\n\n\n@pytest.mark.usefixtures('check_csrf_token')\n@mock.patch.dict('h.models.feature.FEATURES', {'feat': 'A test feature'})\ndef test_features_save_sets_cohorts_when_checkboxes_on(pyramid_request):\n    feat = models.Feature(name='feat')\n    cohort = models.FeatureCohort(name='cohort')\n\n    pyramid_request.db.add(feat)\n    pyramid_request.db.add(cohort)\n    pyramid_request.db.flush()\n\n    pyramid_request.POST = {'feat[cohorts][cohort]': 'on'}\n    views.features_save(pyramid_request)\n\n    feat = pyramid_request.db.query(models.Feature).filter_by(name='feat').first()\n    cohort = pyramid_request.db.query(models.FeatureCohort).filter_by(name='cohort').first()\n\n    assert len(feat.cohorts) == 1\n    assert cohort in feat.cohorts\n\n\n@pytest.mark.usefixtures('check_csrf_token')\n@mock.patch.dict('h.models.feature.FEATURES', {'feat': 'A test feature'})\ndef test_features_save_unsets_cohorts_when_checkboxes_off(pyramid_request):\n    feat = models.Feature(name='feat')\n    cohort = models.FeatureCohort(name='cohort')\n    feat.cohorts.append(cohort)\n\n    pyramid_request.db.add(feat)\n    pyramid_request.db.add(cohort)\n    pyramid_request.db.flush()\n\n    pyramid_request.POST = {'feat[cohorts][cohort]': 'off'}\n    views.features_save(pyramid_request)\n\n    feat = pyramid_request.db.query(models.Feature).filter_by(name='feat').first()\n    cohort = pyramid_request.db.query(models.FeatureCohort).filter_by(name='cohort').first()\n\n    assert len(feat.cohorts) == 0\n    assert cohort not in feat.cohorts\n\n\n@pytest.fixture(autouse=True)\ndef routes(pyramid_config):\n    pyramid_config.add_route('admin_features', '/adm/features')\n    pyramid_config.add_route('admin_cohorts', '/adm/cohorts')\n    pyramid_config.add_route('admin_cohorts_edit', '/adm/cohorts/{id}')\n\n\n@pytest.fixture\ndef Feature(patch):\n    return patch('h.models.Feature')\n\n\n@pytest.fixture\ndef check_csrf_token(patch):\n    return patch('pyramid.session.check_csrf_token')\n"},{"size":8771,"relativepath":"tests/h/admin/views/users_test.py","filename":"users_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport mock\nfrom mock import Mock\nfrom mock import MagicMock\nfrom mock import call\nfrom pyramid import httpexceptions\nimport pytest\n\nfrom h.admin.views import users as views\n\nusers_index_fixtures = pytest.mark.usefixtures('User')\n\n\n@users_index_fixtures\ndef test_users_index(pyramid_request):\n    result = views.users_index(pyramid_request)\n\n    assert result == {'username': None, 'user': None, 'user_meta': {}}\n\n\n@users_index_fixtures\ndef test_users_index_looks_up_users_by_username(User, pyramid_request):\n    pyramid_request.params = {\"username\": \"bob\"}\n    User.get_by_username.return_value = None\n    User.get_by_email.return_value = None\n\n    views.users_index(pyramid_request)\n\n    User.get_by_username.assert_called_with(pyramid_request.db, \"bob\")\n\n\n@users_index_fixtures\ndef test_users_index_looks_up_users_by_email(User, pyramid_request):\n    pyramid_request.params = {\"username\": \"bob@builder.com\"}\n    User.get_by_username.return_value = None\n    User.get_by_email.return_value = None\n\n    views.users_index(pyramid_request)\n\n    User.get_by_email.assert_called_with(pyramid_request.db, \"bob@builder.com\")\n\n\n@users_index_fixtures\ndef test_users_index_queries_annotation_count_by_userid(User, db_session, factories, pyramid_request):\n    User.get_by_username.return_value = factories.User(username='bob')\n    userid = \"acct:bob@{}\".format(pyramid_request.auth_domain)\n    for _ in xrange(8):\n        db_session.add(factories.Annotation(userid=userid))\n    db_session.flush()\n\n    pyramid_request.params = {\"username\": \"bob\"}\n    result = views.users_index(pyramid_request)\n    assert result['user_meta']['annotations_count'] == 8\n\n\n@users_index_fixtures\ndef test_users_index_no_user_found(User, pyramid_request):\n    pyramid_request.params = {\"username\": \"bob\"}\n    User.get_by_username.return_value = None\n    User.get_by_email.return_value = None\n\n    result = views.users_index(pyramid_request)\n\n    assert result == {'username': \"bob\", 'user': None, 'user_meta': {}}\n\n\n@users_index_fixtures\ndef test_users_index_user_found(User, pyramid_request, db_session, factories):\n    pyramid_request.params = {\"username\": \"bob\"}\n    user = User.get_by_username.return_value = factories.User(username='bob')\n\n    result = views.users_index(pyramid_request)\n\n    assert result == {\n        'username': \"bob\",\n        'user': user,\n        'user_meta': {'annotations_count': 0},\n    }\n\n\nusers_activate_fixtures = pytest.mark.usefixtures('User', 'ActivationEvent')\n\n\n@users_activate_fixtures\ndef test_users_activate_gets_user(User, pyramid_request):\n    pyramid_request.params = {\"username\": \"bob\"}\n\n    views.users_activate(pyramid_request)\n\n    User.get_by_username.assert_called_once_with(pyramid_request.db, \"bob\")\n\n\n@users_activate_fixtures\ndef test_users_activate_user_not_found_error(User, pyramid_request):\n    pyramid_request.params = {\"username\": \"bob\"}\n    User.get_by_username.return_value = None\n\n    with pytest.raises(views.UserNotFoundError):\n        views.users_activate(pyramid_request)\n\n\n@users_activate_fixtures\ndef test_users_activate_activates_user(User, pyramid_request):\n    pyramid_request.params = {\"username\": \"bob\"}\n\n    views.users_activate(pyramid_request)\n\n    User.get_by_username.return_value.activate.assert_called_once_with()\n\n\n@users_activate_fixtures\ndef test_users_activate_flashes_success(pyramid_request):\n    pyramid_request.params = {\"username\": \"bob\"}\n\n    views.users_activate(pyramid_request)\n    success_flash = pyramid_request.session.peek_flash('success')\n\n    assert success_flash\n\n\n@users_activate_fixtures\ndef test_users_activate_inits_ActivationEvent(ActivationEvent, User, pyramid_request):\n    pyramid_request.params = {\"username\": \"bob\"}\n\n    views.users_activate(pyramid_request)\n\n    ActivationEvent.assert_called_once_with(pyramid_request,\n                                            User.get_by_username.return_value)\n\n\n@users_activate_fixtures\ndef test_users_activate_calls_notify(ActivationEvent, User, notify, pyramid_request):\n    pyramid_request.params = {\"username\": \"bob\"}\n\n    views.users_activate(pyramid_request)\n\n    notify.assert_called_once_with(ActivationEvent.return_value)\n\n\n@users_activate_fixtures\ndef test_users_activate_redirects(User, pyramid_request):\n    pyramid_request.params = {\"username\": \"bob\"}\n\n    result = views.users_activate(pyramid_request)\n\n    assert isinstance(result, httpexceptions.HTTPFound)\n\n\nusers_delete_fixtures = pytest.mark.usefixtures('User', 'delete_user')\n\n\n@users_delete_fixtures\ndef test_users_delete_user_not_found_error(User, pyramid_request):\n    pyramid_request.params = {\"username\": \"bob\"}\n\n    User.get_by_username.return_value = None\n\n    with pytest.raises(views.UserNotFoundError):\n        views.users_delete(pyramid_request)\n\n\n@users_delete_fixtures\ndef test_users_delete_deletes_user(User, delete_user, pyramid_request):\n    pyramid_request.params = {\"username\": \"bob\"}\n    user = MagicMock()\n\n    User.get_by_username.return_value = user\n\n    views.users_delete(pyramid_request)\n\n    delete_user.assert_called_once_with(pyramid_request, user)\n\n\n@users_delete_fixtures\ndef test_users_delete_group_creator_error(User, delete_user, pyramid_request):\n    pyramid_request.params = {\"username\": \"bob\"}\n    user = MagicMock()\n\n    User.get_by_username.return_value = user\n    delete_user.side_effect = views.UserDeletionError('group creator error')\n\n    views.users_delete(pyramid_request)\n\n    assert pyramid_request.session.peek_flash('error') == [\n        'group creator error'\n    ]\n\ndelete_user_fixtures = pytest.mark.usefixtures('api_storage',\n                                               'elasticsearch_helpers',\n                                               'models',\n                                               'user_created_no_groups')\n\n\n@delete_user_fixtures\ndef test_delete_user_raises_when_group_creator(models, pyramid_request):\n    user = Mock()\n\n    models.Group.created_by.return_value.count.return_value = 10\n\n    with pytest.raises(views.UserDeletionError):\n        views.delete_user(pyramid_request, user)\n\n\n@delete_user_fixtures\ndef test_delete_user_disassociate_group_memberships(fake_db_session, pyramid_request):\n    pyramid_request.db = fake_db_session\n    user = Mock(groups=[Mock()])\n\n    views.delete_user(pyramid_request, user)\n\n    assert user.groups == []\n\n\n@delete_user_fixtures\ndef test_delete_user_queries_annotations(elasticsearch_helpers, factories, fake_db_session, pyramid_request):\n    pyramid_request.db = fake_db_session\n    user = factories.User(username=u'bob')\n\n    views.delete_user(pyramid_request, user)\n\n    elasticsearch_helpers.scan.assert_called_once_with(\n        client=pyramid_request.es.conn,\n        query={\n            'query': {\n                'filtered': {\n                    'filter': {'term': {'user': u'acct:bob@example.com'}},\n                    'query': {'match_all': {}}\n                }\n            }\n        }\n    )\n\n\n@delete_user_fixtures\ndef test_delete_user_deletes_annotations(api_storage, elasticsearch_helpers, fake_db_session, pyramid_request):\n    pyramid_request.db = fake_db_session\n    user = MagicMock()\n    annotation_1 = {'_id': 'annotation-1'}\n    annotation_2 = {'_id': 'annotation-2'}\n\n    elasticsearch_helpers.scan.return_value = [annotation_1, annotation_2]\n\n    views.delete_user(pyramid_request, user)\n\n    assert api_storage.delete_annotation.mock_calls == [\n        call(pyramid_request.db, 'annotation-1'),\n        call(pyramid_request.db, 'annotation-2')\n    ]\n\n\n@delete_user_fixtures\ndef test_delete_user_deletes_user(fake_db_session, pyramid_request):\n    pyramid_request.db = fake_db_session\n    user = MagicMock()\n\n    views.delete_user(pyramid_request, user)\n\n    assert user in pyramid_request.db.deleted\n\n\n@pytest.fixture\ndef pyramid_request(pyramid_request):\n    pyramid_request.es = mock.MagicMock()\n    return pyramid_request\n\n\n@pytest.fixture(autouse=True)\ndef routes(pyramid_config):\n    pyramid_config.add_route('admin_users', '/adm/users')\n\n\n@pytest.fixture\ndef ActivationEvent(patch):\n    return patch('h.admin.views.users.ActivationEvent')\n\n\n@pytest.fixture\ndef User(patch):\n    return patch('h.models.User')\n\n\n@pytest.fixture\ndef api_storage(patch):\n    return patch('h.admin.views.users.storage')\n\n\n@pytest.fixture\ndef delete_user(patch):\n    return patch('h.admin.views.users.delete_user')\n\n\n@pytest.fixture\ndef elasticsearch_helpers(patch):\n    return patch('h.admin.views.users.es_helpers')\n\n\n@pytest.fixture\ndef models(patch):\n    return patch('h.admin.views.users.models')\n\n\n@pytest.fixture\ndef user_created_no_groups(models):\n    # By default, pretend that all users are the creators of 0 groups.\n    models.Group.created_by.return_value.count.return_value = 0\n"},{"size":3442,"relativepath":"tests/h/admin/views/staff_test.py","filename":"staff_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport mock\nfrom pyramid import httpexceptions\nimport pytest\n\nfrom h.admin.views import staff as views\n\n\n@pytest.mark.usefixtures('routes')\nclass TestStaffIndex(object):\n    def test_when_no_staff(self, pyramid_request):\n        result = views.staff_index(pyramid_request)\n\n        assert result[\"staff\"] == []\n\n    @pytest.mark.usefixtures('users')\n    def test_context_contains_staff_usernames(self, pyramid_request):\n        result = views.staff_index(pyramid_request)\n\n        assert set(result[\"staff\"]) == set([\"agnos\", \"bojan\", \"cristof\"])\n\n\n@pytest.mark.usefixtures('users', 'routes')\nclass TestStaffAddRemove(object):\n\n    def test_add_makes_users_staff(self, pyramid_request, users):\n        pyramid_request.params = {\"add\": \"eva\"}\n\n        views.staff_add(pyramid_request)\n\n        assert users['eva'].staff\n\n    def test_add_is_idempotent(self, pyramid_request, users):\n        pyramid_request.params = {\"add\": \"agnos\"}\n\n        views.staff_add(pyramid_request)\n\n        assert users['agnos'].staff\n\n    def test_add_redirects_to_index(self, pyramid_request):\n        pyramid_request.params = {\"add\": \"eva\"}\n\n        result = views.staff_add(pyramid_request)\n\n        assert isinstance(result, httpexceptions.HTTPSeeOther)\n        assert result.location == '/adm/staff'\n\n    def test_add_redirects_to_index_when_user_not_found(self, pyramid_request):\n        pyramid_request.params = {\"add\": \"florp\"}\n\n        result = views.staff_add(pyramid_request)\n\n        assert isinstance(result, httpexceptions.HTTPSeeOther)\n        assert result.location == '/adm/staff'\n\n    def test_add_flashes_when_user_not_found(self, pyramid_request):\n        pyramid_request.params = {\"add\": \"florp\"}\n        pyramid_request.session.flash = mock.Mock()\n\n        views.staff_add(pyramid_request)\n\n        assert pyramid_request.session.flash.call_count == 1\n\n    def test_remove_makes_users_not_staff(self, pyramid_request, users):\n        pyramid_request.params = {\"remove\": \"cristof\"}\n\n        views.staff_remove(pyramid_request)\n\n        assert not users['cristof'].staff\n\n    def test_remove_is_idempotent(self, pyramid_request, users):\n        pyramid_request.params = {\"remove\": \"eva\"}\n\n        views.staff_remove(pyramid_request)\n\n        assert not users['eva'].staff\n\n    def test_remove_redirects_to_index(self, pyramid_request):\n        pyramid_request.params = {\"remove\": \"agnos\"}\n\n        result = views.staff_remove(pyramid_request)\n\n        assert isinstance(result, httpexceptions.HTTPSeeOther)\n        assert result.location == '/adm/staff'\n\n    def test_remove_redirects_to_index_when_user_not_found(self, pyramid_request):\n        pyramid_request.params = {\"remove\": \"florp\"}\n\n        result = views.staff_remove(pyramid_request)\n\n        assert isinstance(result, httpexceptions.HTTPSeeOther)\n        assert result.location == '/adm/staff'\n\n\n@pytest.fixture\ndef routes(pyramid_config):\n    pyramid_config.add_route('admin_staff', '/adm/staff')\n\n\n@pytest.fixture\ndef users(db_session, factories):\n    staff = ['agnos', 'bojan', 'cristof']\n    nonstaff = ['david', 'eva', 'flora']\n\n    users = {}\n\n    for staff in staff:\n        users[staff] = factories.User(username=staff, staff=True)\n    for nonstaff in nonstaff:\n        users[nonstaff] = factories.User(username=nonstaff)\n\n    db_session.add_all(list(users.values()))\n    db_session.flush()\n\n    return users\n"},{"size":2870,"relativepath":"tests/h/admin/views/badge_test.py","filename":"badge_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\nimport pytest\nfrom pyramid import httpexceptions\n\nfrom h import models\nfrom h.admin.views import badge as views\n\n\nclass TestBadgeIndex(object):\n    def test_when_nothing_blocked(self, pyramid_request):\n        result = views.badge_index(pyramid_request)\n\n        assert result[\"uris\"] == []\n\n    def test_with_blocked_uris(self, pyramid_request, blocked_uris):\n        result = views.badge_index(pyramid_request)\n\n        assert set(result[\"uris\"]) == set(blocked_uris)\n\n\n@pytest.mark.usefixtures('blocked_uris', 'routes')\nclass TestBadgeAddRemove(object):\n    def test_add_blocks_uri(self, pyramid_request):\n        pyramid_request.params = {'add': 'test_uri'}\n\n        views.badge_add(pyramid_request)\n\n        assert models.Blocklist.is_blocked(pyramid_request.db, 'test_uri')\n\n    def test_add_redirects_to_index(self, pyramid_request):\n        pyramid_request.params = {'add': 'test_uri'}\n\n        result = views.badge_add(pyramid_request)\n\n        assert isinstance(result, httpexceptions.HTTPSeeOther)\n        assert result.location == '/adm/badge'\n\n    def test_add_flashes_error_if_uri_already_blocked(self, pyramid_request):\n        pyramid_request.params = {'add': 'blocked1'}\n        pyramid_request.session.flash = mock.Mock()\n\n        views.badge_add(pyramid_request)\n\n        assert pyramid_request.session.flash.call_count == 1\n\n    def test_add_redirects_to_index_if_uri_already_blocked(self, pyramid_request):\n        pyramid_request.params = {'add': 'blocked1'}\n\n        result = views.badge_add(pyramid_request)\n\n        assert isinstance(result, httpexceptions.HTTPSeeOther)\n        assert result.location == '/adm/badge'\n\n    def test_remove_unblocks_uri(self, pyramid_request):\n        pyramid_request.params = {'remove': 'blocked2'}\n\n        views.badge_remove(pyramid_request)\n\n        assert not models.Blocklist.is_blocked(pyramid_request.db, 'blocked2')\n\n    def test_remove_redirects_to_index(self, pyramid_request):\n        pyramid_request.params = {'remove': 'blocked1'}\n\n        result = views.badge_remove(pyramid_request)\n\n        assert isinstance(result, httpexceptions.HTTPSeeOther)\n        assert result.location == '/adm/badge'\n\n    def test_remove_redirects_to_index_even_if_not_blocked(self, pyramid_request):\n        pyramid_request.params = {'remove': 'test_uri'}\n\n        result = views.badge_remove(pyramid_request)\n\n        assert isinstance(result, httpexceptions.HTTPSeeOther)\n        assert result.location == '/adm/badge'\n\n\n@pytest.fixture\ndef blocked_uris(db_session):\n    from h import models\n\n    uris = []\n    for uri in ['blocked1', 'blocked2', 'blocked3']:\n        uris.append(models.Blocklist(uri=uri))\n    db_session.add_all(uris)\n    db_session.flush()\n\n    return uris\n\n\n@pytest.fixture\ndef routes(pyramid_config):\n    pyramid_config.add_route('admin_badge', '/adm/badge')\n"},{"size":1135,"relativepath":"tests/h/admin/worker_test.py","filename":"worker_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\n\nfrom h.admin import worker\n\n\nclass TestRenameUser(object):\n    def test_it_raises_when_user_cannot_be_found(self, celery):\n        with pytest.raises(ValueError) as err:\n            worker.rename_user(4, 'panda')\n        assert err.value.message == 'Could not find user with id 4'\n\n    def test_it_finds_the_service(self, celery, user):\n        worker.rename_user(user.id, 'panda')\n\n        celery.request.find_service.assert_called_once_with(name='rename_user')\n\n    def test_it_renames_the_user(self, celery, user):\n        service = celery.request.find_service.return_value\n\n        worker.rename_user(user.id, 'panda')\n\n        service.rename.assert_called_once_with(user, 'panda')\n\n    @pytest.fixture\n    def user(self, factories, db_session):\n        user = factories.User(username='giraffe')\n        db_session.add(user)\n        db_session.flush()\n        return user\n\n    @pytest.fixture\n    def celery(self, patch, db_session):\n        cel = patch('h.admin.worker.celery', autospec=False)\n        cel.request.db = db_session\n        return cel\n"},{"size":3558,"relativepath":"tests/h/admin/services/user_test.py","filename":"user_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport mock\nimport pytest\n\nfrom h import models\nfrom h.admin.services.user import RenameUserService\nfrom h.admin.services.user import UserRenameError\nfrom h.admin.services.user import make_indexer\n\n\nclass TestRenameUserService(object):\n    def test_check_returns_true_when_new_username_does_not_exist(self, service):\n        assert service.check('panda') is True\n\n    def test_check_raises_when_new_userid_is_already_taken(self, service, user, db_session, factories):\n        user_taken = factories.User(username='panda')\n        db_session.add(user_taken)\n        db_session.flush()\n\n        with pytest.raises(UserRenameError) as err:\n            service.check('panda')\n        assert err.value.message == 'Another user already has the username \"panda\"'\n\n    def test_rename_checks_first(self, service, check, user):\n        service.rename(user, 'panda')\n\n        check.assert_called_once_with(service, 'panda')\n\n    def test_rename_changes_the_username(self, service, user, db_session):\n        service.rename(user, 'panda')\n\n        assert db_session.query(models.User).get(user.id).username == 'panda'\n\n    def test_rename_deletes_auth_tickets(self, service, user, db_session, factories):\n        ids = [factories.AuthTicket(user=user).id for _ in xrange(3)]\n\n        service.rename(user, 'panda')\n\n        count = db_session.query(models.AuthTicket).filter(models.AuthTicket.id.in_(ids)).count()\n        assert count == 0\n\n    def test_rename_changes_the_users_annotations_userid(self, service, user, annotations, db_session):\n        service.rename(user, 'panda')\n\n        userids = [ann.userid for ann in db_session.query(models.Annotation)]\n        assert set([user.userid]) == set(userids)\n\n    def test_rename_reindexes_the_users_annotations(self, service, user, annotations, indexer):\n        service.rename(user, 'panda')\n        indexer.assert_called_once_with({ann.id for ann in annotations})\n\n    @pytest.fixture\n    def indexer(self):\n        return mock.Mock(spec_set=[])\n\n    @pytest.fixture\n    def service(self, pyramid_request, indexer):\n        return RenameUserService(session=pyramid_request.db,\n                                 reindex=indexer)\n\n    @pytest.fixture\n    def check(self, patch):\n        return patch('h.admin.services.user.RenameUserService.check')\n\n    @pytest.fixture\n    def user(self, factories, db_session):\n        user = factories.User(username='giraffe')\n        db_session.add(user)\n        db_session.flush()\n        return user\n\n    @pytest.fixture\n    def annotations(self, user, factories, db_session, pyramid_request):\n        anns = []\n        for _ in range(8):\n            anns.append(factories.Annotation(userid=user.userid))\n        db_session.add_all(anns)\n        db_session.flush()\n\n        return anns\n\n\nclass TestMakeIndexer(object):\n    def test_it_indexes_the_given_ids(self, req, index):\n        indexer = make_indexer(req)\n        indexer([1, 2, 3])\n\n        batch_indexer = index.BatchIndexer.return_value\n        batch_indexer.index.assert_called_once_with([1, 2, 3])\n\n    def test_it_skips_indexing_when_no_ids_given(self, req, index):\n        indexer = make_indexer(req)\n\n        indexer([])\n\n        assert not index.BatchIndexer.called\n\n    @pytest.fixture\n    def req(self, pyramid_request):\n        pyramid_request.tm = mock.MagicMock()\n        pyramid_request.es = mock.MagicMock()\n        return pyramid_request\n\n    @pytest.fixture\n    def index(self, patch):\n        return patch('h.admin.services.user.index')\n"},{"size":2168,"relativepath":"tests/h/util/view_test.py","filename":"view_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\nfrom mock import Mock\n\nfrom h.util.view import handle_exception, json_view\n\n\nclass TestHandleException(object):\n    def test_sets_response_status_500(self, pyramid_request):\n        handle_exception(pyramid_request)\n\n        assert pyramid_request.response.status_int == 500\n\n    def test_triggers_sentry_capture(self, pyramid_request):\n        handle_exception(pyramid_request)\n\n        pyramid_request.sentry.captureException.assert_called_once_with()\n\n    def test_reraises_in_debug_mode(self, pyramid_request):\n        pyramid_request.debug = True\n        dummy_exc = ValueError('dummy')\n\n        try:\n            raise dummy_exc\n        except:\n            with pytest.raises(ValueError) as exc:\n                handle_exception(pyramid_request)\n            assert exc.value == dummy_exc\n\n    @pytest.fixture\n    def pyramid_request(self, pyramid_request):\n        sentry = Mock(spec_set=['captureException'])\n        pyramid_request.sentry = sentry\n        pyramid_request.debug = False\n        return pyramid_request\n\n\n@pytest.mark.usefixtures('view_config')\nclass TestJsonView(object):\n    def test_sets_accept(self):\n        result = json_view()\n\n        assert result['accept'] == 'application/json'\n\n    def test_sets_renderer(self):\n        result = json_view()\n\n        assert result['renderer'] == 'json'\n\n    def test_passes_through_other_kwargs(self):\n        result = json_view(foo='bar', baz='qux')\n\n        assert result['foo'] == 'bar'\n        assert result['baz'] == 'qux'\n\n    def test_allows_overriding_accept(self):\n        result = json_view(accept='application/ld+json')\n\n        assert result['accept'] == 'application/ld+json'\n\n    def test_allows_overriding_renderer(self):\n        result = json_view(renderer='h:some/template.json.jinja2')\n\n        assert result['renderer'] == 'h:some/template.json.jinja2'\n\n    @pytest.fixture\n    def view_config(self, patch):\n        def _return_kwargs(**kwargs):\n            return kwargs\n        view_config = patch('h.util.view.view_config')\n        view_config.side_effect = _return_kwargs\n        return view_config\n"},{"size":338,"relativepath":"tests/h/util/user_test.py","filename":"user_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport pytest\n\nfrom h.util import user as user_util\n\n\ndef test_split_user():\n    parts = user_util.split_user(\"acct:seanh@hypothes.is\")\n    assert parts == {'username': 'seanh', 'domain': 'hypothes.is'}\n\n\ndef test_split_user_no_match():\n    with pytest.raises(ValueError):\n        user_util.split_user(\"donkeys\")\n"},{"size":6203,"relativepath":"tests/h/conftest.py","filename":"conftest.py","extension":".py","content":"# -*- coding: utf-8 -*-\n# pylint: disable=no-self-use\n\"\"\"\nThe `conftest` module is automatically loaded by py.test and serves as a place\nto put fixture functions that are useful application-wide.\n\"\"\"\n\nimport functools\nimport os\n\nimport deform\nimport mock\nimport pytest\n\nimport click.testing\nimport sqlalchemy\nfrom pyramid import testing\nfrom pyramid.request import apply_request_extensions\nfrom sqlalchemy.orm import sessionmaker\n\nfrom h import db\nfrom h import form\nfrom h.settings import database_url\n\nTEST_DATABASE_URL = database_url(os.environ.get('TEST_DATABASE_URL',\n                                                'postgresql://postgres@localhost/htest'))\n\nSession = sessionmaker()\n\n\nclass DummyFeature(object):\n\n    \"\"\"\n    A dummy feature flag looker-upper.\n\n    Because we're probably testing all feature-flagged functionality, this\n    feature client defaults every flag to *True*, which is the exact opposite\n    of what happens outside of testing.\n    \"\"\"\n\n    def __init__(self):\n        self.flags = {}\n        self.loaded = False\n\n    def __call__(self, name, *args, **kwargs):\n        return self.flags.get(name, True)\n\n    def load(self):\n        self.loaded = True\n\n\nclass DummySession(object):\n\n    \"\"\"\n    A dummy database session.\n    \"\"\"\n\n    def __init__(self):\n        self.added = []\n        self.deleted = []\n        self.flushed = False\n\n    def add(self, obj):\n        self.added.append(obj)\n\n    def delete(self, obj):\n        self.deleted.append(obj)\n\n    def flush(self):\n        self.flushed = True\n\n\n# A fake version of colander.Invalid\nclass FakeInvalid(object):\n    def __init__(self, errors):\n        self.errors = errors\n\n    def asdict(self):\n        return self.errors\n\n\ndef autopatcher(request, target, **kwargs):\n    \"\"\"Patch and cleanup automatically. Wraps :py:func:`mock.patch`.\"\"\"\n    options = {'autospec': True}\n    options.update(kwargs)\n    patcher = mock.patch(target, **options)\n    obj = patcher.start()\n    request.addfinalizer(patcher.stop)\n    return obj\n\n\n@pytest.yield_fixture\ndef cli():\n    runner = click.testing.CliRunner()\n    with runner.isolated_filesystem():\n        yield runner\n\n\n@pytest.fixture(scope='session')\ndef db_engine():\n    \"\"\"Set up the database connection and create tables.\"\"\"\n    engine = sqlalchemy.create_engine(TEST_DATABASE_URL)\n    db.init(engine, should_create=True, should_drop=True)\n    return engine\n\n\n@pytest.yield_fixture\ndef db_session(db_engine):\n    \"\"\"\n    Prepare the SQLAlchemy session object.\n\n    We enable fast repeatable database tests by setting up the database only\n    once per session (see :func:`db_engine`) and then wrapping each test\n    function in a transaction that is rolled back.\n\n    Additionally, we set a SAVEPOINT before entering the test, and if we\n    detect that the test has committed (i.e. released the savepoint) we\n    immediately open another. This has the effect of preventing test code from\n    committing the outer transaction.\n    \"\"\"\n    conn = db_engine.connect()\n    trans = conn.begin()\n    session = Session(bind=conn)\n    session.begin_nested()\n\n    @sqlalchemy.event.listens_for(session, \"after_transaction_end\")\n    def restart_savepoint(session, transaction):\n        if transaction.nested and not transaction._parent.nested:\n            session.begin_nested()\n\n    try:\n        yield session\n    finally:\n        session.close()\n        trans.rollback()\n        conn.close()\n\n\n@pytest.yield_fixture\ndef factories(db_session):\n    from ..common import factories\n    factories.set_session(db_session)\n    yield factories\n    factories.set_session(None)\n\n\n@pytest.fixture\ndef fake_feature():\n    return DummyFeature()\n\n\n@pytest.fixture\ndef fake_db_session():\n    return DummySession()\n\n\n@pytest.fixture\ndef form_validating_to():\n    def form_validating_to(appstruct):\n        form = mock.MagicMock()\n        form.validate.return_value = appstruct\n        form.render.return_value = 'valid form'\n        return form\n    return form_validating_to\n\n\n@pytest.fixture\ndef invalid_form():\n    def invalid_form(errors=None):\n        if errors is None:\n            errors = {}\n        invalid = FakeInvalid(errors)\n        form = mock.MagicMock()\n        form.validate.side_effect = deform.ValidationFailure(None, None, invalid)\n        form.render.return_value = 'invalid form'\n        return form\n    return invalid_form\n\n\n@pytest.fixture\ndef mailer(pyramid_config):\n    from pyramid_mailer.interfaces import IMailer\n    from pyramid_mailer.testing import DummyMailer\n    mailer = DummyMailer()\n    pyramid_config.registry.registerUtility(mailer, IMailer)\n    return mailer\n\n\n@pytest.fixture\ndef matchers():\n    from ..common import matchers\n    return matchers\n\n\n@pytest.fixture\ndef notify(pyramid_config, request):\n    patcher = mock.patch.object(pyramid_config.registry, 'notify', autospec=True)\n    request.addfinalizer(patcher.stop)\n    return patcher.start()\n\n\n@pytest.fixture\ndef patch(request):\n    return functools.partial(autopatcher, request)\n\n\n@pytest.yield_fixture\ndef pyramid_config(pyramid_settings, pyramid_request):\n    \"\"\"Pyramid configurator object.\"\"\"\n    with testing.testConfig(request=pyramid_request,\n                            settings=pyramid_settings) as config:\n        # Include pyramid_services so it's easy to set up fake services in tests\n        config.include('pyramid_services')\n        apply_request_extensions(pyramid_request)\n\n        yield config\n\n\n@pytest.fixture\ndef pyramid_request(db_session, fake_feature, pyramid_settings):\n    \"\"\"Dummy Pyramid request object.\"\"\"\n    request = testing.DummyRequest(db=db_session, feature=fake_feature)\n    request.auth_domain = request.domain\n    request.create_form = mock.Mock()\n    request.matched_route = mock.Mock()\n    request.registry.settings = pyramid_settings\n    request.is_xhr = False\n    return request\n\n\n@pytest.fixture\ndef pyramid_csrf_request(pyramid_request):\n    \"\"\"Dummy Pyramid request object with a valid CSRF token.\"\"\"\n    pyramid_request.headers['X-CSRF-Token'] = pyramid_request.session.get_csrf_token()\n    return pyramid_request\n\n\n@pytest.fixture\ndef pyramid_settings():\n    \"\"\"Default app settings.\"\"\"\n    return {\n        'sqlalchemy.url': TEST_DATABASE_URL\n    }\n"},{"size":9786,"relativepath":"tests/h/paginator_test.py","filename":"paginator_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\nimport pytest\nfrom webob.multidict import NestedMultiDict\n\nfrom h.paginator import paginate\nfrom h.paginator import paginate_query\n\n\nclass TestPaginate(object):\n\n    def test_current_page_defaults_to_1(self, pyramid_request):\n        \"\"\"If there's no 'page' request param it defaults to 1.\"\"\"\n        pyramid_request.params = {}\n\n        page = paginate(pyramid_request, 600, 10)\n\n        assert page['cur'] == 1\n\n    @pytest.mark.parametrize('page_param,expected', [\n      # If the current page is the first page.\n      ('1',  [1, 2, 3, 4, '...', 60]),\n\n      # If the current page is the last page.\n      ('60',  [1, '...', 57, 58, 59, 60]),\n\n      # If the current page is in the middle.\n      ('30',  [1, '...',27, 28, 29, 30, 31, 32, 33, '...', 60]),\n\n      # If the current page is near the first page.\n      ('2',  [1, 2, 3, 4, 5, '...', 60]),\n\n      # If the current page is near the last page.\n      ('59',  [1, '...', 56, 57, 58, 59, 60]),\n    ])\n    def test_numbers_large_result_set(self, pyramid_request, page_param, expected):\n        pyramid_request.params = {'page': page_param}\n        assert paginate(pyramid_request, 600, 10)['numbers'] == expected\n\n    @pytest.mark.parametrize('page_param,expected', [\n      # If the current page is the first page.\n      ('1',  [1, 2, 3, 4, 5]),\n      # If the current page is the last page.\n      ('5',  [1, 2, 3, 4, 5]),\n      # If the current page is in the middle.\n      ('3',  [1, 2, 3, 4, 5]),\n    ])\n    def test_numbers_small_result_set(self, pyramid_request, page_param, expected):\n        pyramid_request.params = {'page': page_param}\n        assert paginate(pyramid_request, 50, 10)['numbers'] == expected\n\n    @pytest.mark.parametrize('page_param,expected', [\n        # Normally the current page just comes directly from the request's\n        # 'page' param.\n        ('32', 32),\n\n        # If the 'page' param is less than 1 the current page is clipped to 1.\n        ('-3', 1),\n        ('0', 1),\n\n        # If the 'page' param isn't a number the current page defaults to 1.\n        ('foo', 1),\n\n        # If the 'page' param is greater than the number of pages the current\n        # page is clipped to the number of pages.\n        ('100', 60),\n\n    ])\n    def test_current_page(self, pyramid_request, page_param, expected):\n        pyramid_request.params = {'page': page_param}\n\n        page = paginate(\n            pyramid_request,\n            # With 600 items in total and 10 items per page there are 60 pages.\n            600,\n            10)\n\n        assert page['cur'] == expected\n\n    @pytest.mark.parametrize('total,page_size,expected', [\n        # Normally 'max' is just total / page_size.\n        (600, 10, 60),\n\n        # Total doesn't divide evenly into page_size.\n        (605, 10, 61),\n\n        # If total is less than page size there should be one page.\n        (6, 10, 1),\n    ])\n    def test_max(self, pyramid_request, total, page_size, expected):\n        assert paginate(pyramid_request, total, page_size)['max'] == expected\n\n    @pytest.mark.parametrize('page_param,expected', [\n        # Normally 'next' is simply the current page + 1.\n        ('32', 33),\n\n        # If the current page is the last page then 'next' is None.\n        ('60', None),\n    ])\n    def test_next(self, pyramid_request, page_param, expected):\n        pyramid_request.params = {'page': page_param}\n        assert paginate(pyramid_request, 600, 10)['next'] == expected\n\n    @pytest.mark.parametrize('page_param,expected', [\n        # Normally 'prev' is simply the current page - 1.\n        ('32', 31),\n\n        # If the current page is the first page then 'prev' is None.\n        ('1', None),\n    ])\n    def test_prev(self, pyramid_request, page_param, expected):\n        pyramid_request.params = {'page': page_param}\n        assert paginate(pyramid_request, 600, 10)['prev'] == expected\n\n    @pytest.mark.parametrize('params,expected', [\n        # Normally url_for() just replaces the 'page' param with the requested\n        # new page number.\n        ([{'page': '32'}], {'page': 26}),\n\n        # If there is no 'page' param it just adds a 'page' param for the\n        # requested page.\n        ([{}], {'page': 26}),\n\n        # Existing query params (other than 'page') should be preserved.\n        (\n            [{'q': 'user:jeremydean', 'foo': 'bar'}],\n            {'q': ['user:jeremydean'], 'foo': ['bar'], 'page': 26}\n        ),\n        (\n            [{'q': 'user:jeremydean', 'foo': 'bar', 'page': '32'}],\n            {'q': ['user:jeremydean'], 'foo': ['bar'], 'page': 26}\n        ),\n\n        # Repeated params should be preserved.\n        (\n            [{'foo': 'one'}, {'foo': 'two'}],\n            {'foo': ['one', 'two'], 'page': 26}\n        ),\n    ])\n    def test_url_for(self, pyramid_request, params, expected):\n        pyramid_request.params = NestedMultiDict(*params)\n        pyramid_request.current_route_path = mock.Mock(spec_set=['__call__'])\n        url_for = paginate(pyramid_request, 600, 10)['url_for']\n\n        url = url_for(page=26)  # Request the URL for page 26.\n\n        pyramid_request.current_route_path.assert_called_once_with(\n            _query=expected)\n        assert url == pyramid_request.current_route_path.return_value\n\n\n@pytest.mark.usefixtures('paginate')\nclass TestPaginateQuery(object):\n\n    # The current page that will be returned by paginate().\n    CURRENT_PAGE = 3\n\n    # The page_size argument that will be passed to paginate_query().\n    PAGE_SIZE = 10\n\n    def test_it_calls_the_wrapped_view_callable(self,\n                                                pyramid_request,\n                                                view_callable,\n                                                wrapped):\n        \"\"\"It calls the wrapped view callable to get the SQLAlchemy query.\"\"\"\n        wrapped(mock.sentinel.context, pyramid_request)\n\n        view_callable.assert_called_once_with(mock.sentinel.context,\n                                              pyramid_request)\n\n    def test_it_calls_paginate(self,\n                               paginate,\n                               pyramid_request,\n                               wrapped):\n        \"\"\"It calls paginate() to get the paginator template data.\"\"\"\n        wrapped(mock.sentinel.context, pyramid_request)\n\n        paginate.assert_called_once_with(pyramid_request,\n                                         mock.sentinel.total,\n                                         self.PAGE_SIZE)\n\n    def test_it_offsets_the_query(self,\n                                  wrapped,\n                                  pyramid_request,\n                                  query):\n        \"\"\"\n        It offsets the query by the correct amount.\n\n        It offsets the query so that only the results starting from the first\n        result that should be shown on the current page (as returned by\n        paginate()) are fetched from the db.\n\n        \"\"\"\n        wrapped(mock.sentinel.context, pyramid_request)\n\n        # The current page is 3, and there are 10 results per page, so we\n        # would expect the 20 first results (the first two pages) to be offset.\n        query.offset.assert_called_once_with(20)\n\n    def test_it_limits_the_query(self,\n                                 wrapped,\n                                 pyramid_request,\n                                 query):\n        \"\"\"\n        It limits the query by the correct amount.\n\n        It limits the query so that only the results up to the last result that\n        should be shown on the current page are fetched from the db.\n\n        \"\"\"\n        wrapped(mock.sentinel.context, pyramid_request)\n\n        query.limit.assert_called_once_with(self.PAGE_SIZE)\n\n    def test_it_returns_the_query_results(self,\n                                          wrapped,\n                                          pyramid_request):\n        results = wrapped(mock.sentinel.context, pyramid_request)['results']\n\n        assert results == mock.sentinel.all\n\n    def test_it_returns_the_total(self,\n                                  wrapped,\n                                  pyramid_request):\n        total = wrapped(mock.sentinel.context, pyramid_request)['total']\n\n        assert total == mock.sentinel.total\n\n    def test_it_returns_the_paginator_template_data(self,\n                                                    wrapped,\n                                                    paginate,\n                                                    pyramid_request):\n        page = wrapped(mock.sentinel.context, pyramid_request)['page']\n\n        assert page == paginate.return_value\n\n    @pytest.fixture\n    def paginate(self, patch):\n        return patch(\n            'h.paginator.paginate',\n            return_value={\n                'cur': self.CURRENT_PAGE,\n            },\n        )\n\n    @pytest.fixture\n    def query(self):\n        \"\"\"Return a mock SQLAlchemy Query object.\"\"\"\n        mock_query = mock.Mock(spec_set=['count', 'offset', 'limit', 'all'])\n        mock_query.count.side_effect = lambda: mock.sentinel.total\n        mock_query.offset.side_effect = lambda n: mock_query\n        mock_query.limit.side_effect = lambda n: mock_query\n        mock_query.all.side_effect = lambda: mock.sentinel.all\n        return mock_query\n\n    @pytest.fixture\n    def view_callable(self, query):\n        \"\"\"Return a mock view callable for paginate_query() to wrap.\"\"\"\n        view_callable = mock.Mock(\n            return_value=query,\n            spec_set=['__call__', '__name__'],\n        )\n        view_callable.__name__ = 'mock_view_callable'\n        return view_callable\n\n    @pytest.fixture\n    def wrapped(self, view_callable):\n        \"\"\"Return a mock view callable wrapped in paginate_query().\"\"\"\n        return paginate_query(view_callable, self.PAGE_SIZE)\n"},{"size":6567,"relativepath":"tests/h/realtime_test.py","filename":"realtime_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom datetime import datetime\n\nimport pytest\nimport mock\n\nfrom h import realtime\n\n\nclass TestConsumer(object):\n    def test_init_stores_connection(self, consumer):\n        assert consumer.connection == mock.sentinel.connection\n\n    def test_init_stores_routing_key(self, consumer):\n        assert consumer.routing_key == 'annotation'\n\n    def test_init_stores_handler(self, consumer, handler):\n        assert consumer.handler == handler\n\n    def test_get_consumers_creates_a_queue(self, Queue, consumer, generate_queue_name):\n        consumer_factory = mock.Mock(spec_set=[])\n        exchange = realtime.get_exchange()\n\n        consumer.get_consumers(consumer_factory, mock.Mock())\n\n        Queue.assert_called_once_with(generate_queue_name.return_value,\n                                      exchange=exchange,\n                                      durable=False,\n                                      routing_key='annotation',\n                                      auto_delete=True)\n\n    def test_get_consumers_creates_a_consumer(self, Queue, consumer):\n        consumer_factory = mock.Mock(spec_set=[])\n        consumer.get_consumers(consumer_factory, channel=None)\n        consumer_factory.assert_called_once_with(queues=[Queue.return_value],\n                                                 callbacks=[consumer.handle_message])\n\n    def test_get_consumers_returns_list_of_one_consumer(self, consumer):\n        consumer_factory = mock.Mock(spec_set=[])\n        consumers = consumer.get_consumers(consumer_factory, channel=None)\n        assert consumers == [consumer_factory.return_value]\n\n    def test_handle_message_acks_message(self, consumer):\n        message = mock.Mock()\n        consumer.handle_message({}, message)\n\n        message.ack.assert_called_once_with()\n\n    def test_handle_message_calls_the_handler(self, consumer, handler):\n        body = {'foo': 'bar'}\n        consumer.handle_message(body, mock.Mock())\n\n        handler.assert_called_once_with(body)\n\n    def test_handle_message_records_queue_time_if_timestamp_present(self, handler, matchers, statsd_client):\n        consumer = realtime.Consumer(mock.sentinel.connection,\n                                     'annotation',\n                                     handler,\n                                     statsd_client=statsd_client)\n        message = mock.Mock()\n        message.headers = {'timestamp': datetime.utcnow().isoformat() + 'Z'}\n\n        consumer.handle_message({}, message)\n\n        statsd_client.timing.assert_called_once_with('streamer.msg.queueing',\n                                                     matchers.instance_of(int))\n\n    def test_handle_message_doesnt_explode_if_timestamp_missing(self, handler, statsd_client):\n        consumer = realtime.Consumer(mock.sentinel.connection,\n                                     'annotation',\n                                     handler,\n                                     statsd_client=statsd_client)\n        message = mock.Mock()\n        message.headers = {}\n\n        consumer.handle_message({}, message)\n\n    @pytest.fixture\n    def Queue(self, patch):\n        return patch('h.realtime.kombu.Queue')\n\n    @pytest.fixture\n    def consumer(self, handler):\n        return realtime.Consumer(mock.sentinel.connection, 'annotation', handler)\n\n    @pytest.fixture\n    def handler(self):\n        return mock.Mock(spec_set=[])\n\n    @pytest.fixture\n    def statsd_client(self):\n        return mock.Mock(spec_set=['timing'])\n\n    @pytest.fixture\n    def generate_queue_name(self, patch):\n        return patch('h.realtime.Consumer.generate_queue_name')\n\n\nclass TestPublisher(object):\n    def test_publish_annotation(self, matchers, producer_pool, pyramid_request):\n        payload = {'action': 'create', 'annotation': {'id': 'foobar'}}\n        producer = producer_pool['foobar'].acquire().__enter__()\n        exchange = realtime.get_exchange()\n\n        publisher = realtime.Publisher(pyramid_request)\n        publisher.publish_annotation(payload)\n\n        expected_headers = matchers.mapping_containing('timestamp')\n        producer.publish.assert_called_once_with(payload,\n                                                 exchange=exchange,\n                                                 declare=[exchange],\n                                                 routing_key='annotation',\n                                                 headers=expected_headers)\n\n    def test_publish_user(self, matchers, producer_pool, pyramid_request):\n        payload = {'action': 'create', 'user': {'id': 'foobar'}}\n        producer = producer_pool['foobar'].acquire().__enter__()\n        exchange = realtime.get_exchange()\n\n        publisher = realtime.Publisher(pyramid_request)\n        publisher.publish_user(payload)\n\n        expected_headers = matchers.mapping_containing('timestamp')\n        producer.publish.assert_called_once_with(payload,\n                                                 exchange=exchange,\n                                                 declare=[exchange],\n                                                 routing_key='user',\n                                                 headers=expected_headers)\n\n    @pytest.fixture\n    def producer_pool(self, patch):\n        return patch('h.realtime.producer_pool')\n\n\nclass TestGetExchange(object):\n    def test_returns_the_exchange(self):\n        import kombu\n        exchange = realtime.get_exchange()\n        assert isinstance(exchange, kombu.Exchange)\n\n    def test_type(self):\n        exchange = realtime.get_exchange()\n        assert exchange.type == 'direct'\n\n    def test_durable(self):\n        exchange = realtime.get_exchange()\n        assert exchange.durable is False\n\n    def test_delivery_mode(self):\n        \"\"\"Test that delivery mode is 1 (transient)\"\"\"\n        exchange = realtime.get_exchange()\n        assert exchange.delivery_mode == 1\n\n\nclass TestGetConnection(object):\n    def test_defaults(self, Connection):\n        realtime.get_connection({})\n        Connection.assert_called_once_with('amqp://guest:guest@localhost:5672//')\n\n    def test_returns_the_connection(self, Connection):\n        connection = realtime.get_connection({})\n        assert connection == Connection.return_value\n\n    def test_allows_to_overwrite_broker_url(self, Connection):\n        broker_url = 'amqp://alice:bob@rabbitmq.int:5673/prj'\n        realtime.get_connection({'broker_url': broker_url})\n        Connection.assert_called_once_with(broker_url)\n\n    @pytest.fixture\n    def Connection(self, patch):\n        return patch('h.realtime.kombu.Connection')\n"},{"size":12406,"relativepath":"tests/h/form_test.py","filename":"form_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport mock\nimport pytest\n\nfrom h import form\n\n\nclass TestJinja2Renderer(object):\n\n    def test_call_fetches_correct_templates(self, jinja2_env):\n        renderer = form.Jinja2Renderer(jinja2_env)\n\n        renderer('foo')\n        renderer('foo.jinja2')\n        renderer('bar/baz')\n        renderer('bar/baz.jinja2')\n\n        assert jinja2_env.get_template.call_args_list == [\n            mock.call('foo.jinja2'),\n            mock.call('foo.jinja2'),\n            mock.call('bar/baz.jinja2'),\n            mock.call('bar/baz.jinja2'),\n        ]\n\n    def test_call_passes_kwargs_to_render(self, jinja2_env, jinja2_template):\n        renderer = form.Jinja2Renderer(jinja2_env)\n\n        renderer('textinput', foo='foo', bar='bar')\n\n        jinja2_template.render.assert_called_once_with({'foo': 'foo',\n                                                        'bar': 'bar'})\n\n    def test_call_passes_system_context_to_render(self, jinja2_env, jinja2_template):\n        renderer = form.Jinja2Renderer(jinja2_env, {'bar': 'default'})\n\n        renderer('textinput')\n        renderer('textinput', foo='foo')\n        renderer('textinput', foo='foo', bar='bar')\n\n        assert jinja2_template.render.call_args_list == [\n            mock.call({'bar': 'default'}),\n            mock.call({'foo': 'foo', 'bar': 'default'}),\n            mock.call({'foo': 'foo', 'bar': 'bar'}),\n        ]\n\n    @pytest.fixture\n    def jinja2_env(self, jinja2_template):\n        environment = mock.Mock(spec_set=['get_template'])\n        environment.get_template.return_value = jinja2_template\n        return environment\n\n    @pytest.fixture\n    def jinja2_template(self):\n        return mock.Mock(spec_set=['render'])\n\n\nclass TestCreateEnvironment(object):\n    def test_overlays_base_with_correct_args(self):\n        base = mock.Mock(spec_set=['overlay'])\n\n        form.create_environment(base)\n\n        base.overlay.assert_called_once_with(autoescape=True, loader=mock.ANY)\n\n    def test_loader_has_correct_paths(self):\n        base = mock.Mock(spec_set=['overlay'])\n\n        form.create_environment(base)\n        _, kwargs = base.overlay.call_args\n        loader = kwargs['loader']\n\n        assert 'templates/deform' in loader.searchpath[0]\n        assert 'bootstrap_templates' in loader.searchpath[1]\n\n\nclass TestCreateForm(object):\n    def test_returns_form_object(self, Form, pyramid_request):\n        result = form.create_form(pyramid_request, mock.sentinel.schema)\n\n        assert result == Form.return_value\n\n    def test_passes_args_including_renderer_to_form_ctor(self,\n                                                         Form,\n                                                         matchers,\n                                                         pyramid_request):\n        form.create_form(pyramid_request, mock.sentinel.schema, foo='bar')\n\n        Form.assert_called_once_with(mock.sentinel.schema,\n                                     foo='bar',\n                                     renderer=matchers.instance_of(form.Jinja2Renderer))\n\n    def test_adds_feature_client_to_system_context(self,\n                                                   Form,\n                                                   patch,\n                                                   pyramid_request):\n        Jinja2Renderer = patch('h.form.Jinja2Renderer')\n\n        form.create_form(pyramid_request, mock.sentinel.schema)\n\n        Jinja2Renderer.assert_called_once_with(\n            mock.sentinel.jinja2_env,\n            {'feature': pyramid_request.feature},\n        )\n\n    @pytest.fixture\n    def Form(self, patch):\n        return patch('deform.Form')\n\n    @pytest.fixture\n    def pyramid_request(self, pyramid_request):\n        pyramid_request.registry[form.ENVIRONMENT_KEY] = mock.sentinel.jinja2_env\n        return pyramid_request\n\n\nclass TestToXHRResponse(object):\n    \"\"\"Unit tests for to_xhr_response().\"\"\"\n\n    def test_returns_given_result_if_not_xhr(self, pyramid_request):\n        \"\"\"\n        If ``request`` isn't an XHR request it returns ``non_xhr_result``.\n\n        The calling view callable passes in the result that it would have\n        returned normally if this were not an XHR request as the\n        ``non_xhr_result`` argument. If the given ``request`` is not an XHR\n        request then ``non_xhr_result`` should just be returned unmodified.\n\n        \"\"\"\n        pyramid_request.is_xhr = False\n\n        result = form.to_xhr_response(pyramid_request,\n                                      mock.sentinel.non_xhr_result,\n                                      mock.sentinel.form)\n\n        assert result == mock.sentinel.non_xhr_result\n\n    def test_returns_form_if_xhr(self, pyramid_request):\n        \"\"\"\n        If ``request`` is an XHR request it should return the rendered ``form``.\n\n        It should return ``form`` rendered to a ``<form>`` element HTML snippet.\n\n        \"\"\"\n        pyramid_request.is_xhr = True\n        form_ = mock.Mock(spec_set=['render'])\n\n        result = form.to_xhr_response(pyramid_request,\n                                      mock.sentinel.non_xhr_result,\n                                      form_)\n\n        assert result == form_.render.return_value\n\n    def test_does_not_show_flash_message_if_xhr(self, pyramid_request):\n        pyramid_request.is_xhr = True\n        form_ = mock.Mock(spec_set=['render'])\n\n        form.to_xhr_response(pyramid_request,\n                             mock.sentinel.non_xhr_result,\n                             form_)\n\n        assert pyramid_request.session.peek_flash('success') == []\n\n\n@pytest.mark.usefixtures('to_xhr_response')\nclass TestHandleFormSubmission(object):\n\n    def test_it_calls_validate(self, pyramid_request):\n        form_ = mock.Mock(spec_set=['validate'])\n\n        form.handle_form_submission(pyramid_request,\n                                    form_,\n                                    mock_callable(),\n                                    mock.sentinel.on_failure)\n\n        form_.validate.assert_called_once_with(pyramid_request.POST.items())\n\n    def test_if_validation_fails_it_calls_on_failure(self,\n                                                     pyramid_request,\n                                                     invalid_form):\n        on_failure = mock_callable()\n\n        form.handle_form_submission(pyramid_request,\n                                    invalid_form(),\n                                    mock.sentinel.on_success,\n                                    on_failure)\n\n        on_failure.assert_called_once_with()\n\n    def test_if_validation_fails_it_calls_to_xhr_response(self,\n                                                          invalid_form,\n                                                          pyramid_request,\n                                                          to_xhr_response):\n        on_failure = mock_callable()\n        form_ = invalid_form()\n\n        form.handle_form_submission(pyramid_request,\n                                    form_,\n                                    mock.sentinel.on_success,\n                                    on_failure)\n\n        to_xhr_response.assert_called_once_with(\n            pyramid_request, on_failure.return_value, form_)\n\n    def test_if_validation_fails_it_sets_response_status_to_400(self,\n                                                                invalid_form,\n                                                                pyramid_request,\n                                                                to_xhr_response):\n        form.handle_form_submission(pyramid_request,\n                                    invalid_form(),\n                                    mock.sentinel.on_success,\n                                    mock_callable())\n\n        assert to_xhr_response.call_args[0][0].response.status_int == 400\n\n    def test_if_validation_fails_it_returns_to_xhr_response(self,\n                                                            invalid_form,\n                                                            pyramid_request,\n                                                            to_xhr_response):\n        result = form.handle_form_submission(pyramid_request,\n                                             invalid_form(),\n                                             mock.sentinel.on_success,\n                                             mock_callable())\n\n        assert result == to_xhr_response.return_value\n\n    def test_if_validation_succeeds_it_calls_on_success(self,\n                                                        form_validating_to,\n                                                        pyramid_request):\n        form_ = form_validating_to(mock.sentinel.appstruct)\n        on_success = mock_callable()\n\n        form.handle_form_submission(pyramid_request,\n                                    form_,\n                                    on_success,\n                                    mock.sentinel.on_failure)\n\n        on_success.assert_called_once_with(mock.sentinel.appstruct)\n\n    def test_if_validation_succeeds_it_shows_a_flash_message(self,\n                                                             form_validating_to,\n                                                             pyramid_request):\n        form.handle_form_submission(pyramid_request,\n                                    form_validating_to('anything'),\n                                    mock_callable(),\n                                    mock.sentinel.on_failure)\n\n        assert pyramid_request.session.peek_flash('success')\n\n    def test_if_validation_succeeds_it_calls_to_xhr_response(self,\n                                                             form_validating_to,\n                                                             matchers,\n                                                             pyramid_request,\n                                                             to_xhr_response):\n        form_ = form_validating_to('anything')\n\n        form.handle_form_submission(pyramid_request,\n                                    form_,\n                                    mock_callable(return_value=None),\n                                    mock.sentinel.on_failure)\n\n        to_xhr_response.assert_called_once_with(\n            pyramid_request,\n            matchers.redirect_302_to(pyramid_request.url),\n            form_)\n\n    def test_if_validation_succeeds_it_passes_on_success_result_to_to_xhr_response(\n            self,\n            form_validating_to,\n            matchers,\n            pyramid_request,\n            to_xhr_response):\n        \"\"\"\n        A result from on_success() is passed to to_xhr_response().\n\n        If on_success() returns something other than None, it passes that\n        something to to_xhr_response().\n\n        \"\"\"\n        form_ = form_validating_to('anything')\n\n        form.handle_form_submission(pyramid_request,\n                                    form_,\n                                    mock_callable(\n                                        return_value=mock.sentinel.result),\n                                    mock.sentinel.on_failure)\n\n        to_xhr_response.assert_called_once_with(\n            pyramid_request,\n            mock.sentinel.result,\n            form_)\n\n    def test_if_validation_succeeds_it_returns_to_xhr_response(self,\n                                                               form_validating_to,\n                                                               pyramid_request,\n                                                               to_xhr_response):\n        result = form.handle_form_submission(pyramid_request,\n                                             form_validating_to('anything'),\n                                             mock_callable(),\n                                             mock.sentinel.on_failure)\n\n        assert result == to_xhr_response.return_value\n\n    @pytest.fixture\n    def to_xhr_response(self, patch):\n        return patch('h.form.to_xhr_response')\n\n\ndef mock_callable(**kwargs):\n    \"\"\"\n    Return a mock than can be called but doesn't have any accessible properties.\n\n    The mock can be called like ``my_mock_callable()`` but trying to access any\n    other properties like ``my_mock_callable.foo`` will fail. This is a useful\n    value to use when the method under test requires a callable as an argument.\n\n    \"\"\"\n    return mock.Mock(spec_set=['__call__'], **kwargs)\n"},{"size":2103,"relativepath":"tests/h/session_test.py","filename":"session_test.py","extension":".py","content":"import pytest\nimport mock\n\nfrom h import session\n\n\nclass FakeGroup(object):\n    def __init__(self, pubid, name):\n        self.pubid = pubid\n        self.name = name\n        self.slug = pubid\n\n\n@mock.patch('h.models.User', autospec=True)\ndef test_model_sorts_groups(User):\n    fake_user = mock.Mock()\n    fake_user.groups = [\n        FakeGroup('c', 'Group A'),\n        FakeGroup('b', 'Group B'),\n        FakeGroup('a', 'Group B'),\n    ]\n    request = mock.Mock(authenticated_user=fake_user)\n    session_model = session.model(request)\n\n    ids = [group['id'] for group in session_model['groups']]\n\n    assert ids == ['__world__', 'c', 'a', 'b']\n\n\ndef test_model_includes_features(fake_user):\n    feature_dict = {\n        'feature_one': True,\n        'feature_two': False,\n    }\n    request = mock.Mock(authenticated_user=fake_user)\n    request.feature.all.return_value = feature_dict\n\n    assert session.model(request)['features'] == feature_dict\n\n\n@pytest.mark.parametrize(\n    \"user_authenticated,tutorial_dismissed,show_tutorial\",\n    [(False, False, False),\n     (True,  False, True),\n     (True,  True,  False)])\ndef test_model_show_sidebar_tutorial(\n        fake_user, user_authenticated, tutorial_dismissed, show_tutorial):\n    \"\"\"It should return or not return \"show_sidebar_tutorial\" correctly.\n\n    It should return \"show_sidebar_tutorial\": True only if a user\n    is authorized _and_ that user has not dismissed\n    the tutorial. Otherwise, preferences should contain no\n    \"show_sidebar_tutorial\" value at all.\n\n    \"\"\"\n    fake_user.sidebar_tutorial_dismissed = tutorial_dismissed\n    if user_authenticated:\n        authenticated_user = fake_user\n    else:\n        authenticated_user = None\n    request = mock.Mock(\n        authenticated_user=authenticated_user,\n        )\n\n    preferences = session.model(request)['preferences']\n\n    if show_tutorial:\n        assert preferences['show_sidebar_tutorial'] is True\n    else:\n        assert 'show_sidebar_tutorial' not in preferences\n\n\n@pytest.fixture\ndef fake_user():\n    fake_user = mock.Mock()\n    fake_user.groups = []\n    return fake_user\n"},{"size":1211,"relativepath":"tests/h/groups/schemas_test.py","filename":"schemas_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport pytest\n\nimport colander\n\nfrom h.groups import schemas\n\n\nclass TestUnblacklistedGroupNameSlug(object):\n    @pytest.mark.parametrize('group_name', [\n        'edit',\n        'edIT-',\n        'EDit__',\n        'EDIT-------',\n        'eDiT?',\n        'leave',\n        'leAVE-',\n        'LEAve_',\n        'LEAVE---',\n        'LeAvE???',\n    ])\n    def test_blacklisted(self, dummy_node, group_name):\n        blacklist = set(['edit', 'leave'])\n\n        with pytest.raises(colander.Invalid):\n            schemas.unblacklisted_group_name_slug(dummy_node, group_name, blacklist)\n\n    @pytest.mark.parametrize('group_name', [\n        'Birdwatchers',\n        'My Book Club',\n        'Hello World',\n        'Editors',\n        'Leavers',\n    ])\n    def test_passing(self, dummy_node, group_name):\n        blacklist = set(['edit', 'leave'])\n\n        schemas.unblacklisted_group_name_slug(dummy_node, group_name, blacklist)\n\n    @pytest.fixture\n    def dummy_node(self, pyramid_request):\n        class DummyNode(object):\n            def __init__(self, request):\n                self.bindings = {\n                    'request': request\n                }\n        return DummyNode(pyramid_request)\n"},{"size":5992,"relativepath":"tests/h/groups/services_test.py","filename":"services_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport mock\nimport pytest\n\nfrom h.models import Group\nfrom h.groups.services import GroupsService\nfrom h.groups.services import groups_factory\n\n\nclass TestGroupsService(object):\n    def test_create_returns_group(self, db_session, users):\n        svc = GroupsService(db_session, users.get)\n\n        group = svc.create('Anteater fans', 'cazimir')\n\n        assert isinstance(group, Group)\n\n    def test_create_sets_group_name(self, db_session, users):\n        svc = GroupsService(db_session, users.get)\n\n        group = svc.create('Anteater fans', 'cazimir')\n\n        assert group.name == 'Anteater fans'\n\n    def test_create_sets_group_creator(self, db_session, users):\n        svc = GroupsService(db_session, users.get)\n\n        group = svc.create('Anteater fans', 'cazimir')\n\n        assert group.creator == users['cazimir']\n\n    def test_create_sets_description_when_present(self, db_session, users):\n        svc = GroupsService(db_session, users.get)\n\n        group = svc.create('Anteater fans', 'cazimir', 'all about ant eaters')\n\n        assert group.description == 'all about ant eaters'\n\n    def test_create_skips_setting_description_when_missing(self, db_session, users):\n        svc = GroupsService(db_session, users.get)\n\n        group = svc.create('Anteater fans', 'cazimir')\n\n        assert group.description is None\n\n    def test_create_adds_group_to_session(self, db_session, users):\n        svc = GroupsService(db_session, users.get)\n\n        group = svc.create('Anteater fans', 'cazimir')\n\n        assert group in db_session\n\n    def test_create_sets_group_ids(self, db_session, users):\n        svc = GroupsService(db_session, users.get)\n\n        group = svc.create('Anteater fans', 'cazimir')\n\n        assert group.id\n        assert group.pubid\n\n    def test_create_publishes_join_event(self, db_session, users):\n        publish = mock.Mock(spec_set=[])\n        svc = GroupsService(db_session, users.get, publish=publish)\n\n        group = svc.create('Dishwasher disassemblers', 'theresa')\n\n        publish.assert_called_once_with('group-join', group.pubid, 'theresa')\n\n    def test_member_join_adds_user_to_group(self, db_session, users):\n        svc = GroupsService(db_session, users.get)\n        group = Group(name='Donkey Trust', creator=users['cazimir'])\n\n        svc.member_join(group, 'theresa')\n\n        assert users['theresa'] in group.members\n\n    def test_member_join_is_idempotent(self, db_session, users):\n        svc = GroupsService(db_session, users.get)\n        group = Group(name='Donkey Trust', creator=users['cazimir'])\n\n        svc.member_join(group, 'theresa')\n        svc.member_join(group, 'theresa')\n\n        assert group.members.count(users['theresa']) == 1\n\n    def test_member_join_publishes_join_event(self, db_session, users):\n        publish = mock.Mock(spec_set=[])\n        svc = GroupsService(db_session, users.get, publish=publish)\n        group = Group(name='Donkey Trust', creator=users['cazimir'])\n        group.pubid = 'abc123'\n\n        svc.member_join(group, 'theresa')\n\n        publish.assert_called_once_with('group-join', 'abc123', 'theresa')\n\n    def test_member_leave_removes_user_from_group(self, db_session, users):\n        svc = GroupsService(db_session, users.get)\n        group = Group(name='Theresa and her buddies', creator=users['theresa'])\n        group.members.append(users['cazimir'])\n\n        svc.member_leave(group, 'cazimir')\n\n        assert users['cazimir'] not in group.members\n\n    def test_member_leave_is_idempotent(self, db_session, users):\n        svc = GroupsService(db_session, users.get)\n        group = Group(name='Theresa and her buddies', creator=users['theresa'])\n        group.members.append(users['cazimir'])\n\n        svc.member_leave(group, 'cazimir')\n        svc.member_leave(group, 'cazimir')\n\n        assert users['cazimir'] not in group.members\n\n    def test_member_leave_publishes_leave_event(self, db_session, users):\n        publish = mock.Mock(spec_set=[])\n        svc = GroupsService(db_session, users.get, publish=publish)\n        group = Group(name='Donkey Trust', creator=users['theresa'])\n        group.members.append(users['cazimir'])\n        group.pubid = 'abc123'\n\n        svc.member_leave(group, 'cazimir')\n\n        publish.assert_called_once_with('group-leave', 'abc123', 'cazimir')\n\n\n@pytest.mark.usefixtures('user_service')\nclass TestGroupsFactory(object):\n    def test_returns_groups_service(self, pyramid_request):\n        svc = groups_factory(None, pyramid_request)\n\n        assert isinstance(svc, GroupsService)\n\n    def test_provides_request_db_as_session(self, pyramid_request):\n        svc = groups_factory(None, pyramid_request)\n\n        assert svc.session == pyramid_request.db\n\n    def test_wraps_user_service_as_user_fetcher(self, pyramid_request, user_service):\n        svc = groups_factory(None, pyramid_request)\n\n        svc.user_fetcher('foo')\n\n        user_service.fetch.assert_called_once_with('foo')\n\n    def test_provides_realtime_publisher_as_publish(self, patch, pyramid_request):\n        pyramid_request.realtime = mock.Mock(spec_set=['publish_user'])\n        session = patch('h.groups.services.session')\n        svc = groups_factory(None, pyramid_request)\n\n        svc.publish('group-join', 'abc123', 'theresa')\n\n        session.model.assert_called_once_with(pyramid_request)\n        pyramid_request.realtime.publish_user.assert_called_once_with({\n            'type': 'group-join',\n            'session_model': session.model.return_value,\n            'userid': 'theresa',\n            'group': 'abc123',\n        })\n\n\n@pytest.fixture\ndef user_service(pyramid_config):\n    service = mock.Mock(spec_set=['fetch'])\n    service.fetch.return_value = None\n    pyramid_config.register_service(service, name='user')\n    return service\n\n\n@pytest.fixture\ndef users(factories):\n    return {\n        'cazimir': factories.User(username='cazimir'),\n        'theresa': factories.User(username='theresa'),\n    }\n"},{"size":2517,"relativepath":"tests/h/settings_test.py","filename":"settings_test.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\n\nfrom h import settings\n\n\n@pytest.mark.parametrize('setting,varname,type,environ,expected', (\n    # Should return None when the env var in question isn't set\n    ('foo', 'FOO', None, {}, None),\n\n    # Should return the setting as a string when the env var is set\n    ('foo', 'FOO', None, {'FOO': 'bar'}, {'foo': 'bar'}),\n    ('foo.bar', 'FOO', None, {'FOO': 'baz'}, {'foo.bar': 'baz'}),\n\n    # Should coerce the result using the passed type\n    ('foo', 'FOO', bytes, {'FOO': 'bar'}, {'foo': b'bar'}),\n    ('app_port', 'PORT', int, {'PORT': '123'}, {'app_port': 123}),\n))\ndef test_env_setting(setting, varname, type, environ, expected):\n    func = settings.EnvSetting(setting, varname, type)\n\n    result = func(environ)\n\n    assert result == expected\n\n\ndef test_env_setting_returns_nicer_error_for_type_failure():\n    func = settings.EnvSetting('port', 'PORT', type=int)\n\n    with pytest.raises(settings.SettingError):\n        func({'PORT': 'notanint'})\n\n\n@pytest.mark.parametrize('setting,link,pattern,environ,expected', (\n    # Should return None if any of the required vars aren't set\n    ('database_url', 'db', 'db://{addr}', {}, None),\n    ('database_url', 'db', 'db://{addr}', {'DB_HOST': 'foo'}, None),\n    ('database_url', 'db', 'db://{host}:{port}', {'DB_ADDR': 'foo'}, None),\n\n    # Should return the settings object if all of the parts are available\n    ('database_url', 'db', 'db://{addr}',\n     {'DB_ADDR': 'foo'},\n     {'database_url': 'db://foo'}),\n    ('database_url', 'db', 'db://{host}:{port}',\n     {'DB_HOST': 'foo', 'DB_PORT': '123'},\n     {'database_url': 'db://foo:123'}),\n))\ndef test_docker_setting(setting, link, pattern, environ, expected):\n    func = settings.DockerSetting(setting, link, pattern)\n\n    result = func(environ)\n\n    assert result == expected\n\n\ndef test_database_url():\n    url = 'postgres://postgres:1234/database'\n    expected = 'postgresql+psycopg2://postgres:1234/database'\n\n    assert settings.database_url(url) == expected\n\n\ndef test_mandrill_settings():\n    environ = {\n        'MANDRILL_USERNAME': 'foobar',\n        'MANDRILL_APIKEY': 'wibble',\n    }\n    expected = {\n        'mail.username': 'foobar',\n        'mail.password': 'wibble',\n        'mail.host': 'smtp.mandrillapp.com',\n        'mail.port': 587,\n        'mail.tls': True,\n    }\n\n    assert settings.mandrill_settings(environ) == expected\n\n\ndef test_mandrill_settings_unset():\n    assert settings.mandrill_settings({}) is None\n"},{"size":1024,"relativepath":"tests/functional/test_api.py","filename":"test_api.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\n\n\n@pytest.mark.functional\nclass TestAPI(object):\n    def test_annotation_read(self, app, annotation):\n        \"\"\"Fetch an annotation by ID.\"\"\"\n        res = app.get('/api/annotations/' + annotation.id,\n                      headers={b'accept': b'application/json'})\n        data = res.json\n        assert data['id'] == annotation.id\n\n    def test_annotation_read_jsonld(self, app, annotation):\n        \"\"\"Fetch an annotation by ID in jsonld format.\"\"\"\n        res = app.get('/api/annotations/' + annotation.id + '.jsonld')\n        data = res.json\n        assert data['@context'] == 'http://www.w3.org/ns/anno.jsonld'\n        assert data['id'] == 'http://localhost/a/' + annotation.id\n\n\n@pytest.fixture\ndef annotation(db_session, factories):\n    ann =  factories.Annotation(userid='acct:testuser@localhost',\n                                groupid='__world__',\n                                shared=True)\n    db_session.commit()\n    return ann\n"},{"size":4090,"relativepath":"tests/functional/test_accounts.py","filename":"test_accounts.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\n\n\n@pytest.mark.functional\nclass TestAccountSettings(object):\n    \"\"\"Tests for the /account/settings page.\"\"\"\n\n    def test_submit_email_form_without_xhr_returns_full_html_page(self, app):\n        res = app.get('/account/settings')\n\n        email_form = res.forms['email']\n        email_form['email'] = 'new_email@example.com'\n        email_form['email_confirm'] = 'new_email@example.com'\n        email_form['password'] = 'pass'\n\n        res = email_form.submit().follow()\n\n        assert res.body.startswith('<!DOCTYPE html>')\n\n    def test_submit_email_form_with_xhr_returns_partial_html_snippet(self,\n                                                                     app):\n        res = app.get('/account/settings')\n\n        email_form = res.forms['email']\n        email_form['email'] = 'new_email@example.com'\n        email_form['email_confirm'] = 'new_email@example.com'\n        email_form['password'] = 'pass'\n\n        res = email_form.submit(xhr=True, status=200)\n\n        assert res.body.strip('\\n').startswith('<form')\n\n    def test_submit_email_form_with_xhr_returns_plain_text(self, app):\n        res = app.get('/account/settings')\n\n        email_form = res.forms['email']\n        email_form['email'] = 'new_email@example.com'\n        email_form['email_confirm'] = 'new_email@example.com'\n        email_form['password'] = 'pass'\n\n        res = email_form.submit(xhr=True)\n\n        assert res.content_type == 'text/plain'\n\n    def test_submit_invalid_email_form_with_xhr_returns_400(self, app):\n        res = app.get('/account/settings')\n\n        email_form = res.forms['email']\n        email_form['email'] = 'new_email@example.com'\n        email_form['email_confirm'] = 'WRONG'\n        email_form['password'] = 'pass'\n\n        email_form.submit(xhr=True, status=400)\n\n    def test_submit_password_form_without_xhr_returns_full_html_page(self,\n                                                                     app):\n        res = app.get('/account/settings')\n\n        password_form = res.forms['password']\n        password_form['password'] = 'pass'\n        password_form['new_password'] = 'new_password'\n        password_form['new_password_confirm'] = 'new_password'\n\n        res = password_form.submit().follow()\n\n        assert res.body.startswith('<!DOCTYPE html>')\n\n    def test_submit_password_form_with_xhr_returns_partial_html_snippet(self,\n                                                                        app):\n        res = app.get('/account/settings')\n\n        password_form = res.forms['password']\n        password_form['password'] = 'pass'\n        password_form['new_password'] = 'new_password'\n        password_form['new_password_confirm'] = 'new_password'\n\n        res = password_form.submit(xhr=True)\n\n        assert res.body.strip('\\n').startswith('<form')\n\n    def test_submit_password_form_with_xhr_returns_plain_text(self, app):\n        res = app.get('/account/settings')\n\n        password_form = res.forms['password']\n        password_form['password'] = 'pass'\n        password_form['new_password'] = 'new_password'\n        password_form['new_password_confirm'] = 'new_password'\n\n        res = password_form.submit(xhr=True)\n\n        assert res.content_type == 'text/plain'\n\n    def test_submit_invalid_password_form_with_xhr_returns_400(self, app):\n        res = app.get('/account/settings')\n\n        password_form = res.forms['password']\n        password_form['password'] = 'pass'\n        password_form['new_password'] = 'new_password'\n        password_form['new_password_confirm'] = 'WRONG'\n\n        password_form.submit(xhr=True, status=400)\n\n    @pytest.fixture\n    def user(self, db_session, factories):\n        user = factories.User(authority='localhost', password='pass')\n        db_session.add(user)\n        db_session.commit()\n        return user\n\n    @pytest.fixture\n    def app(self, app, user):\n        res = app.get('/login')\n        res.form['username'] = user.username\n        res.form['password'] = 'pass'\n        res.form.submit()\n        return app\n"},{"size":2196,"relativepath":"tests/functional/test_groups.py","filename":"test_groups.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport pytest\n\n\n@pytest.mark.functional\ndef test_group_page_includes_referrer_tag(app, db_session, factories, user):\n    \"\"\"\n    The group read page should include a referrer tag.\n\n    When a logged-in user who is a member of the group visits the group's page,\n    the page should include a `<meta name=\"referrer\" ...` tag that asks the\n    browser not to send the path part of the page's URL to third-party servers\n    in the Referer header when following links on the page.\n\n    This is because the group's URL is secret - if you have it you can join\n    the group.\n    \"\"\"\n    group = factories.Group(creator=user)\n    db_session.commit()\n\n    res = app.get('/groups/{pubid}/{slug}'.format(pubid=group.pubid,\n                                                  slug=group.slug))\n\n    assert res.html.head.find(\n        'meta', attrs={'name': 'referrer'}, content='origin')\n\n\n@pytest.mark.functional\ndef test_submit_create_group_form_without_xhr_returns_full_html_page(app):\n    res = app.get('/groups/new')\n    group_form = res.forms['deform']\n    group_form['name'] = 'My New Group'\n\n    res = group_form.submit().follow()\n\n    assert res.body.startswith('<!DOCTYPE html>')\n\n\n@pytest.mark.functional\ndef test_submit_create_group_form_with_xhr_returns_partial_html_snippet(app):\n    res = app.get('/groups/new')\n    group_form = res.forms['deform']\n    group_form['name'] = 'My New Group'\n\n    res = group_form.submit(xhr=True)\n\n    assert res.body.strip('\\n').startswith('<form')\n\n\n@pytest.mark.functional\ndef test_submit_create_group_form_with_xhr_returns_plain_text(app):\n    res = app.get('/groups/new')\n    group_form = res.forms['deform']\n    group_form['name'] = 'My New Group'\n\n    res = group_form.submit(xhr=True)\n\n    assert res.content_type == 'text/plain'\n\n\n@pytest.fixture\ndef user(db_session, factories):\n    user = factories.User(authority='localhost', password='pass')\n    db_session.add(user)\n    db_session.commit()\n    return user\n\n\n@pytest.fixture\ndef app(app, user):\n    res = app.get('/login')\n    res.form['username'] = user.username\n    res.form['password'] = 'pass'\n    res.form.submit()\n    return app\n"},{"size":2604,"relativepath":"tests/functional/conftest.py","filename":"conftest.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport contextlib\nimport os\n\n\nimport pytest\nfrom webtest import TestApp\n\n\nTEST_SETTINGS = {\n    'es.host': os.environ.get('ELASTICSEARCH_HOST', 'http://localhost:9200'),\n    'es.index': 'hypothesis-test',\n    'h.app_url': 'http://localhost',\n    'h.db.should_create_all': False,\n    'h.db.should_drop_all': False,\n    'h.search.autoconfig': False,\n    'pyramid.debug_all': True,\n    'sqlalchemy.url': os.environ.get('TEST_DATABASE_URL',\n                                     'postgresql://postgres@localhost/htest')\n}\n\n\n@pytest.fixture\ndef app(pyramid_app, db_engine):\n    _clean_database(db_engine)\n    _clean_elasticsearch(TEST_SETTINGS)\n    return TestApp(pyramid_app)\n\n\n@pytest.yield_fixture(scope='session')\ndef db_engine():\n    from h import db\n    engine = db.make_engine(TEST_SETTINGS)\n    yield engine\n    engine.dispose()\n\n\n@pytest.yield_fixture\ndef db_session(db_engine):\n    \"\"\"Get a standalone database session for preparing database state.\"\"\"\n    from h import db\n    session = db.Session(bind=db_engine)\n    yield session\n    session.close()\n\n\n@pytest.yield_fixture\ndef factories(db_session):\n    from ..common import factories\n    factories.set_session(db_session)\n    yield factories\n    factories.set_session(None)\n\n\n@pytest.fixture(scope='session', autouse=True)\ndef init_db(db_engine):\n    from h import db\n    from h import models  # noqa\n    db.init(db_engine, should_drop=True, should_create=True)\n\n\n@pytest.fixture(scope='session', autouse=True)\ndef init_elasticsearch():\n    from memex.search import configure_index, _get_client\n    client = _get_client(TEST_SETTINGS)\n    _drop_indices(TEST_SETTINGS)\n    configure_index(client)\n\n\n@pytest.fixture(scope='session')\ndef pyramid_app():\n    from h.app import create_app\n    return create_app(None, **TEST_SETTINGS)\n\n\ndef _clean_database(engine):\n    from h import db\n    tables = reversed(db.Base.metadata.sorted_tables)\n    with contextlib.closing(engine.connect()) as conn:\n        tx = conn.begin()\n        tnames = ', '.join('\"' + t.name + '\"' for t in tables)\n        conn.execute('TRUNCATE {};'.format(tnames))\n        tx.commit()\n\n\ndef _clean_elasticsearch(settings):\n    import elasticsearch\n\n    conn = elasticsearch.Elasticsearch([settings['es.host']])\n    conn.delete_by_query(index=settings['es.index'],\n                         body={\"query\": {\"match_all\": {}}})\n\n\ndef _drop_indices(settings):\n    import elasticsearch\n\n    conn = elasticsearch.Elasticsearch([settings['es.host']])\n\n    name = settings['es.index']\n    if conn.indices.exists(index=name):\n        conn.indices.delete(index=name)\n"},{"size":189,"relativepath":"tests/README.md","filename":"README.md","extension":".md","content":"Tests\n=====\n\nThis directory contains tests for the `h` application and associated code. Unit\ntests live in the `h` directory, and functional/integrated tests in the\n`functional` directory.\n"},{"size":2558,"relativepath":"setup.py","filename":"setup.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import print_function\n\nimport os\nimport re\nfrom codecs import open\nfrom setuptools import find_packages\nfrom setuptools import setup\nfrom setuptools.command.test import test as _test\n\n###############################################################################\n\nNAME = 'memex'\nDESC = 'Memex: annotation storage and retrieval'\nAUTHOR = 'Hypothes.is Project & contributors'\nAUTHOR_EMAIL = 'contact@hypothes.is'\nURL = 'https://h.readthedocs.io'\nLICENSE = 'Simplified (2-Clause) BSD License'\nKEYWORDS = ['annotation', 'storage', 'hosting']\nCLASSIFIERS = [\n    'Development Status :: 4 - Beta',\n    'Environment :: Console',\n    'Environment :: Web Environment',\n    'Framework :: Pyramid',\n    'Intended Audience :: Developers',\n    'License :: OSI Approved :: BSD License',\n    'Operating System :: OS Independent',\n    'Programming Language :: Python :: 2.7',\n]\nINSTALL_REQUIRES = [\n    'SQLAlchemy>=1.0.13',\n    'bleach>=1.4.3,<1.5',\n    'elasticsearch>=1.1.0,<2.0.0',\n    'jsonschema>=2.5.1,<2.6',\n    'mistune>=0.7.3,<0.8',\n    'psycopg2>=2.6.1,<2.7',\n    'pyparsing>=2.1.5,<2.2',\n    'pyramid-services==0.4',\n    'pyramid>=1.6,<1.7',\n    'python-dateutil>=2.1',\n    'transaction',\n    'zope.interface==4.2.0',\n]\nEXTRAS_REQUIRE = {}\nENTRY_POINTS = {}\n\nwith open('README.rst', encoding='utf-8') as fp:\n    LONGDESC = fp.read()\n\n###############################################################################\n\nHERE = os.path.abspath(os.path.dirname(__file__))\nVERSION_FILE = os.path.join(HERE, 'src', 'memex', '__init__.py')\n\n\ndef get_version():\n    \"\"\"Extract package __version__\"\"\"\n    with open(VERSION_FILE, encoding='utf-8') as fp:\n        content = fp.read()\n    match = re.search(r'^__version__ = [\\'\"]([^\\'\"]*)[\\'\"]', content, re.M)\n    if match:\n        return match.group(1)\n    raise RuntimeError(\"Could not extract package __version__\")\n\n\nclass test(_test):\n    def run(self):\n        print('please run tox instead')\n\n\nif __name__ == \"__main__\":\n    setup(name=NAME,\n          version=get_version(),\n          description=DESC,\n          long_description=LONGDESC,\n          classifiers=CLASSIFIERS,\n          keywords=KEYWORDS,\n          author=AUTHOR,\n          author_email=AUTHOR_EMAIL,\n          url=URL,\n          license=LICENSE,\n          install_requires=INSTALL_REQUIRES,\n          extras_require=EXTRAS_REQUIRE,\n          entry_points=ENTRY_POINTS,\n          cmdclass={'test': test},\n          packages=find_packages(where='src'),\n          package_dir={'': 'src'},\n          zip_safe=False)\n"},{"size":87,"relativepath":"requirements-dev.in","filename":"requirements-dev.in","extension":".in","content":"-r requirements.txt\n\nflake8\nhoncho\npep257\nprospector[with_pyroma]\npyramid_debugtoolbar\n"},{"size":1708,"relativepath":"docs/embedding.rst","filename":"embedding.rst","extension":".rst","content":"How to add Hypothesis to your website\n#####################################\n\nAdding Hypothesis to any web page can be done by adding a single ``<script>``\ntag to a web page. See our `Guide for publishers`_ for details.\n\n.. _Guide for publishers: https://hypothes.is/for-publishers/\n\nCustomizing Hypothesis\n----------------------\n\nTo customize the application, define a function ``window.hypothesisConfig``\nwhich returns an options object.\n\nThe ``constructor`` property should be used to select an annotation\napplication. Four are provided: ``Annotator.Guest``, ``Annotator.Host``,\n``Annotator.Sidebar`` and ``Annotator.PdfSidebar``.\n\n``Annotator.Guest`` expects to connect to an annotator widget running in a\ndifferent frame. Any number of instances can communicate with a single widget\nin order to provide annotation of many frames.\n\n``Annotator.Host`` is an extended version of ``Annotator.Guest`` that will\ninstantiate an annotator widget by loading the location given by the ``app``\noption in an iframe and appending it to the document.\n\n``Annotator.Sidebar`` is an extended ``Annotator.Host`` that puts the widget\nin a sidebar interface. It loads additional plugins that show a bar of bucket\nindicators, each providing the ability to select a cluster of highlights, and a\ntoolbar that can be used to resize the widget and control other aspects of the\nuser interface.\n\n``Annotator.PdfSidebar`` is a custom version of ``Annotator.Sidebar`` with\ndefaults tailored for use in a PDF.js viewer.\n\nThe following is roughly the default configuration::\n\n    window.hypothesisConfig = function () {\n      return {\n        constructor: Annotator.Sidebar,\n        app: 'https://hypothes.is/app.html'\n      };\n    };\n"},{"size":45,"relativepath":"docs/CHANGES.rst","filename":"CHANGES.rst","extension":".rst","content":"Changelog\n#########\n\n.. include:: ../CHANGES\n"},{"size":5148,"relativepath":"docs/make.bat","filename":"make.bat","extension":".bat","content":"@ECHO OFF\n\nREM Command file for Sphinx documentation\n\nif \"%SPHINXBUILD%\" == \"\" (\n\tset SPHINXBUILD=sphinx-build\n)\nset BUILDDIR=_build\nset ALLSPHINXOPTS=-d %BUILDDIR%/doctrees %SPHINXOPTS% .\nset I18NSPHINXOPTS=%SPHINXOPTS% .\nif NOT \"%PAPER%\" == \"\" (\n\tset ALLSPHINXOPTS=-D latex_paper_size=%PAPER% %ALLSPHINXOPTS%\n\tset I18NSPHINXOPTS=-D latex_paper_size=%PAPER% %I18NSPHINXOPTS%\n)\n\nif \"%1\" == \"\" goto help\n\nif \"%1\" == \"help\" (\n\t:help\n\techo.Please use `make ^<target^>` where ^<target^> is one of\n\techo.  html       to make standalone HTML files\n\techo.  dirhtml    to make HTML files named index.html in directories\n\techo.  singlehtml to make a single large HTML file\n\techo.  pickle     to make pickle files\n\techo.  json       to make JSON files\n\techo.  htmlhelp   to make HTML files and a HTML help project\n\techo.  qthelp     to make HTML files and a qthelp project\n\techo.  devhelp    to make HTML files and a Devhelp project\n\techo.  epub       to make an epub\n\techo.  latex      to make LaTeX files, you can set PAPER=a4 or PAPER=letter\n\techo.  text       to make text files\n\techo.  man        to make manual pages\n\techo.  texinfo    to make Texinfo files\n\techo.  gettext    to make PO message catalogs\n\techo.  changes    to make an overview over all changed/added/deprecated items\n\techo.  linkcheck  to check all external links for integrity\n\techo.  doctest    to run all doctests embedded in the documentation if enabled\n\tgoto end\n)\n\nif \"%1\" == \"clean\" (\n\tfor /d %%i in (%BUILDDIR%\\*) do rmdir /q /s %%i\n\tdel /q /s %BUILDDIR%\\*\n\tgoto end\n)\n\nif \"%1\" == \"html\" (\n\t%SPHINXBUILD% -b html %ALLSPHINXOPTS% %BUILDDIR%/html\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Build finished. The HTML pages are in %BUILDDIR%/html.\n\tgoto end\n)\n\nif \"%1\" == \"dirhtml\" (\n\t%SPHINXBUILD% -b dirhtml %ALLSPHINXOPTS% %BUILDDIR%/dirhtml\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Build finished. The HTML pages are in %BUILDDIR%/dirhtml.\n\tgoto end\n)\n\nif \"%1\" == \"singlehtml\" (\n\t%SPHINXBUILD% -b singlehtml %ALLSPHINXOPTS% %BUILDDIR%/singlehtml\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Build finished. The HTML pages are in %BUILDDIR%/singlehtml.\n\tgoto end\n)\n\nif \"%1\" == \"pickle\" (\n\t%SPHINXBUILD% -b pickle %ALLSPHINXOPTS% %BUILDDIR%/pickle\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Build finished; now you can process the pickle files.\n\tgoto end\n)\n\nif \"%1\" == \"json\" (\n\t%SPHINXBUILD% -b json %ALLSPHINXOPTS% %BUILDDIR%/json\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Build finished; now you can process the JSON files.\n\tgoto end\n)\n\nif \"%1\" == \"htmlhelp\" (\n\t%SPHINXBUILD% -b htmlhelp %ALLSPHINXOPTS% %BUILDDIR%/htmlhelp\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Build finished; now you can run HTML Help Workshop with the ^\n.hhp project file in %BUILDDIR%/htmlhelp.\n\tgoto end\n)\n\nif \"%1\" == \"qthelp\" (\n\t%SPHINXBUILD% -b qthelp %ALLSPHINXOPTS% %BUILDDIR%/qthelp\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Build finished; now you can run \"qcollectiongenerator\" with the ^\n.qhcp project file in %BUILDDIR%/qthelp, like this:\n\techo.^> qcollectiongenerator %BUILDDIR%\\qthelp\\TheHypothesisAnnotationFramework.qhcp\n\techo.To view the help file:\n\techo.^> assistant -collectionFile %BUILDDIR%\\qthelp\\TheHypothesisAnnotationFramework.ghc\n\tgoto end\n)\n\nif \"%1\" == \"devhelp\" (\n\t%SPHINXBUILD% -b devhelp %ALLSPHINXOPTS% %BUILDDIR%/devhelp\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Build finished.\n\tgoto end\n)\n\nif \"%1\" == \"epub\" (\n\t%SPHINXBUILD% -b epub %ALLSPHINXOPTS% %BUILDDIR%/epub\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Build finished. The epub file is in %BUILDDIR%/epub.\n\tgoto end\n)\n\nif \"%1\" == \"latex\" (\n\t%SPHINXBUILD% -b latex %ALLSPHINXOPTS% %BUILDDIR%/latex\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Build finished; the LaTeX files are in %BUILDDIR%/latex.\n\tgoto end\n)\n\nif \"%1\" == \"text\" (\n\t%SPHINXBUILD% -b text %ALLSPHINXOPTS% %BUILDDIR%/text\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Build finished. The text files are in %BUILDDIR%/text.\n\tgoto end\n)\n\nif \"%1\" == \"man\" (\n\t%SPHINXBUILD% -b man %ALLSPHINXOPTS% %BUILDDIR%/man\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Build finished. The manual pages are in %BUILDDIR%/man.\n\tgoto end\n)\n\nif \"%1\" == \"texinfo\" (\n\t%SPHINXBUILD% -b texinfo %ALLSPHINXOPTS% %BUILDDIR%/texinfo\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Build finished. The Texinfo files are in %BUILDDIR%/texinfo.\n\tgoto end\n)\n\nif \"%1\" == \"gettext\" (\n\t%SPHINXBUILD% -b gettext %I18NSPHINXOPTS% %BUILDDIR%/locale\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Build finished. The message catalogs are in %BUILDDIR%/locale.\n\tgoto end\n)\n\nif \"%1\" == \"changes\" (\n\t%SPHINXBUILD% -b changes %ALLSPHINXOPTS% %BUILDDIR%/changes\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.The overview file is in %BUILDDIR%/changes.\n\tgoto end\n)\n\nif \"%1\" == \"linkcheck\" (\n\t%SPHINXBUILD% -b linkcheck %ALLSPHINXOPTS% %BUILDDIR%/linkcheck\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Link check complete; look for any errors in the above output ^\nor in %BUILDDIR%/linkcheck/output.txt.\n\tgoto end\n)\n\nif \"%1\" == \"doctest\" (\n\t%SPHINXBUILD% -b doctest %ALLSPHINXOPTS% %BUILDDIR%/doctest\n\tif errorlevel 1 exit /b 1\n\techo.\n\techo.Testing of doctests in the sources finished, look at the ^\nresults in %BUILDDIR%/doctest/output.txt.\n\tgoto end\n)\n\n:end\n"},{"size":8971,"relativepath":"docs/conf.py","filename":"conf.py","extension":".py","content":"# -*- coding: utf-8 -*-\n# pylint: disable=invalid-name\n#\n# The Hypothesis Annotation Framework documentation build configuration file, created by\n# sphinx-quickstart on Fri Oct 12 19:21:42 2012.\n#\n# This file is execfile()d with the current directory set to its containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys, os\nfrom datetime import datetime\n\nCURRENT_YEAR = datetime.now().year\n\non_rtd = os.environ.get('READTHEDOCS') == 'True'\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#sys.path.insert(0, os.path.abspath('.'))\n\n# -- General configuration -----------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n#needs_sphinx = '1.0'\n\n# Add any Sphinx extension module names here, as strings. They can be extensions\n# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.\nextensions = [\n  'sphinx.ext.autodoc',\n  'sphinx.ext.intersphinx',\n  'sphinx.ext.viewcode',\n  'sphinx.ext.todo',\n]\n\n# Render .. todo:: directives in the output.\ntodo_include_todos = True\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = ['_templates']\n\n# The suffix of source filenames.\nsource_suffix = '.rst'\n\n# The encoding of source files.\n#source_encoding = 'utf-8-sig'\n\n# The master toctree document.\nmaster_doc = 'index'\n\n# General information about the project.\nproject = u'The Hypothesis Annotation Framework'\ncopyright = u'2012-{}, Hypothes.is Project and contributors'.format(CURRENT_YEAR)\n\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = '0.0.2'\n# The full version, including alpha/beta/rc tags.\nrelease = '0.0.2'\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#language = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n#today = ''\n# Else, today_fmt is used as the format for a strftime call.\n#today_fmt = '%B %d, %Y'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\n    '_build',\n    'developing/install/targets.rst',\n    ]\n\n# The reST default role (used for this markup: `text`) to use for all documents.\n#default_role = None\n\n# If true, '()' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#add_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n#show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = 'tango'\n\n# A list of ignored prefixes for module index sorting.\n#modindex_common_prefix = []\n\n# Hypothes.is customizations using extension API\n# see http://sphinx-doc.org/latest/extdev/index.html\ndef setup(app):\n    # Add annotation to docs pages\n    app.add_javascript('https://hypothes.is/embed.js')\n\n# -- Options for HTML output ---------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nif not on_rtd:\n    import sphinx_rtd_theme\n    html_theme = 'sphinx_rtd_theme'\n    html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#html_theme_options = {}\n\n# Add any paths that contain custom themes here, relative to this directory.\n#html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# \"<project> v<release> documentation\".\n#html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n#html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n#html_logo = None\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n#html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\n#html_static_path = ['_static']\nhtml_extra_path = ['_extra']\n\n# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,\n# using the given strftime format.\n#html_last_updated_fmt = '%b %d, %Y'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n#html_use_smartypants = True\n\n# Custom sidebar templates, maps document names to template names.\n#html_sidebars = {}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n#html_additional_pages = {}\n\n# If false, no module index is generated.\n#html_domain_indices = True\n\n# If false, no index is generated.\n#html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\n#html_show_sourcelink = True\n\n# If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.\n#html_show_sphinx = True\n\n# If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\n#html_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n#html_use_opensearch = ''\n\n# This is the file name suffix for HTML files (e.g. \".xhtml\").\n#html_file_suffix = None\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = 'TheHypothesisAnnotationFrameworkdoc'\n\n\n# -- Options for LaTeX output --------------------------------------------------\n\nlatex_elements = {\n# The paper size ('letterpaper' or 'a4paper').\n#'papersize': 'letterpaper',\n\n# The font size ('10pt', '11pt' or '12pt').\n#'pointsize': '10pt',\n\n# Additional stuff for the LaTeX preamble.\n#'preamble': '',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title, author, documentclass [howto/manual]).\nlatex_documents = [\n  ('index', 'TheHypothesisAnnotationFramework.tex', u'The Hypothesis Annotation Framework Documentation',\n   u'Hypothes.is Project and contributors', 'manual'),\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n#latex_logo = None\n\n# For \"manual\" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n#latex_use_parts = False\n\n# If true, show page references after internal links.\n#latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n#latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n#latex_appendices = []\n\n# If false, no module index is generated.\n#latex_domain_indices = True\n\n\n# -- Options for manual page output --------------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    ('index', 'thehypothesisannotationframework', u'The Hypothesis Annotation Framework Documentation',\n     [u'Hypothes.is Project and contributors'], 1)\n]\n\n# If true, show URL addresses after external links.\n#man_show_urls = False\n\n\n# -- Options for Texinfo output ------------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n  ('index', 'TheHypothesisAnnotationFramework', u'The Hypothesis Annotation Framework Documentation',\n   u'Hypothes.is Project and contributors', 'TheHypothesisAnnotationFramework', 'One line description of project.',\n   'Miscellaneous'),\n]\n\n# Documents to append as an appendix to all manuals.\n#texinfo_appendices = []\n\n# If false, no module index is generated.\n#texinfo_domain_indices = True\n\n# How to display URL addresses: 'footnote', 'no', or 'inline'.\n#texinfo_show_urls = 'footnote'\n\n\n# Example configuration for intersphinx: refer to the Python standard library.\nintersphinx_mapping = {'http://docs.python.org/': None}\n"},{"size":1213,"relativepath":"docs/developing/cla.rst","filename":"cla.rst","extension":".rst","content":"Contributor License Agreement\n#############################\n\nBefore submitting significant contributions, we ask that you sign one of\nour Contributor License Agreements. This practice ensures that the\nrights of contributors to their contributions are preserved and\nprotects the ongoing availability of the project and a commitment to\nmake it available for anyone to use with as few restrictions as\npossible.\n\nIf contributing as an individual please sign the CLA for individuals:\n\n- `CLA for individuals, HTML <http://hypothes.is/contribute/individual-cla>`_\n- `CLA for individuals, PDF <https://d242fdlp0qlcia.cloudfront.net/uploads/2015/11/03161955/Hypothes.is-Project-Individual.pdf>`_\n\nIf making contributions on behalf of an employer, please sign the CLA for\nemployees:\n\n- `CLA for employers, HTML <http://hypothes.is/contribute/entity-cla>`_\n- `CLA for employers, PDF <https://d242fdlp0qlcia.cloudfront.net/uploads/2015/11/03161955/Hypothes.is-Project-Entity.pdf>`_\n\nA completed form can either be sent by electronic mail to\nlicense@hypothes.is or via conventional mail at the address below. If\nyou have any questions, please contact us.\n\n::\n\n    Hypothes.is Project\n    2261 Market St #632\n    SF, CA 94114\n"},{"size":3399,"relativepath":"docs/developing/install/client.rst","filename":"client.rst","extension":".rst","content":"Client dev install\n==================\n\nThe code for the Hypothesis client (the sidebar) lives in a `Git repo named\nclient`_. Follow this section to get the client running in a local development\nenvironment.\n\n.. seealso::\n\n   The development version of the Hypothesis client currently requires a\n   development version of the Hypothesis website and API, so you should follow\n   :doc:`website` before following this page.\n\nTo install the Hypothesis client in a local development environment:\n\n1. Clone the ``client`` git repo and ``cd`` into it:\n\n   .. code-block:: bash\n\n      git clone https://github.com/hypothesis/client.git\n      cd client\n\n2. Install the client's JavaScript dependencies:\n\n   .. code-block:: bash\n\n      npm install\n\n3. Run the client's test to make sure everything's working:\n\n   .. code-block:: bash\n\n      make test\n\n4. Link your website development environment to your development client.\n   Run ``npm link`` in the ``client`` directory then ``npm link hypothesis``\n   in the ``h`` directory:\n\n   .. code-block:: bash\n\n      client> npm link\n      client> cd ../h\n      h> npm link hypothesis\n\n   .. tip::\n\n      If you get a *permission denied* error when running ``npm link`` you\n      probably need to tell npm to install packages into a directory in your\n      home directory that you have permission to write to. On linux:\n\n      .. code-block:: bash\n\n         npm config set prefix /home/<YOUR_USERNAME>/npm\n\n      On macOS:\n\n      .. code-block:: bash\n\n         npm config set prefix /Users/<YOUR_USERNAME>/npm\n\n      npm will now install executable files into ``$HOME/npm/bin``, so add that\n      directory to your ``$PATH``.\n\n   Both your website development environment and the live reload server (see\n   below) in your client development environment will now use your\n   development client instead of the built client from npm.\n\n   To unlink your website run ``npm unlink hypothesis`` then ``make clean`` in\n   the ``h`` directory, your website development environment and the live\n   reload server will both go back to using the built client from npm:\n\n   .. code-block:: bash\n\n      h> npm unlink hypothesis\n      h> make clean dev\n\n5. You can now test the client in a web browser by running the live reload\n   server.\n\n   .. note::\n\n      The live reload server uses the\n      *Hypothesis client from your website development environment*,\n      not the client from your client development environment!\n\n      By default your website dev env serves up the built client from npm.\n      Make sure you've linked your website dev env to your client dev env\n      (see above) so that your website serves up the client from your client\n      dev env, then the live reload server will use your dev client as well.\n\n   First run the web service on http://localhost:5000/, the client won't work\n   without this because it sends HTTP requests to http://localhost:5000/ to\n   fetch and to save annotations. In the ``h`` directory run:\n\n   .. code-block:: bash\n\n      h> make dev\n\n   Now in another terminal, in the ``client`` directory, run the live reload\n   server:\n\n   .. code-block:: bash\n\n      client> gulp watch\n\n   Now open http://localhost:3000/ in a browser to see the client running in\n   the live reload server. The live reload server automatically reloads the\n   client whenever you modify any of its styles, templates or scripts.\n\n\n.. include:: targets.rst\n"},{"size":212,"relativepath":"docs/developing/install/targets.rst","filename":"targets.rst","extension":".rst","content":".. _Git repo named h: https://github.com/hypothesis/h/\n.. _Git repo named client: https://github.com/hypothesis/client/\n.. _built copy of the Hypothesis client from npm: https://www.npmjs.com/package/hypothesis/\n"},{"size":991,"relativepath":"docs/developing/install/index.rst","filename":"index.rst","extension":".rst","content":"Hypothesis dev install\n======================\n\nThese sections tell you how to install Hypothesis in a development environment.\n\nHypothesis is built from two main codebases:\n\n1. The code for the https://hypothes.is/ website itself, which lives in a\n   `Git repo named h`_. This includes an HTTP API for fetching and saving\n   annotations.\n\n2. The code for the Hypothesis annotation client (the sidebar), which lives in\n   a `Git repo named client`_. The client sends HTTP requests to the web\n   service to fetch and save annotations.\n\nIf you just want to work on the https://hypothes.is/ website and API then\nyou can just follow the :doc:`website` section, your development site will\nautomatically use a `built copy of the Hypothesis client from npm`_.\n\nIf you want to work on the Hypothesis client code then you need development\ninstalls of both the website/API *and* the client.\nFirst follow :doc:`website` then :doc:`client`.\n\n\n.. toctree::\n\n   website\n   client\n\n.. include:: targets.rst\n"},{"size":9874,"relativepath":"docs/developing/install/website.rst","filename":"website.rst","extension":".rst","content":"Website dev install\n===================\n\nThe code for the https://hypothes.is/ website and API lives in a\n`Git repo named h`_. To get this code running in a local development\nenvironment the first thing you need to do is install h's system dependencies.\n\nFollow either the\n`Installing the system dependencies on Ubuntu 14.04`_ or the\n`Installing the system dependencies on OS X`_ section below, depending on which\noperating system you're using, then move on to `Installing the services`_ and\nthe sections that follow it.\n\n\nInstalling the system dependencies on Ubuntu 14.04\n--------------------------------------------------\n\nThis section describes how to install h's system dependencies on Ubuntu 14.04.\nThese steps will also probably work with few or no changes on other versions\nof Ubuntu, Debian, or other Debian-based GNU/Linux distributions.\n\nInstall the following packages:\n\n.. code-block:: bash\n\n    sudo apt-get install -y --no-install-recommends \\\n        build-essential \\\n        git \\\n        libevent-dev \\\n        libffi-dev \\\n        libfontconfig \\\n        libpq-dev \\\n        python-dev \\\n        python-pip \\\n        python-virtualenv\n\nInstall node by following the\n`instructions on nodejs.org <https://nodejs.org/en/download/package-manager/>`_\n(the version of the nodejs package in the standard Ubuntu repositories is too\nold).\n\nUpgrade pip, virtualenv and npm:\n\n.. code-block:: bash\n\n    sudo pip install -U pip virtualenv\n    sudo npm install -g npm\n\n\nInstalling the system dependencies on OS X\n------------------------------------------\n\nThis section describes how to install h's system dependencies on Mac OS X.\n\nThe instructions that follow assume you have previously installed Homebrew_.\n\n.. _Homebrew: http://brew.sh/\n\nInstall the following packages:\n\n.. code-block:: bash\n\n    brew install \\\n        libevent \\\n        libffi \\\n        node \\\n        python\n\n\nInstalling the services\n-----------------------\n\nh requires the following external services:\n\n- PostgreSQL_ 9.4+\n- Elasticsearch_ v1.0+, with the `Elasticsearch ICU Analysis`_ plugin\n- RabbitMQ_ v3.5+\n\n.. _PostgreSQL: http://www.postgresql.org/\n.. _Elasticsearch: http://www.elasticsearch.org/\n.. _Elasticsearch ICU Analysis: http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/analysis-icu-plugin.html\n.. _RabbitMQ: https://rabbitmq.com/\n\nYou can install these services however you want, but the easiest way is by\nusing Docker. This should work on any operating system that Docker can be\ninstalled on:\n\n1. Install Docker by following the instructions on the\n   `Docker website`_.\n\n2. Download and run the\n   `official RabbitMQ image <https://hub.docker.com/_/rabbitmq/>`_,\n   the `official PostgreSQL image <https://hub.docker.com/_/postgres/>`_, and\n   our custom\n   `Elasticsearch with ICU image <https://hub.docker.com/r/nickstenning/elasticsearch-icu/>`_:\n\n   .. code-block:: bash\n\n      docker run -d --name postgres -p 5432:5432 postgres\n      docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 nickstenning/elasticsearch-icu\n      docker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 --hostname rabbit rabbitmq:3-management\n\n   You'll now have three Docker containers named ``postgres``, ``elasticsearch``,\n   and ``rabbitmq`` running and exposing their various services on the\n   ports defined above. You should be able to see them by running ``docker ps``.\n   You should also be able to visit your Elasticsearch service by opening\n   http://localhost:9200/ in a browser, and connect to your PostgreSQL by\n   running ``psql postgresql://postgres@localhost/postgres`` (if you have psql\n   installed).\n\n   .. note::\n\n      You only need to run the above ``docker run`` commands once. If you need\n      to start the containers again (for example after restarting your\n      computer), you can just run:\n\n      .. code-block:: bash\n\n         docker start postgres elasticsearch rabbitmq\n\n3. Create the `htest` database in the ``postgres`` container. This is needed\n   to run the h tests:\n\n   .. code-block:: bash\n\n      docker run -it --link postgres:postgres --rm postgres sh -c 'exec psql -h \"$POSTGRES_PORT_5432_TCP_ADDR\" -p \"$POSTGRES_PORT_5432_TCP_PORT\" -U postgres -c \"CREATE DATABASE htest;\"'\n\n\n.. tip::\n\n   You can use the PostgreSQL Docker image to open a psql shell to your\n   Dockerized database without having to install psql on your host machine.\n   Do:\n\n   .. code-block:: bash\n\n      docker run -it --link postgres:postgres --rm postgres sh -c 'exec psql -h \"$POSTGRES_PORT_5432_TCP_ADDR\" -p \"$POSTGRES_PORT_5432_TCP_PORT\" -U postgres'\n\n   This runs psql in a fourth Docker container (from the same official\n   PostgreSQL image, which also contains psql) and links it to your named\n   ``postgres`` container using Docker's container linking system.\n   The psql container is automatically removed (``--rm``) when you exit the\n   psql shell.\n\n.. tip::\n\n   Use the ``docker logs`` command to see what's going on inside your\n   Docker containers, for example:\n\n   .. code-block:: bash\n\n      docker logs rabbitmq\n\n   For more on how to use Docker see the `Docker website`_.\n\n\n.. _Docker website: https://www.docker.com/\n\n\nInstalling the gulp command\n---------------------------\n\nInstall ``gulp-cli`` to get the ``gulp`` command:\n\n.. code-block:: bash\n\n    sudo npm install -g gulp-cli\n\n\nGetting the h source code from GitHub\n-------------------------------------\n\nUse ``git`` to download the h source code:\n\n.. code-block:: bash\n\n    git clone https://github.com/hypothesis/h.git\n\nThis will download the code into an ``h`` directory in your current working\ndirectory.\n\nChange into the ``h`` directory from the remainder of the installation\nprocess:\n\n.. code-block:: bash\n\n   cd h\n\n\nCreating a Python virtual environment\n-------------------------------------\n\nCreate a Python virtual environment to install and run the h Python code and\nPython dependencies in:\n\n.. code-block:: bash\n\n   virtualenv .venv\n\n\n.. _activating_your_virtual_environment:\n\nActivating your virtual environment\n-----------------------------------\n\nActivate the virtual environment that you've created:\n\n.. code-block:: bash\n\n   source .venv/bin/activate\n\n.. tip::\n\n   You'll need to re-activate this virtualenv with the\n   ``source .venv/bin/activate`` command each time you open a new terminal,\n   before running h.\n   See the `Virtual Environments`_ section in the Hitchhiker's guide to\n   Python for an introduction to Python virtual environments.\n\n.. _Virtual Environments: http://docs.python-guide.org/en/latest/dev/virtualenvs/\n\n\nRunning h\n---------\n\nStart a development server:\n\n.. code-block:: bash\n\n    make dev\n\nThe first time you run ``make dev`` it might take a while to start because\nit'll need to install the application dependencies and build the client assets.\n\nThis will start the server on port 5000 (http://localhost:5000), reload the\napplication whenever changes are made to the source code, and restart it should\nit crash for some reason.\n\n\n.. _running-the-tests:\n\nRunning h's tests\n-----------------\n\nThere are test suites for both the frontend and backend code. To run the\ncomplete set of tests, run:\n\n.. code-block:: bash\n\n    make test\n\nTo run the frontend test suite only, run the appropriate test task with gulp.\nFor example:\n\n.. code-block:: bash\n\n    gulp test\n\nWhen working on the front-end code, you can run the Karma test runner in\nauto-watch mode which will re-run the tests whenever a change is made to the\nsource code. To start the test runner in auto-watch mode, run:\n\n.. code-block:: bash\n\n    gulp test-watch\n\nTo run only a subset of tests for front-end code, use the ``--grep``\nargument or mocha's `.only()`_ modifier.\n\n.. code-block:: bash\n\n    gulp test-watch --grep <pattern>\n\n.. _.only(): http://jaketrent.com/post/run-single-mocha-test/\n\n\nDebugging h\n-----------\n\nThe `pyramid_debugtoolbar`_ package is loaded by default in the development\nenvironment.  This will provide stack traces for exceptions and allow basic\ndebugging. A more advanced profiler can also be accessed at the /_debug_toolbar\npath.\n\n    http://localhost:5000/_debug_toolbar/\n\nCheck out the `pyramid_debugtoolbar documentation`_ for information on how to\nuse and configure it.\n\n.. _pyramid_debugtoolbar: https://github.com/Pylons/pyramid_debugtoolbar\n.. _pyramid_debugtoolbar documentation: http://docs.pylonsproject.org/projects/pyramid-debugtoolbar/en/latest/\n\nYou can turn on SQL query logging by setting the :envvar:`DEBUG_QUERY`\nenvironment variable (to any value). Set it to the special value ``trace`` to\nturn on result set logging as well.\n\n\nFeature flags\n-------------\n\nFeatures flags allow admins to enable or disable features for certain groups\nof users. You can enable or disable them from the Administration Dashboard.\n\nTo access the Administration Dashboard, you will need to first create a\nuser account in your local instance of H and then give that account\nadmin access rights using H's command-line tools.\n\nSee the :doc:`/developing/administration` documentation for information\non how to give the initial user admin rights and access the Administration\nDashboard.\n\nTroubleshooting\n---------------\n\nCannot connect to the Docker daemon\n```````````````````````````````````\n\nIf you get an error that looks like this when trying to run ``docker``\ncommands::\n\n Cannot connect to the Docker daemon. Is the docker daemon running on this host?\n Error: failed to start containers: postgres\n\nit could be because you don't have permission to access the Unix socket that\nthe docker daemon is bound to. On some operating systems (e.g. Linux) you need\nto either:\n\n* Take additional steps during Docker installation to give your Unix user\n  access to the Docker daemon's port (consult the installation\n  instructions for your operating system on the `Docker website`_), or\n\n* Prefix all ``docker`` commands with ``sudo``.\n\n\n.. include:: targets.rst\n"},{"size":7900,"relativepath":"docs/developing/making-changes-to-model-code.rst","filename":"making-changes-to-model-code.rst","extension":".rst","content":"============================\nMaking changes to model code\n============================\n\n\n---------------------------------\nGuidelines for writing model code\n---------------------------------\n\nNo length limits on database columns\n====================================\n\nDon't put any length limits on your database columns (for example\n``sqlalchemy.Column(sqlalchemy.Unicode(30), ...)``). These can cause painful\ndatabase migrations.\n\nAlways use ``sqlalchemy.UnicodeText()`` with no length limit as the type for\ntext columns in the database (you can also use ``sqlalchemy.Text()`` if you're\nsure the column will never receive non-ASCII characters).\n\nWhen necessary validate the lengths of strings in Python code instead.\nThis can be done using `SQLAlchemy validators <http://docs.sqlalchemy.org/en/rel_1_0/orm/mapped_attributes.html>`_\nin model code.\n\nView callables for HTML forms should also use Colander schemas to validate user\ninput, in addition to any validation done in the model code, because Colander\nsupports returning per-field errors to the user.\n\n\n------------------------------------\nCreating a database migration script\n------------------------------------\n\nIf you've made any changes to the database schema (for example: added or\nremoved a SQLAlchemy ORM class, or added, removed or modified a\n``sqlalchemy.Column`` on an ORM class) then you need to create a database\nmigration script that can be used to upgrade the production database from the\nprevious to your new schema.\n\nWe use `Alembic <https://alembic.readthedocs.io/en/latest/>`_ to create and run\nmigration scripts. See the Alembic docs (and look at existing scripts in\n`h/migrations/versions <https://github.com/hypothesis/h/tree/master/h/migrations/versions>`_)\nfor details, but the basic steps to create a new migration script for h are:\n\n1. Create the revision script by running ``alembic revision``, for example:\n\n   .. code-block:: bash\n\n      alembic -c conf/alembic.ini revision -m \"add the foobar table\"\n\n   This will create a new script in ``h/migrations/versions/``.\n\n2. Edit the generated script, fill in the ``upgrade()`` and ``downgrade()``\n   methods.\n\n   See https://alembic.readthedocs.io/en/latest/ops.html#ops for details.\n\n   .. note::\n\n      Not every migration should have a ``downgrade()`` method. For example if\n      the upgrade removes a max length constraint on a text field, so that\n      values longer than the previous max length can now be entered, then a\n      downgrade that adds the constraint back may not work with data created\n      using the updated schema.\n\n3. Stamp your database.\n\n   Before running any upgrades or downgrades you need to stamp the database\n   with its current revision, so Alembic knows which migration scripts to run:\n\n   .. code-block:: bash\n\n      alembic -c conf/alembic.ini stamp <revision_id>\n\n   ``<revision_id>`` should be the revision corresponding to the version of the\n   code that was present when the current database was created. The will\n   usually be the ``down_revision`` from the migration script that you've just\n   generated.\n\n4. Test your ``upgrade()`` function by upgrading your database to the most\n   recent revision. This will run all migration scripts newer than the revision\n   that your db is currently stamped with, which usually means just your new\n   revision script:\n\n   .. code-block:: bash\n\n      alembic -c conf/alembic.ini upgrade head\n\n   After running this command inspect your database's schema to check that it's\n   as expected, and run h to check that everything is working.\n\n   .. note::\n\n      You should make sure that there's some repesentative data in the relevant\n      columns of the database before testing upgrading and downgrading it.\n      Some migration script crashes will only happen when there's data present.\n\n5. Test your ``downgrade()`` function:\n\n   .. code-block:: bash\n\n      alembic -c conf/alembic.ini downgrade -1\n\n   After running this command inspect your database's schema to check that it's\n   as expected. You can then upgrade it again:\n\n   .. code-block:: bash\n\n      alembic -c conf/alembic.ini upgrade +1\n\nBatch deletes and updates in migration scripts\n==============================================\n\nIt's important that migration scripts don't lock database tables for too long,\nso that when the script is run on the production database concurrent database\ntransactions from web requests aren't held up.\n\nAn SQL ``DELETE`` command acquires a ``FOR UPDATE`` row-level lock on the\nrows that it selects to delete. An ``UPDATE`` acquires a ``FOR UPDATE`` lock on\nthe selected rows *if the update modifies any columns that have a unique index\non them that can be used in a foreign key*. While held this ``FOR UPDATE`` lock\nprevents any concurrent transactions from modifying or deleting the selected\nrows.\n\nSo if your migration script is going to ``DELETE`` or ``UPDATE`` a large number\nof rows at once and committing that transaction is going to take a long time\n(longer than 100ms) then you should instead do multiple ``DELETE``\\s or\n``UPDATE``\\s of smaller numbers of rows, committing each as a separate\ntransaction. This will allow concurrent transactions to be sequenced in-between\nyour migration script's transactions.\n\nFor example, here's some Python code that deletes all the rows that match a\nquery in batches of 25:\n\n.. code-block:: python\n\n   query = <some sqlalchemy query>\n   query = query.limit(25)\n   while True:\n       if query.count() == 0:\n           break\n       for row in query:\n           session.delete(row)\n       session.commit()\n\nSeparate data and schema migrations\n===================================\n\nIt's easier for deployment if you do *data migrations* (code that creates,\nupdates or deletes rows) and *schema migrations* (code that modifies the\ndatabase *schema*, for example adding a new column to a table) in separate\nmigration scripts instead of combining them into one script. If you have a\nsingle migration that needs to modify some data and then make a schema change,\nimplement it as two consecutive migration scripts instead.\n\nDon't import model classes into migration scripts\n=================================================\n\nDon't import model classes, for example\n``from memex.models import Annotation``, in migration scripts.\nInstead copy and paste the ``Annotation`` class into your migration script.\n\nThis is because the script needs the schema of the ``Annotation`` class\nas it was at a particular point in time, which may be different from the\nschema in ``memex.models.Annotation`` when the script is run in the future.\n\nThe script's copy of the class usually only needs to contain the definitions of\nthe primary key column(s) and any other columns that the script uses, and only\nneeds the name and type attributes of these columns. Other attributes of the\ncolumns, columns that the script doesn't use, and methods can usually be left\nout of the script's copy of the model class.\n\nTroubleshooting migration scripts\n=================================\n\n(sqlite3.OperationalError) near \"ALTER\"\n---------------------------------------\n\nSQLite doesn't support ``ALTER TABLE``. To get around this, use\n`Alembic's batch mode <https://alembic.readthedocs.io/en/latest/batch.html>`_.\n\n\nCannot add a NOT NULL column with default value NULL\n----------------------------------------------------\n\nIf you're adding a column to the model with ``nullable=False`` then when the\ndatabase is upgraded it needs to insert values into this column for each of\nthe already existing rows in the table, and it can't just insert ``NULL`` as it\nnormally would. So you need to tell the database what default value to insert\nhere.\n\n``default=`` isn't enough (that's only used when the application is creating\ndata, not when migration scripts are running), you need to add a\n``server_default=`` argument to your ``add_column()`` call.\n\nSee the existing migration scripts for examples.\n"},{"size":566,"relativepath":"docs/developing/administration.rst","filename":"administration.rst","extension":".rst","content":"Accessing the admin interface\n-----------------------------\n\nTo access the admin interface, a user must be logged in and have admin\npermissions. To grant admin permissions to a user, run the following command:\n\n.. code-block:: bash\n\n  hypothesis user admin <username>\n\nFor example, to make the user 'joe' an admin in the development environment:\n\n.. code-block:: bash\n\n  hypothesis --dev user admin joe\n\nWhen this user signs in they can now access the adminstration panel at\n``/admin``. The administration panel has options for managing users and optional\nfeatures.\n"},{"size":2846,"relativepath":"docs/developing/submitting-a-pr.rst","filename":"submitting-a-pr.rst","extension":".rst","content":"Submitting a Pull Request\n#########################\n\nTo submit code or documentation to h you should submit a pull request.\n\nFor trivial changes, such as documentation changes or minor errors,\nPRs may be submitted directly to master. This also applies to changes\nmade through the GitHub editing interface. Authors do not need to\nsign the CLA for these, or follow fork or branch naming guidelines.\n\nFor any non-trivial changes, please create a branch for review. Fork\nthe main repository and create a local branch. Later, when the branch\nis ready for review, push it to a fork and submit a pull request.\n\nDiscussion and review in the pull request is normal and expected. By\nusing a separate branch, it is possible to push new commits to the\npull request branch without mixing new commits from other features or\nmainline development.\n\nSome things to remember when submitting or reviewing a pull request:\n\n- Your pull request should contain one logically separate piece of work, and\n  not any unrelated changes.\n\n- When writing commit messages, please bear the following in mind:\n\n  * http://tbaggery.com/2008/04/19/a-note-about-git-commit-messages.html\n  * https://github.com/blog/831-issues-2-0-the-next-generation\n\n  Please minimize issue gardening by using the GitHub syntax for closing\n  issues with commit messages.\n\n- Name your branch in a way that makes it easier to follow the history back\n  to issues. The recommended template is ``<issue name>-<slug>``.\n\n  For instance, ``43-browser-extensions`` would be a branch to address issue\n  ``#43``, which is to create browser extensions.\n\n- Don't merge on feature branches. Feature branches should merge into upstream\n  branches, but never contain merge commits in the other direction.\n  Consider using ``--rebase`` when pulling if you must keep a long-running\n  branch up to date. It's better to start a new branch and, if applicable, a\n  new pull request when performing this action on branches you have published.\n\n- Code should follow our :doc:`coding standards <code-style>`.\n\n- All pull requests should come with code comments. For Python code these\n  should be in the form of Python `docstrings`_. For AngularJS code please use\n  `ngdoc`_. Other documentation can be put into the ``docs/`` subdirectory, but\n  is not required for acceptance.\n\n- All pull requests should come with unit tests. For the time being, functional\n  and integration tests should be considered optional if the project does not\n  have any harness set up yet.\n\n  For how to run the tests, see :ref:`running-the-tests`.\n\n- Your pull request should add a line to the :doc:`changelog </CHANGES>`\n  briefly describing the change and giving its GitHub pull request number.\n\n.. _docstrings: http://legacy.python.org/dev/peps/pep-0257/\n.. _ngdoc: https://github.com/angular/angular.js/wiki/Writing-AngularJS-Documentation\n"},{"size":2867,"relativepath":"docs/developing/code-style.rst","filename":"code-style.rst","extension":".rst","content":"Code style\n##########\n\nThis section contains some code style guidelines for the different programming\nlanguages used in the project.\n\n\nPython\n------\n\nFollow `PEP 8 <https://www.python.org/dev/peps/pep-0008/>`_, the linting tools\nbelow can find PEP 8 problems for you automatically.\n\nDocstrings\n``````````\n\nAll public modules, functions, classes, and methods should normally have\ndocstrings. See `PEP 257 <https://www.python.org/dev/peps/pep-0257/>`_ for\ngeneral advice on how to write docstrings (although we don't write module\ndocstrings that describe every object exported by the module).\n\nThe ``pep257`` tool (which is run by ``prospector``, see below) can point out\nPEP 257 violations for you.\n\nIt's good to use Sphinx references in docstrings because they can be syntax\nhighlighted and hyperlinked when the docstrings are extracted by Sphinx into\nHTML documentation, and because Sphinx can print warnings for references that\nare no longer correct:\n\n* Use `Sphinx Python cross-references <http://www.sphinx-doc.org/en/stable/domains.html#cross-referencing-python-objects>`_\n  to reference other Python modules, functions etc. from docstrings (there are\n  also Sphinx domains for referencing\n  objects from other programming languages, such as\n  `JavaScript <http://www.sphinx-doc.org/en/stable/domains.html#the-javascript-domain>`_).\n\n* Use `Sphinx info field lists <http://www.sphinx-doc.org/en/stable/domains.html#info-field-lists>`_\n  to document parameters, return values and exceptions that might be raised.\n\n* You can also use `reStructuredText <http://www.sphinx-doc.org/en/stable/rest.html>`_\n  to add markup (bold, code samples, lists, etc) to docstrings.\n\n\nLinting\n```````\n\nWe recommend running `Flake8 <https://pypi.python.org/pypi/flake8>`_\nand `Prospector <https://pypi.python.org/pypi/prospector>`_ over your code to\nfind bugs and style problems, using the configurations provided in this git\nrepo. With our configurations Flake8 is faster and less noisy so is nicer to\nrun more frequently, Prospector is more thorough so it can be run less\nfrequently and may find some problems that Flake8 missed.\n\nAutomated code formatting\n`````````````````````````\n\nYou can use `YAPF <https://github.com/google/yapf>`_ (along with the YAPF\nconfiguration in this git repo) to automatically reformat Python code.\nWe don't strictly adhere to YAPF-generated formatting but it can be a useful\nconvenience.\n\nAdditional reading\n``````````````````\n\n* Although we don't strictly follow all of it, the\n  `Google Python Style Guide <https://google.github.io/styleguide/pyguide.html>`_\n  contains a lot of good advice.\n\n\nFront-end Development\n---------------------\n\nSee the `Hypothesis Front-end Toolkit`_ repository for documentation on code\nstyle and tooling for JavaScript, CSS and HTML.\n\n.. _Hypothesis Front-end Toolkit: https://github.com/hypothesis/frontend-toolkit\n\n"},{"size":3000,"relativepath":"docs/developing/ssl.rst","filename":"ssl.rst","extension":".rst","content":"=================================\nServing h over SSL in development\n=================================\n\nIf you want to annotate a site that's served over HTTPS then you'll need to\nserve h over HTTPS as well, since the browser will refuse to load external\nscripts (eg. H's bookmarklet) via HTTP on a page served via HTTPS.\n\nTo serve your local dev instance of h over HTTPS:\n\n1. Generate a private key and certificate signing request::\n\n    openssl req -newkey rsa:1024 -nodes -keyout .tlskey.pem -out .tlscsr.pem\n\n2. Generate a self-signed certificate::\n\n    openssl x509 -req -in .tlscsr.pem -signkey .tlskey.pem -out .tlscert.pem\n\n3. Run ``hypothesis devserver`` with the ``--https`` option::\n\n    hypothesis devserver --https\n\n4. Since the certificate is self-signed, you will need to instruct your browser to\n   trust it explicitly by visiting https://localhost:5000 and selecting the option\n   to bypass the validation error.\n\n---------------\nTroubleshooting\n---------------\n\nInsecure Response errors in the console\n=======================================\n\nThe sidebar fails to load and you see ``net::ERR_INSECURE_RESPONSE`` errors in\nthe console.  You need to open https://localhost:5000 and tell the browser to allow\naccess to the site even though the certificate isn't known.\n\n\nServer not found, the connection was reset\n==========================================\n\nWhen you're serving h over SSL in development making non-SSL requests to h\nwon't work.\n\nIf you get an error like **Server not found** or **The connection was reset**\nin your browser (it varies from browser to browser), possibly accompanied by a\ngunicorn crash with\n``AttributeError: 'NoneType' object has no attribute 'uri'``, make sure that\nyou're loading https://localhost:5000 in your browser, not ``http://``.\n\n\nWebSocket closed abnormally, code: 1006\n=======================================\n\nIf you see the error message\n**Error: WebSocket closed abnormally, code: 1006** in your browser,\npossibly accompanied by another error message like\n**Firefox can't establish a connection to the server at wss://localhost:5001/ws**,\nthis can be because you need to add a security exception to allow your browser\nto connect to the websocket. Visit https://localhost:5001 in a browser tab and\nadd a security exception then try again.\n\n\n403 response when connecting to WebSocket\n=========================================\n\nIf your browser is getting a 403 response when trying to connect to the\nWebSocket along with error messages like these:\n\n* WebSocket connection to 'wss://localhost:5001/ws' failed: Error during WebSocket handshake: Unexpected response code: 403\n* Check that your H service is configured to allow WebSocket connections from https://127.0.0.1:5000\n* WebSocket closed abnormally, code: 1006\n* WebSocket closed abnormally, code: 1001\n* Firefox can't establish a connection to the server at wss://localhost:5001/ws\n\nmake sure that you're opening https://localhost:5000 in your browser and\n*not* https://127.0.0.1:5000.\n"},{"size":417,"relativepath":"docs/developing/documentation.rst","filename":"documentation.rst","extension":".rst","content":"Writing documentation\n#####################\n\nTo build the documentation issue the ``make dirhtml`` command from the ``docs``\ndirectory:\n\n.. code-block:: bash\n\n   cd docs\n   make dirhtml\n\nWhen the build finishes you can view the documentation by running a static\nweb server in the newly generated ``_build/dirhtml`` directory. For example:\n\n.. code-block:: bash\n\n   cd _build/dirhtml; python -m SimpleHTTPServer; cd -\n"},{"size":344,"relativepath":"docs/developing/index.rst","filename":"index.rst","extension":".rst","content":"Developing Hypothesis\n#####################\n\nThe following sections document how to setup a development environment for h\nand how to contribute code or documentation to the project.\n\n.. toctree::\n   :maxdepth: 1\n\n   cla\n   install/index\n   administration\n   submitting-a-pr\n   code-style\n   documentation\n   ssl\n   making-changes-to-model-code\n"},{"size":156,"relativepath":"docs/developing/chrome-extension.rst","filename":"chrome-extension.rst","extension":".rst","content":":orphan:\n\nThe Hypothesis browser extensions now live in `their own repository`_.\n\n.. _their own repository: https://github.com/hypothesis/browser-extension\n"},{"size":869,"relativepath":"docs/community.rst","filename":"community.rst","extension":".rst","content":"The Hypothesis community\n########################\n\nPlease be courteous and respectful in your communication on IRC\n(`#hypothes.is`_ on `freenode.net`_), the mailing list (`subscribe`_,\n`archive`_), and `GitHub`_. Humor is appreciated, but remember that\nsome nuance may be lost in the medium and plan accordingly.\n\n.. _#hypothes.is: http://webchat.freenode.net/?channels=hypothes.is\n.. _freenode.net: http://freenode.net/\n.. _subscribe: mailto:dev+subscribe@list.hypothes.is\n.. _archive: https://groups.google.com/a/list.hypothes.is/forum/#!forum/dev\n.. _GitHub: http://github.com/hypothesis/h\n\nIf you plan to be an active contributor please join our mailing list\nto coordinate development effort. This coordination helps us avoid\nduplicating efforts and raises the level of collaboration. For small\nfixes, feel free to open a pull request without any prior discussion.\n"},{"size":3505,"relativepath":"docs/arch/adr-001.rst","filename":"adr-001.rst","extension":".rst","content":"ADR 1: PostgreSQL persistence for annotations\n=============================================\n\nContext\n-------\n\nThe annotations stored by the Hypothesis web service are arguably its most\ncritical data. Until now they have been stored in an Elasticsearch index,\nprimarily as a result of historical accident (this is how `annotator-store`_,\nwhich was originally intended as a demonstrator application, stored\nannotations). Alongside, we store \"document metadata\" which describes\nrelationships between different URIs, as scraped from metadata within annotated\npages.\n\nWhile storing annotation data directly in Elasticsearch makes for a very simple\nJSON API (data is passed essentially unaltered by the web application straight\nto Elasticsearch) it has a number of disadvantages, including:\n\n1. The persistence guarantees made by Elasticsearch are weak relative to most\n   databases, and while many `data loss bugs`_ have been fixed, it is not\n   unreasonable to have ongoing concerns about durability of data in\n   Elasticsearch.\n\n2. The lack of database-enforced schema validation means that maintaining data\n   validity becomes an application-layer concern. The fact that Elasticsearch\n   also lacks transactional write capabilities makes certain kinds of validation\n   checks nearly impossible to implement correctly.\n\n3. Serving as both primary persistence store and search index causes tension\n   between the desire to keep data normalised (to simplify the process of\n   ensuring data consistency), and to keep data in a format suitable for\n   efficient search, which usually implies denormalisation.\n\n4. As requirements for search and query change, it is desirable to be able to\n   iterate on the format of the search index. When the search index is also the\n   primary data store, this introduces additional risks which typically deter or\n   at least increase the cost of such iteration.\n\n5. Lastly, making changes to the internal schema of annotation data in\n   Elasticsearch requires the creation of custom in-house data migration tools.\n   In contrast, most relational database systems have established schema and\n   data migration libraries available.\n\n.. _annotator-store: https://github.com/openannotation/annotator-store.\n.. _data loss bugs: https://aphyr.com/posts/317-jepsen-elasticsearch\n\nDecision\n--------\n\nWe will migrate all annotation data, and all associated document metadata, into\na PostgreSQL database, which will serve as the primary data store for such data.\n\nWe will continue to use Elasticsearch as a search index, but the data stored\nwithin will be \"ephemeral\" -- that is, we will always be able to regenerate it\nfrom data stored in PostgreSQL.\n\nThe internal schemas of the data stored in PostgreSQL will be designed to\nsimplify data manipulation while ensuring self-consistency.\n\nWe will build appropriate tools to ensure that the Elasticsearch index is kept\nup-to-date as data in the PostgreSQL database changes.\n\nStatus\n------\n\nAccepted.\n\nConsequences\n------------\n\nThese changes will make it easier and safer to iterate on the internal schemas\nof annotation storage, thanks to improved migration tooling for PostgreSQL and\nthe presence of transactional updates.\n\nThey will also make it easier and safe to iterate on the format of the search\nindex used to search annotations, thanks to the ephemeral nature of the data in\nthe search index.\n\nThe potential future minimal requirements for a program which reuses the code\nwhich serves our \"annotation API\" now include PostgreSQL.\n"},{"size":2132,"relativepath":"docs/arch/index.rst","filename":"index.rst","extension":".rst","content":":orphan:\n\nArchitecture decision records\n=============================\n\nHere you will find documents which describe significant architectural decisions\nmade or proposed when developing the Hypothesis software. We record these in\norder to provide a reference for the history, motivation, and rationale for past\ndecisions.\n\nADRs\n----\n\n.. toctree::\n   :maxdepth: 1\n   :glob:\n\n   adr-*\n\nWhat are ADRs?\n--------------\n\nQuoting from the `blog post which inspired this repository`_, an architecture\ndecision record, or ADR, is:\n\n    ...a short text file in a [specific] format...[which] describes a set of\n    forces and a single decision in response to those forces. Note that the\n    decision is the central piece here, so specific forces may appear in\n    multiple ADRs.\n\nThe standard sections of an ADR are:\n\n    **Title** These documents have names that are short noun phrases. For\n    example, \"ADR 1: Deployment on Ruby on Rails 3.0.10\" or \"ADR 9: LDAP for\n    Multitenant Integration\"\n\n    **Context** This section describes the forces at play, including\n    technological, political, social, and project local. These forces are\n    probably in tension, and should be called out as such. The language in this\n    section is value-neutral. It is simply describing facts.\n\n    **Decision** This section describes our response to these forces. It is\n    stated in full sentences, with active voice. \"We will ...\"\n\n    **Status** A decision may be \"proposed\" if the project stakeholders haven't\n    agreed with it yet, or \"accepted\" once it is agreed. If a later ADR changes\n    or reverses a decision, it may be marked as \"deprecated\" or \"superseded\"\n    with a reference to its replacement.\n\n    **Consequences** This section describes the resulting context, after\n    applying the decision. All consequences should be listed here, not just the\n    \"positive\" ones. A particular decision may have positive, negative, and\n    neutral consequences, but all of them affect the team and project in the\n    future.\n\n.. _blog post which inspired this repository: http://thinkrelevance.com/blog/2011/11/15/documenting-architecture-decisions\n"},{"size":3705,"relativepath":"docs/arch/adr-002.rst","filename":"adr-002.rst","extension":".rst","content":"ADR 2: Service layer for testable business logic\n================================================\n\nContext\n-------\n\nAs we are currently using it, Pyramid is a model-view-template (MVT) web\napplication framework. Models describe domain objects and manage their\npersistence, views handle HTTP requests, and templates define the user\ninterface.\n\n\"Business logic\" is a shorthand for the heart of what the application actually\ndoes. It is the code that manages the interactions of our domain objects, rather\nthan code that handles generic concerns such as HTTP request handling or SQL\ngeneration.\n\nIt is not always clear where to put \"business logic\" in an MVT application:\n\n- Some logic can live with its associated domain object(s) in the models layer,\n  but this quickly gets complicated when dealing with multiple models from\n  different parts of the system. It is easy to create circular import\n  dependencies.\n\n- Putting logic in the views typically makes them extremely hard to test, as\n  this makes a single component responsible for receiving and validating data\n  from the client, performing business logic operations, and preparing response\n  data.\n\nThere are other problems associated with encapsulating business logic in views.\nBusiness logic typically interacts directly with the model layer. This means\nthat either a) all view tests (including those which don't test business logic)\nneed a database, or b) we stub out the models layer for some or all view tests.\nStubbing out the database layer in a way that doesn't couple tests to the view\nimplementation is exceedingly difficult, in part due to the large interface of\nSQLAlchemy.\n\nOne way to resolve this problem is to introduce a \"services layer\" between views\nand the rest of the application, which is intended to encapsulate the bulk of\napplication business logic and hide persistence concerns from the views.\n\n[This blog post][1] by [Nando Farestan][2] may help provide additional\nbackground on the motivation for a \"services layer.\"\n\n[1]: http://nando.oui.com.br/2014/04/01/large_apps_with_sqlalchemy__architecture.html\n[2]: http://nando.oui.com.br/index.html\n\nDecision\n--------\n\nWe will employ a \"services layer\" to encapsulate business logic that satifies\none or both of the following conditions:\n\n1. The logic is of \"non-trivial\" complexity. This is clearly open to\n   interpretation. As a rule of thumb: if you have to ask yourself the question\n   \"is this trivial\" then it is probably not.\n\n2. The business logic handles more than one type of domain objects.\n\nThe services layer will be tested independently of views, and used from both\nviews and other parts of the application which have access to a request object.\n\nServices will take the form of instances with some defined interface which are\nassociated with a request and can be retrieved from the request object.\n\nStatus\n------\n\nAccepted.\n\nConsequences\n------------\n\nWe hope that adding a services layer will substantially simplify the process of\nwriting and, in particular, testing view code.\n\nViews tests will likely be able to run faster, as they can be unit tested\nagainst a stubbed service, rather than having to hit the database.\n\nWe will no longer need to stub or mock SQLAlchemy interfaces for testing, thus\nreducing the extent to which tests are coupled to the implementation of the\nsystem under test.\n\nTo achieve these things we are introducing additional concepts (\"service\",\n\"service factory\") the purpose of which may not be immediately apparent,\nespecially to programmers new to the codebase.\n\nThere will likely be non-service-based views code in the codebase for some time,\nthus we are potentially introducing inconsistency between different parts of the\ncode.\n"},{"size":9502,"relativepath":"docs/_extra/api/hypothesis.yaml","filename":"hypothesis.yaml","extension":".yaml","content":"swagger: \"2.0\"\ninfo:\n  version: 1.0.0\n  title: Hypothesis\n  description: |\n    # Hypothesis API documentation\n\n    This document details the Hypothesis public HTTP API. It is targeted at\n    developers interested in integrating functionality from Hypothesis into\n    their own applications.\n\n    ## Authorization\n\n    ### API tokens\n    Some of the API URLs documented below require a valid API token.\n    To use these API URLs you should:\n\n    1. Generate yourself an API token on your [Hypothesis developer\n       page](https://hypothes.is/account/developer) (you must be logged in to\n       Hypothesis to get to this page).\n    2. Put the API token in the `Authorization` header in your request.\n\n    *Example request:*\n\n        GET /api\n        Host: hypothes.is\n        Accept: application/json\n        Authorization: Bearer 6879-31d62c13b0099456de5379de90f90395\n\n    (Replace `6879-31d62c13b0099456de5379de90f90395` with your own API token.)\n\n    ### Client credentials direct authorization\n    The user creation API is intended for use by \"third-party accounts\" clients.\n    These endpoints are authenticated by HTTP Basic Auth using your client ID as\n    the username and your client secret as the password.\n\n    For example, with client details as follows\n\n        Client ID: 96653f8e-80be-11e6-b32b-c7bcde86613a\n        Client Secret: E-hReVMuRyZbyr1GikieEw4JslaM6sDpb18_9V59PFw\n\n    you can compute the Authorization header [as described in\n    RFC7617](https://tools.ietf.org/html/rfc7617):\n\n        $ echo -n '96653f8e-80be-11e6-b32b-c7bcde86613a:E-hReVMuRyZbyr1GikieEw4JslaM6sDpb18_9V59PFw' | base64\n        OTY2NTNmOGUtODBiZS0xMWU2LWIzMmItYzdiY2RlODY2MTNhOkUtaFJlVk11UnlaYnlyMUdpa2llRXc0SnNsYU02c0RwYjE4XzlWNTlQRnc=\n\n    *Example request:*\n\n        POST /users\n        Host: hypothes.is\n        Accept: application/json\n        Content-Type: application/json\n        Authorization: Basic OTY2NTNmOGUtODBiZS0xMWU2LWIzMmItYzdiY2RlODY2MTNhOkUtaFJlVk11UnlaYnlyMUdpa2llRXc0SnNsYU02c0RwYjE4XzlWNTlQRnc=\n\n        {\n          \"authority\": \"example.com\",\n          \"username\": \"jbloggs1\",\n          \"email\": \"jbloggs1@example.com\"\n        }\n\n  termsOfService: https://hypothes.is/terms-of-service\n  license:\n    name: BSD (2-Clause)\n    url: https://github.com/hypothesis/h/blob/master/LICENSE\nhost: hypothes.is\nbasePath: /api\nschemes:\n  - https\nconsumes:\n  - application/json\nproduces:\n  - application/json\nsecurityDefinitions:\n  developerAPIKey:\n    type: apiKey\n    description: Authorize with a developer API key.\n    name: Authorization\n    in: header\n  authClientCredentials:\n    type: basic\n    description: Authorize using OAuth client credentials with HTTP Basic Auth.\nsecurity:\n  - developerAPIKey: []\npaths:\n  /:\n    get:\n      summary: Service root\n      description: Provides a list of links to resources offered by the API.\n      operationId: root\n      responses:\n        '200':\n          description: Success\n      security: []\n  /annotations:\n    post:\n      summary: Create a new annotation\n      operationId: createAnnotation\n      parameters:\n        - name: annotation\n          in: body\n          description: Annotation to be created\n          required: true\n          schema:\n            $ref: '#/definitions/NewAnnotation'\n      responses:\n        '200':\n          description: Annotation successfully created\n          schema:\n            $ref: '#/definitions/Annotation'\n        '400':\n          description: Could not create annotation from your request\n          schema:\n            $ref: '#/definitions/Error'\n  /annotations/{id}:\n    get:\n      summary: Fetch an annotation\n      operationId: fetchAnnotation\n      parameters:\n        - name: id\n          in: path\n          description: ID of annotation to return\n          required: true\n          type: string\n      responses:\n        '200':\n          description: Success\n          schema:\n            $ref: '#/definitions/Annotation'\n        '404':\n          description: Annotation not found or no permission to view\n          schema:\n            $ref: '#/definitions/Error'\n    put:\n      summary: Update an annotation\n      operationId: updateAnnotation\n      parameters:\n        - name: id\n          in: path\n          description: ID of annotation to return\n          required: true\n          type: string\n        - name: annotation\n          in: body\n          description: Updated annotation body\n          required: true\n          schema:\n            $ref: '#/definitions/NewAnnotation'\n      responses:\n        '200':\n          description: Success\n          schema:\n            $ref: '#/definitions/Annotation'\n        '400':\n          description: Could not create annotation from your request\n          schema:\n            $ref: '#/definitions/Error'\n        '404':\n          description: Annotation not found or no permission to update\n          schema:\n            $ref: '#/definitions/Error'\n    delete:\n      summary: Delete an annotation\n      operationId: deleteAnnotation\n      parameters:\n        - name: id\n          in: path\n          description: ID of annotation to return\n          required: true\n          type: string\n      responses:\n        '200':\n          description: Success\n          schema:\n            type: object\n            required:\n              - deleted\n              - id\n            properties:\n              deleted:\n                type: boolean\n                enum:\n                  - true\n              id:\n                type: string\n        '404':\n          description: Annotation not found or no permission to delete\n          schema:\n            $ref: '#/definitions/Error'\n  /search:\n    get:\n      summary: Search for annotations\n      operationId: search\n      parameters:\n        - name: limit\n          in: query\n          description: The maximum number of annotations to return.\n          required: false\n          type: integer\n          minimum: 0\n          maximum: 200\n          default: 20\n        - name: offset\n          in: query\n          description: >\n            The minimum number of initial annotations to skip. This is\n            used for pagination.\n          required: false\n          type: integer\n          default: 0\n          minimum: 0\n        - name: sort\n          in: query\n          description: The field by which annotations should be sorted.\n          required: false\n          type: string\n          default: updated\n        - name: order\n          in: query\n          description: The order in which the results should be sorted.\n          required: false\n          type: string\n          enum: [asc, desc]\n          default: desc\n        - name: uri\n          in: query\n          description: |\n            Limit the results to annotations matching the specific URI or equivalent URIs.\n\n            URI can be a URL (a web page address) or a URN representing another kind of resource such as DOI (Digital Object Identifier) or a PDF fingerprint.\n          required: false\n          type: string\n        - name: user\n          in: query\n          description: Limit the results to annotations made by the specified user.\n          required: false\n          type: string\n        - name: group\n          in: query\n          description: Limit the results to annotations made in the specified group.\n          required: false\n          type: string\n        - name: tag\n          in: query\n          description: Limit the results to annotations tagged with the specified value.\n          required: false\n          type: string\n        - name: any\n          in: query\n          description: |\n            Limit the results to annotations in which one of a number of common fields contain the passed value.\n          required: false\n          type: string\n      responses:\n        '200':\n          description: Search results\n          schema:\n            $ref: '#/definitions/SearchResults'\n  /users:\n    post:\n      summary: Create a new user\n      description: |\n        Only for specific auth clients, this API call allows clients with a\n        designated authority to create users within their authority.\n      operationId: createUser\n      parameters:\n        - name: user\n          in: body\n          description: User to be created\n          required: true\n          schema:\n            $ref: '#/definitions/NewUser'\n      responses:\n        '200':\n          description: User successfully created\n          schema:\n            $ref: '#/definitions/User'\n        '400':\n          description: Could not create user from your request\n          schema:\n            $ref: '#/definitions/Error'\n      security:\n        - authClientCredentials: []\ndefinitions:\n  NewAnnotation:\n    $ref: './schemas/annotation-schema.json'\n  Annotation:\n    allOf:\n      - $ref: '#/definitions/NewAnnotation'\n      - required:\n        - id\n        properties:\n          id:\n            type: string\n  Error:\n    type: object\n    required:\n      - status\n    properties:\n      status:\n        type: string\n        enum:\n          - failure\n      reason:\n        type: string\n        description: A human-readable description of the reason(s) for failure.\n  SearchResults:\n    type: object\n    required:\n      - rows\n      - total\n    properties:\n      rows:\n        type: array\n        items:\n          $ref: '#/definitions/Annotation'\n      total:\n        description: Total number of results matching query.\n        type: integer\n  NewUser:\n    $ref: './schemas/new-user-schema.json'\n  User:\n    $ref: './schemas/user-schema.json'\n"},{"size":304,"relativepath":"docs/_extra/api/schemas/user-schema.json","filename":"user-schema.json","extension":".json","content":"{\n  \"$schema\": \"http://json-schema.org/draft-04/schema#\",\n  \"allOf\": [\n    {\"$ref\": \"./new-user-schema.json\"},\n    {\n      \"type\": \"object\",\n      \"properties\": {\n        \"userid\": {\n          \"type\": \"string\",\n          \"pattern\": \"^acct:.+$\"\n        }\n      },\n      \"required\": [\"userid\"]\n    }\n  ]\n}\n"},{"size":444,"relativepath":"docs/_extra/api/schemas/new-user-schema.json","filename":"new-user-schema.json","extension":".json","content":"{\n  \"$schema\": \"http://json-schema.org/draft-04/schema#\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"authority\": {\n      \"type\": \"string\",\n      \"format\": \"hostname\"\n    },\n    \"username\": {\n      \"type\": \"string\",\n      \"minLength\": 3,\n      \"maxLength\": 30,\n      \"pattern\": \"^[A-Za-z0-9._]+$\"\n    },\n    \"email\": {\n      \"type\": \"string\",\n      \"format\": \"email\"\n    }\n  },\n  \"required\": [\n    \"authority\",\n    \"username\",\n    \"email\"\n  ]\n}\n"},{"size":1035,"relativepath":"docs/_extra/api/schemas/annotation-schema.json","filename":"annotation-schema.json","extension":".json","content":"{\n  \"$schema\": \"http://json-schema.org/draft-04/schema#\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"group\": {\n      \"type\": \"string\"\n    },\n    \"permissions\": {\n      \"title\": \"Permissions\",\n      \"description\": \"Annotation action access control list\",\n      \"type\": \"object\",\n      \"patternProperties\": {\n        \"^(admin|delete|read|update)$\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"string\",\n            \"pattern\": \"^(acct:|group:).+$\"\n          }\n        }\n      },\n      \"required\": [\n        \"read\"\n      ]\n    },\n    \"references\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      }\n    },\n    \"tags\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      }\n    },\n    \"target\": {\n      \"type\": \"array\",\n      \"items\": [\n        {\n          \"type\": \"object\",\n          \"properties\": {\n            \"selector\": {\n            }\n          }\n        }\n      ]\n    },\n    \"text\": {\n      \"type\": \"string\"\n    },\n    \"uri\": {\n      \"type\": \"string\"\n    }\n  }\n}\n"},{"size":326,"relativepath":"docs/_extra/api/index.html","filename":"index.html","extension":".html","content":"<!DOCTYPE html>\n<html>\n  <head>\n    <title>Hypothesis API documentation</title>\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  </head>\n  <body>\n    <redoc spec-url=\"hypothesis.yaml\"></redoc>\n    <script src=\"https://rebilly.github.io/ReDoc/releases/v1.x.x/redoc.min.js\"></script>\n  </body>\n</html>\n"},{"size":5668,"relativepath":"docs/Makefile","filename":"Makefile","extension":"","content":"# Makefile for Sphinx documentation\n#\n\n# You can set these variables from the command line.\nSPHINXOPTS    =\nSPHINXBUILD   = sphinx-build\nPAPER         =\nBUILDDIR      = _build\n\n# Internal variables.\nPAPEROPT_a4     = -D latex_paper_size=a4\nPAPEROPT_letter = -D latex_paper_size=letter\nALLSPHINXOPTS   = -d $(BUILDDIR)/doctrees $(PAPEROPT_$(PAPER)) $(SPHINXOPTS) .\n# the i18n builder cannot share the environment and doctrees with the others\nI18NSPHINXOPTS  = $(PAPEROPT_$(PAPER)) $(SPHINXOPTS) .\n\n.PHONY: help clean html dirhtml singlehtml pickle json htmlhelp qthelp devhelp epub latex latexpdf text man changes linkcheck doctest gettext\n\nhelp:\n\t@echo \"Please use \\`make <target>' where <target> is one of\"\n\t@echo \"  html       to make standalone HTML files\"\n\t@echo \"  dirhtml    to make HTML files named index.html in directories\"\n\t@echo \"  singlehtml to make a single large HTML file\"\n\t@echo \"  pickle     to make pickle files\"\n\t@echo \"  json       to make JSON files\"\n\t@echo \"  htmlhelp   to make HTML files and a HTML help project\"\n\t@echo \"  qthelp     to make HTML files and a qthelp project\"\n\t@echo \"  devhelp    to make HTML files and a Devhelp project\"\n\t@echo \"  epub       to make an epub\"\n\t@echo \"  latex      to make LaTeX files, you can set PAPER=a4 or PAPER=letter\"\n\t@echo \"  latexpdf   to make LaTeX files and run them through pdflatex\"\n\t@echo \"  text       to make text files\"\n\t@echo \"  man        to make manual pages\"\n\t@echo \"  texinfo    to make Texinfo files\"\n\t@echo \"  info       to make Texinfo files and run them through makeinfo\"\n\t@echo \"  gettext    to make PO message catalogs\"\n\t@echo \"  changes    to make an overview of all changed/added/deprecated items\"\n\t@echo \"  linkcheck  to check all external links for integrity\"\n\t@echo \"  doctest    to run all doctests embedded in the documentation (if enabled)\"\n\nclean:\n\t-rm -rf $(BUILDDIR)/*\n\nhtml:\n\t$(SPHINXBUILD) -b html $(ALLSPHINXOPTS) $(BUILDDIR)/html\n\t@echo\n\t@echo \"Build finished. The HTML pages are in $(BUILDDIR)/html.\"\n\ndirhtml:\n\t$(SPHINXBUILD) -b dirhtml $(ALLSPHINXOPTS) $(BUILDDIR)/dirhtml\n\t@echo\n\t@echo \"Build finished. The HTML pages are in $(BUILDDIR)/dirhtml.\"\n\nsinglehtml:\n\t$(SPHINXBUILD) -b singlehtml $(ALLSPHINXOPTS) $(BUILDDIR)/singlehtml\n\t@echo\n\t@echo \"Build finished. The HTML page is in $(BUILDDIR)/singlehtml.\"\n\npickle:\n\t$(SPHINXBUILD) -b pickle $(ALLSPHINXOPTS) $(BUILDDIR)/pickle\n\t@echo\n\t@echo \"Build finished; now you can process the pickle files.\"\n\njson:\n\t$(SPHINXBUILD) -b json $(ALLSPHINXOPTS) $(BUILDDIR)/json\n\t@echo\n\t@echo \"Build finished; now you can process the JSON files.\"\n\nhtmlhelp:\n\t$(SPHINXBUILD) -b htmlhelp $(ALLSPHINXOPTS) $(BUILDDIR)/htmlhelp\n\t@echo\n\t@echo \"Build finished; now you can run HTML Help Workshop with the\" \\\n\t      \".hhp project file in $(BUILDDIR)/htmlhelp.\"\n\nqthelp:\n\t$(SPHINXBUILD) -b qthelp $(ALLSPHINXOPTS) $(BUILDDIR)/qthelp\n\t@echo\n\t@echo \"Build finished; now you can run \"qcollectiongenerator\" with the\" \\\n\t      \".qhcp project file in $(BUILDDIR)/qthelp, like this:\"\n\t@echo \"# qcollectiongenerator $(BUILDDIR)/qthelp/TheHypothesisAnnotationFramework.qhcp\"\n\t@echo \"To view the help file:\"\n\t@echo \"# assistant -collectionFile $(BUILDDIR)/qthelp/TheHypothesisAnnotationFramework.qhc\"\n\ndevhelp:\n\t$(SPHINXBUILD) -b devhelp $(ALLSPHINXOPTS) $(BUILDDIR)/devhelp\n\t@echo\n\t@echo \"Build finished.\"\n\t@echo \"To view the help file:\"\n\t@echo \"# mkdir -p $$HOME/.local/share/devhelp/TheHypothesisAnnotationFramework\"\n\t@echo \"# ln -s $(BUILDDIR)/devhelp $$HOME/.local/share/devhelp/TheHypothesisAnnotationFramework\"\n\t@echo \"# devhelp\"\n\nepub:\n\t$(SPHINXBUILD) -b epub $(ALLSPHINXOPTS) $(BUILDDIR)/epub\n\t@echo\n\t@echo \"Build finished. The epub file is in $(BUILDDIR)/epub.\"\n\nlatex:\n\t$(SPHINXBUILD) -b latex $(ALLSPHINXOPTS) $(BUILDDIR)/latex\n\t@echo\n\t@echo \"Build finished; the LaTeX files are in $(BUILDDIR)/latex.\"\n\t@echo \"Run \\`make' in that directory to run these through (pdf)latex\" \\\n\t      \"(use \\`make latexpdf' here to do that automatically).\"\n\nlatexpdf:\n\t$(SPHINXBUILD) -b latex $(ALLSPHINXOPTS) $(BUILDDIR)/latex\n\t@echo \"Running LaTeX files through pdflatex...\"\n\t$(MAKE) -C $(BUILDDIR)/latex all-pdf\n\t@echo \"pdflatex finished; the PDF files are in $(BUILDDIR)/latex.\"\n\ntext:\n\t$(SPHINXBUILD) -b text $(ALLSPHINXOPTS) $(BUILDDIR)/text\n\t@echo\n\t@echo \"Build finished. The text files are in $(BUILDDIR)/text.\"\n\nman:\n\t$(SPHINXBUILD) -b man $(ALLSPHINXOPTS) $(BUILDDIR)/man\n\t@echo\n\t@echo \"Build finished. The manual pages are in $(BUILDDIR)/man.\"\n\ntexinfo:\n\t$(SPHINXBUILD) -b texinfo $(ALLSPHINXOPTS) $(BUILDDIR)/texinfo\n\t@echo\n\t@echo \"Build finished. The Texinfo files are in $(BUILDDIR)/texinfo.\"\n\t@echo \"Run \\`make' in that directory to run these through makeinfo\" \\\n\t      \"(use \\`make info' here to do that automatically).\"\n\ninfo:\n\t$(SPHINXBUILD) -b texinfo $(ALLSPHINXOPTS) $(BUILDDIR)/texinfo\n\t@echo \"Running Texinfo files through makeinfo...\"\n\tmake -C $(BUILDDIR)/texinfo info\n\t@echo \"makeinfo finished; the Info files are in $(BUILDDIR)/texinfo.\"\n\ngettext:\n\t$(SPHINXBUILD) -b gettext $(I18NSPHINXOPTS) $(BUILDDIR)/locale\n\t@echo\n\t@echo \"Build finished. The message catalogs are in $(BUILDDIR)/locale.\"\n\nchanges:\n\t$(SPHINXBUILD) -b changes $(ALLSPHINXOPTS) $(BUILDDIR)/changes\n\t@echo\n\t@echo \"The overview file is in $(BUILDDIR)/changes.\"\n\nlinkcheck:\n\t$(SPHINXBUILD) -b linkcheck $(ALLSPHINXOPTS) $(BUILDDIR)/linkcheck\n\t@echo\n\t@echo \"Link check complete; look for any errors in the above output \" \\\n\t      \"or in $(BUILDDIR)/linkcheck/output.txt.\"\n\ndoctest:\n\t$(SPHINXBUILD) -b doctest $(ALLSPHINXOPTS) $(BUILDDIR)/doctest\n\t@echo \"Testing of doctests in the sources finished, look at the \" \\\n\t      \"results in $(BUILDDIR)/doctest/output.txt.\"\n"},{"size":438,"relativepath":"docs/index.rst","filename":"index.rst","extension":".rst","content":"Hypothesis\n==========\n\nHypothesis is a tool for annotating the web. This documentation is for:\n\n* Publishers embedding Hypothesis in their web pages.\n* Developers working with data stored in the Hypothesis service.\n* Contributors to the Hypothesis service and client.\n\nContents\n--------\n\n.. toctree::\n   :maxdepth: 1\n\n   community\n   embedding\n   The Hypothesis API <http://h.readthedocs.io/en/latest/api/>\n   developing/index\n   CHANGES\n"},{"size":130,"relativepath":"MANIFEST.in","filename":"MANIFEST.in","extension":".in","content":"include AUTHORS CHANGES CODE_OF_CONDUCT LICENSE NOTICE\ninclude *.rst\ngraft src\nglobal-exclude __pycache__\nglobal-exclude *.py[co]\n"},{"size":1942,"relativepath":"CONTRIBUTING.rst","filename":"CONTRIBUTING.rst","extension":".rst","content":"Contributing to Hypothesis\n==========================\n\nThank you for your interest! We love contributions from other people, so please\nfeel free to fix bugs, make improvements, update documentation, or do anything\nelse that you think will help.\n\nWe ask only that you follow a few simple guidelines for contributing:\n\n1. Be courteous and respectful of others. Read our `communication guidelines\n   <https://h.readthedocs.io/en/latest/community.html>`_.\n\n2. If you find a bug, please report it in `a GitHub issue\n   <https://github.com/hypothesis/h/issues>`_, but do check first that no-one\n   else has already reported the same problem. Please try and give us enough\n   detail to reproduce your issue. If you're not sure what that means, `here's a\n   guide on how to report bugs effectively\n   <http://www.chiark.greenend.org.uk/~sgtatham/bugs.html>`_.\n\n   **Please do not submit feature requests or support queries as GitHub\n   issues**: send those `to our mailing list\n   <https://groups.google.com/a/list.hypothes.is/forum/#!forum/dev>`_ where the\n   community can discuss them!\n\n3. If you have ideas on new features or changes to the codebase that go beyond\n   bug fixes, please `write to the community developer mailing list\n   <https://groups.google.com/a/list.hypothes.is/forum/#!forum/dev>`_ **before\n   you start work**. That way we'll avoid duplicating effort, and you will\n   maximise the chances that your work is integrated quickly and painlessly.\n\n4. If you haven't already done so (and you're submitting substantial changes to\n   the code or documentation), please ensure you sign our `Contributor License\n   Agreement <https://h.readthedocs.io/en/latest/developing/cla.html>`_.\n\nStill reading?\n--------------\n\nIf you're wondering about how to set up a development environment, how to build\nthe documentation, or anything else, there's plenty more in our `Contributor's\nguide <https://h.readthedocs.io/en/latest/developing/>`_.\n"},{"size":2161,"relativepath":"package.json","filename":"package.json","extension":".json","content":"{\n  \"name\": \"h\",\n  \"private\": true,\n  \"version\": \"0.0.0\",\n  \"description\": \"The Internet, peer reviewed.\",\n  \"dependencies\": {\n    \"autoprefixer\": \"^6.0.3\",\n    \"babel-preset-es2015\": \"^6.14.0\",\n    \"babelify\": \"^7.3.0\",\n    \"bootstrap\": \"3.3.5\",\n    \"browserify\": \"^13.1.0\",\n    \"browserify-shim\": \"^3.8.12\",\n    \"commander\": \"^2.9.0\",\n    \"core-js\": \"^1.2.5\",\n    \"end-of-stream\": \"^1.1.0\",\n    \"exorcist\": \"^0.4.0\",\n    \"gulp\": \"^3.9.1\",\n    \"gulp-batch\": \"^1.0.5\",\n    \"gulp-changed\": \"^1.3.0\",\n    \"gulp-if\": \"^2.0.0\",\n    \"gulp-newer\": \"^1.2.0\",\n    \"gulp-postcss\": \"^6.1.0\",\n    \"gulp-svgmin\": \"^1.2.2\",\n    \"gulp-util\": \"^3.0.7\",\n    \"hypothesis\": \"^0.46.0\",\n    \"is-equal-shallow\": \"^0.1.3\",\n    \"jquery\": \"1.11.1\",\n    \"js-polyfills\": \"^0.1.16\",\n    \"mkdirp\": \"^0.5.1\",\n    \"node-sass\": \"^3.8.0\",\n    \"postcss\": \"^5.0.6\",\n    \"postcss-url\": \"^5.1.1\",\n    \"query-string\": \"^3.0.1\",\n    \"raven-js\": \"^3.7.0\",\n    \"scroll-into-view\": \"^1.7.1\",\n    \"through2\": \"^2.0.1\",\n    \"uglifyify\": \"^3.0.1\",\n    \"vinyl\": \"^1.1.1\",\n    \"watchify\": \"^3.7.0\",\n    \"whatwg-fetch\": \"^0.10.1\"\n  },\n  \"devDependencies\": {\n    \"chai\": \"^3.5.0\",\n    \"check-dependencies\": \"^0.12.0\",\n    \"diff\": \"^2.2.2\",\n    \"eslint\": \"^3.1.1\",\n    \"eslint-config-hypothesis\": \"^1.0.0\",\n    \"fetch-mock\": \"^5.1.5\",\n    \"gulp-eslint\": \"^3.0.1\",\n    \"karma\": \"^1.1.0\",\n    \"karma-browserify\": \"^5.1.0\",\n    \"karma-chai\": \"^0.1.0\",\n    \"karma-mocha\": \"^1.1.1\",\n    \"karma-mocha-reporter\": \"^2.0.4\",\n    \"karma-phantomjs-launcher\": \"^1.0.1\",\n    \"karma-sinon\": \"^1.0.5\",\n    \"mocha\": \"^2.4.5\",\n    \"proxyquire\": \"^1.7.4\",\n    \"proxyquire-universal\": \"^1.0.8\",\n    \"proxyquireify\": \"^3.2.1\",\n    \"sinon\": \"^1.17.3\",\n    \"syn\": \"^0.2.2\",\n    \"websocket\": \"^1.0.22\"\n  },\n  \"engines\": {\n    \"node\": \"0.10.x\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"https://github.com/hypothesis/h.git\"\n  },\n  \"license\": \"Simplified BSD License\",\n  \"bugs\": {\n    \"url\": \"https://github.com/hypothesis/h/issues\"\n  },\n  \"homepage\": \"https://github.com/hypothesis/h\",\n  \"browserify\": {\n    \"transform\": [\n      \"babelify\",\n      \"browserify-shim\"\n    ]\n  },\n  \"browserify-shim\": {\n    \"jquery\": \"$\"\n  }\n}\n"},{"size":2707,"relativepath":"requirements.txt","filename":"requirements.txt","extension":".txt","content":"#\n# This file is autogenerated by pip-compile\n# To update, run:\n#\n#    pip-compile --output-file requirements.txt requirements.in\n#\n\n-e .\nalembic==0.8.7\namqp==1.4.9               # via kombu\nanyjson==0.3.3            # via kombu\nbcrypt==3.1.0\nbilliard==3.3.0.23        # via celery\nbleach==1.4.3\ncelery==3.1.23\ncertifi==2016.2.28\ncffi==1.7.0\nChameleon==2.24           # via deform\nclick==6.6\ncolander==1.3.1           # via deform\ncontextlib2==0.5.4        # via raven\ncryptography==1.4\ndeform-jinja2==0.5\ndeform==0.9.9\nelasticsearch==1.9.0\nenum34==1.1.6             # via cryptography\nfunctools32==3.2.3.post2  # via jsonschema\ngevent==1.1.2\ngreenlet==0.4.10          # via gevent\ngunicorn==19.6.0\nhtml5lib==0.9999999       # via bleach\nidna==2.1                 # via cryptography\nipaddress==1.0.16         # via cryptography\niso8601==0.1.11           # via colander\nitsdangerous==0.24\nJinja2==2.8               # via deform-jinja2, pyramid-jinja2\njsonpointer==1.0\njsonschema==2.5.1\nkombu==3.0.35\nMako==1.0.4               # via alembic\nMarkupSafe==0.23          # via jinja2, mako, pyramid-jinja2\nmistune==0.7.3\nnewrelic==2.68.0.50\npasslib==1.6.5\nPasteDeploy==1.5.2        # via pyramid\npeppercorn==0.5           # via deform\npsycogreen==1.0\npsycopg2==2.6.2\npyasn1==0.1.9             # via cryptography\npycparser==2.14           # via cffi\nPyJWT==1.4.1\npyparsing==2.1.5\npyramid-authsanity==0.1.0a4\npyramid-jinja2==2.6.2\npyramid-layout==1.0\npyramid-mailer==0.14.1\npyramid-multiauth==0.8.0\npyramid-services==0.4\npyramid-tm==0.12.1\npyramid==1.7.3\npython-dateutil==2.5.3\npython-editor==1.0.1      # via alembic\npython-slugify==1.1.4\npytz==2016.6.1            # via celery\nraven==5.24.3\nrepoze.lru==0.6           # via pyramid\nrepoze.sendmail==4.1\nsix==1.10.0               # via bcrypt, bleach, cryptography, html5lib, python-dateutil\nSQLAlchemy==1.0.14        # via alembic, zope.sqlalchemy\nstatsd==3.2.1\ntransaction==1.6.1        # via pyramid-tm, repoze.sendmail, zope.sqlalchemy\ntranslationstring==1.3    # via colander, deform, pyramid\nunicodecsv==0.14.1\nUnidecode==0.4.19         # via python-slugify\nurllib3==1.16             # via elasticsearch\nvenusian==1.0             # via pyramid\nWebOb==1.6.1              # via pyramid\nws4py==0.3.5\nwsaccel==0.6.2\nzope.deprecation==4.1.2   # via deform, pyramid, pyramid-jinja2\nzope.interface==4.3.2     # via pyramid, pyramid-authsanity, pyramid-services, repoze.sendmail, transaction, zope.sqlalchemy\nzope.sqlalchemy==0.7.7\n\n# The following packages are commented out because they are\n# considered to be unsafe in a requirements file:\n# setuptools                # via cryptography, pyramid, repoze.sendmail, zope.deprecation, zope.interface, zope.sqlalchemy\n"},{"size":51020,"relativepath":"CHANGES","filename":"CHANGES","extension":"","content":"0.38.0 (2016-08-08)\n===================\n\nFeatures\n--------\n\n- Add \"proxy\" auth policy mode (#3638).\n\n- Implement new form designs for logged out forms under a feature flag (#3640).\n\nMiscellanea\n-----------\n\n- Add `hypothesis user add` command (#3634) and move admin command under the\n  users subcommand as well (#3632).\n\n- Replace \"firstRun\" config option with \"openSidebar\" and \"openLoginForm\"\n  (#3643).\n\n- Change URL paths for reset password, forgot password and register (#3651).\n\n- Update Hypothesis client to v0.38.0. See\n  https://github.com/hypothesis/client/releases/tag/v0.38.0\n\n0.36.0 (2016-07-27)\n===================\n\nMiscellanea\n-----------\n\n- Refactor `h.api.search` interface, it is now a `Search` class which can be\n  customized on a per-query basis, the return value also changed to be a new\n  `SearchResult` (#3622, #3623).\n\n- Update Hypothesis client to v0.36.0. See\n  https://github.com/hypothesis/client/releases/tag/v0.36.0\n\n0.35.0 (2016-07-22)\n===================\n\nFeatures\n--------\n\n- Add ability to rename users from admin control panel (#3584)\n\n- Improve the copy on reply notification emails (#3602)\n\nBug fixes\n---------\n\n- Fix case sensitivity in user search queries (#3611)\n\nMiscellanea\n-----------\n\n- Move the URLs for account settings from /profile to /accounts (#3604)\n\n- The Hypothesis browser extension has now been moved to its own repository\n  (#3620)\n\n- Update Hypothesis client to v0.35.0. See\n  https://github.com/hypothesis/client/releases/tag/v0.35.0\n\n0.33.0 (2016-07-13)\n===================\n\nBug fixes\n---------\n\n- Add a missing unique constraint on the `user_group` join table, and a\n  migration to fix existing databases (#3591).\n\nMiscellanea\n-----------\n\n- Update Hypothesis client to v0.33.0. See\n  https://github.com/hypothesis/client/releases/tag/v0.33.0\n\n0.32.0 (2016-07-08)\n===================\n\nFeatures\n--------\n\n- Treat HTTP/HTTPS URLs that are the same except for their protocol as\n  equivalent (#3558).\n\n- Improve performance of real-time updates service (#3574).\n\n- Use consistent terminology for 'Log in', 'Log out' and 'Sign up' actions\n  (#3578).\n\nBug fixes\n---------\n\n- Fix missing escaping of user input in server-rendered forms (#3585).\n\n- Prevent browsers disclosing group URLs to websites linked to from groups\n  pages (#3579).\n\n- Fix a problem where data migrations would update annotations' last-update\n  timestamp (#3586).\n\nMiscellanea\n-----------\n\n- Remove assets that relate to the Hypothesis client.  These are now part of\n  the hypothesis/client repository (#3577, #3571)\n\n- Update Hypothesis client to v0.32.0. See\n  https://github.com/hypothesis/client/releases/tag/v0.32.0\n\n\n0.31.0 (2016-06-29)\n===================\n\nFeatures\n--------\n\n- Show annotations and page notes in separate tabs in the sidebar (feature\n  flagged: selection_tabs) (#3504)\n\n- The 'Share' action for replies is now a direct link to the parent annotation\n  and its associated conversation in context (#3539).\n\n- Reply notification emails now contain direct links to see the original\n  annotation and its associated conversation in context (#3536).\n\nBug fixes\n---------\n\n- Fix adder not responding to selection changes after making a selection\n  which does not contain any text (#3522, #3526).\n\n- Fix incorrect 'You do not have permission to see this annotation' message in\n  the client when direct-linking to an annotation in a PDF (#3529).\n\n- Fix annotation cards containing long URLs overflowing their container\n  (#3546).\n\n0.30.0 (2016-06-23)\n===================\n\nFeatures\n--------\n\n- Users now get their own clean welcome page when they finish installing the\n  browser extension (#3505).\n\n- The search API can now accept multiple `uri` parameters and will return\n  annotations made on any of the passed URIs (#3517).\n\n- The annotation client now uses the multiple-`uri`-parameter feature to ensure\n  that all annotations are loaded on PDFs (#3524).\n\nBug fixes\n---------\n\n- Fix an issue where highlights weren't shown correctly in PDFs (#3531).\n\nMiscellanea\n-----------\n\n- Our brief experiment with using PDF fingerprint URNs as target `source`\n  properties has ended (#3524).\n\n0.29.0 (2016-06-20)\n===================\n\nFeatures\n--------\n\n- Add '#annotated' hashtag to default tweet message to make following\n  annotation activity on social media easier (#3482).\n\n- Unify the 'About this Version', 'Feedback' and 'Help' menu items in the\n  client (#3485).\n\n- Automatically expand the conversation when direct-linking to annotations\n  (#3489).\n\nBug fixes\n---------\n\n- Fix group names wrapping onto multiple lines in sidebar (#3469).\n\n- Fix the permalink pages for annotation replies. These now show the complete\n  conversation thread which the reply appeared in, highlighting the reply\n  matching the URL (#3474, #3483).\n\n- Fix annotations without quotes resulting in entire pages or large sections of\n  pages being highlighted (#3475).\n\n- Fix annotations made on PDFs in browsers other than Safari not appearing when\n  the same PDF was viewed in Safari and vice-versa (#3494).\n\nMiscellanea\n-----------\n\n- Record message processing times in realtime update service (#3484, #3486).\n\n0.28.1 (2016-06-14)\n===================\n\nBug fixes\n---------\n\n- Revert code that loads annotations from database in `/api/search` which caused\n  the request times for certain URIs to skyrocket (9af5b65).\n\n0.28.0 (2016-06-13)\n===================\n\nFeatures\n--------\n\n- Add option to disable the badge on the extension's toolbar button (#3342).\n\n- Avoid revealing information about the file structure of the user's system to\n  the Hypothesis service by not saving \"file://\" URLs with annotations made on\n  PDFs (#3441).\n\nBug fixes\n---------\n\n- Fix cursor style for annotation cards (#3463).\n\n- Fix styling of quotes in annotation bodies (#3464).\n\n- Fix annotation adder not being shown if the page already has a selection when\n  Hypothesis is activated (#3453).\n\n0.27.0 (2016-06-09)\n===================\n\nFeatures\n--------\n- It is now possible to authenticate to the WebSocket using an API token\n  (#3419).\n\n- Improve anchoring of annotations on PDFs by using the PDF fingerprint, when\n  available, instead of the URL (#3404).\n\nMiscellanea\n-----------\n\n- Load annotations from database in streamer server (#3378)\n\n- Remove the \"links\" field from the search index (#3413).\n\n- Add CLI command for moving existing annotations to a new URL (#3416).\n\n0.26.0 (2016-06-07)\n===================\n\nFeatures\n--------\n\n- Show adder in response to selection changes made via touch or keyboard input\n  (#3347)\n\n- Change timestamps in annotation cards to link to the standalone annotation\n  page rather than the original document (#3395)\n\n- Improve presentation of reply threads (#3376)\n\nBug fixes\n---------\n\n- Fix client on web pages which define a global variable called \"global\"\n  (#3385)\n\n- Support relative URLs for the \"serviceUrl\" parameter in the client specifying\n  the Hypothesis service to connect to (#3381)\n\n- Fix spacing around 'Share' icon in annotation cards (#3399)\n\n- Fix display of numbered and bullet-point lists in annotation cards (#3396)\n\n- URL encode Twitter/Facebook/Google share links correctly (#3394)\n\nMiscellanea\n-----------\n\n- Documentation pages now have URLs without a '.html' extension (#3373)\n\n- Remove \"direct_linking\" feature flag (#3382)\n\n0.25.0 (2016-05-26)\n===================\n\nMiscellanea\n-----------\n\n- Remove code that writes to the legacy storage system (#3357)\n\n- Visual improvements to the adder (#3346, #3370)\n\n- Alleviate the issue where not all replies are loaded by increasing the limit\n  to 200 per request (#3374)\n\n0.24.0 (2016-05-25)\n===================\n\nFeatures\n--------\n\n- Improved performance and reduced memory usage of the sidebar when using\n  Hypothesis on heavily annotated pages (#3287, #3360).\n\n0.23.1 (2016-05-24)\n===================\n\nBug fixes\n---------\n\n- We have had to temporarily revert the change which allows authenticating to the\n  WebSocket with API tokens, as this had unintended side-effects preventing\n  cookie authentication to same (3ed6ff3).\n\n- Fix a problem with updating page notes when the 'postgres' feature flag was\n  switched on (#3355).\n\n0.23.0 (2016-05-23)\n===================\n\nFeatures\n--------\n\n- It is now possible to authenticate to the WebSocket using an API token\n  (#3345).\n\nBug fixes\n---------\n\n- The search `limit` parameter is now clamped within a range of acceptable\n  values (#3341).\n\nMiscellanea\n-----------\n\n- The setting for the WebSocket URL has changed from `H_WEBSOCKET_URL` to\n  `WEBSOCKET_URL` (#3329).\n\n- Added a code of conduct to the project repository (e3fad12).\n\n- Numerous important changes to support the upcoming migration of annotation\n  data to PostgreSQL (#3323, #3349, #3350, 4c25cd8).\n\n0.22.0 (2016-05-12)\n===================\n\nFeatures\n--------\n\n- New visual design for annotation cards (#3274).\n\n- Annotation cards now display more precise timestamps for annotations which\n  were last changed more than 24 hours ago. (#3247)\n\nMiscellanea\n-----------\n\n- Added `hypothesis devserver` command which runs all the services needed for a\n  development instance of Hypothesis and multiplexes their output into the\n  terminal (#3307).\n\n- Added `hypothesis migrate` command to simplify the execution of database\n  migrations (#3319).\n\n- Removed several unused `hypothesis` subcommands (#3303).\n\n- Added `--dev` flag to `hypothesis` command which replaces the need to specify\n  a config file path as an argument to subcommands (#3303).\n\n\n0.21.0 (2016-05-06)\n===================\n\nFeatures\n--------\n\n- Show adder when Hypothesis loads if there is already a text selection on the\n  page (#3257).\n\n- Make annotation adder position itself more intelligently in relation to the\n  selected text and viewport boundaries (#3257).\n\n- Add \"indexer\" worker queue to handle synchronisation of the search index with\n  the database under the 'postgres' feature flag (#3242).\n\nBug fixes\n---------\n\n- Fix a syntax error thrown when injecting the Hypothesis sidebar (#3289).\n\nMiscellanea\n-----------\n\n- Link to the Chrome extension on the help page (#3265).\n\n- Major work on storage as we continue to work towards a migration of all\n  annotation data to PostgreSQL (#3262, #3250, #3242).\n\n- Preliminary builds of a Firefox WebExtensions add-on (#3263).\n\n0.20.0 (2016-04-25)\n===================\n\nFeatures\n--------\n\n- Remove any empty annotations with no tags or text when creating new\n  annotations (#3214).\n\n- Add a 'Copy to Clipboard' button in the annotation share dialog (#3197).\n\n- Add 'About this version' panel accessible via Help -> About this version\n  (#3216).\n\n- When activing Hypothesis on a page whose canonical URL has changed since it\n  was first annotated, surface all annotations for that page, not just those\n  made since the page had its current canonical URL (#3241). This fixes an\n  issue where annotations disappeared from WordPress blogs.\n\nBug fixes\n---------\n\n- Fix sidebar not scrolling to show Share or Login dialogs when activating them\n  via links in the top bar (#3215).\n\n- Do not treat characters inside math expressions as possible markdown\n  formatting commands (#3208).\n\n- Fix failure to anchor annotations made at the start of PDF pages (#3234).\n\n- Fixed KaTeX font URLs failing to load when rendering math (#3209).\n\n- Handle request failures more gracefully for various network requests made by\n  the sidebar (#3210, #3211).\n\nMiscellanea\n-----------\n\n- Switched real-time message processing from NSQ to RabbitMQ (#3217).\n\n0.19.1 (2016-04-14)\n===================\n\nBug fixes\n---------\n\n- Fix a bug that prevented the \"Post\" button from correctly updating its\n  enabled/disabled state when typing an annotation body (#3213).\n\n0.19.0 (2016-04-14)\n===================\n\nFeatures\n--------\n\n- Background tasks are now processed by Celery workers rather than our own\n  homebrew worker implementation (#3189).\n\n- Improved display for local files in the \"recently annotated documents\" list on\n  group pages (#3200).\n\nBug fixes\n---------\n\n- Fix the display of documents with multiple possible titles in group pages\n  (#3200).\n\nMiscellanea\n-----------\n\n- More changes to support the migration of annotation data to PostgreSQL (#3203,\n  #3206).\n\n0.18.0 (2016-04-13)\n===================\n\nFeatures\n--------\n\n- Annotations are now available in (beta-quality) Web Annotation compatible\n  JSON-LD format via the API (#3181).\n\nBug fixes\n---------\n\n- Don't report expected/unavoidable errors when injecting the sidebar to Sentry\n  (#3186).\n\n- Fix broken links in the admin panel (#3187).\n\n- Fix an infinite loop occasionally triggered by the truncation of long\n  annotations (#3188).\n\nMiscellanea\n-----------\n\n- Numerous major changes to annotation storage as part of the work to migrate\n  annotation data to PostgreSQL (#3153, #3184, #3190, #3199).\n\n- Add a skeleton functional test suite for the web application (#3198).\n\n0.17.0 (2016-04-06)\n===================\n\nBug fixes\n---------\n\n- Fix a regression in sorting annotations when the sort order is set to\n  'Location' (#3179).\n\n- Clicking on an annotation quote now scrolls the page to that annotation when\n  the quote is collapsed (#3180).\n\nMiscellanea\n-----------\n\n- Add a live reload facility for development of the Hypothesis front-end\n  (#3038).\n\n0.16.0 (2016-04-04)\n===================\n\nBug fixes\n---------\n\n- Fix a bug that prevented \"direct links\" to annotations on PDFs from working\n  correctly (#3139).\n\nMiscellanea\n-----------\n\n- Annotation \"incontext\" links are now generated with the URL of the annotated\n  page appended (#3172).\n\n0.15.0 (2016-03-31)\n===================\n\nFeatures\n--------\n\n- Improved iconography for annotation cards (#3116).\n\n- Add \"call to action\" copy explaining to logged-out users what they're looking\n  at when viewing a direct-linked annotation (#3124).\n\n- Annotation selections in the sidebar are now preserved across\n  login/logout/account change -- this applies to \"direct links\" in particular\n  (#3133).\n\n- Admin information pages for users now show group memberships (#3138).\n\nBug fixes\n---------\n\n- Fixed a typo in the Chrome extension content security policy that caused\n  extension console warnings (#3140).\n\n- Fix a bug that caused worker processes to crash when encountering unexpected\n  exceptions while handling NSQ messages (#3156).\n\nMiscellanea\n-----------\n\n- Sentry error reports from the client code are now configured using a distinct\n  DSN (#3132).\n\n- Elasticsearch client timeouts and gunicorn worker timeouts are now\n  configurable using environment variables (1a6ae98, e0ef808).\n\n0.14.0 (2016-03-23)\n===================\n\nMiscellanea\n-----------\n\n- Remove usage of `h.accounts.User.status` bitfield (#3120).\n\n- Show message when a direct-linked annotation is selected but the annotation\n  is not available (#3093).\n\n- Properly hook up Chrome production extension with production bouncer (#3077).\n\n0.13.0 (2016-03-22)\n===================\n\nFeatures\n--------\n\n- The 'adder' that appears when selecting text has a new, clearer design, and\n  the toolbar 'note' button allows the creation of annotations when a selection\n  has been made (#3078).\n\n- The client can now respond to a URL fragment of the form `#annotations:<id>`\n  in order to focus and scroll to a specified annotation on page load (#3085).\n\n- The 'link' button on annotation cards can now display links to annotations in\n  context on the page where they were made (feature flagged: direct_linking)\n  (#3105).\n\nBug fixes\n---------\n\n- Fixed an issue where the client displayed an inconsistent login state when\n  switching accounts with Hypothesis active in multiple tabs (#2924).\n\n- Fixed an issue where private group annotations were not loaded correctly after\n  switching user accounts (#3083).\n\n- The Chrome extension now correctly indicates when it was not injected into a\n  page because another Hypothesis client is already present (#3097).\n\n- Fix cursor position after using editor toolbar buttons to create a new list\n  or quote, if the selection was previously empty and the cursor was positioned\n  at the start of the line (#3114).\n\nMiscellanea\n-----------\n\n- The undocumented `window.hypothesisInstall()` function has been removed\n  (#3098).\n\n- Substantial improvements to the feature flagging system, reducing the amount\n  of network chatter between the application and the database (#3110, #3115).\n\n0.12.0 (2016-03-14)\n===================\n\nBug fixes\n---------\n\n- Fixed error when rendering invalid LaTeX markup. As a side effect,\n  the fallback to MathJax rendering for markup that is not supported\n  by KaTeX has been removed for the time being (#3042).\n\n- Render annotation's text property as empty string instead of `null` (#3072).\n\n- Split out DocumentMeta type normalisation to only use it in the Postgres\n  migration (#3090).\n\nMiscellanea\n-----------\n\n- Render annotation links in API response (#3081) including an `incontext` link\n  behind the direct-linking feature flag (#3087).\n\n- Properly hook up Chrome staging extension with staging bouncer (#3077).\n\n- Add a utility script to aid the transition away from CoffeeScript (#3075).\n\n- Remove `h.claim` package (#3089).\n\n- Clean up old and unused feature flags (#3088).\n\n0.11.0 (2016-03-08)\n===================\n\nBug fixes\n---------\n\n- Replies are now correctly displayed after creation (#3057).\n\n- Fix a bug that caused annotations to be rendered incorrectly, both in the API\n  (where they had a `permission` field instead of a `permissions` field) and in\n  the UI (where they had edit controls they shouldn't have had) (#3059).\n\n- Fix a bug that caused page notes to be hidden on all pages (#3063).\n\n- Fix compatibility with IE 10, 11.0 and early versions of Microsoft Edge\n  (#3064).\n\n- Restore two-step confirmation for user deletion in admin panel (#3066).\n\nMiscellanea\n-----------\n\n- Early support for serving Content-Security-Policy headers from the\n  application (#3024).\n\n0.10.0 (2016-03-07)\n===================\n\nFeatures\n--------\n\n- The annotation text input is focused automatically when\n  new annotations are created (#3041).\n\nMiscellanea\n-----------\n\n- Introduce a presentation layer for the API (#3011, #3047, #3050, #3054).\n- Handle deleted annotations in Postgres migration script (#3040).\n- Updated the Ubuntu development install instuctions (#3046).\n- Upload sourcemaps to Sentry (#3055).\n\n0.9.7 (2016-03-01)\n==================\n\nBug fixes\n---------\n\n- Fix error in NSQ connection configuration (c25fa95).\n\n0.9.6 (2016-03-01)\n==================\n\nBug fixes\n---------\n\n- Fix WebSocket server initialization (#3039).\n\n0.9.5 (2016-03-01)\n==================\n\nBug fixes\n---------\n\n- Fix a bug that prevented the release from being built (a7e2189).\n\n0.9.4 (2016-03-01)\n==================\n\nFeatures\n--------\n\n- Enable admins to activate users (#3015).\n\n- Preserve selection when applying block formatting (67409c8).\n\nBug fixes\n---------\n\n- Fix a link to our mailing list archive (#3019).\n\n- Fix typo in NIPSA admin template (50abf12).\n\n- Fix tags autocomplete dropdown CSS (#3009).\n\nMiscellanea\n-----------\n\n- Pyramid upgraded to 1.6 (#3034).\n\n- The undocumented API endpoint /api/annotations has been removed (#3036).\n\n0.9.3 (2016-02-24)\n==================\n\nBug fixes\n---------\n\n- Fix the definition of the bouncer URL match pattern in the Chrome extension\n  manifest (6ce2dad).\n\n- Ensure the streamer routes messages correctly when NSQ_NAMESPACE is set\n  (#3008).\n\n0.9.2 (2016-02-24)\n==================\n\nBug fixes\n---------\n\n- Fix a blocker bug preventing database transactions from being committed\n  correctly (7ef09c3).\n\n0.9.1 (2016-02-24)\n==================\n\nBug fixes\n---------\n\n- Major improvements to the behaviour of the websocket server (AKA the\n  \"streamer\") under high concurrency (#2996).\n\nMiscellaneous\n-------------\n\n- This release contains an all-new build system for the frontend assets, which\n  include the assets for the web service and the browser extension (#2958).\n\n- A second large piece of the work to move annotation storage into PostgreSQL\n  has been merged (#2986).\n\n0.9.0 (2016-02-22)\n==================\n\nFeatures\n--------\n\n- Users can now generate long-lived API tokens from their profile page (#2948).\n\n- Correctly detect when the Chrome extension is being installed by an\n  administrative policy and suppress the \"welcome page\" tab (#2964).\n\nBug fixes\n---------\n\n- Fix a crash that prevented signups if the username blacklist was missing\n  (#2954).\n\n- Groups lists are now scrollable -- long lists of groups don't flow off the end\n  of the page and become unreachable (#2973).\n\n- Fix a bug that prevented users from replying to annotations on stream search\n  pages (#2978).\n\n- The icons in the sidebar now load on GitHub and other sites that\n  restrict loading of inline fonts using Content Security Policy. (#2266)\n\nMiscellaneous\n-------------\n\n- Attempting to create an annotation in a group of which the logged-in user is\n  not a member will now result in an explanatory error message rather than a 404\n  (#2981).\n\n- Client upgraded to use Angular 1.5 (#2967).\n\n- An important first tranche of work that will move annotation storage to\n  PostgreSQL has been merged (#2955).\n\n- Source maps are now generated for production builds of the client\n  and front-end assets for easier debugging and better error reporting.\n\n- The download size of the client application has been reduced\n  by 44% from 516KB (minified and gzipped) to 290KB.\n\n0.8.15 (2016-02-12)\n===================\n\nBug fixes\n---------\n\n- Ensure a useful error is shown when users with unactivated accounts attempt to\n  sign in (#2952).\n\n- Fix an error that would prevent Hypothesis from loading in IE10/11 (#2953).\n\n0.8.14 (2016-02-12)\n===================\n\nBug fixes\n---------\n\n- Fix an issue where a Hypothesis client that couldn't connect to the web\n  service would busy-loop (#2916).\n\n- Fix a bug where the \"sidebar tutorial\" wouldn't correctly dismiss (#2925).\n\n- Ensure that requests to the badge API correctly send a cookie (#2929).\n\n- Numerous small fixes to the Hypothesis client and Chrome extension (#2933,\n  #2941, #2947).\n\nMiscellanea\n-----------\n\n- The API component of the web application now only accepts API tokens for\n  authentication (#2923).\n\n- Improvements to the handling of unexpected errors in the Chrome extension\n  (#2942).\n\n0.8.13 (2016-02-05)\n===================\n\nFeatures\n--------\n\n- Improve messaging for users who click on an activation link more than once, or\n  who visit an activation link when already logged in (#2904).\n\n- Allow administrators to delete user accounts from the admin panel (#2907).\n\nBug fixes\n---------\n\n- Fix a character encoding bug that prevented CSV export of groups from the\n  admin panel (#2989).\n\n- Display the correct number of annotations for all users in the admin panel\n  (#2900).\n\n- Suppress an unsightly flash of banner on the stream pages (#2908).\n\n- Fix a bug that prevented editing of group annotations on stream pages (#2911).\n\nMiscellanea\n-----------\n\n- Numerous changes to the build process for the Chrome extension. Command-line\n  flags have changed (#2091, #2913).\n\n- Make it possible to build a client/extension that doesn't use a websocket\n  endpoint (#2906).\n\n- Move the websocket service into a standalone Pyramid application. This allows\n  the main web application to use a simpler worker type, thus preventing\n  database connection pool exhaustion in high load environments (#2913).\n\n- Move mail delivery to a worker process. This ensures that failures to deliver\n  mail are a) retried, and b) do not trigger transaction rollbacks in web\n  requests (#2903).\n\n0.8.12 (2016-02-01)\n===================\n\nFeatures\n--------\n\n- Searching for \"group:<groupid>\" in the stream pages will now function\n  correctly (#2882).\n\n- Detect when the Chrome extension is being installed by an administrative\n  policy and suppress the \"welcome page\" tab (#2891).\n\nBug fixes\n---------\n\n- Don't display the \"create an account\" banner on the stream or standalone\n  annotation pages (#2879).\n\n- Fix a problem where canceling edits to an annotation would revert the\n  annotation to its first known state rather than the state before the edit was\n  started (#2884).\n\n- Fix a problem where multiple clicks on the save button would create multiple\n  near-identical annotations (#2887).\n\nMiscellanea\n-----------\n\n- Add support for Sentry client-side error reporting in the Chrome extension and\n  site code (#2850).\n\n- Strip WebTrends \"WT.*\" query parameters as part of URI normalization (#2862).\n\n- Removed the incomplete Firefox extension code which had fallen a long way\n  behind Chrome, with the intention of replacing it with one based on\n  WebExtensions in the near future (#2877).\n\n0.8.11 (2016-01-14)\n===================\n\nBug fixes\n---------\n\n- Fix a bug that prevented the Docker container from correctly starting up\n  (614e6b9).\n\n0.8.10 (2016-01-14)\n===================\n\nBug fixes\n---------\n\n- Fix a bug that prevented Hypothesis from working on GitHub (#2847).\n\n- Fix a couple of crashing bugs in the Chrome extension (#2849, #2851).\n\n- Fix a bug that caused the wrong group name to display on annotations in the\n  stream (#2854).\n\n- Fix a bug where threads were being shown uncollapsed instead of collapsed\n  initially, and the collapse/uncollapse buttons didn't work (#2855).\n\n- Strip the proxy prefixes from URLs we know to be proxied (through our \"via\"\n  service) when normalising (#2861).\n\nMiscellanea\n-----------\n\n- Add a clear \"call to action\" banner in the sidebar for signed-out users\n  (#2843).\n\n- Avoid truncating annotation cards that exceed the collapsed height\n  by only a small amount (feature flagged: truncate_annotations) (#2859).\n\n0.8.9 (2016-01-11)\n==================\n\nBug fixes\n---------\n\n- Fix a bug where annotation deletions were not correctly processed by the\n  \"real-time\" streamer (7daa709)\n\nFeatures\n--------\n\n- Add a tutorial for new users to the sidebar (feature flagged:\n  sidebar_tutorial). (#2824)\n\n0.8.8 (2016-01-11)\n==================\n\nBug fixes\n---------\n\n- Fix a bug where embedded videos were not always shown (#2828, #2807).\n\n- Fix numerous usability issues and a potential denial-of-service attack\n  associated with password resets (#2803).\n\n- Fix a bug which prevented Hypothesis from being correctly re-activated on a\n  Chrome tab after it navigated (#2838).\n\nFeatures\n--------\n\n- Embedded videos can now be shown fullscreen (#2814, #2816).\n\n- PDF documents can now be detected regardless of file extension (#2834).\n\nMiscellanea\n-----------\n\n- We now clear any \"selection\" of annotations when a new annotation is created,\n  so the editor is always visible (#2817).\n\n- Various improvements to the appearance of truncated annotations (feature\n  flagged: truncate_annotations) (#2802).\n\n0.8.7 (2015-12-18)\n==================\n\nBug fixes\n---------\n\n- Links containing underscores within annotations are no longer mangled (#2801).\n\n- Fix a crash when invalid data is sent to the login endpoint (#2793).\n\nFeatures\n--------\n\n- New homepage design (feature flagged: new_homepage) (#2770).\n\n- Change YouTube and Vimeo links into video embeds\n  (feature flagged: embed_media) (#2805).\n\n0.8.6 (2015-12-11)\n==================\n\nBug fixes\n---------\n\n- Fix broken standalone annotation pages for replies (#2786).\n\n- Fix a bug where realtime updates weren't delivered to standalone annotation\n  pages for replies if the thread root on that page was also a reply (#2787).\n\n- A number of other small fixes and clean-ups.\n\n0.8.5 (2015-12-08)\n==================\n\nBug fixes\n---------\n\n- Fix a blocker bug preventing annotations from being created (3d014fc).\n\n0.8.4 (2015-12-08)\n==================\n\nBug fixes\n---------\n\n- Fix a crash when rendering /robots.txt (e1c6021).\n\n0.8.3 (2015-12-08)\n==================\n\nBug fixes\n---------\n\n- Fix a crash that meant that reply notification emails would not be sent if\n  the annotation replied to had no text (#2771).\n\n- Fix a bug where realtime annotation updates weren't being sent to logged-out\n  clients (#2776).\n\nFeatures\n--------\n\n- A report on groups is now available in the admin dashboard, which can be\n  downloaded in CSV format (#2764, #2772).\n\nMiscellanea\n-----------\n\n- Banner added to the homepage (#2758).\n\n- The community guidelines are now linked from the signup form (#2760).\n\n- The frontend code that controls the annotation card widget has been translated\n  to JavaScript, and numerous aspects of it have been refactored or simplified\n  (#2756, #2761, #2762, #2763).\n\n- The site now serves a robots.txt file (#2778).\n\n0.8.2 (2015-11-30)\n==================\n\nBug fixes\n---------\n\n- Fix a problem where messages that were supposed to be sent over the WebSocket\n  on reconnect weren't (#2746).\n\n- Fix a bug where an old sort control was shown in the sidebar (#2751).\n\n- Fix a bug where creating an annotation before login could result in invalid\n  data being sent to the server (#2754).\n\nMiscellanea\n-----------\n\n- The Hypothesis home page is now served by this application (#2740).\n\n- Annotation data is now validated using JSON Schema (#2745).\n\n0.8.1 (2015-11-26)\n==================\n\nBug fixes\n---------\n\n- Fix a series of bugs relating to the incorrect handling of replies on the\n  stream pages (#2737).\n\nFeatures\n--------\n\n- Enable highlights by default, everywhere (#2739).\n\n0.8.0 (2015-11-24)\n==================\n\nBug fixes\n---------\n\n- Fix a bug where unsaved drafts persisted on logout (#2708).\n\n- Fix a bug where annotation permissions/post intent was not preserved when\n  changing between groups (#2717).\n\n- Don't attempt to update the timestamps of unsaved annotations far too\n  frequently (#2725).\n\n- Fix a bug where a websocket reconnection wouldn't retransmit its search filter\n  state (#2719).\n\n- Ensure that the permissions (shared/public) of new annotations is correctly\n  preserved when switching between groups (#2713).\n\nFeatures\n--------\n\n- Annotations can now be made and shared in private groups (#2729).\n\nMiscellanea\n-----------\n\n- First steps towards Python 3 compatibility (#2706).\n\n- Old and unused feature flag data is now purged from the database on\n  application startup (#2733).\n\n0.7.13 (2015-11-03)\n===================\n\nBug fixes\n---------\n\n- Fix a broken reference within our code (502e8df).\n\n0.7.12 (2015-11-03)\n===================\n\nBug fixes\n---------\n\n- Fix a couple of small display issues (#2704, #2710).\n\n- Fix an issue where badge URLs were not correctly encoded before being sent to\n  the server (#2709).\n\n0.7.11 (2015-11-02)\n===================\n\nBug fixes\n---------\n\n- Fix a problem where occasionally the set of public annotations would be loaded\n  into the initial view rather than the set of annotations for the focused group\n  (feature flagged: groups) (#2684).\n\n- Fix a bug where creating an annotation when signed out (and subsequently\n  signing in and saving it) could result in invalid permissions fields (#2687).\n\n- Fix a problem in Safari where the search box didn't expand when you clicked on\n  it (#2699).\n\n- Fix improper case-sensitivity for tag searches (e.g. searches for \"Tag123\" now\n  correctly return annotations tagged with \"tag123\") (#2690).\n\nFeatures\n--------\n\n- Ignore the \"gclid\" query parameter (a Google AdWords click-tracking param)\n  when normalising URLs (72f0509).\n\n- Draft annotations are now preserved when switching from group to group in the\n  sidebar (#2689).\n\nMiscellanea\n-----------\n\n- Improvements to Sentry logging (the current URL, headers, and userid are now\n  recorded with exceptions) (#2697).\n\n- Show the werkzeug debugger on exceptions in development (#2698).\n\n0.7.10 (2015-10-28)\n===================\n\nBug fixes\n---------\n\n- Fix a problem where an incorrect search query was sent to our server due to\n  semicolons in the page URL (6513184).\n\n0.7.9 (2015-10-28)\n==================\n\nBug fixes\n---------\n\n- Fix a problem where activating the Chrome extension would obliterate a version\n  of Hypothesis embedded on the page (#2657).\n\n- Fix a visual issue causing the \"Clear selection\" and \"Clear search\" buttons to\n  be briefly visible when they shouldn't have been (#2668).\n\n- Fix a crash triggered when the set of connected WebSocket clients changed\n  while handling a message (#2647).\n\n- Fix a bug where cancelling leaving a group nonetheless resulted in group focus\n  changing (#2669).\n\nFeatures\n--------\n\n- Improved appearance and behaviour of the sort control for annotations (feature\n  flagged: groups) (#2643).\n\n- Replies now inherit the publication scope of their parents. That is: replies\n  to group annotations will go to the same group (#2650).\n\n- Support HTTP conditional responses (ETag/If-None-Match and\n  Last-Modified/If-Modified-Since) under appropriate conditions (#2664).\n\n- Groups landing pages now show a list of recently annotated pages (feature\n  flagged: groups) (#2667).\n\nMiscellanea\n-----------\n\n- Upgrade to Angular 1.4.7 (#2629).\n\n- Account settings and profile forms are now rendered by the server (#2636).\n\n- The Chrome extension can now be built in a way that allows distinguishing\n  between development versions of the extension and production ones (#2639).\n\n- No longer perform the URI expansion step when searching for annotations on\n  URLs which have been marked \"canonical\". This hopefully reduces the number of\n  false-positive annotations we load on pages with appropriate metadata (#2652).\n\n- Replace group public IDs (hashids) with randomly generated IDs (#2662).\n\n0.7.8 (2015-10-20)\n==================\n\nBug fixes\n---------\n\n- Fix a problem where the realtime updates feature would silently stop\n  processing messages on exceptions (#2617).\n\n- Groups in the groups dropdown are always focused, even if their identifier\n  starts with a number (feature flagged: groups) (#2627).\n\nFeatures\n--------\n\n- Improved appearance and behaviour of the controls to clear a selection or a\n  search (#2615).\n\n- Improved appearance and behaviour of the sidebar \"top bar\" (partially feature\n  flagged: groups) (#2616).\n\n- RSS feed contains authorship information (usernames) (#2621).\n\nMiscellanea\n-----------\n\n- Search query filters revert to default AND behaviour (#2620).\n\n- Joining a group from a signed out state is now easier (#2625).\n\n0.7.7 (2015-10-14)\n==================\n\nBug fixes\n---------\n\n- Clean up annotated document filenames before display (so \"my%20doc.pdf\"\n  becomes \"my doc.pdf\") (#2597).\n\n- Annotators are now able to select the privacy of their annotations before they\n  are able to save them (#2601).\n\n- The component that fetches feature flag data for the frontend will no longer\n  busy-poll the ajax endpoint if it receives an error (#2612).\n\nFeatures\n--------\n\n- Add the ability to leave a group (feature flagged: groups) (#2588).\n\n- Notify the frontend in real time, using the websocket, when groups are\n  joined/left (feature flagged: groups) (#2591).\n\n- Truncate long annotation quotes and bodies (feature flagged:\n  truncate_annotations) (#2451).\n\nMiscellanea\n-----------\n\n- The Chrome extension is now built using browserify (#2609).\n\n- Accounts forms (login/register/forgot password) are now rendered by the server\n  (#2582).\n\n0.7.6 (2015-10-08)\n==================\n\nBug fixes\n---------\n\n- Fix a bug where the URL of the annotated page didn't appear on annotation\n  cards in Safari/IE (#2574).\n\n- Fix the ability to \"select\" one or more annotations in the sidebar by clicking\n  on a highlight in the page (#2576).\n\nFeatures\n--------\n\n- Introduce a new, clearer \"save\" button for annotation editing (#2550).\n\n- Add the ability to focus the current view on annotations from a specific group\n  (feature flagged: groups) (#2566).\n\n- Show the filenames of locally annotated files on annotation cards (#2570).\n\n- Improve the appearance of the user flow when joining a group (#2577).\n\nMiscellanea\n-----------\n\n- Deprecate the use of SQLite in development environments (#2579).\n\n0.7.5 (2015-10-01)\n==================\n\nBug fixes\n---------\n\n- Fix a bug where cancelling a change to an annotation did not reset changes to\n  the annotation text (#2562).\n\n- Fix the broken email notification system (#2558).\n\n- Fix a crash caused by submitting an annotation with null document \"link\"\n  fields (#2520).\n\nFeatures\n--------\n\n- Removed support for old-style Annotator front-end auth (11135fd).\n\n- URLs in annotation text are now automatically converted to links (#2552).\n\n0.7.4 (2015-09-25)\n==================\n\nBug fixes\n---------\n\n- Support retrieving comments (\"page notes\") through search when using new\n  normalized URI search (feature flagged: groups) (#2549).\n\n- Fix standalone annotation pages failing to display their annotation (92010c1).\n\n- Fix unanchored annotation warnings displaying in the wrong places (feature\n  flagged: show_unanchored_annotations) (#2542).\n\n- Fix a bug where newly created annotations would sometimes disappear from the\n  sidebar for a few moments (#2542).\n\n- Fix display of page titles on some annotation cards (#2533).\n\n- Fix a couple of crashes when annotations were created without expected fields\n  (#2545, #2546).\n\nFeatures\n--------\n\n- Improved group selection menu (feature flagged: groups) (#2514).\n\n0.7.3 (2015-09-22)\n==================\n\nBug fixes\n---------\n\n- Fix annotation in IE10.\n\nFeatures\n--------\n\n- New and improved Dockerfile built on Alpine Linux, resulting in a\n  substantially smaller built image (down to 250MB from ~750MB).\n\n- Remove the need to patch the global window object (upgrade to dom-anchor-*\n  v2.0.0).\n\n- Added a stream RSS feed at `/stream.rss`.\n\n0.7.2 (2015-08-14)\n==================\n\nBug fixes\n---------\n\n- Fixed a regression that prevented infinite scroll from working on the stream.\n\nFeatures\n--------\n\n- Improve scrolling performance by using a fluidly sized body and scrolling\n  the whole document rather than a fixed body.\n\n- Rewrite infinite scroll pagination to use regular HTTP requests instead of\n  WebSocket.\n\n0.7.1 (2015-08-13)\n==================\n\nBug fixes\n---------\n\n- Clicking on annotation cards and the navigational bucket indicators should\n  work once more in the PDF.js viewer.\n\n- Fixed an issue with timezone localization that caused unnecessary errors to\n  be thrown and caught. Auditing this resulted in a removal of some significant\n  bloat from unnecessary code.\n\nFeatures\n--------\n\n- When sorting annotations by document location the TextPositionSelector\n  information is now used instead of highlight position information. This\n  causes less shuffling and re-rendering on load and when lazy-rendered pages\n  in the PDF.js viewer appear and disappear at the cost of seeing annotations\n  that have changed position or that target content within fixed position\n  containers sometimes appear to be out of order.\n\n- Removed an unnecessary call, originating in the infinite scrolling code, from\n  the sidebar widget.\n\n0.7.0 (2015-08-10)\n==================\n\nBug fixes\n---------\n\n- Only update the stream websocket filter when there is at least one URI to\n  search.\n  See https://github.com/hypothesis/h/pull/2419\n\n- Don't give admins permissions globally, but require instead that resources\n  specifically grant privileges to admins.\n  See https://github.com/hypothesis/h/pull/2424\n\n- Ensure that API requests always have a valid token if the user is logged in.\n  See https://github.com/hypothesis/h/pull/2415\n\nFeatures\n--------\n\n- Enable users to create and share groups.\n  See https://github.com/hypothesis/h/pull/2402 and\n  https://github.com/hypothesis/h/pull/2412\n\n- New, experimental URI normalization, accessible by turning on the\n  'search_normalized' feature.\n  See https://github.com/hypothesis/h/pull/2413\n\n- Add a staff user designation and support feature toggles for staff only.\n  See https://github.com/hypothesis/h/pull/2416\n\n- Support feature toggles for admins only.\n  See https://github.com/hypothesis/h/pull/2435\n\n- Improve the scrolling experience when clicking on bucket tabs and annotation\n  cards. The view now scrolls so that the annotation is one fifth of the way\n  down the screen, allowing room for navigation bars but leaving the annotation\n  near the top of the screen.\n\n- Support for the PDF.js viewer shipping in Firefox 40.\n\n- Add a NIPSA service worker definition.\n\n0.6.0 (2015-07-29)\n==================\n\nBug fixes\n---------\n\n- Support for relative URLs return from document metadata plugins.\n\n- Fix a possible infinite digest cycle in the features client.\n\n- All not found responses now have a 404 status code.\n\nFeatures\n--------\n\n- Support for flagging users as \"Not In Public Site Areas\" or \"NIPSA\".\n  See https://github.com/hypothesis/h/pull/2300\n\n- Support for admin users.\n\n- Support for turning features on only for admins.\n\n- A new administration page for admins.\n\nBackwards Incompatibilities\n---------------------------\n\n- Support for the h.autologin feature has been removed.\n\nSecurity\n--------\n\n- Session cookies are now marked as HttpOnly to prevent session stealing by\n  cross-site scripting attacks.\n\n0.5.1 (2015-07-21)\n==================\n\nBug fixes\n---------\n\n- Fix an error preventing the Atom feed from working.\n\n0.5.0 (2015-07-21)\n==================\n\nFeatures\n--------\n\n- Share a link to a page with annotations using the Via proxy service.\n  See https://github.com/hypothesis/h/pull/2215\n\n- Make the privacy setting more obvious on new annotations.\n  See https://github.com/hypothesis/h/pull/2322\n\n- Use better security practices when making HTTPS requests.\n  See https://github.com/hypothesis/h/issues/2343\n\n- Make it possible for administrators to enable and disable features without\n  redeploying.\n  See https://github.com/hypothesis/h/issues/2354\n\n- Preliminary support for admin users.\n  See https://github.com/hypothesis/h/pull/2358\n\nBug fixes\n---------\n\n- Improve performance, reliability, and responsiveness on complex or dynamic\n  pages, avoiding non-responsive script errors and anchoring failures.\n  See https://github.com/hypothesis/h/pull/2362\n\n- Prevent annotating when not signed in to avoid confusing users with data\n  loss.\n  See https://github.com/hypothesis/h/pull/2361\n\n- Make it possible to embed a guest frame once again, that participates in\n  annotation with an existing sidebar.\n  See https://github.com/hypothesis/h/pull/2340\n\n- Fix formatting issues with the Atom feed.\n  See https://github.com/hypothesis/h/pull/2341 and\n  https://github.com/hypothesis/h/pull/2338\n\n- Fix an issue where badly formatted annotations could break the Atom feed.\n  See https://github.com/hypothesis/h/pull/2345\n\n- Speed up searches by avoiding an extra request on the backend.\n  See https://github.com/hypothesis/h/pull/2346\n\n- Speed up searches by avoiding extra requests on the frontend.\n  See https://github.com/hypothesis/h/pull/2348\n\n- Address several causes of stuck transactions that make migrations difficult\n  and could, in some cases, make the server return errors for many requests.\n  See https://github.com/hypothesis/h/pull/2381\n\n- Fix an issue where failed document equivalence searches resulted in\n  annotations on http://example.com/ being returned.\n  See https://github.com/hypothesis/h/pull/2334\n\n- Avoid some problems caused by annotating the application itself, such as\n  by annotating the stream page.\n\n- User experience and usability improvements.\n  See https://github.com/hypothesis/h/pull/2330\n  https://github.com/hypothesis/h/pull/2352 and\n  https://github.com/hypothesis/h/pull/2349\n\n- Fix the token command-line tool to generate proper tokens even when the\n  server is running on a port other than the default.\n  See https://github.com/hypothesis/h/pull/2357\n\nDocumentation\n-------------\n\n- Expand the search API documentation to better describe the available fields\n  for filtering.\n  See https://github.com/hypothesis/h/pull/2344\n\n0.4.2 (2015-06-16)\n==================\n\n- Silence SQLAlchemy warnings (#2258)\n- Show errors when math parsing fails (#2241)\n- Let users change their email address (#2131)\n- Fix inappropriate WebSocket error reporting in logs (#2256)\n- Support for Python 2.7.9\n- Improve extension build documentation (#2265)\n- Remove dependency on horus\n  (#2274, #2281, #2284, #2291, #2313, #2312, #2317, #2318)\n- Keep CSS for annotator component separate from the site (#2279)\n- Prevent environment variables from interfering with tests (#2283)\n- Clearly indicate support for using email addresses for login (#2288)\n- Improve search code (#2282)\n- Improve reporting of form errors (#2290)\n- Support anonymous CORS in the API (#2303)\n- Remove unnecessary toast messages when editing a user profile (#2310)\n- Improve Docker build caching (#2311)\n- Upgrade gnsq dependency\n- Simplify database session handling (#2320)\n\n0.4.1 (2015-05-21)\n==================\n\n- Add NIPSA flag to user table (migration needed!)\n- Upgrade to Annotator v1.2.x tip (6536160)\n- Hide the widget panel until ready for input (#2207)\n- Fix UI z-index to actual maximum (#1909)\n- Change annotation card action from 'share' to 'link'\n- Add a client-side error when saving an annotation fails\n- Snap the sidebar closed as well as open (#2162)\n- Put NSQ usage behind feature flag. The API no longer requires NSQ.\n- For development, disable WebSocket streaming, email notifications, and NSQ.\n- Lots of linting.\n- Added support for URL parameters to the Atom feed at ``/stream.atom``.\n  For example: ``/stream.atom?user=seanh`` or\n  ``/stream.atom?user=seanh&tags=foo,bar``.\n- Users can now change their email addresses using the Account form (#2131)\n\n0.4.0 (2015-05-05)\n==================\n\nHighlights\n----------\n\n- Add Markdown Editor (#1479)\n- Add Math support for annotations (#1558)\n- Simpler CSS grid system (#1577)\n- Improved Chrome extensions handling of PDF.js viewer (#1563)\n- Post-install Welcome page for user onboarding (#1579)\n- Switched to Jinja2 for server-side templates (#1628)\n- Initial Firefox Addon (#1434)\n- Add `./bin/hypothesis reindex` command (#1715)\n- Rework Back End Authentication and Authorization (#1791)\n- Import Annotator (#1856)\n- Depend on upstream Annotator (#1866)\n- Enable Sentry logging in production environments (#1906)\n- Open Graph protocol metadata added to Annotation view (#1921)\n- Refactor auth and separate API from main app (#1951)\n- Use key derivation to provide secret keys (#1981)\n- Add claim account system (#1941)\n- Browserify ALL THE THINGS (#1972)\n- Add `./bin/hypothesis token` command to generate OAuth tokens  (#2032)\n- Refactor UX (#2031)\n- Auto-complete tags (#2042)\n- Add Atom feed support for `/stream` (#2072)\n- Improve packaging, bundling and module boilerplate (#2092)\n- Google Analytics support (#2139)\n- Mobile support (#2137)\n- Protect against double embedding/injecting (#2166)\n- Add a blocklist of sites h doesn't work on (#2157)\n- Overhaul URI analysis (#2184)\n\n0.3.2 (2014-09-24)\n==================\n\nPatch release to upgrade angular.js in light of security vulnerabilities.\nSee http://avlidienbrunn.se/angular.txt\n\n0.3.1 (2014-08-25)\n==================\n\nFixes\n-----\n\n- The token API returns OAuth errors rather than choking (#1406)\n\nBackwards Incompatibilities\n---------------------------\n\n- Support for clients before v0.2 has been dropped\n\n0.3.0 (2014-08-23)\n==================\n\nNew Features\n------------\n\n- Account deactivation and password change support (#632, #1275)\n- Heatmap tabs no longer show reply count.\n- HTML emails for reply notifications\n- Update dom-text libraries to support PDF.js v1.0.277\n- Better tokenization of URIs for search (#1308, #1407)\n- Markdown previews (#1418)\n\nFixes\n-----\n\n- Improved form validation (#1275, #1388, #1394)\n- Source citation information on cards in the stream (#1390, #1423, #1425)\n- Searching for a bare username works again (#1391)\n- Add iconography for privacy settings\n- Replace various SVGs with CSS (#1399)\n- Drop jQueryUI\n- Make clean properly removes only what it should now\n- Improve the copy on reply notification emails\n- Restyle tags (#1430, #1435)\n- Various other usability and style enhancements (#1354, #1410, #1414)\n\nKnown Issues\n------------\n\n- Searching for tags with spaces does not work\n- Standalone annotation page shows stream updates\n- Sphinx documentation is broken\n\n0.2.2 (2014-08-15)\n==================\n\nFixes\n-----\n\n- Fix user search (#1391)\n- Fix page search\n\nKnown issues\n------------\n\n- In some circumstances, Firefox can freeze on initial load.\n\n0.2.1 (2014-08-11)\n==================\n\n- Revert to using MANIFEST.in so built assets get shipped in the source\n  release.\n\n0.2.0 (2014-08-10)\n==================\n\n- Improve usability of the toolbar (#1268, #1316)\n- Make the stream cards interactive (#1281, #1290)\n- Make the annotation card on a standalone annotation page interactive (#427)\n- Fix race conditions with realtime updates (#1306, #1307)\n- Exponential backoff on socket failures (#1291)\n- Fix infinite scroll regression on stream\n- Add a front end test framework (#240, #1309)\n- Revalidate forms when autofilled (#374)\n- Introduce environment variable overrides for important settings\n- Allow bundling assets of a debug build in the extension (#1230)\n- Make it possible to override all templates (#1337)\n- Simplify the search entry, getting rid of visualsearch.js (#1326)\n- Fix infinite scroll in stream (#1373)\n- Fix several reports of broken styles on certain sites (#1372)\n- Factor out the identity, session, and authentication system into its own\n  package, making it entirely optional (#1357)\n- Remove PDF.js from the Chrome extension until it can be made opt-in (#1384)\n- Rework the reply notification emails -- still disabled by default (#1378)\n\n0.1.3 (2014-07-14)\n==================\n\n- Include missing package data\n\n0.1.2 (2014-07-14)\n==================\n\n- Include package data in source distributions\n\n0.1.1 (2014-07-14)\n==================\n\n- Fix versioneer issue with Python release packages\n\n0.1.0 (2014-07-11)\n==================\n\n- Searchable stream (#719)\n- Sidebar search (#606)\n- Realtime updates (#356)\n- Private annotations and highlights (#530)\n- Page level comments (#115)\n- Support for tags on annotations (#514)\n- Support for annotating PDF.js viewers (#74)\n- Chrome and Firefox extensions (#43)\n- Addition of unit tests for some modules (#240)\n- Support for sharing a sidebar between frames (#778)\n- Improved URI search (#1243)\n- Improved authentication form errors (#1279)\n- Pluggable authentication via pyramid_multiauth (#1167)\n\n0.0.6 (2013-01-08)\n==================\n\n- Flash messages (#233)\n- Static asset build script (#161)\n- Finish registration form flow (#159)\n- Separate detail and bucket views (#162)\n- Slide-over detail view (#150)\n\n0.0.5 (2012-11-27)\n==================\n\n- Use AngularJS (#198)\n- Confirm discarding of drafts (#188)\n- Markdown support (#91)\n- Resizable sidebar (#26)\n\n0.0.4 (2012-11-6)\n=================\n\n- Refactoring of horus and SCSS\n- Reply counts on threads\n- Visual improvements\n\n0.0.3 (2012-10-16)\n==================\n\n- Up/down tabs are hidden when count is zero\n- Long excerpts are truncated and show with less/more links\n- New persona dropdown (tinyman)\n- Password reset fixed\n- Initial sphinx documentation added\n\n0.0.2 (2012-10-09)\n==================\n\n- Replace account system\n- Threaded replies\n- Sidebar iframe\n- Release management\n- Miscellaneous gardening\n\n0.0.1 (2012-04-16)\n==================\n\n- Set up scaffolding, accounts, annotator\n"},{"size":553,"relativepath":"requirements.in","filename":"requirements.in","extension":".in","content":"PyJWT\nSQLAlchemy\nalembic\nbcrypt\ncelery\ncertifi\ncffi\nclick\ncryptography\ndeform < 1.0\ndeform-jinja2\nelasticsearch < 2.0.0\ngevent\ngunicorn\nitsdangerous\njsonpointer == 1.0\njsonschema\nkombu\nnewrelic\npasslib\npsycogreen\npsycopg2\npyramid\npyramid_authsanity\npyramid_layout\npyramid-jinja2\npyramid-multiauth\npyramid-services\npyramid_mailer\npyramid_tm\npython-dateutil\npython-slugify < 1.2.0\nraven\nstatsd\nunicodecsv\nwsaccel\nws4py\nzope.sqlalchemy\n\n# Version pin for known bug\n# https://github.com/repoze/repoze.sendmail/issues/31\nrepoze.sendmail < 4.2\n\n-e .  # memex\n"},{"size":3093,"relativepath":"CODE_OF_CONDUCT","filename":"CODE_OF_CONDUCT","extension":"","content":"Contributor Covenant Code of Conduct\n\nOur Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, gender identity and expression, level of experience,\nnationality, personal appearance, race, religion, or sexual identity and\norientation.\n\nOur Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\nadvances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\nOur Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\nScope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\nEnforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at abuse-prevention@hypothes.is. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\nAttribution\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 1.4,\navailable at http://contributor-covenant.org/version/1/4/\n"},{"size":486,"relativepath":"h/stats.py","filename":"stats.py","extension":".py","content":"# -*- coding: utf-8 -*-\nimport statsd\n\n__all__ = ('get_client',)\n\n\ndef get_client(settings):\n    return statsd.StatsClient(host=settings.get('statsd.host', 'localhost'),\n                              port=settings.get('statsd.port', 8125))\n\n\ndef includeme(config):\n    # Allow easy access to a statsd client as `request.stats`\n    config.add_request_method(lambda r: get_client(r.registry.settings),\n                              name='stats',\n                              reify=True)\n"},{"size":2845,"relativepath":"h/migrations/env.py","filename":"env.py","extension":".py","content":"from __future__ import with_statement\n\nimport logging\nimport os\n\nfrom alembic import context\nfrom sqlalchemy import MetaData\nfrom sqlalchemy import engine_from_config, pool\n\nfrom h.settings import database_url\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nconfig = context.config\n\nfrom h import db\nfrom memex import db as api_db\n\n# Import all model modules here in order to populate the metadata\nfrom h import models  # noqa\nfrom memex.models import annotation  # noqa\n\n# Since we have multiple MetaData objects (one from the app and one from the\n# API), we need to merge them all for alembic autogenerate to work correctly.\ntarget_metadata = MetaData(naming_convention=db.Base.metadata.naming_convention)\n\nfor metadata in [db.Base.metadata, api_db.Base.metadata]:\n    for t in metadata.tables.values():\n        t.tometadata(target_metadata)\n\n\ndef configure_logging():\n    logging.basicConfig(format='%(asctime)s %(process)d %(name)s [%(levelname)s] '\n                               '%(message)s',\n                        datefmt='%Y-%m-%d %H:%M:%S',\n                        level=logging.INFO)\n\n    if 'DEBUG_QUERY' in os.environ:\n        level = logging.INFO\n        if os.environ.get('DEBUG_QUERY') == 'trace':\n            level = logging.DEBUG\n        logging.getLogger('sqlalchemy.engine').setLevel(level)\n\n\ndef get_database_url():\n    if 'DATABASE_URL' in os.environ:\n        return database_url(os.environ['DATABASE_URL'])\n    return config.get_main_option(\"sqlalchemy.url\")\n\n\ndef run_migrations_offline():\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    context.configure(url=get_database_url(),\n                      transaction_per_migration=True)\n\n    context.run_migrations()\n\n\ndef run_migrations_online():\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n    section = config.config_ini_section\n\n    config.set_section_option(section, 'sqlalchemy.url', get_database_url())\n\n    engine = engine_from_config(\n        config.get_section(section),\n        prefix='sqlalchemy.',\n        poolclass=pool.NullPool)\n\n    connection = engine.connect()\n    context.configure(\n        connection=connection,\n        target_metadata=target_metadata,\n        transaction_per_migration=True,\n    )\n\n    try:\n        context.run_migrations()\n    finally:\n        connection.close()\n\nconfigure_logging()\n\nif context.is_offline_mode():\n    run_migrations_offline()\nelse:\n    run_migrations_online()\n"},{"size":399,"relativepath":"h/migrations/script.py.mako","filename":"script.py.mako","extension":".mako","content":"\"\"\"\n${message}\n\nRevision ID: ${up_revision}\nRevises: ${down_revision}\nCreate Date: ${create_date}\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\n${imports if imports else \"\"}\n\nrevision = ${repr(str(up_revision))}\ndown_revision = ${repr(str(down_revision))}\n\n\ndef upgrade():\n    ${upgrades if upgrades else \"pass\"}\n\n\ndef downgrade():\n    ${downgrades if downgrades else \"pass\"}\n"},{"size":563,"relativepath":"h/migrations/versions/afd433075707_add_index_to_user_authority_column.py","filename":"afd433075707_add_index_to_user_authority_column.py","extension":".py","content":"\"\"\"\nAdd index to user authority column\n\nRevision ID: afd433075707\nRevises: 504a6a4db06d\nCreate Date: 2016-08-19 14:26:08.706027\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\n\n\nrevision = 'afd433075707'\ndown_revision = '504a6a4db06d'\n\n\ndef upgrade():\n    # Creating a concurrent index does not work inside a transaction\n    op.execute('COMMIT')\n    op.create_index(op.f('ix__user__authority'), 'user', ['authority'],\n                    postgresql_concurrently=True)\n\n\ndef downgrade():\n    op.drop_index(op.f('ix__user__authority'), 'user')\n"},{"size":459,"relativepath":"h/migrations/versions/f6ffcfc50583_add_annotation_extra_server_default.py","filename":"f6ffcfc50583_add_annotation_extra_server_default.py","extension":".py","content":"\"\"\"add annotation.extra server default\n\nRevision ID: f6ffcfc50583\nRevises: 98157e28a7e1\nCreate Date: 2016-06-06 15:14:36.642775\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = 'f6ffcfc50583'\ndown_revision = '98157e28a7e1'\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\ndef upgrade():\n    op.alter_column('annotation', 'extra', server_default=sa.func.jsonb('{}'))\n\n\ndef downgrade():\n    op.alter_column('annotation', 'extra', server_default=None)\n"},{"size":415,"relativepath":"h/migrations/versions/a001b7b4c78e_add_document_title_column.py","filename":"a001b7b4c78e_add_document_title_column.py","extension":".py","content":"\"\"\"\nAdd document title column\n\nRevision ID: a001b7b4c78e\nRevises: 94c989e06363\nCreate Date: 2016-09-12 11:59:35.296908\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\nrevision = 'a001b7b4c78e'\ndown_revision = '94c989e06363'\n\n\ndef upgrade():\n    op.add_column('document', sa.Column('title', sa.UnicodeText()))\n\n\ndef downgrade():\n    op.drop_column('document', 'title')\n"},{"size":987,"relativepath":"h/migrations/versions/42bd46b9b1ea_fill_in_missing_password_updated_fields.py","filename":"42bd46b9b1ea_fill_in_missing_password_updated_fields.py","extension":".py","content":"\"\"\"fill in missing password_updated fields\n\nRevision ID: 42bd46b9b1ea\nRevises: 43e7c4ed2fd7\nCreate Date: 2016-01-07 14:20:44.094611\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = '42bd46b9b1ea'\ndown_revision = None\n\nimport datetime\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.orm import sessionmaker\n\nSession = sessionmaker()\n\nuser = sa.table('user',\n                sa.column('id', sa.Integer),\n                sa.column('password_updated', sa.DateTime))\n\n\ndef upgrade():\n    bind = op.get_bind()\n    session = Session(bind=bind)\n\n    # Add the password_updated field to each row lacking one.\n    # This is O(N) but does not lock the whole table.\n    for id_, _ in session.query(user).all():\n        op.execute(user.update().\n                   where(user.c.id == id_).\n                   where(user.c.password_updated == None).\n                   values(password_updated=datetime.datetime.utcnow()))\n\n\ndef downgrade():\n    # Nothing to do here.\n    pass\n"},{"size":421,"relativepath":"h/migrations/versions/ddb5f0baa429_add_nipsa_column_to_user_table.py","filename":"ddb5f0baa429_add_nipsa_column_to_user_table.py","extension":".py","content":"\"\"\"\nAdd NIPSA column to user table\n\nRevision ID: ddb5f0baa429\nRevises: 6d9257ad610d\nCreate Date: 2016-09-16 16:58:03.585538\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport sqlalchemy as sa\nfrom alembic import op\n\n\nrevision = 'ddb5f0baa429'\ndown_revision = '6d9257ad610d'\n\n\ndef upgrade():\n    op.add_column('user', sa.Column('nipsa', sa.Boolean, nullable=True))\n\n\ndef downgrade():\n    op.drop_column('user', 'nipsa')\n"},{"size":433,"relativepath":"h/migrations/versions/98157e28a7e1_make_annotation_extra_non_nullable.py","filename":"98157e28a7e1_make_annotation_extra_non_nullable.py","extension":".py","content":"\"\"\"Make annotation.extra non-nullable.\n\nRevision ID: 98157e28a7e1\nRevises: 77c2af032aca\nCreate Date: 2016-06-06 14:52:41.277688\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = '98157e28a7e1'\ndown_revision = '77c2af032aca'\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\ndef upgrade():\n    op.alter_column('annotation', 'extra', nullable=False)\n\n\ndef downgrade():\n    op.alter_column('annotation', 'extra', nullable=True)\n"},{"size":576,"relativepath":"h/migrations/versions/c36369fe730f_add_token_client_id_column.py","filename":"c36369fe730f_add_token_client_id_column.py","extension":".py","content":"\"\"\"\nAdd token.client_id column\n\nRevision ID: c36369fe730f\nRevises: e15e47228c43\nCreate Date: 2016-10-19 15:24:13.387546\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects import postgresql\n\n\nrevision = 'c36369fe730f'\ndown_revision = 'e15e47228c43'\n\n\ndef upgrade():\n    op.add_column('token', sa.Column(\n        'authclient_id',\n        postgresql.UUID(),\n        sa.ForeignKey('authclient.id', ondelete='cascade'),\n        nullable=True,\n    ))\n\n\ndef downgrade():\n    op.drop_column('token', 'authclient_id')\n"},{"size":430,"relativepath":"h/migrations/versions/64cf31f9f721_add_expires_column_to_token_table.py","filename":"64cf31f9f721_add_expires_column_to_token_table.py","extension":".py","content":"\"\"\"\nAdd expires column to token table\n\nRevision ID: 64cf31f9f721\nRevises: d536d9a342f3\nCreate Date: 2016-08-15 15:45:21.813078\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport sqlalchemy as sa\nfrom alembic import op\n\nrevision = '64cf31f9f721'\ndown_revision = 'd536d9a342f3'\n\n\ndef upgrade():\n    op.add_column('token', sa.Column('expires', sa.DateTime, nullable=True))\n\n\ndef downgrade():\n    op.drop_column('token', 'expires')\n"},{"size":1488,"relativepath":"h/migrations/versions/9e01b7287da2_remove_duplicates_from_user_group_table.py","filename":"9e01b7287da2_remove_duplicates_from_user_group_table.py","extension":".py","content":"\"\"\"\nRemove duplicate rows from the user_group table.\n\nRevision ID: 9e01b7287da2\nRevises: 6f86796f64e0\nCreate Date: 2016-07-08 17:54:57.399139\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\nrevision = '9e01b7287da2'\ndown_revision = '6f86796f64e0'\n\nSession = sessionmaker()\n\n\nuser_group = sa.table('user_group',\n                      sa.Column('user_id', sa.Integer),\n                      sa.Column('group_id', sa.Integer))\n\n\ndef upgrade():\n    session = Session(bind=op.get_bind())\n\n    # Find all the groups of duplicate user_group rows that have the same\n    # user_id and group_id values.\n    groups = (\n        session.query(user_group)\n        .group_by('user_id', 'group_id')\n        .having(sa.func.count('*') > 1))\n\n    for user_id, group_id in groups:\n        # Delete all the rows from the group of duplicate rows.\n        # This deletes _all_ the rows from the group, we'll have to put back\n        # one row later.\n        session.execute(\n            user_group.delete()\n            .where(user_group.c.user_id == user_id)\n            .where(user_group.c.group_id == group_id)\n        )\n\n        # Re-insert one row in place of the deleted group of duplicate rows.\n        session.execute(user_group.insert().values(user_id=user_id,\n                                                   group_id=group_id))\n\n\ndef downgrade():\n    pass\n"},{"size":683,"relativepath":"h/migrations/versions/4886d7a14074_add_constraints_to_sidebar_tutorial_.py","filename":"4886d7a14074_add_constraints_to_sidebar_tutorial_.py","extension":".py","content":"\"\"\"Add constraints to user.sidebar_tutorial_dismissed column.\n\nRevision ID: 4886d7a14074\nRevises: 6f6a853fa2a\nCreate Date: 2016-01-07 12:51:33.807404\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = '4886d7a14074'\ndown_revision = '6f6a853fa2a'\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\ndef upgrade():\n    op.alter_column('user', 'sidebar_tutorial_dismissed', nullable=False)\n    op.alter_column('user', 'sidebar_tutorial_dismissed',\n                    server_default=sa.sql.expression.false())\n\n\ndef downgrade():\n    op.alter_column('user', 'sidebar_tutorial_dismissed', server_default=None)\n    op.alter_column('user', 'sidebar_tutorial_dismissed', nullable=True)\n"},{"size":562,"relativepath":"h/migrations/versions/ccebe818f8e0_add_not_null_constraint_to_docuri_types.py","filename":"ccebe818f8e0_add_not_null_constraint_to_docuri_types.py","extension":".py","content":"\"\"\"\nAdd NOT NULL constraint to document_uri type fields\n\nRevision ID: ccebe818f8e0\nRevises: 467ea2898660\nCreate Date: 2016-06-29 10:57:37.466053\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nrevision = 'ccebe818f8e0'\ndown_revision = '467ea2898660'\n\nfrom alembic import op\n\n\ndef upgrade():\n    op.alter_column('document_uri', 'type', nullable=False)\n    op.alter_column('document_uri', 'content_type', nullable=False)\n\n\ndef downgrade():\n    op.alter_column('document_uri', 'type', nullable=True)\n    op.alter_column('document_uri', 'content_type', nullable=True)\n"},{"size":421,"relativepath":"h/migrations/versions/3e1727613916_add_document_web_uri_column.py","filename":"3e1727613916_add_document_web_uri_column.py","extension":".py","content":"\"\"\"\nAdd document web_uri column\n\nRevision ID: 3e1727613916\nRevises: a001b7b4c78e\nCreate Date: 2016-09-12 13:21:56.739838\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\nrevision = '3e1727613916'\ndown_revision = 'a001b7b4c78e'\n\n\ndef upgrade():\n    op.add_column('document', sa.Column('web_uri', sa.UnicodeText()))\n\n\ndef downgrade():\n    op.drop_column('document', 'web_uri')\n"},{"size":438,"relativepath":"h/migrations/versions/e15e47228c43_remove_token_userid_uniqueness.py","filename":"e15e47228c43_remove_token_userid_uniqueness.py","extension":".py","content":"\"\"\"\nRemove uniqueness constraint on token.userid\n\nRevision ID: e15e47228c43\nRevises: 5dce9a8c42c2\nCreate Date: 2016-10-19 16:17:06.067310\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\n\n\nrevision = 'e15e47228c43'\ndown_revision = '5dce9a8c42c2'\n\n\ndef upgrade():\n    op.drop_constraint('uq__token__userid', 'token')\n\n\ndef downgrade():\n    op.create_unique_constraint(\n        'uq__token__userid', 'token', ['userid'])\n"},{"size":507,"relativepath":"h/migrations/versions/0d4755a0d88b_remove_status_column_from_user_table.py","filename":"0d4755a0d88b_remove_status_column_from_user_table.py","extension":".py","content":"\"\"\"Remove status column from user table\n\nRevision ID: 0d4755a0d88b\nRevises: 2494fea98d2d\nCreate Date: 2016-03-21 20:07:07.002482\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = '0d4755a0d88b'\ndown_revision = '2494fea98d2d'\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\ndef upgrade():\n    # Dropping a column is O(1) so this is safe to run against a production\n    # database.\n    op.drop_column('user', 'status')\n\n\ndef downgrade():\n    op.add_column('user', sa.Column('status', sa.Integer()))\n"},{"size":473,"relativepath":"h/migrations/versions/e17d3ce4fcd2_add_unique_constraint_to_user_group_.py","filename":"e17d3ce4fcd2_add_unique_constraint_to_user_group_.py","extension":".py","content":"\"\"\"\nAdd a unique constraint to user_group table.\n\nRevision ID: e17d3ce4fcd2\nRevises: 9e01b7287da2\nCreate Date: 2016-07-08 18:56:20.118573\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\n\n\nrevision = 'e17d3ce4fcd2'\ndown_revision = '9e01b7287da2'\n\n\ndef upgrade():\n    op.create_unique_constraint(\n        'uq__user_group__user_id', 'user_group', ['user_id', 'group_id'])\n\n\ndef downgrade():\n    op.drop_constraint('uq__user_group__user_id', 'user_group')\n"},{"size":1421,"relativepath":"h/migrations/versions/1e88c31d8b1a_add_authticket_table.py","filename":"1e88c31d8b1a_add_authticket_table.py","extension":".py","content":"\"\"\"\nAdd authticket table\n\nRevision ID: 1e88c31d8b1a\nRevises: f9d3058bec5f\nCreate Date: 2016-09-16 12:22:26.480404\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\nrevision = '1e88c31d8b1a'\ndown_revision = 'f9d3058bec5f'\n\n\ndef upgrade():\n    op.create_table('authticket',\n                    sa.Column('id',\n                              sa.UnicodeText(),\n                              primary_key=True),\n                    sa.Column('created',\n                              sa.DateTime,\n                              server_default=sa.func.now(),\n                              nullable=False),\n                    sa.Column('updated',\n                              sa.DateTime,\n                              server_default=sa.func.now(),\n                              nullable=False),\n                    sa.Column('expires',\n                              sa.DateTime,\n                              nullable=False),\n                    sa.Column('user_id',\n                              sa.Integer(),\n                              nullable=False),\n                    sa.Column('user_userid',\n                              sa.UnicodeText(),\n                              nullable=False),\n                    sa.ForeignKeyConstraint(['user_id'], ['user.id'],\n                                            ondelete='cascade'))\n\n\ndef downgrade():\n    op.drop_table('authticket')\n"},{"size":834,"relativepath":"h/migrations/versions/6f86796f64e0_add_user_profile_columns.py","filename":"6f86796f64e0_add_user_profile_columns.py","extension":".py","content":"\"\"\"\nAdd user profile columns\n\nRevision ID: 6f86796f64e0\nRevises: 7cf52a00822b\nCreate Date: 2016-07-06 11:28:50.075057\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\nrevision = '6f86796f64e0'\ndown_revision = '7cf52a00822b'\n\n\ndef upgrade():\n    op.add_column('user', sa.Column('display_name', sa.UnicodeText()))\n    op.add_column('user', sa.Column('description', sa.UnicodeText()))\n    op.add_column('user', sa.Column('location', sa.UnicodeText()))\n    op.add_column('user', sa.Column('uri', sa.UnicodeText()))\n    op.add_column('user', sa.Column('orcid', sa.UnicodeText()))\n\n\ndef downgrade():\n    op.drop_column('user', 'display_name')\n    op.drop_column('user', 'description')\n    op.drop_column('user', 'location')\n    op.drop_column('user', 'uri')\n    op.drop_column('user', 'orcid')\n"},{"size":424,"relativepath":"h/migrations/versions/7cf52a00822b_add_group_description_column.py","filename":"7cf52a00822b_add_group_description_column.py","extension":".py","content":"\"\"\"\nAdd group.description column\n\nRevision ID: 7cf52a00822b\nRevises: 9e6b4f70f588\nCreate Date: 2016-07-06 11:02:08.163718\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\nrevision = '7cf52a00822b'\ndown_revision = '9e6b4f70f588'\n\n\ndef upgrade():\n    op.add_column('group', sa.Column('description', sa.UnicodeText()))\n\n\ndef downgrade():\n    op.drop_column('group', 'description')\n"},{"size":1469,"relativepath":"h/migrations/versions/5e535a075f16_remove_null_document_titles.py","filename":"5e535a075f16_remove_null_document_titles.py","extension":".py","content":"\"\"\"\nRemove null document titles.\n\nRevision ID: 5e535a075f16\nRevises: a44ef07b085a\nCreate Date: 2016-09-14 15:11:26.551596\n\"\"\"\nfrom __future__ import unicode_literals\n\nimport logging\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects import postgresql as pg\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\n\nrevision = '5e535a075f16'\ndown_revision = 'a44ef07b085a'\n\n\nlog = logging.getLogger(__name__)\n\n\nBase = declarative_base()\nSession = sessionmaker()\n\n\nclass DocumentMeta(Base):\n    __tablename__ = 'document_meta'\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n    type = sa.Column(sa.UnicodeText)\n    value = sa.Column(pg.ARRAY(sa.UnicodeText, zero_indexes=True))\n\n\ndef upgrade():\n    session = Session(bind=op.get_bind())\n    n = 0\n    for document_meta in session.query(DocumentMeta).filter_by(type='title'):\n        new_titles = []\n        for original_title in document_meta.value:\n            if original_title is None:\n                n += 1\n                log.info(\n                    \"removing null title from document_meta {id}\".format(\n                        id=document_meta.id))\n            else:\n                new_titles.append(original_title)\n        if len(new_titles) != len(document_meta.value):\n            document_meta.value = new_titles\n    session.commit()\n    log.info(\"deleted {n} null document titles\".format(n=n))\n\n\ndef downgrade():\n    pass\n"},{"size":828,"relativepath":"h/migrations/versions/296573bb30b3_add_feature_featurecohort_association_table.py","filename":"296573bb30b3_add_feature_featurecohort_association_table.py","extension":".py","content":"\"\"\"add feature_featurecohort association table\n\nRevision ID: 296573bb30b3\nRevises: f6ffcfc50583\nCreate Date: 2016-06-09 16:35:09.065224\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = '296573bb30b3'\ndown_revision = 'f6ffcfc50583'\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\ndef upgrade():\n    op.create_table('featurecohort_feature',\n        sa.Column('id', sa.Integer(), nullable=False),\n        sa.Column('feature_id', sa.Integer(), nullable=False),\n        sa.Column('cohort_id', sa.Integer(), nullable=False),\n        sa.PrimaryKeyConstraint('id'),\n        sa.ForeignKeyConstraint(['cohort_id'], ['featurecohort.id']),\n        sa.ForeignKeyConstraint(['feature_id'], ['feature.id']),\n        sa.UniqueConstraint('cohort_id', 'feature_id'),\n    )\n\n\ndef downgrade():\n    op.drop_table('featurecohort_feature')\n"},{"size":613,"relativepath":"h/migrations/versions/6f6a853fa2a_fill_in_sidebar_tutorial_dismissed_.py","filename":"6f6a853fa2a_fill_in_sidebar_tutorial_dismissed_.py","extension":".py","content":"\"\"\"Fill in user.sidebar_tutorial_dismissed column default values.\n\nRevision ID: 6f6a853fa2a\nRevises: 1ef80156ee4\nCreate Date: 2016-01-06 19:12:14.402260\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = '6f6a853fa2a'\ndown_revision = '1ef80156ee4'\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy import orm\n\n\nSession = orm.sessionmaker()\n\n\nuser = sa.table('user', sa.column('sidebar_tutorial_dismissed', sa.Boolean))\n\n\ndef upgrade():\n    bind = op.get_bind()\n    session = Session(bind=bind)\n    op.execute(user.update().values(sidebar_tutorial_dismissed=True))\n\n\ndef downgrade():\n    pass\n"},{"size":931,"relativepath":"h/migrations/versions/bdaa06b14557_add_authclient_table.py","filename":"bdaa06b14557_add_authclient_table.py","extension":".py","content":"\"\"\"\nAdd AuthClient table\n\nRevision ID: bdaa06b14557\nRevises: afd433075707\nCreate Date: 2016-09-08 14:00:17.363281\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects import postgresql\n\nrevision = 'bdaa06b14557'\ndown_revision = 'afd433075707'\n\n\ndef upgrade():\n    op.create_table('authclient',\n    sa.Column('id', postgresql.UUID(), server_default=sa.func.uuid_generate_v1mc(), nullable=False),\n    sa.Column('created', sa.DateTime(), server_default=sa.func.now(), nullable=False),\n    sa.Column('updated', sa.DateTime(), server_default=sa.func.now(), nullable=False),\n    sa.Column('name', sa.UnicodeText(), nullable=True),\n    sa.Column('secret', sa.UnicodeText(), nullable=False),\n    sa.Column('authority', sa.UnicodeText(), nullable=False),\n    sa.PrimaryKeyConstraint('id', name=op.f('pk__authclient'))\n    )\n\n\ndef downgrade():\n    op.drop_table('authclient')\n"},{"size":571,"relativepath":"h/migrations/versions/21f87f395e26_add_group_name_index.py","filename":"21f87f395e26_add_group_name_index.py","extension":".py","content":"\"\"\"Add index to group.name column\n\nRevision ID: 21f87f395e26\nRevises: 0d4755a0d88b\nCreate Date: 2016-03-24 15:12:59.803179\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = '21f87f395e26'\ndown_revision = '0d4755a0d88b'\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\ndef upgrade():\n    # Creating a concurrent index does not work inside a transaction\n    op.execute('COMMIT')\n    op.create_index(op.f('ix__group__name'), 'group', ['name'],\n                    postgresql_concurrently=True)\n\n\ndef downgrade():\n    op.drop_index(op.f('ix__group__name'), 'group')\n"},{"size":658,"relativepath":"h/migrations/versions/addee5d1686f_add_annotation_document_id_column.py","filename":"addee5d1686f_add_annotation_document_id_column.py","extension":".py","content":"\"\"\"\nAdd annotation document_id column\n\nRevision ID: addee5d1686f\nRevises: 63e8b1fe1d4b\nCreate Date: 2016-09-22 15:55:06.069829\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\nrevision = 'addee5d1686f'\ndown_revision = '63e8b1fe1d4b'\n\n\ndef upgrade():\n    op.add_column('annotation', sa.Column('document_id',\n                                          sa.Integer,\n                                          sa.ForeignKey('document.id'),\n                                          nullable=True,\n                                          index=True))\n\n\ndef downgrade():\n    op.drop_column('annotation', 'document_id')\n"},{"size":442,"relativepath":"h/migrations/versions/6b801ecc60f1_add_a_primary_key_to_the_user_group_.py","filename":"6b801ecc60f1_add_a_primary_key_to_the_user_group_.py","extension":".py","content":"\"\"\"\nAdd a primary key to the user_group table.\n\nRevision ID: 6b801ecc60f1\nRevises: e17d3ce4fcd2\nCreate Date: 2016-07-08 17:42:20.891383\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\nrevision = '6b801ecc60f1'\ndown_revision = 'e17d3ce4fcd2'\n\n\ndef upgrade():\n    op.add_column('user_group', sa.Column('id', sa.Integer, primary_key=True))\n\n\ndef downgrade():\n    op.drop_column('user_group', 'id')\n"},{"size":751,"relativepath":"h/migrations/versions/f3b8e76ae9f5_add_document_uri_and_meta_updated_index.py","filename":"f3b8e76ae9f5_add_document_uri_and_meta_updated_index.py","extension":".py","content":"\"\"\"Add Document URI and Meta updated index\n\nRevision ID: f3b8e76ae9f5\nRevises: fde6cdcdd39a\nCreate Date: 2016-05-13 14:58:37.679724\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = 'f3b8e76ae9f5'\ndown_revision = 'fde6cdcdd39a'\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\ndef upgrade():\n    op.execute('COMMIT')\n    op.create_index(op.f('ix__document_uri_updated'), 'document_uri', ['updated'],\n                    postgresql_concurrently=True)\n    op.create_index(op.f('ix__document_meta_updated'), 'document_meta', ['updated'],\n                    postgresql_concurrently=True)\n\n\ndef downgrade():\n    op.drop_index(op.f('ix__document_uri_updated'), 'document_uri')\n    op.drop_index(op.f('ix__document_meta_updated'), 'document_meta')\n"},{"size":1198,"relativepath":"h/migrations/versions/3bcd62dd7260_add_featurecohort_table.py","filename":"3bcd62dd7260_add_featurecohort_table.py","extension":".py","content":"\"\"\"add cohort table\n\nRevision ID: 3bcd62dd7260\nRevises: dfa82518915a\nCreate Date: 2016-05-10 17:01:02.704596\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = '3bcd62dd7260'\ndown_revision = 'dfa82518915a'\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\ndef upgrade():\n    op.create_table('featurecohort',\n        sa.Column('id', sa.Integer(), nullable=False),\n        sa.Column('name', sa.UnicodeText(), nullable=False),\n        sa.Column('created', sa.DateTime(), server_default=sa.func.now(), nullable=False),\n        sa.Column('updated', sa.DateTime(), server_default=sa.func.now(), nullable=False),\n        sa.PrimaryKeyConstraint('id'),\n    )\n    op.create_table('featurecohort_user',\n        sa.Column('id', sa.Integer(), nullable=False),\n        sa.Column('user_id', sa.Integer(), nullable=False),\n        sa.Column('cohort_id', sa.Integer(), nullable=False),\n        sa.PrimaryKeyConstraint('id'),\n        sa.ForeignKeyConstraint(['cohort_id'], ['featurecohort.id']),\n        sa.ForeignKeyConstraint(['user_id'], ['user.id']),\n        sa.UniqueConstraint('cohort_id', 'user_id'),\n    )\n\n\ndef downgrade():\n    op.drop_table('featurecohort_user')\n    op.drop_table('featurecohort')\n"},{"size":527,"relativepath":"h/migrations/versions/fde6cdcdd39a_add_annotation_updated_index.py","filename":"fde6cdcdd39a_add_annotation_updated_index.py","extension":".py","content":"\"\"\"add annotation.updated index\n\nRevision ID: fde6cdcdd39a\nRevises: 3bcd62dd7260\nCreate Date: 2016-04-27 13:42:14.201644\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = 'fde6cdcdd39a'\ndown_revision = '3bcd62dd7260'\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\ndef upgrade():\n    op.execute('COMMIT')\n    op.create_index(op.f('ix__annotation_updated'), 'annotation', ['updated'],\n                    postgresql_concurrently=True)\n\n\ndef downgrade():\n    op.drop_index(op.f('ix__annotation_updated'), 'annotation')\n"},{"size":559,"relativepath":"h/migrations/versions/f9d3058bec5f_add_constraints_to_user_nipsa_column.py","filename":"f9d3058bec5f_add_constraints_to_user_nipsa_column.py","extension":".py","content":"\"\"\"\nAdd constraints to user NIPSA column\n\nRevision ID: f9d3058bec5f\nRevises: b7117b569f8b\nCreate Date: 2016-09-19 13:07:58.098068\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport sqlalchemy as sa\nfrom alembic import op\n\n\nrevision = 'f9d3058bec5f'\ndown_revision = 'b7117b569f8b'\n\n\ndef upgrade():\n    op.alter_column('user', 'nipsa', nullable=False)\n    op.alter_column('user', 'nipsa', server_default=sa.sql.expression.false())\n\ndef downgrade():\n    op.alter_column('user', 'nipsa', nullable=True)\n    op.alter_column('user', 'nipsa', server_default=None)\n"},{"size":411,"relativepath":"h/migrations/versions/de42d613c18d_add_constraints_to_user_authority_column.py","filename":"de42d613c18d_add_constraints_to_user_authority_column.py","extension":".py","content":"\"\"\"\nAdd constraints to user authority column\n\nRevision ID: de42d613c18d\nRevises: 2e2cc6a0c521\nCreate Date: 2016-08-15 18:18:19.037667\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\n\n\nrevision = 'de42d613c18d'\ndown_revision = '2e2cc6a0c521'\n\n\ndef upgrade():\n    op.alter_column('user', 'authority', nullable=False)\n\n\ndef downgrade():\n    op.alter_column('user', 'authority', nullable=True)\n"},{"size":779,"relativepath":"h/migrations/versions/77c2af032aca_add_document_uri_and_meta_docid_ix.py","filename":"77c2af032aca_add_document_uri_and_meta_docid_ix.py","extension":".py","content":"\"\"\"Add Document URI and Meta document_id index\n\nRevision ID: 77c2af032aca\nRevises: f3b8e76ae9f5\nCreate Date: 2016-05-13 15:06:55.496502\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = '77c2af032aca'\ndown_revision = 'f3b8e76ae9f5'\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\ndef upgrade():\n    op.execute('COMMIT')\n    op.create_index(op.f('ix__document_uri_document_id'), 'document_uri', ['document_id'],\n                    postgresql_concurrently=True)\n    op.create_index(op.f('ix__document_meta_document_id'), 'document_meta', ['document_id'],\n                    postgresql_concurrently=True)\n\n\ndef downgrade():\n    op.drop_index(op.f('ix__document_uri_document_id'), 'document_uri')\n    op.drop_index(op.f('ix__document_meta_document_id'), 'document_meta')\n"},{"size":1206,"relativepath":"h/migrations/versions/b7117b569f8b_fill_user_nipsa_column.py","filename":"b7117b569f8b_fill_user_nipsa_column.py","extension":".py","content":"\"\"\"\nFill user NIPSA column\n\nRevision ID: b7117b569f8b\nRevises: ddb5f0baa429\nCreate Date: 2016-09-16 17:03:25.264475\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy import orm\n\nfrom h.util.user import split_user\n\nrevision = 'b7117b569f8b'\ndown_revision = 'ddb5f0baa429'\n\nSession = orm.sessionmaker()\n\n\nuser = sa.table('user',\n                sa.column('username', sa.UnicodeText),\n                sa.column('authority', sa.UnicodeText),\n                sa.column('nipsa', sa.Boolean))\nnipsa = sa.table('nipsa', sa.column('userid', sa.UnicodeText))\n\n\ndef upgrade():\n    bind = op.get_bind()\n    session = Session(bind=bind)\n\n    op.execute(user.update().values(nipsa=False))\n\n    # Fetch all the existing NIPSA'd userids and set the NIPSA flag on the\n    # corresponding rows in the user table, if they exist.\n    for (userid,) in session.query(nipsa):\n        val = split_user(userid)\n        op.execute(user\n                   .update()\n                   .where(sa.and_(user.c.username == val['username'],\n                                  user.c.authority == val['domain']))\n                   .values(nipsa=True))\n\n\ndef downgrade():\n    pass\n"},{"size":1975,"relativepath":"h/migrations/versions/d536d9a342f3_fill_in_annotation_text_rendered_column.py","filename":"d536d9a342f3_fill_in_annotation_text_rendered_column.py","extension":".py","content":"\"\"\"\nFill in annotation text_rendered column\n\nRevision ID: d536d9a342f3\nRevises: 39b1935d9e7b\nCreate Date: 2016-08-10 14:09:01.787927\n\"\"\"\n\nfrom __future__ import unicode_literals\nfrom __future__ import print_function\n\nimport sys\nfrom collections import namedtuple\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\nfrom memex import markdown\n\n\nrevision = 'd536d9a342f3'\ndown_revision = '39b1935d9e7b'\n\nBase = declarative_base()\nSession = sessionmaker()\n\n\nclass Window(namedtuple('Window', ['start', 'end'])):\n    pass\n\n\nclass Annotation(Base):\n    __tablename__ = 'annotation'\n\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n    updated = sa.Column(sa.DateTime)\n\n    text = sa.Column(sa.UnicodeText)\n    text_rendered = sa.Column(sa.UnicodeText)\n\n\ndef upgrade():\n    session = Session(bind=op.get_bind())\n\n    fill_annotations_text_rendered(session)\n\n\ndef downgrade():\n    pass\n\n\ndef fill_annotations_text_rendered(session):\n    windows = _fetch_windows(session)\n    session.rollback()\n\n    for window in windows:\n        _fill_annotation_window_text_rendered(session, window)\n        session.commit()\n\n        print('.', end='')\n        sys.stdout.flush()\n\n\ndef _fill_annotation_window_text_rendered(session, window):\n    query = session.query(Annotation) \\\n        .filter(Annotation.updated.between(window.start, window.end)) \\\n        .order_by(Annotation.updated.asc())\n\n    for a in query:\n        a.text_rendered = markdown.render(a.text)\n\n\ndef _fetch_windows(session, chunksize=100):\n    updated = session.query(Annotation.updated). \\\n        execution_options(stream_results=True). \\\n        order_by(Annotation.updated.desc()).all()\n\n    count = len(updated)\n    windows = [Window(start=updated[min(x+chunksize, count)-1].updated,\n                      end=updated[x].updated)\n               for x in xrange(0, count, chunksize)]\n\n    return windows\n"},{"size":578,"relativepath":"h/migrations/versions/94c989e06363_remove_old_user_constraints.py","filename":"94c989e06363_remove_old_user_constraints.py","extension":".py","content":"\"\"\"\nRemove old user constraints\n\nThese were created in b0e1a12de5e8 in order to avoid making that migration\nirreversible. This is the irreversible part.\n\nRevision ID: 94c989e06363\nRevises: b0e1a12de5e8\nCreate Date: 2016-09-08 16:21:25.444258\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\n\n\nrevision = '94c989e06363'\ndown_revision = 'b0e1a12de5e8'\n\n\ndef upgrade():\n    op.drop_constraint('uq__user__email_old', 'user')\n    op.drop_constraint('uq__user__uid_old', 'user')\n    op.drop_constraint('uq__user__username_old', 'user')\n\n\ndef downgrade():\n    pass\n"},{"size":4481,"relativepath":"h/migrations/versions/bcdd81e23920_fill_in_missing_annotation_document_id.py","filename":"bcdd81e23920_fill_in_missing_annotation_document_id.py","extension":".py","content":"\"\"\"\nFill in missing Annotation.document_id\n\nRevision ID: bcdd81e23920\nRevises: addee5d1686f\nCreate Date: 2016-09-22 16:02:42.284670\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom collections import namedtuple\nimport logging\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\nfrom sqlalchemy.orm import subqueryload\n\nfrom memex.db import types\nfrom memex.uri import normalize as uri_normalize\n\n\nrevision = 'bcdd81e23920'\ndown_revision = 'addee5d1686f'\n\nlog = logging.getLogger(__name__)\n\nBase = declarative_base()\nSession = sessionmaker()\n\n\nclass Window(namedtuple('Window', ['start', 'end'])):\n    pass\n\n\nclass Document(Base):\n    __tablename__ = 'document'\n    id = sa.Column(sa.Integer, primary_key=True)\n    created = sa.Column(sa.DateTime)\n    updated = sa.Column(sa.DateTime)\n    web_uri = sa.Column('web_uri', sa.UnicodeText())\n    document_uris = sa.orm.relationship('DocumentURI',\n                                        backref='document',\n                                        order_by='DocumentURI.created.asc()')\n\n\nclass DocumentURI(Base):\n    __tablename__ = 'document_uri'\n    id = sa.Column(sa.Integer, primary_key=True)\n    created = sa.Column(sa.DateTime)\n    updated = sa.Column(sa.DateTime)\n    uri = sa.Column(sa.UnicodeText)\n    uri_normalized = sa.Column(sa.UnicodeText)\n    claimant = sa.Column(sa.UnicodeText)\n    claimant_normalized = sa.Column(sa.UnicodeText)\n    type = sa.Column(sa.UnicodeText)\n    document_id = sa.Column(sa.Integer,\n                            sa.ForeignKey('document.id'),\n                            nullable=False)\n\n\nclass Annotation(Base):\n    __tablename__ = 'annotation'\n    id = sa.Column(types.URLSafeUUID, primary_key=True)\n    created = sa.Column(sa.DateTime)\n    updated = sa.Column(sa.DateTime)\n    target_uri = sa.Column(sa.UnicodeText)\n    target_uri_normalized = sa.Column(sa.UnicodeText)\n    document_id = sa.Column(sa.Integer,\n                            sa.ForeignKey('document.id'),\n                            nullable=True)\n    document = sa.orm.relationship('Document')\n    document_through_uri = sa.orm.relationship(\n        'Document',\n        secondary='document_uri',\n        primaryjoin='Annotation.target_uri_normalized == DocumentURI.uri_normalized',\n        secondaryjoin='DocumentURI.document_id == Document.id',\n        viewonly=True,\n        uselist=False)\n\n\ndef upgrade():\n    session = Session(bind=op.get_bind())\n\n    windows = _fetch_windows(session)\n    session.rollback()\n\n    new_documents = 0\n    document_id_updated = 0\n\n    for window in windows:\n        query = session.query(Annotation) \\\n            .filter(Annotation.updated.between(window.start, window.end)) \\\n            .filter(Annotation.document_id.is_(None)) \\\n            .order_by(Annotation.updated.asc())\n\n        for ann in query:\n            if ann.document_id:\n                continue\n\n            if ann.document_through_uri is None:\n                uri = ann.target_uri\n                uri_normalized = uri_normalize(uri)\n\n                doc = Document(created=ann.created, updated=ann.updated)\n                docuri = DocumentURI(created=ann.created,\n                                     updated=ann.updated,\n                                     claimant=uri,\n                                     claimant_normalized=uri_normalized,\n                                     uri=uri,\n                                     uri_normalized=uri_normalized,\n                                     type='self-claim',\n                                     document=doc)\n                ann.document = doc\n                session.flush()\n                new_documents += 1\n            else:\n                ann.document_id = ann.document_through_uri.id\n                document_id_updated += 1\n\n        session.commit()\n\n    log.debug('Created %d new documents' % new_documents)\n    log.debug('Filled in %d existing document ids' % document_id_updated)\n\n\ndef downgrade():\n    pass\n\n\ndef _fetch_windows(session, chunksize=200):\n    updated = session.query(Annotation.updated). \\\n        filter_by(document_id=None). \\\n        execution_options(stream_results=True). \\\n        order_by(Annotation.updated.desc()).all()\n\n    count = len(updated)\n    windows = [Window(start=updated[min(x+chunksize, count)-1].updated,\n                      end=updated[x].updated)\n               for x in xrange(0, count, chunksize)]\n\n    return windows\n"},{"size":461,"relativepath":"h/migrations/versions/2e2cc6a0c521_fill_in_user_authority_column.py","filename":"2e2cc6a0c521_fill_in_user_authority_column.py","extension":".py","content":"\"\"\"\nFill in user authority column\n\nRevision ID: 2e2cc6a0c521\nRevises: f48100c9af86\nCreate Date: 2016-08-15 18:13:08.372479\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport sqlalchemy as sa\nfrom alembic import op\n\nrevision = '2e2cc6a0c521'\ndown_revision = 'f48100c9af86'\n\nuser_table = sa.table('user', sa.Column('authority', sa.UnicodeText()))\n\n\ndef upgrade():\n    op.execute(user_table.update().values(authority='hypothes.is'))\n\n\ndef downgrade():\n    pass\n\n"},{"size":447,"relativepath":"h/migrations/versions/43e7c4ed2fd7_make_user_password_updated_non_nullable.py","filename":"43e7c4ed2fd7_make_user_password_updated_non_nullable.py","extension":".py","content":"\"\"\"make user password_updated non-nullable\n\nRevision ID: 43e7c4ed2fd7\nRevises: 530268a1937c\nCreate Date: 2015-12-22 15:48:14.867487\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = '43e7c4ed2fd7'\ndown_revision = '42bd46b9b1ea'\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\ndef upgrade():\n    op.alter_column('user', 'password_updated', nullable=False)\n\n\ndef downgrade():\n    op.alter_column('user', 'password_updated', nullable=True)\n"},{"size":6819,"relativepath":"h/migrations/versions/467ea2898660_fix_document_uri_unique_constraint.py","filename":"467ea2898660_fix_document_uri_unique_constraint.py","extension":".py","content":"\"\"\"\nFix document_uri type fields\n\nRevision ID: 467ea2898660\nRevises: 40740282ae9e\nCreate Date: 2016-06-16 18:37:20.703447\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nrevision = '467ea2898660'\ndown_revision = '40740282ae9e'\n\nimport logging\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\nlog = logging.getLogger(__name__)\n\nBase = declarative_base()\nSession = sessionmaker()\n\n\nclass DocumentURI(Base):\n    __tablename__ = 'document_uri'\n\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n    updated = sa.Column(sa.DateTime)\n\n    claimant_normalized = sa.Column(sa.UnicodeText)\n    uri_normalized = sa.Column(sa.UnicodeText)\n\n    type = sa.Column(sa.UnicodeText)\n    content_type = sa.Column(sa.UnicodeText)\n\n\n\ndef batch_delete(query, session):\n    \"\"\"\n    Delete the result rows from the given query in batches.\n\n    This minimizes the amount of time that the table(s) that the query selects\n    from will be locked for at once.\n\n    \"\"\"\n    n = 0\n    query = query.limit(25)\n    while True:\n        if query.count() == 0:\n            break\n        for row in query:\n            n += 1\n            session.delete(row)\n        session.commit()\n    return n\n\n\ndef merge_duplicate_document_uris(session):\n    \"\"\"\n    Merge duplicate document_uri rows into single rows.\n\n    Find groups of document_uri rows that have the same claimant_normalized,\n    uri_normalized, type and content_type.\n\n    These duplicate rows must all contain null values in their type or\n    content_type columns (or both) otherwise they couldn't co-exist in the\n    database because of the\n    (claimant_normalized, uri_normalized, type, content_type) unique\n    constraint.\n\n    These groups of duplicate rows will not be able to co-exist in the database\n    anymore when we try to change null values in the type and content_type\n    columns to empty strings in preparation for adding NOT NULL constraints to\n    these columns.\n\n    So for each group of duplicate rows delete all but the most recently\n    updated row, thus enabling us to later change nulls to empty strings\n    without crashing.\n\n    \"\"\"\n    groups = (\n        session.query(DocumentURI.claimant_normalized,\n                      DocumentURI.uri_normalized,\n                      DocumentURI.type,\n                      DocumentURI.content_type)\n       .group_by(DocumentURI.claimant_normalized,\n                 DocumentURI.uri_normalized,\n                 DocumentURI.type,\n                 DocumentURI.content_type)\n        .having(sa.func.count('*') > 1))\n\n    n = 0\n\n    for group in groups:\n        document_uris = (\n            session.query(DocumentURI)\n            .filter_by(claimant_normalized=group[0],\n                        uri_normalized=group[1],\n                        type=group[2],\n                        content_type=group[3])\n            .order_by(DocumentURI.updated.desc())\n            .offset(1))\n        n += batch_delete(document_uris, session)\n\n    log.info('deleted %d duplicate rows from document_uri (NULL)' % n)\n\n\ndef delete_conflicting_document_uris(session):\n    \"\"\"\n    Delete NULL DocumentURIs where there's already an empty string one.\n\n    Later we're going to be finding all DocumentURIs with NULL for their type\n    or content_type and changing them to empty strings.  But for each one of\n    these NULL DocumentURIs if there is already a matching DocumentURI - same\n    claimant_normalized, uri_normalized, type and content_type but that already\n    has an empty string instead of NULL for the type and/or content_type - then\n    trying to change the NULL DocumentURI to an empty string one will fail with\n    IntegrityError.\n\n    So find all the DocumentURIs with an empty string for their type and/or\n    content_type and for each one find any matching DocumentURIs but with\n    NULL for the type and/or content_type and delete them.\n\n    After this it should be safe to change all NULL types and content_types\n    in document_uri to empty strings.\n\n    \"\"\"\n    doc_uris = session.query(DocumentURI).filter(\n        sa.or_(\n            DocumentURI.type == '',\n            DocumentURI.content_type == '',\n        )\n    )\n\n    n = 0\n\n    for doc_uri in doc_uris:\n\n        conflicting_doc_uris = session.query(DocumentURI).filter(\n            DocumentURI.claimant_normalized == doc_uri.claimant_normalized,\n            DocumentURI.uri_normalized == doc_uri.uri_normalized,\n            DocumentURI.id != doc_uri.id,\n        )\n\n        if doc_uri.type == '' and doc_uri.content_type == '':\n            conflicting_doc_uris = conflicting_doc_uris.filter(\n                sa.or_(\n                    DocumentURI.type == '',\n                    DocumentURI.type.is_(None),\n                ),\n                sa.or_(\n                    DocumentURI.content_type == '',\n                    DocumentURI.content_type.is_(None),\n                ),\n            )\n        elif doc_uri.type == '':\n            conflicting_doc_uris = conflicting_doc_uris.filter(\n                sa.or_(\n                    DocumentURI.type == '',\n                    DocumentURI.type.is_(None),\n                ),\n                DocumentURI.content_type == doc_uri.content_type,\n            )\n        elif doc_uri.content_type == '':\n            conflicting_doc_uris = conflicting_doc_uris.filter(\n                DocumentURI.type == doc_uri.type,\n                sa.or_(\n                    DocumentURI.content_type == '',\n                    DocumentURI.content_type.is_(None),\n                ),\n            )\n\n        n += batch_delete(conflicting_doc_uris, session)\n\n    log.info('deleted %d duplicate rows from document_uri (empty string/NULL)' % n)\n\ndef change_nulls_to_empty_strings(session):\n    \"\"\"\n    Change all null values in the type and content_type columns to ''.\n\n    This will enable us to add NOT NULL constraints to the type and\n    content_type columns with crashing.\n\n    \"\"\"\n    n = 0\n\n    while True:\n        doc_uris = (\n            session.query(DocumentURI)\n            .filter(\n                sa.or_(\n                    DocumentURI.type == sa.sql.expression.null(),\n                    DocumentURI.content_type == sa.sql.expression.null(),\n                )\n            )\n            .limit(25)\n        )\n\n        if doc_uris.count() == 0:\n            break\n\n        for doc_uri in doc_uris:\n            n += 1\n            doc_uri.type = doc_uri.type or ''\n            doc_uri.content_type = doc_uri.content_type or ''\n\n        session.commit()\n\n    log.info(\"replaced NULL with '' in %d rows\" % n)\n\n\ndef upgrade():\n    session = Session(bind=op.get_bind())\n    merge_duplicate_document_uris(session)\n    delete_conflicting_document_uris(session)\n    change_nulls_to_empty_strings(session)\n\n\ndef downgrade():\n    pass\n"},{"size":459,"relativepath":"h/migrations/versions/39b1935d9e7b_add_annotation_text_rendered.py","filename":"39b1935d9e7b_add_annotation_text_rendered.py","extension":".py","content":"\"\"\"Add the text_rendered column to the annotation table\n\nRevision ID: 39b1935d9e7b\nRevises: 6b801ecc60f1\nCreate Date: 2016-08-09 15:19:49.572331\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\nrevision = '39b1935d9e7b'\ndown_revision = '6b801ecc60f1'\n\n\ndef upgrade():\n    op.add_column('annotation', sa.Column('text_rendered', sa.UnicodeText))\n\n\ndef downgrade():\n    op.drop_column('annotation', 'text_rendered')\n"},{"size":1086,"relativepath":"h/migrations/versions/2494fea98d2d_add_the_token_table.py","filename":"2494fea98d2d_add_the_token_table.py","extension":".py","content":"\"\"\"Add the token table.\n\nRevision ID: 2494fea98d2d\nRevises: 4886d7a14074\nCreate Date: 2016-02-15 11:20:00.787358\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = '2494fea98d2d'\ndown_revision = '4886d7a14074'\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\ndef upgrade():\n    token_table = op.create_table(\n        'token',\n        sa.Column('created',\n                  sa.DateTime,\n                  server_default=sa.func.now(),\n                  nullable=False),\n        sa.Column('updated',\n                  sa.DateTime,\n                  server_default=sa.func.now(),\n                  nullable=False),\n        sa.Column('id',\n                  sa.Integer(),\n                  autoincrement=True,\n                  primary_key=True),\n        sa.Column('userid',\n                  sa.UnicodeText(),\n                  nullable=False,\n                  unique=True),\n        sa.Column('value',\n                  sa.UnicodeText(),\n                  index=True,\n                  nullable=False,\n                  unique=True))\n\n\ndef downgrade():\n    op.drop_table('token')\n"},{"size":2469,"relativepath":"h/migrations/versions/58bb601c390f_fill_in_missing_denormalized_document_title.py","filename":"58bb601c390f_fill_in_missing_denormalized_document_title.py","extension":".py","content":"\"\"\"\nFill in missing denormalized Document.title\n\nRevision ID: 58bb601c390f\nRevises: 3e1727613916\nCreate Date: 2016-09-12 12:21:40.904620\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom collections import namedtuple\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\nfrom sqlalchemy.orm import subqueryload\n\n\nrevision = '58bb601c390f'\ndown_revision = '3e1727613916'\n\nBase = declarative_base()\nSession = sessionmaker()\n\n\nclass Window(namedtuple('Window', ['start', 'end'])):\n    pass\n\n\nclass Document(Base):\n    __tablename__ = 'document'\n    id = sa.Column(sa.Integer, primary_key=True)\n    updated = sa.Column(sa.DateTime)\n    title = sa.Column(sa.UnicodeText())\n    meta_titles = sa.orm.relationship('DocumentMeta',\n                                      primaryjoin='and_(Document.id==DocumentMeta.document_id, DocumentMeta.type==u\"title\")',\n                                      order_by='DocumentMeta.updated.asc()',\n                                      viewonly=True)\n\n\nclass DocumentMeta(Base):\n    __tablename__ = 'document_meta'\n    id = sa.Column(sa.Integer, primary_key=True)\n    updated = sa.Column(sa.DateTime)\n    type = sa.Column(sa.UnicodeText)\n    value = sa.Column(sa.UnicodeText)\n    document_id = sa.Column(sa.Integer,\n                            sa.ForeignKey('document.id'),\n                            nullable=False)\n\n\ndef upgrade():\n    session = Session(bind=op.get_bind())\n\n    windows = _fetch_windows(session)\n    session.rollback()\n\n    for window in windows:\n        query = session.query(Document) \\\n            .filter(Document.updated.between(window.start, window.end)) \\\n            .options(subqueryload(Document.meta_titles)) \\\n            .order_by(Document.updated.asc())\n\n        for doc in query:\n            doc.title = _document_title(doc)\n\n        session.commit()\n\n\ndef downgrade():\n    pass\n\n\ndef _document_title(document):\n    for meta in document.meta_titles:\n        if meta.value:\n            return meta.value[0]\n\n\ndef _fetch_windows(session, chunksize=100):\n    updated = session.query(Document.updated). \\\n        execution_options(stream_results=True). \\\n        order_by(Document.updated.desc()).all()\n\n    count = len(updated)\n    windows = [Window(start=updated[min(x+chunksize, count)-1].updated,\n                      end=updated[x].updated)\n               for x in xrange(0, count, chunksize)]\n\n    return windows\n"},{"size":439,"relativepath":"h/migrations/versions/f48100c9af86_add_authority_column_to_user_table.py","filename":"f48100c9af86_add_authority_column_to_user_table.py","extension":".py","content":"\"\"\"\nAdd authority column to user table\n\nRevision ID: f48100c9af86\nRevises: 64cf31f9f721\nCreate Date: 2016-08-15 18:10:23.511861\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport sqlalchemy as sa\nfrom alembic import op\n\n\nrevision = 'f48100c9af86'\ndown_revision = '64cf31f9f721'\n\n\ndef upgrade():\n    op.add_column('user', sa.Column('authority', sa.UnicodeText(), nullable=True))\n\n\ndef downgrade():\n    op.drop_column('user', 'authority')\n"},{"size":4020,"relativepath":"h/migrations/versions/9e6b4f70f588_removing_trailing_from_pdf_urns.py","filename":"9e6b4f70f588_removing_trailing_from_pdf_urns.py","extension":".py","content":"\"\"\"Remove trailing # from PDF URNs.\n\nRevision ID: 9e6b4f70f588\nRevises: 467ea2898660\nCreate Date: 2016-06-21 17:50:14.261947\n\n\"\"\"\n# pylint: disable=invalid-name, wrong-import-position\nfrom __future__ import unicode_literals\n\nimport logging\n\n# revision identifiers, used by Alembic.\nrevision = '9e6b4f70f588'\ndown_revision = 'ccebe818f8e0'\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.orm import sessionmaker\nfrom sqlalchemy.ext.declarative import declarative_base\n\nfrom memex.db import types\n\nBase = declarative_base()\nSession = sessionmaker()\n\n\nlog = logging.getLogger(__name__)\n\n\nclass Annotation(Base):\n    __tablename__ = 'annotation'\n    id = sa.Column(types.URLSafeUUID, primary_key=True)\n    target_uri = sa.Column(sa.UnicodeText)\n\n\nclass DocumentURI(Base):\n    __tablename__ = 'document_uri'\n    id = sa.Column(sa.Integer, primary_key=True)\n    claimant = sa.Column(sa.UnicodeText)\n    claimant_normalized = sa.Column(sa.UnicodeText)\n    uri = sa.Column(sa.UnicodeText)\n    uri_normalized = sa.Column(sa.UnicodeText)\n    type = sa.Column(sa.UnicodeText)\n    content_type = sa.Column(sa.UnicodeText)\n\n\n\ndef upgrade():\n    session = Session(bind=op.get_bind())\n\n    document_uris = session.query(DocumentURI).filter(\n        sa.or_(\n            DocumentURI.claimant.like('urn:x-pdf:%#'),\n            DocumentURI.claimant_normalized.like('urn:x-pdf:%#'),\n            DocumentURI.uri.like('urn:x-pdf:%#'),\n            DocumentURI.uri_normalized.like('urn:x-pdf:%#'),\n        )\n    )\n\n    num_doc_uris_with_trailing_hashes = 0\n    num_conflicting_doc_uris = 0\n    num_without_conflicting_doc_uris = 0\n\n    for doc_uri in document_uris:\n\n        any_trailing_hash_found = False\n\n        if doc_uri.claimant.endswith('#'):\n            any_trailing_hash_found = True\n            new_claimant = doc_uri.claimant[:-1]\n        else:\n            new_claimant = doc_uri.claimant\n\n        if doc_uri.claimant_normalized.endswith('#'):\n            any_trailing_hash_found = True\n            new_claimant_normalized = doc_uri.claimant_normalized[:-1]\n        else:\n            new_claimant_normalized = doc_uri.claimant_normalized\n\n        if doc_uri.uri.endswith('#'):\n            any_trailing_hash_found = True\n            new_uri = doc_uri.uri[:-1]\n        else:\n            new_uri = doc_uri.uri\n\n        if doc_uri.uri_normalized.endswith('#'):\n            any_trailing_hash_found = True\n            new_uri_normalized = doc_uri.uri_normalized[:-1]\n        else:\n            new_uri_normalized = doc_uri.uri_normalized\n\n        if any_trailing_hash_found:\n            num_doc_uris_with_trailing_hashes += 1\n\n        conflicting_doc_uris = session.query(DocumentURI).filter_by(\n            claimant_normalized=new_claimant_normalized,\n            uri_normalized=new_uri_normalized,\n            type=doc_uri.type,\n            content_type=doc_uri.content_type)\n\n        conflicting_doc_uri = conflicting_doc_uris.one_or_none()\n\n        if conflicting_doc_uri:\n            num_conflicting_doc_uris += 1\n            session.delete(doc_uri)\n        else:\n            num_without_conflicting_doc_uris += 1\n            doc_uri.claimant = new_claimant\n            doc_uri.claimant_normalized = new_claimant_normalized\n            doc_uri.uri = new_uri\n            doc_uri.uri_normalized = new_uri_normalized\n\n    log.info(\"found %s rows with trailing #'s\",\n             num_doc_uris_with_trailing_hashes)\n    log.info(\"%s of these were deleted because rows without the trailing \"\n             \"#'s already existed\", num_conflicting_doc_uris)\n    log.info(\"and %s rows were updated to remove trailing #'s\",\n             num_without_conflicting_doc_uris)\n\n    annotations = session.query(Annotation).filter(\n        Annotation.target_uri.like('urn:x-pdf:%#'))\n\n    log.info(\"removing trailing #'s from target_uri's of %s annotations\",\n             annotations.count())\n\n    for annotation in annotations:\n        annotation.target_uri = annotation.target_uri[:-1]\n\n    session.commit()\n\n\ndef downgrade():\n    pass\n"},{"size":568,"relativepath":"h/migrations/versions/40740282ae9e_add_default_to_document_uri_types.py","filename":"40740282ae9e_add_default_to_document_uri_types.py","extension":".py","content":"\"\"\"\nAdd default to document_uri type fields\n\nRevision ID: 40740282ae9e\nRevises: 296575bb30b3\nCreate Date: 2016-06-29 11:01:40.936313\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nrevision = '40740282ae9e'\ndown_revision = '296573bb30b3'\n\nfrom alembic import op\n\n\ndef upgrade():\n    op.alter_column('document_uri', 'type', server_default='')\n    op.alter_column('document_uri', 'content_type', server_default='')\n\n\ndef downgrade():\n    op.alter_column('document_uri', 'type', server_default=None)\n    op.alter_column('document_uri', 'content_type', server_default=None)\n"},{"size":1575,"relativepath":"h/migrations/versions/6964a8237c88_strip_whitespace_from_document_titles.py","filename":"6964a8237c88_strip_whitespace_from_document_titles.py","extension":".py","content":"\"\"\"\nstrip whitespace from document titles\n\nRevision ID: 6964a8237c88\nRevises: 5e535a075f16\nCreate Date: 2016-09-14 15:17:23.096224\n\"\"\"\nfrom __future__ import unicode_literals\n\nimport logging\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects import postgresql as pg\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\n\nrevision = '6964a8237c88'\ndown_revision = '5e535a075f16'\n\n\nlog = logging.getLogger(__name__)\n\n\nBase = declarative_base()\nSession = sessionmaker()\n\n\nclass DocumentMeta(Base):\n    __tablename__ = 'document_meta'\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n    type = sa.Column(sa.UnicodeText)\n    value = sa.Column(pg.ARRAY(sa.UnicodeText, zero_indexes=True))\n\n\ndef upgrade():\n    session = Session(bind=op.get_bind())\n    n = 0\n    for document_meta in session.query(DocumentMeta).filter_by(type='title'):\n        new_titles = []\n        for original_title in document_meta.value:\n            stripped_title = original_title.strip()\n            if original_title != stripped_title:\n                n += 1\n                log.info(\n                    \"updated '{original_title}' to '{stripped_title}'\".format(\n                        original_title=original_title,\n                        stripped_title=stripped_title))\n            new_titles.append(stripped_title)\n\n        if new_titles != document_meta.value:\n            document_meta.value = new_titles\n\n    session.commit()\n    log.info(\"updated {n} document titles\".format(n=n))\n\n\ndef downgrade():\n    pass\n"},{"size":411,"relativepath":"h/migrations/versions/53a74d7ae1b0_remove_nipsa_table.py","filename":"53a74d7ae1b0_remove_nipsa_table.py","extension":".py","content":"\"\"\"\nRemove NIPSA table\n\nRevision ID: 53a74d7ae1b0\nRevises: 1e88c31d8b1a\nCreate Date: 2016-09-20 12:12:03.600081\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport sqlalchemy as sa\nfrom alembic import op\n\n\nrevision = '53a74d7ae1b0'\ndown_revision = '1e88c31d8b1a'\n\n\ndef upgrade():\n    op.drop_table('nipsa')\n\n\ndef downgrade():\n    op.create_table('nipsa', sa.Column('userid', sa.UnicodeText, primary_key=True))\n"},{"size":2175,"relativepath":"h/migrations/versions/b0e1a12de5e8_update_user_unique_constraints.py","filename":"b0e1a12de5e8_update_user_unique_constraints.py","extension":".py","content":"\"\"\"\nUpdate user unique constraints\n\nRevision ID: b0e1a12de5e8\nRevises: bdaa06b14557\nCreate Date: 2016-09-08 16:03:59.857402\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects import postgresql\n\nrevision = 'b0e1a12de5e8'\ndown_revision = 'bdaa06b14557'\n\n\ndef upgrade():\n    # First we move the existing unique constraint indices out of the way\n    op.execute(sa.text('ALTER TABLE \"user\" RENAME CONSTRAINT uq__user__email TO uq__user__email_old'))\n    op.execute(sa.text('ALTER TABLE \"user\" RENAME CONSTRAINT uq__user__uid TO uq__user__uid_old'))\n    op.execute(sa.text('ALTER TABLE \"user\" RENAME CONSTRAINT uq__user__username TO uq__user__username_old'))\n\n    # Then we can generate the new indices in the background\n    op.execute('COMMIT')\n    op.create_index(op.f('uq__user__email'), 'user', ['email', 'authority'],\n                    unique=True,\n                    postgresql_concurrently=True)\n    op.create_index(op.f('uq__user__uid'), 'user', ['uid', 'authority'],\n                    unique=True,\n                    postgresql_concurrently=True)\n    op.create_index(op.f('uq__user__username'), 'user', ['username', 'authority'],\n                    unique=True,\n                    postgresql_concurrently=True)\n\n    # Lastly, we can create the constraints using the new indices\n    op.execute(sa.text('ALTER TABLE \"user\" ADD CONSTRAINT uq__user__email UNIQUE USING INDEX uq__user__email'))\n    op.execute(sa.text('ALTER TABLE \"user\" ADD CONSTRAINT uq__user__uid UNIQUE USING INDEX uq__user__uid'))\n    op.execute(sa.text('ALTER TABLE \"user\" ADD CONSTRAINT uq__user__username UNIQUE USING INDEX uq__user__username'))\n\ndef downgrade():\n    op.drop_constraint('uq__user__email', 'user')\n    op.drop_constraint('uq__user__uid', 'user')\n    op.drop_constraint('uq__user__username', 'user')\n\n    op.execute(sa.text('ALTER TABLE \"user\" RENAME CONSTRAINT uq__user__email_old TO uq__user__email'))\n    op.execute(sa.text('ALTER TABLE \"user\" RENAME CONSTRAINT uq__user__uid_old TO uq__user__uid'))\n    op.execute(sa.text('ALTER TABLE \"user\" RENAME CONSTRAINT uq__user__username_old TO uq__user__username'))\n"},{"size":2377,"relativepath":"h/migrations/versions/dfa82518915a_create_document_tables.py","filename":"dfa82518915a_create_document_tables.py","extension":".py","content":"\"\"\"Create document tables\n\nRevision ID: dfa82518915a\nRevises: 4c0c44605c09\nCreate Date: 2016-02-10 14:52:08.236839\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = 'dfa82518915a'\ndown_revision = '4c0c44605c09'\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects import postgresql\n\n\ndef upgrade():\n    op.create_table('document',\n        sa.Column('id', sa.Integer, primary_key=True),\n        sa.Column('created', sa.DateTime, server_default=sa.func.now(), nullable=False),\n        sa.Column('updated', sa.DateTime, server_default=sa.func.now(), nullable=False),\n    )\n\n    op.create_table('document_meta',\n        sa.Column('id', sa.Integer, primary_key=True),\n        sa.Column('created', sa.DateTime, server_default=sa.func.now(), nullable=False),\n        sa.Column('updated', sa.DateTime, server_default=sa.func.now(), nullable=False),\n        sa.Column('claimant', sa.UnicodeText, nullable=False),\n        sa.Column('claimant_normalized', sa.UnicodeText, nullable=False),\n        sa.Column('type', sa.UnicodeText, nullable=False),\n        sa.Column('value', postgresql.ARRAY(sa.UnicodeText, zero_indexes=True), nullable=False),\n        sa.Column('document_id', sa.Integer, nullable=False),\n        sa.ForeignKeyConstraint(['document_id'], [u'document.id']),\n        sa.UniqueConstraint('claimant_normalized', 'type'),\n    )\n\n    op.create_table('document_uri',\n        sa.Column('id', sa.Integer, primary_key=True),\n        sa.Column('created', sa.DateTime, server_default=sa.func.now(), nullable=False),\n        sa.Column('updated', sa.DateTime, server_default=sa.func.now(), nullable=False),\n        sa.Column('claimant', sa.UnicodeText, nullable=False),\n        sa.Column('claimant_normalized', sa.UnicodeText, nullable=False),\n        sa.Column('uri', sa.UnicodeText, nullable=False),\n        sa.Column('uri_normalized', sa.UnicodeText, nullable=False, index=True),\n        sa.Column('type', sa.UnicodeText, nullable=True),\n        sa.Column('content_type', sa.UnicodeText, nullable=True),\n        sa.Column('document_id', sa.Integer(), nullable=False),\n        sa.ForeignKeyConstraint(['document_id'], [u'document.id']),\n        sa.UniqueConstraint('claimant_normalized', 'uri_normalized', 'type', 'content_type')\n    )\n\n\ndef downgrade():\n    op.drop_table('document_uri')\n    op.drop_table('document_meta')\n    op.drop_table('document')\n"},{"size":2263,"relativepath":"h/migrations/versions/4c0c44605c09_create_annotation_table.py","filename":"4c0c44605c09_create_annotation_table.py","extension":".py","content":"\"\"\"Create annotation table\n\nRevision ID: 4c0c44605c09\nRevises: 4886d7a14074\nCreate Date: 2016-01-20 12:58:16.249481\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = '4c0c44605c09'\ndown_revision = '21f87f395e26'\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects import postgresql\n\n\nfrom memex.db import types\n\n\ndef upgrade():\n    op.create_table('annotation',\n        sa.Column('id',\n                  types.URLSafeUUID,\n                  server_default=sa.func.uuid_generate_v1mc(),\n                  primary_key=True),\n        sa.Column('created', sa.DateTime, server_default=sa.func.now(), nullable=False),\n        sa.Column('updated', sa.DateTime, server_default=sa.func.now(), nullable=False),\n        sa.Column('userid', sa.UnicodeText(), nullable=False),\n        sa.Column('groupid', sa.UnicodeText(), server_default=u'__world__', nullable=False),\n        sa.Column('text', sa.UnicodeText(), nullable=True),\n        sa.Column('tags', postgresql.ARRAY(sa.UnicodeText, zero_indexes=True), nullable=True),\n        sa.Column('shared', sa.Boolean, server_default=sa.sql.expression.false(), nullable=False),\n        sa.Column('target_uri', sa.UnicodeText(), nullable=False),\n        sa.Column('target_uri_normalized', sa.UnicodeText(), nullable=False),\n        sa.Column('target_selectors',\n                  postgresql.JSONB,\n                  server_default=sa.func.jsonb('[]'),\n                  nullable=True),\n        sa.Column('references',\n                  postgresql.ARRAY(types.URLSafeUUID),\n                  server_default=sa.text('ARRAY[]::uuid[]'),\n                  nullable=True),\n        sa.Column('extra', postgresql.JSONB, nullable=True),\n    )\n    op.create_index(op.f('ix__annotation_groupid'), 'annotation', ['groupid'], unique=False)\n    op.create_index(op.f('ix__annotation_tags'), 'annotation', ['tags'], postgresql_using='gin', unique=False)\n    op.create_index(op.f('ix__annotation_userid'), 'annotation', ['userid'], unique=False)\n\n\ndef downgrade():\n    op.drop_index(op.f('ix__annotation_userid'), table_name='annotation')\n    op.drop_index(op.f('ix__annotation_tags'), table_name='annotation')\n    op.drop_index(op.f('ix__annotation_groupid'), table_name='annotation')\n    op.drop_table('annotation')\n"},{"size":1257,"relativepath":"h/migrations/versions/6d9257ad610d_delete_empty_array_document_titles.py","filename":"6d9257ad610d_delete_empty_array_document_titles.py","extension":".py","content":"\"\"\"\nDelete document_meta rows that have type 'title' and an empty array value.\n\nRevision ID: 6d9257ad610d\nRevises: 3d71ec81d18c\nCreate Date: 2016-09-14 16:06:33.439592\n\"\"\"\nfrom __future__ import unicode_literals\n\nimport logging\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects import postgresql as pg\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\n\nrevision = '6d9257ad610d'\ndown_revision = '3d71ec81d18c'\n\n\nlog = logging.getLogger(__name__)\n\n\nBase = declarative_base()\nSession = sessionmaker()\n\n\nclass DocumentMeta(Base):\n    __tablename__ = 'document_meta'\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n    type = sa.Column(sa.UnicodeText)\n    value = sa.Column(pg.ARRAY(sa.UnicodeText, zero_indexes=True))\n\n\ndef upgrade():\n    session = Session(bind=op.get_bind())\n    to_delete = []\n    for document_meta in session.query(DocumentMeta).filter_by(type='title'):\n        if document_meta.value == []:\n            to_delete.append(document_meta)\n    for document_meta in to_delete:\n        session.delete(document_meta)\n    session.commit()\n    log.info(\"deleted {n} empty-array document titles\".format(\n        n=len(to_delete)))\n\n\ndef downgrade():\n    pass\n"},{"size":2425,"relativepath":"h/migrations/versions/a44ef07b085a_fill_in_missing_denormalized_document_web_uri.py","filename":"a44ef07b085a_fill_in_missing_denormalized_document_web_uri.py","extension":".py","content":"\"\"\"\nFill in missing denormalized Document.web_uri\n\nRevision ID: a44ef07b085a\nRevises: 58bb601c390f\nCreate Date: 2016-09-12 15:31:00.597582\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom collections import namedtuple\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\nfrom sqlalchemy.orm import subqueryload\n\nfrom memex._compat import urlparse\n\n\nrevision = 'a44ef07b085a'\ndown_revision = '58bb601c390f'\n\nBase = declarative_base()\nSession = sessionmaker()\n\n\nclass Window(namedtuple('Window', ['start', 'end'])):\n    pass\n\n\nclass Document(Base):\n    __tablename__ = 'document'\n    id = sa.Column(sa.Integer, primary_key=True)\n    updated = sa.Column(sa.DateTime)\n    web_uri = sa.Column(sa.UnicodeText())\n    document_uris = sa.orm.relationship('DocumentURI',\n                                        backref='document',\n                                        order_by='DocumentURI.created.asc()')\n\n\nclass DocumentURI(Base):\n    __tablename__ = 'document_uri'\n    id = sa.Column(sa.Integer, primary_key=True)\n    created = sa.Column(sa.DateTime)\n    uri = sa.Column(sa.UnicodeText)\n    document_id = sa.Column(sa.Integer,\n                            sa.ForeignKey('document.id'),\n                            nullable=False)\n\n\ndef upgrade():\n    session = Session(bind=op.get_bind())\n\n    windows = _fetch_windows(session)\n    session.rollback()\n\n    for window in windows:\n        query = session.query(Document) \\\n            .filter(Document.updated.between(window.start, window.end)) \\\n            .options(subqueryload(Document.document_uris)) \\\n            .order_by(Document.updated.asc())\n\n        for doc in query:\n            doc.web_uri = _document_web_uri(doc)\n\n        session.commit()\n\n\ndef downgrade():\n    pass\n\n\ndef _document_web_uri(document):\n    for docuri in document.document_uris:\n        uri = urlparse.urlparse(docuri.uri)\n        if uri.scheme in ['http', 'https']:\n            return docuri.uri\n\n\ndef _fetch_windows(session, chunksize=100):\n    updated = session.query(Document.updated). \\\n        execution_options(stream_results=True). \\\n        order_by(Document.updated.desc()).all()\n\n    count = len(updated)\n    windows = [Window(start=updated[min(x+chunksize, count)-1].updated,\n                      end=updated[x].updated)\n               for x in xrange(0, count, chunksize)]\n\n    return windows\n"},{"size":423,"relativepath":"h/migrations/versions/5dce9a8c42c2_disallow_null_annotation_document_id.py","filename":"5dce9a8c42c2_disallow_null_annotation_document_id.py","extension":".py","content":"\"\"\"\nDisallow null annotation document_id\n\nRevision ID: 5dce9a8c42c2\nRevises: bcdd81e23920\nCreate Date: 2016-09-22 17:22:09.294825\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom alembic import op\n\n\nrevision = '5dce9a8c42c2'\ndown_revision = 'bcdd81e23920'\n\n\ndef upgrade():\n    op.alter_column('annotation', 'document_id', nullable=False)\n\n\ndef downgrade():\n    op.alter_column('annotation', 'document_id', nullable=True)\n"},{"size":1369,"relativepath":"h/migrations/versions/63e8b1fe1d4b_clean_up_document_uris.py","filename":"63e8b1fe1d4b_clean_up_document_uris.py","extension":".py","content":"\"\"\"\nRemove whitespace from the document_uri.uri column.\n\nRevision ID: 63e8b1fe1d4b\nRevises: 6d9257ad610d\nCreate Date: 2016-09-15 15:26:31.286536\n\"\"\"\nfrom __future__ import unicode_literals\n\nimport logging\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\n\nrevision = '63e8b1fe1d4b'\ndown_revision = '53a74d7ae1b0'\n\nlog = logging.getLogger(__name__)\n\n\nBase = declarative_base()\nSession = sessionmaker()\n\n\nclass DocumentURI(Base):\n    __tablename__ = 'document_uri'\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n    uri = sa.Column(sa.UnicodeText)\n\n\ndef upgrade():\n    session = Session(bind=op.get_bind())\n    changed = []\n    to_delete = []\n    for document_uri in session.query(DocumentURI):\n\n        stripped_uri = document_uri.uri.strip()\n        if not stripped_uri:\n            to_delete.append(document_uri)\n        elif stripped_uri != document_uri.uri:\n            document_uri.uri = stripped_uri\n            changed.append(document_uri)\n\n    for document_uri in to_delete:\n        session.delete(document_uri)\n\n    session.commit()\n\n    log.info(\n        \"Removed whitespace from {n} document_uris\".format(n=len(changed)))\n    log.info(\n        \"Deleted {n} document_uris with empty uris\".format(n=len(to_delete)))\n\n\ndef downgrade():\n    pass\n"},{"size":1484,"relativepath":"h/migrations/versions/3d71ec81d18c_delete_empty_document_titles.py","filename":"3d71ec81d18c_delete_empty_document_titles.py","extension":".py","content":"\"\"\"\nDelete empty-string document titles.\n\nRevision ID: 3d71ec81d18c\nRevises: 6964a8237c88\nCreate Date: 2016-09-14 16:03:41.490371\n\"\"\"\nfrom __future__ import unicode_literals\n\nimport logging\n\nfrom alembic import op\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects import postgresql as pg\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\n\nrevision = '3d71ec81d18c'\ndown_revision = '6964a8237c88'\n\n\nlog = logging.getLogger(__name__)\n\n\nBase = declarative_base()\nSession = sessionmaker()\n\n\nclass DocumentMeta(Base):\n    __tablename__ = 'document_meta'\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n    type = sa.Column(sa.UnicodeText)\n    value = sa.Column(pg.ARRAY(sa.UnicodeText, zero_indexes=True))\n\n\ndef upgrade():\n    session = Session(bind=op.get_bind())\n    n = 0\n    for document_meta in session.query(DocumentMeta).filter_by(type='title'):\n        new_titles = []\n        for original_title in document_meta.value:\n            if original_title == '':\n                n += 1\n                log.info(\n                    \"removing empty title from document_meta {id}\".format(\n                        id=document_meta.id))\n            else:\n                new_titles.append(original_title)\n        if len(new_titles) != len(document_meta.value):\n            document_meta.value = new_titles\n    session.commit()\n    log.info(\"deleted {n} empty-string document titles\".format(n=n))\n\n\ndef downgrade():\n    pass\n"},{"size":504,"relativepath":"h/migrations/versions/1ef80156ee4_add_sidebar_tutorial_dismissed_column_.py","filename":"1ef80156ee4_add_sidebar_tutorial_dismissed_column_.py","extension":".py","content":"\"\"\"Add the sidebar_tutorial_dismissed column to user table.\n\nRevision ID: 1ef80156ee4\nRevises: 43645baa68b2\nCreate Date: 2015-12-21 18:49:15.688177\n\n\"\"\"\n\n# revision identifiers, used by Alembic.\nrevision = '1ef80156ee4'\ndown_revision = '43e7c4ed2fd7'\n\nfrom alembic import op\nimport sqlalchemy as sa\n\n\ndef upgrade():\n    op.add_column(\n        'user',\n        sa.Column('sidebar_tutorial_dismissed', sa.Boolean(), nullable=True))\n\ndef downgrade():\n    op.drop_column('user', 'sidebar_tutorial_dismissed')\n"},{"size":699,"relativepath":"h/migrations/versions/504a6a4db06d_relax_password_constraints.py","filename":"504a6a4db06d_relax_password_constraints.py","extension":".py","content":"\"\"\"\nRelax password constraints\n\nRevision ID: 504a6a4db06d\nRevises: de42d613c18d\nCreate Date: 2016-08-18 22:32:51.092582\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport sqlalchemy as sa\nfrom alembic import op\n\n\nrevision = '504a6a4db06d'\ndown_revision = 'de42d613c18d'\n\n\ndef upgrade():\n    op.alter_column('user', 'password', nullable=True)\n    op.alter_column('user', 'password_updated', nullable=True, server_default=None)\n    op.alter_column('user', 'salt', nullable=True)\n\ndef downgrade():\n    op.alter_column('user', 'password', nullable=False)\n    op.alter_column('user', 'password_updated', nullable=False, server_default=sa.func.now())\n    op.alter_column('user', 'salt', nullable=False)\n"},{"size":54226,"relativepath":"h/static/styles/vendor/fonts/selection.json","filename":"selection.json","extension":".json","content":"{\n\t\"IcoMoonType\": \"selection\",\n\t\"icons\": [\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M640 64c0-35.593-28.624-64-63.933-64h-64.134c-35.603 0-63.933 28.654-63.933 64h-63.813c-36.163 0-64.187 28.624-64.187 63.933l-128.096 0.067c-35.265 0-63.904 28.85-63.904 64.438v767.124c0 35.641 28.611 64.438 63.904 64.438h704.192c35.265 0 63.904-28.85 63.904-64.438v-767.124c0-35.641-28.611-64.438-63.904-64.438h-128.096v-0.067c0-35.603-28.738-63.933-64.187-63.933h-63.813zM256 128h64v128h448v-128h64v192h-576v-192z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"grid\": 16,\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"clipboard\"\n\t\t\t\t],\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": [\n\t\t\t\t\t\t1\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 70,\n\t\t\t\t\"id\": 38,\n\t\t\t\t\"name\": \"clipboard\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 59660\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 0\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M0 73.324c0-40.496 32.806-73.324 73.324-73.324h731.067c40.496 0 73.324 32.806 73.324 73.324v731.067c0 40.496-32.806 73.324-73.324 73.324h-731.067c-40.496 0-73.324-32.806-73.324-73.324v-731.067zM329.143 877.714l109.714 146.286 109.714-146.286h-219.429zM256.297 146.286h-110.011v585.143h110.011v-182.751c0-109.651 42.428-109.465 72.846-109.82 36.571 0.265 73.835 2.219 73.835 73.27v219.301h110.011v-252.022c0-113.693-74.132-150.151-147.275-150.151-72.747 0-73.143 0-109.418 73.1v-256.071zM694.857 730.949c40.396 0 73.143-32.64 73.143-72.903s-32.747-72.903-73.143-72.903c-40.396 0-73.143 32.64-73.143 72.903s32.747 72.903 73.143 72.903z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"width\": 878,\n\t\t\t\t\"grid\": 16,\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"hypothesis-logo\"\n\t\t\t\t],\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": [\n\t\t\t\t\t\t1\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 69,\n\t\t\t\t\"id\": 37,\n\t\t\t\t\"name\": \"hypothesis-logo\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 59659\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 1\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M64 960h-64c0 0 0 0 0-64 0-128 64-192 64-192l448-448 192 192-448 448c0 0-64 64-192 64zM576 192l192 192c0 0 0 0 64-64s64-128 0-192c-64-64-128-64-192 0s-64 64-64 64z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"annotation-edit\"\n\t\t\t\t],\n\t\t\t\t\"grid\": 16,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": [\n\t\t\t\t\t\t1\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t\"width\": 896\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 1,\n\t\t\t\t\"id\": 0,\n\t\t\t\t\"name\": \"annotation-edit\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 59655\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 2\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M346.506 384h-101.49l128-128-90.51-90.51-282.51 282.51 282.51 282.51 90.51-90.51-128-128h101.49c384 0 384 384 384 384h128c0 0 0-512-512-512v0z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"Reply\",\n\t\t\t\t\t\"annotation-reply\"\n\t\t\t\t],\n\t\t\t\t\"grid\": 16,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": [\n\t\t\t\t\t\t1\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t\"width\": 864\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 67,\n\t\t\t\t\"id\": 1,\n\t\t\t\t\"name\": \"annotation-reply\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 59658\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 3\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M0 320h576l-58.208 640.283c-3.199 35.19-33.817 63.717-69.98 63.717h-319.625c-35.45 0-66.776-28.47-69.98-63.717l-58.208-640.283z\",\n\t\t\t\t\t\"M11.113 63.028c6.138-34.809 39.243-58.068 73.986-51.942l441.503 77.849c34.724 6.123 57.94 39.062 51.759 74.114l-11.113 63.028-567.249-100.021 11.113-63.028z\"\n\t\t\t\t],\n\t\t\t\t\"width\": 608,\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"trash\",\n\t\t\t\t\t\"annotation-delete\"\n\t\t\t\t],\n\t\t\t\t\"grid\": 16,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": [\n\t\t\t\t\t\t1,\n\t\t\t\t\t\t1\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 63,\n\t\t\t\t\"id\": 2,\n\t\t\t\t\"name\": \"annotation-delete\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 59656\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 4\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M311.010 597.007c5.823-16.589 8.99-34.429 8.99-53.007s-3.167-36.418-8.99-53.007l197.902-141.359c27.25 21.521 61.668 34.366 99.087 34.366 88.366 0 160-71.634 160-160s-71.634-160-160-160c-88.366 0-160 71.634-160 160 0 18.579 3.167 36.418 8.99 53.007l-197.902 141.359c-27.25-21.521-61.668-34.366-99.087-34.366-88.366 0-160 71.634-160 160s71.634 160 160 160c37.419 0 71.838-12.845 99.087-34.366l197.902 141.359c-5.823 16.589-8.99 34.429-8.99 53.007 0 88.366 71.634 160 160 160s160-71.634 160-160c0-88.366-71.634-160-160-160-37.419 0-71.838 12.845-99.087 34.366l-197.902-141.359z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"annotation-share\"\n\t\t\t\t],\n\t\t\t\t\"grid\": 16,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": [\n\t\t\t\t\t\t1\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t\"width\": 768\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 64,\n\t\t\t\t\"id\": 3,\n\t\t\t\t\"name\": \"annotation-share\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 59657\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 5\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M448 448v153.6h254.080c-10.24 65.92-76.8 193.28-254.080 193.28-152.96 0-277.76-126.72-277.76-282.88s124.8-282.88 277.76-282.88c87.040 0 145.28 37.12 178.56 69.12l121.6-117.12c-78.080-72.96-179.2-117.12-300.16-117.12-247.68 0-448 200.32-448 448s200.32 448 448 448c258.56 0 430.080-181.76 430.080-437.76 0-29.44-3.2-51.84-7.040-74.24h-423.040z\",\n\t\t\t\t\t\"M1408 448h-128v-128h-128v128h-128v128h128v128h128v-128h128z\"\n\t\t\t\t],\n\t\t\t\t\"width\": 1417,\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"google-plus\",\n\t\t\t\t\t\"brand\",\n\t\t\t\t\t\"social\"\n\t\t\t\t],\n\t\t\t\t\"grid\": 16,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": [\n\t\t\t\t\t\t1,\n\t\t\t\t\t\t1\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 58,\n\t\t\t\t\"id\": 4,\n\t\t\t\t\"name\": \"google-plus\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 59654\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 6\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M324.901 387.878c23.454-131.878 123.099-131.878 123.099-131.878v-64c0 0-192 0-192 256 0 5.664 0.501 10.826 1.415 15.487-0.93 5.365-1.415 10.882-1.415 16.513 0 53.019 42.981 96 96 96s96-42.981 96-96c0-53.019-42.981-96-96-96-9.411 0-18.505 1.354-27.099 3.878zM644.901 387.878c23.454-131.878 123.099-131.878 123.099-131.878v-64c0 0-192 0-192 256 0 5.664 0.501 10.826 1.415 15.487-0.93 5.365-1.415 10.882-1.415 16.513 0 53.019 42.981 96 96 96s96-42.981 96-96c0-53.019-42.981-96-96-96-9.411 0-18.505 1.354-27.099 3.878zM0 63.904c0-35.293 28.456-63.904 64.056-63.904h895.888c35.377 0 64.056 29.134 64.056 64.269v959.731l-256-192h-703.842c-35.434 0-64.158-28.639-64.158-63.904v-704.192z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(122, 122, 122)\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": [\n\t\t\t\t\t\t0\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"annotate\"\n\t\t\t\t],\n\t\t\t\t\"grid\": 16\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(122, 122, 122)\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 52,\n\t\t\t\t\"id\": 5,\n\t\t\t\t\"name\": \"annotate\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 59651\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 7\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M192 960h512v64h-512v-64z\",\n\t\t\t\t\t\"M576 0h256l64 576h-384l64-576z\",\n\t\t\t\t\t\"M768 768l64-64v-64h-256v64l64 64v128h64l64-64v-64z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(122, 122, 122)\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(122, 122, 122)\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(122, 122, 122)\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": [\n\t\t\t\t\t\t0,\n\t\t\t\t\t\t0,\n\t\t\t\t\t\t0\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"highlight\"\n\t\t\t\t],\n\t\t\t\t\"grid\": 16\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(122, 122, 122)\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(122, 122, 122)\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(122, 122, 122)\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 53,\n\t\t\t\t\"id\": 6,\n\t\t\t\t\"name\": \"highlight\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 59652\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 8\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M64 128.438v767.124c0 35.641 28.85 64.438 64.438 64.438h703.187c70.963 0 128.375-57.475 128.375-128.375v-703.187c0-35.641-28.85-64.438-64.438-64.438h-767.124c-35.641 0-64.438 28.85-64.438 64.438zM192 256h640v64h-640v-64zM192 448h576v64h-576v-64zM192 640h384v64h-384v-64zM768 704h192v64h-192v-64zM704 704h64v256h-64v-256z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(122, 122, 122)\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": [\n\t\t\t\t\t\t0\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"note\"\n\t\t\t\t],\n\t\t\t\t\"grid\": 16\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(122, 122, 122)\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 54,\n\t\t\t\t\"id\": 7,\n\t\t\t\t\"name\": \"note\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 59653\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 9\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M704 320c0-128-64-256-256-256s-256 128-256 256c0 101.519 80.517 283.555 177.691 354.529-9.267 33.272-24.535 68.315-49.691 93.471-0.752 0.752-1.558 1.512-2.415 2.278-142.872 6.448-317.585 31.142-317.585 125.722 0 26.128 0 64 0 64s128 64 448 64c320 0 448-64 448-64v-64c0-94.58-174.714-119.274-317.586-125.722-0.856-0.767-1.662-1.526-2.414-2.278-25.156-25.156-40.424-60.199-49.691-93.471 97.174-70.975 177.691-253.010 177.691-354.529z\"\n\t\t\t\t],\n\t\t\t\t\"width\": 896,\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"account\"\n\t\t\t\t],\n\t\t\t\t\"grid\": 16,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": [\n\t\t\t\t\t\t1\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 1,\n\t\t\t\t\"id\": 8,\n\t\t\t\t\"name\": \"account\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 59392\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 10\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M256 282.51v357.49h128v-357.49l128 128 90.51-90.51-282.51-282.51-282.51 282.51 90.51 90.51 128-128z\",\n\t\t\t\t\t\"M640 741.49v-357.49h128v357.49l128-128 90.51 90.51-282.51 282.51-282.51-282.51 90.51-90.51 128 128z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"filter\"\n\t\t\t\t],\n\t\t\t\t\"grid\": 16,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": [\n\t\t\t\t\t\t1,\n\t\t\t\t\t\t1\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 2,\n\t\t\t\t\"id\": 9,\n\t\t\t\t\"name\": \"sort\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 59393\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 11\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M786.342 727.020c62.469-47.317 114.23-168.674 114.23-236.353 0-85.333-41.143-170.667-164.571-170.667s-164.571 85.333-164.571 170.667c0 67.679 51.761 189.036 114.23 236.353-5.957 22.181-15.772 45.543-31.944 62.314-0.483 0.501-1.002 1.008-1.552 1.519-91.847 4.298-204.162 20.761-204.162 83.814 0 17.419 0 42.667 0 42.667s82.286 42.667 288 42.667c205.714 0 288-42.667 288-42.667v-42.667c0-63.053-112.316-79.516-204.163-83.814-0.55-0.511-1.068-1.018-1.552-1.519-16.171-16.77-25.987-40.133-31.944-62.314v0z\",\n\t\t\t\t\t\"M338.342 535.020c62.469-47.317 114.23-168.674 114.23-236.353 0-85.333-41.143-170.667-164.571-170.667s-164.571 85.333-164.571 170.667c0 67.679 51.761 189.036 114.23 236.353-5.957 22.181-15.772 45.543-31.944 62.314-0.483 0.501-1.002 1.008-1.552 1.519-91.847 4.298-204.162 20.761-204.162 83.814 0 17.419 0 42.667 0 42.667s82.286 42.667 288 42.667c205.714 0 288-42.667 288-42.667v-42.667c0-63.053-112.316-79.516-204.163-83.814-0.55-0.511-1.068-1.018-1.552-1.519-16.171-16.77-25.987-40.133-31.944-62.314v0z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"groups\"\n\t\t\t\t],\n\t\t\t\t\"grid\": 16,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": [\n\t\t\t\t\t\t1,\n\t\t\t\t\t\t1\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 3,\n\t\t\t\t\"id\": 10,\n\t\t\t\t\"name\": \"group\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58910\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 12\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M512 0c-282.77 0-512 229.23-512 512s229.23 512 512 512 512-229.23 512-512-229.23-512-512-512zM512 928c-229.75 0-416-186.25-416-416s186.25-416 416-416 416 186.25 416 416-186.25 416-416 416z\",\n\t\t\t\t\t\"M672 256l-160 160-160-160-96 96 160 160-160 160 96 96 160-160 160 160 96-96-160-160 160-160z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"cancel-circle\",\n\t\t\t\t\t\"close\",\n\t\t\t\t\t\"remove\",\n\t\t\t\t\t\"delete\"\n\t\t\t\t],\n\t\t\t\t\"grid\": 16\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 4,\n\t\t\t\t\"id\": 11,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"cancel-outline\",\n\t\t\t\t\"code\": 58905\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 13\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M559.066 64c0 0-200.956 0-267.94 0-120.12 0-233.17 91.006-233.17 196.422 0 107.726 81.882 194.666 204.088 194.666 8.498 0 16.756-0.17 24.842-0.752-7.93 15.186-13.602 32.288-13.602 50.042 0 29.938 16.104 54.21 36.468 74.024-15.386 0-30.242 0.448-46.452 0.448-148.782-0.002-263.3 94.758-263.3 193.020 0 96.778 125.542 157.314 274.334 157.314 169.624 0 263.306-96.244 263.306-193.028 0-77.6-22.896-124.072-93.686-174.134-24.216-17.144-70.53-58.836-70.53-83.344 0-28.72 8.196-42.868 51.428-76.646 44.312-34.624 75.672-83.302 75.672-139.916 0-67.406-30.020-133.098-86.372-154.772h84.954l59.96-43.344zM465.48 719.458c2.126 8.972 3.284 18.206 3.284 27.628 0 78.2-50.392 139.31-194.974 139.31-102.842 0-177.116-65.104-177.116-143.3 0-76.642 92.126-140.444 194.964-139.332 24 0.254 46.368 4.116 66.67 10.69 55.826 38.826 95.876 60.762 107.172 105.004zM300.818 427.776c-69.038-2.064-134.636-77.226-146.552-167.86-11.916-90.666 34.37-160.042 103.388-157.99 69.010 2.074 134.638 74.814 146.558 165.458 11.906 90.66-34.39 162.458-103.394 160.392zM832 256v-192h-64v192h-192v64h192v192h64v-192h192v-64z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"google-plus\",\n\t\t\t\t\t\"brand\",\n\t\t\t\t\t\"social\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58515,\n\t\t\t\t\"grid\": 16\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 12,\n\t\t\t\t\"order\": 5,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 60040,\n\t\t\t\t\"ligatures\": \"google-plus, brand2\",\n\t\t\t\t\"name\": \"google-plus-old\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 14\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M910.551 960h-797.099c-27.32 0-49.452-22.146-49.452-49.455v-797.093c0-27.316 22.136-49.452 49.452-49.452h797.099c27.309 0 49.449 22.136 49.449 49.452v797.093c0 27.313-22.143 49.455-49.449 49.455zM704.98 605.631h116.725l17.478-135.204h-134.203v-86.319c0-39.145 10.896-65.82 67.162-65.82l71.765-0.031v-120.927c-12.412-1.648-55.012-5.329-104.574-5.329-103.47 0-174.308 63.008-174.308 178.718v99.709h-117.024v135.204h117.024v354.369h139.955v-354.369z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"facebook\",\n\t\t\t\t\t\"brand\",\n\t\t\t\t\t\"social\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58521,\n\t\t\t\t\"grid\": 16,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": [\n\t\t\t\t\t\t1\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 13,\n\t\t\t\t\"order\": 6,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 60045,\n\t\t\t\t\"ligatures\": \"facebook2, brand7\",\n\t\t\t\t\"name\": \"facebook\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 15\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M1024 194.418c-37.676 16.708-78.164 28.002-120.66 33.080 43.372-26 76.686-67.17 92.372-116.23-40.596 24.078-85.556 41.56-133.41 50.98-38.32-40.83-92.922-66.34-153.346-66.34-116.022 0-210.088 94.058-210.088 210.078 0 16.466 1.858 32.5 5.44 47.878-174.6-8.764-329.402-92.4-433.018-219.506-18.084 31.028-28.446 67.116-28.446 105.618 0 72.888 37.088 137.192 93.46 174.866-34.438-1.092-66.832-10.542-95.154-26.278-0.020 0.876-0.020 1.756-0.020 2.642 0 101.788 72.418 186.696 168.522 206-17.626 4.8-36.188 7.372-55.348 7.372-13.538 0-26.698-1.32-39.528-3.772 26.736 83.46 104.32 144.206 196.252 145.896-71.9 56.35-162.486 89.934-260.916 89.934-16.958 0-33.68-0.994-50.116-2.94 92.972 59.61 203.402 94.394 322.042 94.394 386.422 0 597.736-320.124 597.736-597.744 0-9.108-0.206-18.168-0.61-27.18 41.056-29.62 76.672-66.62 104.836-108.748z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"twitter\",\n\t\t\t\t\t\"brand\",\n\t\t\t\t\t\"tweet\",\n\t\t\t\t\t\"social\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58525,\n\t\t\t\t\"grid\": 16\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 14,\n\t\t\t\t\"order\": 7,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 60049,\n\t\t\t\t\"ligatures\": \"twitter, brand11\",\n\t\t\t\t\"name\": \"twitter\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 16\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M512.008 12.642c-282.738 0-512.008 229.218-512.008 511.998 0 226.214 146.704 418.132 350.136 485.836 25.586 4.738 34.992-11.11 34.992-24.632 0-12.204-0.48-52.542-0.696-95.324-142.448 30.976-172.504-60.41-172.504-60.41-23.282-59.176-56.848-74.916-56.848-74.916-46.452-31.778 3.51-31.124 3.51-31.124 51.4 3.61 78.476 52.766 78.476 52.766 45.672 78.27 119.776 55.64 149.004 42.558 4.588-33.086 17.852-55.68 32.506-68.464-113.73-12.942-233.276-56.85-233.276-253.032 0-55.898 20.004-101.574 52.76-137.428-5.316-12.9-22.854-64.972 4.952-135.5 0 0 43.006-13.752 140.84 52.49 40.836-11.348 84.636-17.036 128.154-17.234 43.502 0.198 87.336 5.886 128.256 17.234 97.734-66.244 140.656-52.49 140.656-52.49 27.872 70.528 10.35 122.6 5.036 135.5 32.82 35.856 52.694 81.532 52.694 137.428 0 196.654-119.778 239.95-233.79 252.624 18.364 15.89 34.724 47.046 34.724 94.812 0 68.508-0.596 123.644-0.596 140.508 0 13.628 9.222 29.594 35.172 24.566 203.322-67.776 349.842-259.626 349.842-485.768 0-282.78-229.234-511.998-511.992-511.998z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"github\",\n\t\t\t\t\t\"brand\",\n\t\t\t\t\t\"octacat\",\n\t\t\t\t\t\"social\"\n\t\t\t\t],\n\t\t\t\t\"grid\": 16\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 8,\n\t\t\t\t\"id\": 15,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"ligatures\": \"github, brand40\",\n\t\t\t\t\"name\": \"github\",\n\t\t\t\t\"code\": 59648\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 17\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M136.294 750.93c-75.196 0-136.292 61.334-136.292 136.076 0 75.154 61.1 135.802 136.292 135.802 75.466 0 136.494-60.648 136.494-135.802-0.002-74.742-61.024-136.076-136.494-136.076zM0.156 347.93v196.258c127.784 0 247.958 49.972 338.458 140.512 90.384 90.318 140.282 211.036 140.282 339.3h197.122c-0.002-372.82-303.282-676.070-675.862-676.070zM0.388 0v196.356c455.782 0 826.756 371.334 826.756 827.644h196.856c0-564.47-459.254-1024-1023.612-1024z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"feed\",\n\t\t\t\t\t\"rss\",\n\t\t\t\t\t\"social\"\n\t\t\t\t],\n\t\t\t\t\"grid\": 16\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 16,\n\t\t\t\t\"order\": 9,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"ligatures\": \"feed2, rss\",\n\t\t\t\t\"name\": \"feed\",\n\t\t\t\t\"code\": 59649\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 18\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M511.102 7.877c141.596 0 261.041 48.601 358.274 145.833 97.8 97.831 146.747 217.261 146.747 358.29 0 141.643-48.033 259.56-144.069 353.768-102.022 100.242-222.334 150.355-360.952 150.355-136.255 0-254.472-49.53-354.682-148.559-99.013-99.029-148.543-217.529-148.543-355.564 0-138.019 49.53-257.449 148.543-358.274 97.233-97.248 215.434-145.849 354.682-145.849v0zM512.898 98.808c-114.625 0-211.543 40.22-290.769 120.627-82.235 84.031-123.337 181.563-123.337 292.58 0 111.632 40.802 208.266 122.407 289.839 81.621 81.636 178.838 122.423 291.667 122.423 112.215 0 210.062-41.070 293.478-123.321 79.226-76.217 118.831-172.536 118.831-288.973 0-114.625-40.22-212.126-120.611-292.565-80.408-80.408-177.64-120.611-291.667-120.611v0zM647.94 386.867v206.139h-57.596v244.846h-156.656v-244.831h-57.596v-206.155c0-9.011 3.151-16.652 9.437-22.953 6.317-6.286 13.974-9.452 22.953-9.452h207.069c8.397 0 15.911 3.151 22.496 9.452 6.569 6.302 9.893 13.958 9.893 22.953v0zM441.769 257.245c0-47.388 23.394-71.113 70.231-71.113s70.215 23.694 70.215 71.113c0 46.805-23.41 70.215-70.215 70.215s-70.231-23.41-70.231-70.215v0z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"visibility\": false\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"by\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58911,\n\t\t\t\t\"grid\": 16\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"visibility\": false\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 10,\n\t\t\t\t\"id\": 17,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58911,\n\t\t\t\t\"name\": \"cc-by\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 19\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M512 928v0c229.75 0 416-186.25 416-416s-186.25-416-416-416c-229.75 0-416 186.25-416 416s186.25 416 416 416v0zM512 1024v0c-282.77 0-512-229.23-512-512s229.23-512 512-512c282.77 0 512 229.23 512 512s-229.23 512-512 512v0z\",\n\t\t\t\t\t\"M445.726 579.882l66.274 67.882c-33.922 34.745-80.785 56.236-132.548 56.236-103.527 0-187.452-85.961-187.452-192s83.925-192 187.452-192c51.763 0 98.626 21.49 132.548 56.235l-66.274 67.882c-16.961-17.373-40.392-28.118-66.274-28.118-51.763 0-93.726 42.981-93.726 96s41.962 96 93.726 96c25.882 0 49.313-10.745 66.274-28.118z\",\n\t\t\t\t\t\"M765.726 579.882l66.274 67.882c-33.922 34.745-80.785 56.236-132.548 56.236-103.527 0-187.452-85.961-187.452-192s83.925-192 187.452-192c51.763 0 98.626 21.49 132.548 56.235l-66.274 67.882c-16.961-17.373-40.392-28.118-66.274-28.118-51.763 0-93.726 42.981-93.726 96s41.962 96 93.726 96c25.882 0 49.313-10.745 66.274-28.118z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"cc\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58912,\n\t\t\t\t\"grid\": 16,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": [\n\t\t\t\t\t\t1,\n\t\t\t\t\t\t1,\n\t\t\t\t\t\t1\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"fill\": \"rgb(166, 166, 166)\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 11,\n\t\t\t\t\"id\": 18,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58912,\n\t\t\t\t\"name\": \"cc-logo\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 20\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M507.569 228.091c-166.439 0-208.297 157.050-208.297 290.186 0 133.152 41.842 290.186 208.297 290.186 166.424 0 208.282-157.034 208.282-290.186 0-133.136-41.858-290.186-208.282-290.186v0zM507.569 337.517c6.758 0 12.918 1.040 18.716 2.473 11.989 10.335 17.849 24.592 6.349 44.473l-110.844 203.697c-3.403-25.773-3.891-51.042-3.891-69.9 0-58.636 4.064-180.744 89.671-180.744v0zM590.529 431.426c5.876 31.256 6.711 63.898 6.711 86.851 0 58.652-4.064 180.775-89.639 180.775-6.743 0-12.95-0.709-18.716-2.143-1.103-0.331-2.111-0.677-3.182-1.056-1.764-0.504-3.623-1.071-5.293-1.733-19.062-8.113-31.067-22.78-13.769-48.727l123.888-213.969z\",\n\t\t\t\t\t\"M506.514 14.154c-139.847 0-257.717 48.679-353.737 146.511-48.632 48.632-85.748 104.086-111.569 165.92-25.206 61.235-37.762 125.070-37.762 191.693 0 67.237 12.556 131.072 37.762 191.693 25.206 60.652 61.771 115.192 109.789 163.777 48.601 48.033 103.172 85.055 163.808 110.86 61.219 25.238 125.070 37.778 191.709 37.778 66.623 0 131.387-13.013 193.82-38.833 62.417-25.821 118.091-62.921 167.322-111.553 47.435-46.206 83.322-99.202 107.315-159.208 24.592-60.605 36.722-125.464 36.722-194.513 0-68.419-12.13-133.183-36.706-193.82-24.608-61.204-60.621-115.318-108.024-162.737-99.060-98.43-219.42-147.566-360.448-147.566v0zM508.625 104.88c114.026 0 211.291 40.424 292.297 121.446 39.022 39.022 68.923 83.653 89.324 133.451 20.417 49.814 30.704 102.684 30.704 158.499 0 115.854-39.637 211.952-118.248 288.768-40.834 39.637-86.678 70.057-137.689 91.073-50.412 21.016-102.368 31.413-156.388 31.413-54.634 0-106.937-10.287-156.735-30.688-49.829-21.016-94.539-51.011-134.16-90.049-39.621-39.605-70.183-84.33-91.782-134.16-21-50.397-31.776-102.368-31.776-156.388 0-54.619 10.776-106.921 31.776-156.735 21.599-50.412 52.177-95.689 91.782-135.924 78.612-80.392 175.655-120.706 290.895-120.706v0z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{\n\t\t\t\t\t\t\"visibility\": false\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\t\"visibility\": false\n\t\t\t\t\t}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"zero\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58913,\n\t\t\t\t\"grid\": 16\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{\n\t\t\t\t\t\"visibility\": false\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"visibility\": false\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 12,\n\t\t\t\t\"id\": 19,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58913,\n\t\t\t\t\"name\": \"cc-zero\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 21\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M950.154 192h-876.308c-40.719 0-73.846 33.127-73.846 73.846v492.308c0 40.721 33.127 73.846 73.846 73.846h876.308c40.721 0 73.846-33.125 73.846-73.846v-492.308c0-40.719-33.125-73.846-73.846-73.846zM576 703.875l-128 0.125v-192l-96 123.077-96-123.077v192h-128v-384h128l96 128 96-128 128-0.125v384zM767.091 735.875l-159.091-223.875h96v-192h128v192h96l-160.909 223.875z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"6868681\": [\n\t\t\t\t\t\t0\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"markdown\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58891,\n\t\t\t\t\"grid\": 16\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 13,\n\t\t\t\t\"id\": 20,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"markdown\",\n\t\t\t\t\"code\": 58891\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 22\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M576 640v192h128l-192 192-192-192h128v-192zM448 384v-192h-128l192-192 192 192h-128v192zM384 576h-192v128l-192-192 192-192v128h192zM640 448h192v-128l192 192-192 192v-128h-192z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"move\"\n\t\t\t\t],\n\t\t\t\t\"grid\": 16\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 21,\n\t\t\t\t\"order\": 51,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 59650,\n\t\t\t\t\"name\": \"move\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 23\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M426.667 725.333l213.333-213.333-213.333-213.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"arrow-right\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58909,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 14,\n\t\t\t\t\"id\": 0,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58909,\n\t\t\t\t\"name\": \"arrow-right\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 24\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M298.667 426.667l213.333 213.333 213.333-213.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"arrow-drop-down\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58921,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 15,\n\t\t\t\t\"id\": 1,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58921,\n\t\t\t\t\"name\": \"arrow-drop-down\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 25\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M166.4 512c0-72.96 59.307-132.267 132.267-132.267h170.667v-81.067h-170.667c-117.76 0-213.333 95.573-213.333 213.333s95.573 213.333 213.333 213.333h170.667v-81.067h-170.667c-72.96 0-132.267-59.307-132.267-132.267zM341.333 554.667h341.333v-85.333h-341.333v85.333zM725.333 298.667h-170.667v81.067h170.667c72.96 0 132.267 59.307 132.267 132.267s-59.307 132.267-132.267 132.267h-170.667v81.067h170.667c117.76 0 213.333-95.573 213.333-213.333s-95.573-213.333-213.333-213.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"link\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58920,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 2,\n\t\t\t\t\"order\": 16,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58920,\n\t\t\t\t\"name\": \"link\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 26\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M128 736v160h160l472.107-472.107-160-160-472.107 472.107zM883.413 300.587c16.64-16.64 16.64-43.733 0-60.373l-99.627-99.627c-16.64-16.64-43.733-16.64-60.373 0l-78.080 78.080 160 160 78.080-78.080z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"create\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58919,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 3,\n\t\t\t\t\"order\": 17,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"create\",\n\t\t\t\t\"code\": 58919\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 27\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M256 810.667c0 47.147 38.187 85.333 85.333 85.333h341.333c47.147 0 85.333-38.187 85.333-85.333v-512h-512v512zM810.667 170.667h-149.333l-42.667-42.667h-213.333l-42.667 42.667h-149.333v85.333h597.333v-85.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"delete\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58916,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 4,\n\t\t\t\t\"order\": 68,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58916,\n\t\t\t\t\"name\": \"delete\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 28\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M810.667 554.667h-597.333v-85.333h597.333v85.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"remove\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58917,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 5,\n\t\t\t\t\"order\": 19,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58917,\n\t\t\t\t\"name\": \"remove\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 29\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M128 736v160h160l472.107-472.107-160-160-472.107 472.107zM883.413 300.587c16.64-16.64 16.64-43.733 0-60.373l-99.627-99.627c-16.64-16.64-43.733-16.64-60.373 0l-78.080 78.080 160 160 78.080-78.080z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"edit\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58918,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 6,\n\t\t\t\t\"order\": 20,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58918,\n\t\t\t\t\"name\": \"edit\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 30\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M725.333 128h-426.667c-47.147 0-84.907 38.187-84.907 85.333l-0.427 682.667 298.667-128 298.667 128v-682.667c0-47.147-38.187-85.333-85.333-85.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"bookmark\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58880,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 7,\n\t\t\t\t\"order\": 21,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"bookmark\",\n\t\t\t\t\"code\": 58880\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 31\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M384 689.92l-177.92-177.92-60.373 60.373 238.293 238.293 512-512-60.373-60.373z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"done\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58881,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 8,\n\t\t\t\t\"order\": 22,\n\t\t\t\t\"name\": \"done\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58881\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 32\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M768 341.333h-42.667v-85.333c0-117.76-95.573-213.333-213.333-213.333s-213.333 95.573-213.333 213.333v85.333h-42.667c-47.147 0-85.333 38.187-85.333 85.333v426.667c0 47.147 38.187 85.333 85.333 85.333h512c47.147 0 85.333-38.187 85.333-85.333v-426.667c0-47.147-38.187-85.333-85.333-85.333zM512 725.333c-47.147 0-85.333-38.187-85.333-85.333s38.187-85.333 85.333-85.333 85.333 38.187 85.333 85.333-38.187 85.333-85.333 85.333zM644.267 341.333h-264.533v-85.333c0-72.96 59.307-132.267 132.267-132.267s132.267 59.307 132.267 132.267v85.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"lock\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58882,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 9,\n\t\t\t\t\"order\": 23,\n\t\t\t\t\"name\": \"lock\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58882\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 33\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M384 640v0c141.385 0 256-114.615 256-256s-114.615-256-256-256c-141.385 0-256 114.615-256 256s114.615 256 256 256v0zM384 768v0c-212.077 0-384-171.923-384-384s171.923-384 384-384c212.077 0 384 171.923 384 384s-171.923 384-384 384v0z\",\n\t\t\t\t\t\"M594.745 685.255l316.784 316.784 90.51-90.51-316.784-316.784-90.51 90.51z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"search\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58883,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 10,\n\t\t\t\t\"order\": 24,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"search\",\n\t\t\t\t\"code\": 58883\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 34\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M829.013 553.6c1.707-13.653 2.987-27.52 2.987-41.6s-1.28-27.947-2.987-41.6l90.24-70.613c8.107-6.4 10.453-17.92 5.12-27.307l-85.333-147.84c-5.333-9.173-16.427-13.013-26.027-9.173l-106.24 42.88c-21.973-16.853-46.080-31.147-72.107-42.027l-16-113.067c-1.92-10.027-10.667-17.92-21.333-17.92h-170.667c-10.667 0-19.413 7.893-21.12 17.92l-16 113.067c-26.027 10.88-50.133 24.96-72.107 42.027l-106.24-42.88c-9.6-3.627-20.693 0-26.027 9.173l-85.333 147.84c-5.333 9.173-2.987 20.693 5.12 27.307l90.027 70.613c-1.707 13.653-2.987 27.52-2.987 41.6s1.28 27.947 2.987 41.6l-90.027 70.613c-8.107 6.4-10.453 17.92-5.12 27.307l85.333 147.84c5.333 9.173 16.427 13.013 26.027 9.173l106.24-42.88c21.973 16.853 46.080 31.147 72.107 42.027l16 113.067c1.707 10.027 10.453 17.92 21.12 17.92h170.667c10.667 0 19.413-7.893 21.12-17.92l16-113.067c26.027-10.88 50.133-24.96 72.107-42.027l106.24 42.88c9.6 3.627 20.693 0 26.027-9.173l85.333-147.84c5.333-9.173 2.987-20.693-5.12-27.307l-90.027-70.613zM512 661.333c-82.56 0-149.333-66.773-149.333-149.333s66.773-149.333 149.333-149.333 149.333 66.773 149.333 149.333-66.773 149.333-149.333 149.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"settings\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58884,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 11,\n\t\t\t\t\"order\": 25,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"settings\",\n\t\t\t\t\"code\": 58884\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 35\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M512 192c-213.333 0-395.52 132.693-469.333 320 73.813 187.307 256 320 469.333 320 213.547 0 395.52-132.693 469.333-320-73.813-187.307-255.787-320-469.333-320zM512 725.333c-117.76 0-213.333-95.573-213.333-213.333s95.573-213.333 213.333-213.333 213.333 95.573 213.333 213.333-95.573 213.333-213.333 213.333zM512 384c-70.613 0-128 57.387-128 128s57.387 128 128 128 128-57.387 128-128-57.387-128-128-128z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"visibility\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58885,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 12,\n\t\t\t\t\"order\": 26,\n\t\t\t\t\"name\": \"visibility\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58885\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 36\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M512 298.667c117.76 0 213.333 95.573 213.333 213.333 0 27.52-5.547 53.76-15.147 77.867l124.8 124.8c64.427-53.76 115.2-123.307 146.56-202.667-74.027-187.307-256-320-469.547-320-59.733 0-116.907 10.667-170.027 29.867l92.16 91.947c24.107-9.387 50.347-15.147 77.867-15.147zM85.333 182.4l116.693 116.693c-70.4 55.040-126.080 128.213-159.36 212.907 73.813 187.307 256 320 469.333 320 66.133 0 129.28-12.8 187.093-36.053l18.133 18.133 124.373 124.587 54.4-54.187-756.267-756.48-54.4 54.4zM321.28 418.133l65.92 65.92c-1.92 9.173-3.2 18.347-3.2 27.947 0 70.613 57.387 128 128 128 9.6 0 18.773-1.28 27.733-3.2l65.92 65.92c-28.373 14.080-59.947 22.613-93.653 22.613-117.76 0-213.333-95.573-213.333-213.333 0-33.707 8.533-65.28 22.613-93.867zM504.96 384.64l134.4 134.4 0.64-7.040c0-70.613-57.387-128-128-128l-7.040 0.64z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"visibility-off\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58886,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 13,\n\t\t\t\t\"order\": 27,\n\t\t\t\t\"name\": \"visibility-off\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58886\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 37\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M810.667 554.667h-256v256h-85.333v-256h-256v-85.333h256v-256h85.333v256h256v85.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"add\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58888,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 14,\n\t\t\t\t\"order\": 28,\n\t\t\t\t\"name\": \"add\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58888\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 38\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M810.667 273.707l-60.373-60.373-238.293 238.293-238.293-238.293-60.373 60.373 238.293 238.293-238.293 238.293 60.373 60.373 238.293-238.293 238.293 238.293 60.373-60.373-238.293-238.293z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"clear\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58889,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 15,\n\t\t\t\t\"order\": 29,\n\t\t\t\t\"name\": \"clear\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58889\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 39\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M682.667 42.667h-512c-47.147 0-85.333 38.187-85.333 85.333v597.333h85.333v-597.333h512v-85.333zM810.667 213.333h-469.333c-47.147 0-85.333 38.187-85.333 85.333v597.333c0 47.147 38.187 85.333 85.333 85.333h469.333c47.147 0 85.333-38.187 85.333-85.333v-597.333c0-47.147-38.187-85.333-85.333-85.333zM810.667 896h-469.333v-597.333h469.333v597.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"content-copy\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58890,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 16,\n\t\t\t\t\"order\": 30,\n\t\t\t\t\"name\": \"content-copy\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58890\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 40\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M614.4 256l-17.067-85.333h-384v725.333h85.333v-298.667h238.933l17.067 85.333h298.667v-426.667z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"flag\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58892,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 17,\n\t\t\t\t\"order\": 31,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"flag\",\n\t\t\t\t\"code\": 58892\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 41\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M426.667 384v-170.667l-298.667 298.667 298.667 298.667v-174.933c213.333 0 362.667 68.267 469.333 217.6-42.667-213.333-170.667-426.667-469.333-469.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"reply\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58893,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 18,\n\t\t\t\t\"order\": 32,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"reply\",\n\t\t\t\t\"code\": 58893\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 42\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M757.333 298.667l-160-160-426.667 426.667v160h160l426.667-426.667zM883.413 172.587c16.64-16.64 16.64-43.733 0-60.373l-99.627-99.627c-16.64-16.64-43.733-16.64-60.373 0l-83.413 83.413 160 160 83.413-83.413z\",\n\t\t\t\t\t\"M0 853.333h1024v170.667h-1024z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"border-color\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58894,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 19,\n\t\t\t\t\"order\": 33,\n\t\t\t\t\"name\": \"border-color\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58894\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 43\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M665.6 460.373c41.173-28.8 70.4-75.307 70.4-119.040 0-96.213-74.453-170.667-170.667-170.667h-266.667v597.333h300.373c89.387 0 158.293-72.533 158.293-161.707 0-64.853-36.907-120.107-91.733-145.92zM426.667 277.333h128c35.413 0 64 28.587 64 64s-28.587 64-64 64h-128v-128zM576 661.333h-149.333v-128h149.333c35.413 0 64 28.587 64 64s-28.587 64-64 64z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"format-bold\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58895,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 20,\n\t\t\t\t\"order\": 34,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"format-bold\",\n\t\t\t\t\"code\": 58895\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 44\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M426.667 170.667v128h94.507l-146.347 341.333h-118.827v128h341.333v-128h-94.507l146.347-341.333h118.827v-128z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"format-italic\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58896,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 21,\n\t\t\t\t\"order\": 35,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"format-italic\",\n\t\t\t\t\"code\": 58896\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 45\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M170.667 448c-35.413 0-64 28.587-64 64s28.587 64 64 64 64-28.587 64-64-28.587-64-64-64zM170.667 192c-35.413 0-64 28.587-64 64s28.587 64 64 64 64-28.587 64-64-28.587-64-64-64zM170.667 711.040c-31.36 0-56.96 25.387-56.96 56.96s25.6 56.96 56.96 56.96 56.96-25.387 56.96-56.96-25.6-56.96-56.96-56.96zM298.667 810.667h597.333v-85.333h-597.333v85.333zM298.667 554.667h597.333v-85.333h-597.333v85.333zM298.667 213.333v85.333h597.333v-85.333h-597.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"format-list-bulleted\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58897,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 22,\n\t\t\t\t\"order\": 36,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"format-list-bulleted\",\n\t\t\t\t\"code\": 58897\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 46\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M85.333 725.333h85.333v21.333h-42.667v42.667h42.667v21.333h-85.333v42.667h128v-170.667h-128v42.667zM128 341.333h42.667v-170.667h-85.333v42.667h42.667v128zM85.333 469.333h76.8l-76.8 89.6v38.4h128v-42.667h-76.8l76.8-89.6v-38.4h-128v42.667zM298.667 213.333v85.333h597.333v-85.333h-597.333zM298.667 810.667h597.333v-85.333h-597.333v85.333zM298.667 554.667h597.333v-85.333h-597.333v85.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"format-list-numbered\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58898,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 23,\n\t\t\t\t\"order\": 37,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"format-list-numbered\",\n\t\t\t\t\"code\": 58898\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 47\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M256 725.333h128l85.333-170.667v-256h-256v256h128zM597.333 725.333h128l85.333-170.667v-256h-256v256h128z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"format-quote\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58899,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 24,\n\t\t\t\t\"order\": 38,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"format-quote\",\n\t\t\t\t\"code\": 58899\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 48\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M768 170.667h-512v85.333l277.333 256-277.333 256v85.333h512v-128h-298.667l213.333-213.333-213.333-213.333h298.667z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"functions\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58900,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 25,\n\t\t\t\t\"order\": 39,\n\t\t\t\t\"name\": \"functions\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58900\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 49\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M853.333 85.333h-682.667c-47.147 0-85.333 38.187-85.333 85.333v512c0 47.147 38.187 85.333 85.333 85.333h597.333l170.667 170.667v-768c0-47.147-38.187-85.333-85.333-85.333zM768 597.333h-512v-85.333h512v85.333zM768 469.333h-512v-85.333h512v85.333zM768 341.333h-512v-85.333h512v85.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"insert-comment\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58903,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 40,\n\t\t\t\t\"id\": 26,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58903,\n\t\t\t\t\"name\": \"insert-comment\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 50\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M166.4 512c0-72.96 59.307-132.267 132.267-132.267h170.667v-81.067h-170.667c-117.76 0-213.333 95.573-213.333 213.333s95.573 213.333 213.333 213.333h170.667v-81.067h-170.667c-72.96 0-132.267-59.307-132.267-132.267zM341.333 554.667h341.333v-85.333h-341.333v85.333zM725.333 298.667h-170.667v81.067h170.667c72.96 0 132.267 59.307 132.267 132.267s-59.307 132.267-132.267 132.267h-170.667v81.067h170.667c117.76 0 213.333-95.573 213.333-213.333s-95.573-213.333-213.333-213.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"insert-link\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58901,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 27,\n\t\t\t\t\"order\": 41,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"insert-link\",\n\t\t\t\t\"code\": 58901\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 51\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M896 810.667v-597.333c0-47.147-38.187-85.333-85.333-85.333h-597.333c-47.147 0-85.333 38.187-85.333 85.333v597.333c0 47.147 38.187 85.333 85.333 85.333h597.333c47.147 0 85.333-38.187 85.333-85.333zM362.667 576l106.667 128.213 149.333-192.213 192 256h-597.333l149.333-192z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"insert-photo\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58902,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 28,\n\t\t\t\t\"order\": 42,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"insert-photo\",\n\t\t\t\t\"code\": 58902\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 52\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M512 85.333c-235.733 0-426.667 190.933-426.667 426.667s190.933 426.667 426.667 426.667 426.667-190.933 426.667-426.667-190.933-426.667-426.667-426.667zM725.333 664.96l-60.373 60.373-152.96-152.96-152.96 152.96-60.373-60.373 152.96-152.96-152.96-152.96 60.373-60.373 152.96 152.96 152.96-152.96 60.373 60.373-152.96 152.96 152.96 152.96z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"cancel\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58906,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 29,\n\t\t\t\t\"order\": 43,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"cancel\",\n\t\t\t\t\"code\": 58906\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 53\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M384 689.92l-177.92-177.92-60.373 60.373 238.293 238.293 512-512-60.373-60.373z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"check\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58907,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 30,\n\t\t\t\t\"order\": 44,\n\t\t\t\t\"name\": \"check\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58907\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 54\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M657.707 316.373l-60.373-60.373-256 256 256 256 60.373-60.373-195.627-195.627z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"chevron-left\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58887,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 45,\n\t\t\t\t\"id\": 31,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58887,\n\t\t\t\t\"name\": \"chevron-left\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 55\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M426.667 256l-60.373 60.373 195.627 195.627-195.627 195.627 60.373 60.373 256-256z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"chevron-right\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58904,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 46,\n\t\t\t\t\"id\": 32,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58904,\n\t\t\t\t\"name\": \"chevron-right\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 56\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M810.667 273.707l-60.373-60.373-238.293 238.293-238.293-238.293-60.373 60.373 238.293 238.293-238.293 238.293 60.373 60.373 238.293-238.293 238.293 238.293 60.373-60.373-238.293-238.293z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"close\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58908,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 33,\n\t\t\t\t\"order\": 47,\n\t\t\t\t\"name\": \"close\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58908\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 57\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M512 85.333c-235.733 0-426.667 190.933-426.667 426.667s190.933 426.667 426.667 426.667 426.667-190.933 426.667-426.667-190.933-426.667-426.667-426.667zM469.333 850.347c-168.32-20.907-298.667-164.267-298.667-338.347 0-26.24 3.2-51.84 8.96-76.373l204.373 204.373v42.667c0 47.147 38.187 85.333 85.333 85.333v82.347zM763.52 742.187c-10.88-34.56-42.88-59.52-80.853-59.52h-42.667v-128c0-23.467-19.2-42.667-42.667-42.667h-256v-85.333h85.333c23.467 0 42.667-19.2 42.667-42.667v-85.333h85.333c47.147 0 85.333-38.187 85.333-85.333v-17.707c125.013 50.56 213.333 173.013 213.333 316.373 0 88.747-34.133 169.387-89.813 230.187z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"public\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58914,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 34,\n\t\t\t\t\"order\": 48,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"name\": \"public\",\n\t\t\t\t\"code\": 58914\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 58\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M768 686.293c-32.427 0-61.653 12.587-83.84 32.853l-304-177.28c2.347-9.6 3.84-19.627 3.84-29.867s-1.493-20.267-3.84-29.867l300.8-175.573c22.827 21.333 53.333 34.56 87.040 34.56 70.613 0 128-57.387 128-128s-57.387-128-128-128-128 57.387-128 128c0 10.24 1.493 20.267 3.84 29.867l-300.8 175.573c-22.827-21.333-53.333-34.56-87.040-34.56-70.613 0-128 57.387-128 128s57.387 128 128 128c33.707 0 64.213-13.227 87.040-34.56l304 177.28c-2.133 8.96-3.413 18.347-3.413 27.947 0 68.693 55.68 124.373 124.373 124.373s124.373-55.68 124.373-124.373-55.68-124.373-124.373-124.373z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"colorPermutations\": {\n\t\t\t\t\t\"12212212211661661661\": []\n\t\t\t\t},\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"share\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58915,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [],\n\t\t\t\"properties\": {\n\t\t\t\t\"id\": 35,\n\t\t\t\t\"order\": 49,\n\t\t\t\t\"name\": \"share\",\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58915\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 59\n\t\t},\n\t\t{\n\t\t\t\"icon\": {\n\t\t\t\t\"paths\": [\n\t\t\t\t\t\"M853.333 170.667h-682.667c-47.147 0-84.907 38.187-84.907 85.333l-0.427 512c0 47.147 38.187 85.333 85.333 85.333h682.667c47.147 0 85.333-38.187 85.333-85.333v-512c0-47.147-38.187-85.333-85.333-85.333zM853.333 341.333l-341.333 213.333-341.333-213.333v-85.333l341.333 213.333 341.333-213.333v85.333z\"\n\t\t\t\t],\n\t\t\t\t\"attrs\": [\n\t\t\t\t\t{}\n\t\t\t\t],\n\t\t\t\t\"isMulticolor\": false,\n\t\t\t\t\"tags\": [\n\t\t\t\t\t\"mail\"\n\t\t\t\t],\n\t\t\t\t\"defaultCode\": 58922,\n\t\t\t\t\"grid\": 24\n\t\t\t},\n\t\t\t\"attrs\": [\n\t\t\t\t{}\n\t\t\t],\n\t\t\t\"properties\": {\n\t\t\t\t\"order\": 50,\n\t\t\t\t\"id\": 36,\n\t\t\t\t\"prevSize\": 24,\n\t\t\t\t\"code\": 58922,\n\t\t\t\t\"name\": \"mail\"\n\t\t\t},\n\t\t\t\"setIdx\": 0,\n\t\t\t\"setId\": 1,\n\t\t\t\"iconIdx\": 60\n\t\t}\n\t],\n\t\"height\": 1024,\n\t\"metadata\": {\n\t\t\"name\": \"h\"\n\t},\n\t\"preferences\": {\n\t\t\"fontPref\": {\n\t\t\t\"prefix\": \"h-icon-\",\n\t\t\t\"metadata\": {\n\t\t\t\t\"fontFamily\": \"h\",\n\t\t\t\t\"majorVersion\": 1,\n\t\t\t\t\"minorVersion\": 5\n\t\t\t},\n\t\t\t\"showGlyphs\": true,\n\t\t\t\"metrics\": {\n\t\t\t\t\"emSize\": 1024,\n\t\t\t\t\"baseline\": 6.25,\n\t\t\t\t\"whitespace\": 50\n\t\t\t},\n\t\t\t\"resetPoint\": 58880,\n\t\t\t\"showQuickUse\": true,\n\t\t\t\"quickUsageToken\": false,\n\t\t\t\"showMetrics\": true,\n\t\t\t\"showMetadata\": false,\n\t\t\t\"embed\": false,\n\t\t\t\"showSelector\": false,\n\t\t\t\"showVersion\": true\n\t\t},\n\t\t\"imagePref\": {\n\t\t\t\"color\": 0,\n\t\t\t\"height\": 32,\n\t\t\t\"columns\": 16,\n\t\t\t\"margin\": 16,\n\t\t\t\"png\": false,\n\t\t\t\"sprites\": true,\n\t\t\t\"prefix\": \"icon-\"\n\t\t},\n\t\t\"historySize\": 100,\n\t\t\"showCodes\": true,\n\t\t\"gridSize\": 16,\n\t\t\"showLiga\": false,\n\t\t\"showGrid\": true,\n\t\t\"showGlyphs\": true,\n\t\t\"showQuickUse\": true,\n\t\t\"showQuickUse2\": true,\n\t\t\"showSVGs\": true\n\t}\n}"},{"size":3669,"relativepath":"h/static/styles/vendor/icomoon.css","filename":"icomoon.css","extension":".css","content":"@font-face {\n    font-family: 'h';\n  src: url('../fonts/h.woff') format('woff');\n    font-weight: normal;\n    font-style: normal;\n}\n\n[class^=\"h-icon-\"], [class*=\" h-icon-\"] {\n    /* use !important to prevent issues with browser extensions that change fonts */\n    font-family: 'h' !important;\n    speak: none;\n    font-style: normal;\n    font-weight: normal;\n    font-variant: normal;\n    text-transform: none;\n    line-height: 1;\n\n    /* Better Font Rendering =========== */\n    -webkit-font-smoothing: antialiased;\n    -moz-osx-font-smoothing: grayscale;\n}\n\n.h-icon-clipboard:before {\n    content: \"\\e90c\";\n}\n.h-icon-hypothesis-logo:before {\n    content: \"\\e90b\";\n}\n.h-icon-annotation-edit:before {\n    content: \"\\e907\";\n}\n.h-icon-annotation-reply:before {\n    content: \"\\e90a\";\n}\n.h-icon-annotation-delete:before {\n    content: \"\\e908\";\n}\n.h-icon-annotation-share:before {\n    content: \"\\e909\";\n}\n.h-icon-google-plus:before {\n    content: \"\\e906\";\n}\n.h-icon-annotate:before {\n    content: \"\\e903\";\n}\n.h-icon-highlight:before {\n    content: \"\\e904\";\n}\n.h-icon-note:before {\n    content: \"\\e905\";\n}\n.h-icon-account:before {\n    content: \"\\e800\";\n}\n.h-icon-sort:before {\n    content: \"\\e801\";\n}\n.h-icon-group:before {\n    content: \"\\e61e\";\n}\n.h-icon-cancel-outline:before {\n    content: \"\\e619\";\n}\n.h-icon-google-plus-old:before {\n    content: \"\\ea88\";\n}\n.h-icon-facebook:before {\n    content: \"\\ea8d\";\n}\n.h-icon-twitter:before {\n    content: \"\\ea91\";\n}\n.h-icon-github:before {\n    content: \"\\e900\";\n}\n.h-icon-feed:before {\n    content: \"\\e901\";\n}\n.h-icon-cc-by:before {\n    content: \"\\e61f\";\n}\n.h-icon-cc-logo:before {\n    content: \"\\e620\";\n}\n.h-icon-cc-zero:before {\n    content: \"\\e621\";\n}\n.h-icon-markdown:before {\n    content: \"\\e60b\";\n}\n.h-icon-move:before {\n    content: \"\\e902\";\n}\n.h-icon-arrow-right:before {\n    content: \"\\e61d\";\n}\n.h-icon-arrow-drop-down:before {\n    content: \"\\e629\";\n}\n.h-icon-link:before {\n    content: \"\\e628\";\n}\n.h-icon-create:before {\n    content: \"\\e627\";\n}\n.h-icon-delete:before {\n    content: \"\\e624\";\n}\n.h-icon-remove:before {\n    content: \"\\e625\";\n}\n.h-icon-edit:before {\n    content: \"\\e626\";\n}\n.h-icon-bookmark:before {\n    content: \"\\e600\";\n}\n.h-icon-done:before {\n    content: \"\\e601\";\n}\n.h-icon-lock:before {\n    content: \"\\e602\";\n}\n.h-icon-search:before {\n    content: \"\\e603\";\n}\n.h-icon-settings:before {\n    content: \"\\e604\";\n}\n.h-icon-visibility:before {\n    content: \"\\e605\";\n}\n.h-icon-visibility-off:before {\n    content: \"\\e606\";\n}\n.h-icon-add:before {\n    content: \"\\e608\";\n}\n.h-icon-clear:before {\n    content: \"\\e609\";\n}\n.h-icon-content-copy:before {\n    content: \"\\e60a\";\n}\n.h-icon-flag:before {\n    content: \"\\e60c\";\n}\n.h-icon-reply:before {\n    content: \"\\e60d\";\n}\n.h-icon-border-color:before {\n    content: \"\\e60e\";\n}\n.h-icon-format-bold:before {\n    content: \"\\e60f\";\n}\n.h-icon-format-italic:before {\n    content: \"\\e610\";\n}\n.h-icon-format-list-bulleted:before {\n    content: \"\\e611\";\n}\n.h-icon-format-list-numbered:before {\n    content: \"\\e612\";\n}\n.h-icon-format-quote:before {\n    content: \"\\e613\";\n}\n.h-icon-functions:before {\n    content: \"\\e614\";\n}\n.h-icon-insert-comment:before {\n    content: \"\\e617\";\n}\n.h-icon-insert-link:before {\n    content: \"\\e615\";\n}\n.h-icon-insert-photo:before {\n    content: \"\\e616\";\n}\n.h-icon-cancel:before {\n    content: \"\\e61a\";\n}\n.h-icon-check:before {\n    content: \"\\e61b\";\n}\n.h-icon-chevron-left:before {\n    content: \"\\e607\";\n}\n.h-icon-chevron-right:before {\n    content: \"\\e618\";\n}\n.h-icon-close:before {\n    content: \"\\e61c\";\n}\n.h-icon-public:before {\n    content: \"\\e622\";\n}\n.h-icon-share:before {\n    content: \"\\e623\";\n}\n.h-icon-mail:before {\n    content: \"\\e62a\";\n}\n\n"},{"size":1146,"relativepath":"h/static/styles/vendor/ICOMOON.md","filename":"ICOMOON.md","extension":".md","content":"# Icon Fonts\n\nThe icon fonts for H were created with [icomoon](https://icomoon.io/app). The source file which contains the SVG definitions of the icons is `fonts/selection.json`.\n\nThe icons used are from the _Icomoon Free_ and [_Material Icons_](https://www.google.com/design/icons/) libraries which are both pre-installed in the icomoon app.\n\n## Adding New Icons\n\nTo add new icons, you'll need to load `selection.json` into the icomoon app,\nadd the relevant icons and then use the app's _Generate Font_ facility.\n\n 1. Go to the [icomoon app](https://icomoon.io/app) and import `selection.json`\n    as a new project.\n 2. Search for icons or import the ones you want to add from another source and\n    add them to the 'h' set.\n 3. Select the 'Edit' tool, click on the new icon and enter a name for use in the generated\n    `h-icon-<name>` class name.\n 4. Ensure all icons in the 'h' set are selected, then go to the 'Generate Font' tab in icomoon\n    and click the 'Download' button which appears _within_ the tab.\n 5. Run `scripts/update-icon-font.py <icomoon zip archive>` to update the icon font\n 6. Commit the updated files to the repository.\n"},{"size":359,"relativepath":"h/static/styles/site.scss","filename":"site.scss","extension":".scss","content":"@import 'partials/base';\n@import 'partials/reset';\n@import 'partials/elements';\n\n// Components\n@import 'partials/group-form';\n@import 'partials/primary-action-btn';\n@import 'partials/share-link';\n\n.body {\n  background: $grey-2;\n  font-family: $sans-font-family;\n}\n\n.content {\n  margin-left: auto;\n  margin-right: auto;\n}\n\n.content--narrow {\n  width: 450px;\n}\n"},{"size":101,"relativepath":"h/static/styles/partials/_flashbar.scss","filename":"_flashbar.scss","extension":".scss","content":"@at-root {\n  .flashbar {\n    max-width: 1130px;\n    margin-left: auto;\n    margin-right: auto;\n  }\n}\n"},{"size":41,"relativepath":"h/static/styles/partials/_styled-text.scss","filename":"_styled-text.scss","extension":".scss","content":".styled-text {\n  @include styled-text;\n}\n"},{"size":746,"relativepath":"h/static/styles/partials/_share-link.scss","filename":"_share-link.scss","extension":".scss","content":"// form for sharing links\n\n.share-link-container {\n  font-size: $body1-font-size;\n  line-height: $body1-line-height;\n  margin-top: 1px;\n  white-space: normal;\n}\n\n.share-link {\n  color: $gray-light;\n}\n\n.share-link:hover {\n  width: 100%;\n  color: $gray-dark;\n}\n\n.share-link-field {\n  padding: 3px;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  margin-top: 12px;\n  margin-bottom: 8px;\n  border: 1px solid $gray-lighter;\n  border-radius: 2px;\n  width: 100%;\n}\n\n.share-link-icons {\n  display: flex;\n  flex-direction: row;\n  justify-content: center;\n}\n\n.share-link-icon {\n  color: $color-dove-gray;\n  display: inline-block;\n  font-size: 24px;\n  text-decoration: none;\n  margin-left: 5px;\n  margin-right: 5px;\n\n  &:hover {\n    color: $brand-color;\n  }\n}\n"},{"size":827,"relativepath":"h/static/styles/partials/_primary-action-btn.scss","filename":"_primary-action-btn.scss","extension":".scss","content":"@mixin primary-action-btn {\n  // note that there is currently some duplication here between\n  // the styling for this element and <dropdown-menu-btn>\n  color: $color-seashell;\n  background-color: $color-dove-gray;\n  height: 35px;\n  border: none;\n  border-radius: 2px;\n\n  font-weight: bold;\n  font-size: $body1-font-size;\n\n  padding-left: 12px;\n  padding-right: 12px;\n\n  &:disabled {\n    color: $gray-light;\n  }\n\n  &:hover:enabled {\n    background-color: $color-mine-shaft;\n  }\n}\n\n// A dark grey button used for the primary action\n// in a form\n.primary-action-btn {\n  @include primary-action-btn;\n}\n\n.primary-action-btn--short {\n  height: 30px;\n}\n\n.primary-action-btn__icon {\n  color: $color-silver-chalice;\n  display: inline-block;\n  font-weight: bold;\n  margin-left: -3px;\n  margin-right: 3px;\n  transform: translateY(1px);\n}\n"},{"size":3309,"relativepath":"h/static/styles/partials/_group-form.scss","filename":"_group-form.scss","extension":".scss","content":"// The group-form block implements the styles used by the forms for\n// creating, joining and sharing groups\n\n@at-root {\n  @mixin flex-center-column {\n    display: flex;\n    flex-direction: column;\n    align-items: center;\n  }\n\n  $border-color: $gray-lighter;\n  $border: 1px solid $border-color;\n\n  .is-hidden {\n    display: none;\n  }\n\n  .group-form {\n    @include flex-center-column();\n\n    font-size: $body2-font-size;\n    background-color: $white;\n    border: $border;\n    color: $color-dove-gray;\n    padding-bottom: 45px;\n    padding-left: 5px;\n    padding-right: 5px;\n    margin-top: 75px;\n\n    &__form {\n      @include flex-center-column();\n    }\n\n    &__heading-icon {\n      margin-top: 40px;\n      font-size: 24px;\n    }\n\n    &__invite-icon {\n      margin-top: 40px;\n      margin-bottom: 35px;\n      width: 85px;\n      height: 65px;\n    }\n\n    &__heading {\n      font-size: $title-font-size;\n      font-weight: $title-font-weight;\n      margin-bottom: 40px;\n    }\n\n    &__heading--short {\n      font-size: $title-font-size;\n      font-weight: $title-font-weight;\n      margin-bottom: 5px;\n    }\n\n    &__nocontent-text {\n      padding-top: 10px;\n    }\n\n    .form-field {\n      @include flex-center-column();\n    }\n\n    &__description-label, &__name-label {\n      font-size: 18px;\n      margin-bottom: 10px;\n    }\n\n    &__description-input {\n      display: block;\n      margin-bottom: 40px;\n      width: 350px;\n      height: 105px;\n      border: none;\n\n      &:placeholder {\n        color: $color-alto;\n      }\n    }\n\n    &__name-input {\n      font-size: 28px;\n      font-weight: bold;\n      border: none;\n      text-align: center;\n      margin-bottom: 40px;\n      width: 350px;\n      outline: none;\n\n      // TODO - Cyan cursor color\n\n      &:placeholder {\n        color: $color-alto;\n      }\n    }\n  }\n\n  .group-document-list, .group-members-list {\n    display: flex;\n    justify-content: left;\n    font-size: $body2-font-size;\n    line-height: $body2-line-height;\n    background-color: $white;\n    color: $color-dove-gray;\n    border-left: $border;\n    border-right: $border;\n    padding-top: 20px;\n    padding-left: 20px;\n    padding-right: 20px;\n\n    &__heading {\n      font-weight: bold;\n      margin-bottom: 1em;\n    }\n\n    &__list li {\n      margin-bottom: 1.2em;\n\n      em {\n        font-style: italic;\n        color: $color-silver-chalice;\n      }\n    }\n\n    &__memberlist li {\n      margin-bottom: 0.2em;\n    }\n\n  }\n\n  .group-members-list {\n    border-bottom: $border;\n    padding-bottom: 20px;\n  }\n\n  .group-form-footer {\n    @include flex-center-column();\n\n    justify-content: center;\n    border: $border;\n    border-top: none;\n    color: $color-dove-gray;\n    font-size: $body2-font-size;\n    line-height: $body2-line-height;\n\n    min-height: 43px;\n    background-color: $color-wild-sand;\n    padding-left: 18px;\n    padding-right: 18px;\n\n    &__explain-link {\n      color: $color-silver-chalice;\n    }\n\n    &__explain-text {\n      padding-bottom: 22px;\n    }\n\n    &__heading {\n      font-weight: bold;\n      margin-top: 22px;\n      margin-bottom: 4px;\n    }\n\n    &__list {\n      padding-left: 18px;\n    }\n  }\n\n  .group-form-footer-link {\n    @include flex-center-column();\n    color: $gray-light;\n    justify-content: center;\n    height: 35px;\n\n    a {\n      color: inherit;\n    }\n  }\n}\n"},{"size":1417,"relativepath":"h/static/styles/partials/_grid.scss","filename":"_grid.scss","extension":".scss","content":"// A mobile first grid system. Requires the columns to be wrapped in a\n// .grid container. Each column then should have a width applied. See\n// mixins/grid for more info on available widths.\n//\n// By default a column width will apply to all viewport widths. In most cases\n// a mobile viewport should not use columns so a more specific class will be\n// required. The viewports available are:\n//\n//   wide-handheld, tablet and desktop\n//\n// Each of these cascade, so a tablet class will apply to tablet sized\n// viewports as well as desktops.\n//\n// Examples\n//\n// This creates a grid that only has rows on mobile. Two columns on tablets and\n// four columns on desktop sized viewports.\n//\n//   <div class=\"grid\">\n//     <div class=\"column-tablet-1-2 column-desktop-1-4\"></div>\n//     <div class=\"column-tablet-1-2 column-desktop-1-4\"></div>\n//     <div class=\"column-tablet-1-2 column-desktop-1-4\"></div>\n//     <div class=\"column-tablet-1-2 column-desktop-1-4\"></div>\n//   </div>\n\n$grid-default-gutter: 20px !default;\n\n.grid {\n  @include grid-row($grid-default-gutter);\n}\n\n[class^=\"column-\"], [class*=\" column-\"] {\n  @include grid-column($grid-default-gutter);\n}\n\n@include grid-setup(\"column-\");\n\n@include wide-handheld-and-up {\n  @include grid-setup(\"column-wide-handheld-\");\n}\n\n@include tablet-and-up {\n  @include grid-setup(\"column-tablet-\");\n}\n\n@include desktop-and-up {\n  @include grid-setup(\"column-desktop-\");\n}\n"},{"size":5857,"relativepath":"h/static/styles/partials/_forms.scss","filename":"_forms.scss","extension":".scss","content":"// Common form styles.\n.form-field {\n  @include pie-clearfix;\n  clear: both;\n  margin-bottom: .75em;\n}\n\n.form-heading {\n  position: relative;\n  text-transform: uppercase;\n  font-weight: bold;\n  font-size: 1em;\n  margin-top: 1.5em;\n  margin-bottom: 1.5em;\n\n  span {\n    position: relative;\n    background: white;\n    padding-right: .4em;\n    z-index: 1;\n  }\n\n  &:after {\n    content: \"\";\n    display: block;\n    height: 1px;\n    background: $gray-lighter;\n    width: 100%;\n    position: absolute;\n    top: 50%;\n    left: 0;\n    margin-top: -1px;\n    z-index: 0;\n  }\n}\n\n.form-description {\n  margin-bottom: 1em;\n}\n\n.form-flash {\n  background: $color-dove-gray;\n  color: $white;\n  width: 100%;\n  font-weight: bold;\n  text-align: center;\n  margin: 1em 0 0 0;\n  padding: 0;\n  display: inline-block; // disable container margin collapse\n\n  p { margin: 0.75em; }\n}\n\n.form-input,\n.form-label {\n  width: 100%;\n  display: block;\n}\n\n.form-label {\n  cursor: pointer;\n  font-weight: bold;\n  margin-bottom: .4em;\n}\n\n.form-label--light {\n  font-weight: normal;\n}\n\n.form-hint {\n  font-size: .833em;\n  margin-left: .25em;\n  color: $gray-light;\n  -webkit-font-smoothing: antialiased;\n}\n\n.form-required, .form-required[title] {\n  cursor: help;\n  color: $gray-light;\n  border-bottom: none;\n  -webkit-font-smoothing: antialiased;\n}\n\n.form-input {\n  @include form-input;\n\n  &:focus, &.js-focus {\n    @include form-input-focus;\n  }\n}\n\n.form-textarea {\n  min-height: 8em;\n  max-width: 100%;\n  resize: vertical;\n}\n\n.form-field-error {\n  .form-input {\n    &, &:focus, &.js-focus {\n      @include form-input-error;\n    }\n  }\n\n  .form-error-list {\n    display: block;\n  }\n}\n\n.form-select {\n  display: block;\n}\n\n.form-error-list {\n  position: relative;\n  display: none;\n  background: $error-color;\n  margin-top: .75em;\n  padding: .25em .75em;\n  float: left;\n  border-radius: 2px;\n\n  .form-error {\n    font-size: .833em;\n    color: white;\n  }\n\n  &:after {\n    bottom: 100%;\n    left: 50%;\n    border: solid transparent;\n    content: \" \";\n    height: 0;\n    width: 0;\n    position: absolute;\n    pointer-events: none;\n    border-color: rgba($error-color, 0);\n    border-bottom-color: $error-color;\n    border-width: 4px;\n    margin-left: -4px;\n  }\n}\n\n.form-error {\n  color: $error-color;\n}\n\n.form-checkbox-item {\n  padding-left: 1.5em;\n\n  .form-checkbox, [type=checkbox], [type=radio] {\n    float: left;\n    margin-left: -1.5em;\n    margin-top: .25em;\n  }\n\n  .form-label {\n    display: inline;\n  }\n}\n\n.form-inline {\n  display: flex;\n\n  .form-input {\n    flex-grow: 1;\n    width: auto;\n  }\n\n  .btn {\n    margin-left: .5em;\n  }\n}\n\n.form-actions {\n  @include pie-clearfix;\n  margin-top: .75em;\n}\n\n.form-actions-message {\n  font-size: .833em;\n  float: left;\n  margin-top: 1em;\n}\n\n.form-actions-buttons {\n  @include pie-clearfix;\n  float: right;\n\n  > * {\n    margin-left: .75em;\n    &:first-child {\n      margin-left: 0;\n    }\n  }\n}\n\n// Allows buttons to be positioned explicitly.\n.form-actions-left {\n  float: left;\n}\n\n.form-actions-right {\n  float: right;\n}\n\n.btn {\n  @include btn;\n\n  &:hover, &:focus, &:active,\n  &.js-hover, &.js-focus, &.js-active {\n    @include btn-hover;\n  }\n\n  &:focus, &.js-focus {\n    @include focus-outline;\n  }\n\n  &:active, &.js-active {\n    @include btn-active;\n  }\n\n  &[disabled], &.js-disabled {\n    @include btn-disabled;\n  }\n}\n\n.btn-danger {\n  background: linear-gradient(to bottom, $error-color, shade($error-color, 5%));\n  color: white;\n  border-color: shade($error-color, 15%);\n  text-shadow: 0 -1px 0 rgba(0, 0, 0, .1);\n\n  &:focus, &:hover, &:active, &.js-hover, &.js-focus, &.js-active {\n    box-shadow: 0 1px 0 rgba(0, 0, 0, .05);\n    color: white;\n    background: tint($error-color, 5%);\n    border-color: $error-color;\n  }\n\n  &:active, &.js-active {\n    box-shadow: inset 0 1px 0 rgba(0, 0, 0, .3);\n    color: white;\n    background: shade($error-color, 10%);\n    border-color: shade($error-color, 30%);\n  }\n}\n\n.btn-clean {\n  border: none;\n\n  &, &:focus, &:hover, &:active, &[disabled],\n  &.js-hover, &.js-focus, &.js-active, &.js-disabled {\n    box-shadow: none;\n    background: none;\n  }\n\n  &:focus, &:hover, &:active, &.js-hover, &.js-focus, &.js-active {\n    color: $link-color;\n  }\n\n  &:active, &.js-active {\n    color: $link-color-hover;\n  }\n\n  &[disabled], &.js-disabled {\n    color: $text-color;\n  }\n}\n\n.btn-icon {\n  display: inline-block;\n  font-size: 16px;\n}\n\n// Positions a message/icon to the left of a button.\n.btn-with-message {\n  position: relative;\n}\n\n.btn-message {\n  font-style: italic;\n  color: $gray-light;\n  margin-right: .5em;\n  position: absolute;\n  right: 100%;\n  top: 0;\n  white-space: nowrap;\n}\n\n.btn-message-icon {\n  display: inline-block;\n  background: $success-color;\n  border-radius: 50%;\n  color: #FFF;\n  padding: 2px;\n}\n\n// a light grey cancel/remove button which darkens on hover\n.btn--cancel {\n  color: $color-silver;\n  &:hover {\n    color: darken($color-silver, 15%);\n  }\n}\n\n// Handles state transitions from \"default\" -> \"loading\" -> \"success\"\n[status-button-state] .btn-message {\n  top: -999em;\n  left: -999em;\n  right: auto;\n}\n\n[status-button-state=success] .btn-message-success,\n[status-button-state=loading] .btn-message-loading {\n  left: auto;\n  top: 0;\n  right: 100%;\n}\n\n[status-button-state] .btn-message-text {\n  transition: opacity .2s .6s ease-in;\n  opacity: 0;\n}\n\n[status-button-state=success] .btn-message-success .btn-message-text {\n  opacity: 1;\n}\n\n[status-button-state] .btn-message-success .btn-message-icon {\n  transform: scale(0);\n}\n\n[status-button-state=success] .btn-message-success .btn-message-icon {\n  transition: transform .15s 0 cubic-bezier(0, 1.8, 1, 1.8);\n  transform: scale(1);\n}\n\n// TODO: Move into seperate module stylesheet.\n.account-form {\n  margin-top: 2.25em;\n  margin-bottom: 2.25em;\n\n  &:first-child {\n    margin-top: 1.2em;\n  }\n\n  &:last-child {\n    margin-bottom: 1.2em;\n  }\n}\n"},{"size":325,"relativepath":"h/static/styles/partials/_elements.scss","filename":"_elements.scss","extension":".scss","content":"// basic standard styling for elements\na {\n  color: $link-color;\n  text-decoration: none;\n}\n\na:active, a:focus {\n  text-decoration: none;\n}\n\na:hover {\n  text-decoration: none;\n  color: $link-color-hover;\n}\n\nol {\n  list-style-type: decimal;\n  padding-left: 3em;\n}\n\nsvg { -webkit-tap-highlight-color: rgba(255, 255, 255, 0); }\n"},{"size":2705,"relativepath":"h/static/styles/partials/_base.scss","filename":"_base.scss","extension":".scss","content":"// Colors and shades of gray\n// Names courtesy of http://chir.ag/projects/name-that-color\n\n$white: #fff !default;\n$black: #000 !default;\n\n\n// Grays\n// ---------------------\n$gray: #777 !default;\n$gray-darker: #333;\n$gray-dark: #585858;\n$gray-light: #969696 !default;\n$gray-lighter: #d3d3d3 !default;\n$gray-lightest: #f9f9f9 !default;\n\n$color-mine-shaft: #3A3A3A;\n$color-dove-gray: #626262;\n$color-gray: #818181;\n$color-silver-chalice: #a6a6a6;\n$color-silver: #bbb;\n$color-alto: #dedede;\n$color-seashell: #f1f1f1;\n$color-wild-sand: #f5f5f5;\n\n\n// Colors\n// ---------------------\n$brand-color: #bd1c2b !default;\n\n$button-text-color: $gray-dark !default;\n$button-background-start: $white !default;\n$button-background-end: #f0f0f0 !default;\n$button-background-gradient: to bottom, $button-background-start, $button-background-end !default;\n\n$error-color: #f0480c !default;\n$success-color: #1cbd41 !default;\n\n\n// Variables for the new color palette\n// ------------------------------------\n$grey-1: #F2F2F2;\n$grey-2: #ECECEC;\n$grey-3: #DBDBDB;\n$grey-4: #A6A6A6;\n$grey-5: #7A7A7A;\n$grey-6: #3F3F3F;\n$grey-7: #202020;\n\n$brand: #BD1C2B;\n$highlight: #58CEF4;\n\n\n@function color-weight($c, $n: 500) {\n  @if $n == 50 {\n    @return tint($c, 85%);\n  } @if $n == 100 {\n    @return tint($c, 70%);\n  } @if $n == 200 {\n    @return tint($c, 50%);\n  } @if $n == 300 {\n    @return tint($c, 30%);\n  } @if $n == 400 {\n    @return tint($c, 15%);\n  } @if $n == 500 {\n    @return $c;\n  } @if $n == 600 {\n    @return shade($c, 15%);\n  } @if $n == 700 {\n    @return shade($c, 30%);\n  } @if $n == 800 {\n    @return shade($c, 50%);\n  } @if $n == 900 {\n    @return shade($c, 85%);\n  }\n}\n\n\n// Scaffolding\n// -------------------------\n$body-background:        $white !default;\n$text-color:             $gray-dark !default;\n\n\n// Links\n// -------------------------\n$link-color:             $brand-color !default;\n$link-color-hover:       color-weight($brand-color, 700) !default;\n\n\n// Typography\n// -------------------------\n$sans-font-family:        \"Helvetica Neue\", Helvetica, Arial, \"Lucida Grande\", sans-serif !default;\n$mono-font-family:        Open Sans Mono, Menlo, DejaVu Sans Mono, monospace !default;\n\n$base-font-size:          16px !default;\n$base-line-height:        20px !default;\n\n$body1-font-size:         12px;\n$body1-line-height:       1.4em;\n\n$body2-font-size:         14px;\n$body2-line-height:       1.4em;\n\n$title-font-size:         20px;\n$title-font-weight:       bold;\n\n$normal-font-size: 13px;\n$normal-line-height: 17px;\n\n$small-font-size: 11px;\n$small-line-height: 12px;\n\n// Include all mixins, making them available to the stylesheet. N.B. Mixins\n// should *never* output CSS, so this is safe.\n@import 'mixins/all';\n"},{"size":975,"relativepath":"h/static/styles/partials/_reset.scss","filename":"_reset.scss","extension":".scss","content":"/*\n  Consistency fixes\n  adopted from http://necolas.github.com/normalize.css/\n  */\n\n* {\n  box-sizing: border-box;\n}\n\nhtml {\n  height: 100%;\n  text-size-adjust: 100%;\n}\n\nbody {\n  min-height: 100%;\n  font-size: 100%;\n  margin: 0;\n}\n\nsub, sup {\n  font-size: 75%;\n  line-height: 0;\n  position: relative;\n}\n\nsup {top: -.5em;}\nsub {bottom: -.25em;}\n\npre {\n  white-space: pre;\n  white-space: pre-wrap;\n  word-wrap: break-word;\n}\n\nb, strong {font-weight: bold;}\nabbr[title] {border-bottom: 1px dotted;}\n\na img, img {\n  -ms-interpolation-mode: bicubic;\n}\n\ninput, textarea, button, select {\n  @include reset-font;\n  line-height: normal;\n  margin: 0;\n}\n\nbutton,\nhtml input[type=\"button\"],\ninput[type=\"reset\"],\ninput[type=\"submit\"] {\n  cursor: pointer;\n  -webkit-appearance: button;\n}\n\ntextarea {overflow: auto;}\n\nimg::selection,\nimg::-moz-selection {\n  background: transparent;\n}\n\nul, ol, li {\n  @include reset-box-model;\n}\n\nul, ol {\n  list-style: none;\n}\n\nblockquote {\n  margin: 0;\n}\n"},{"size":467,"relativepath":"h/static/styles/old-home.scss","filename":"old-home.scss","extension":".scss","content":"@at-root {\n  .press-release-banner {\n    background-color: #f7f7f7;\n    border: 1px solid #ccc;\n    border-radius: 4px;\n  }\n\n  .press-release-banner > p {\n    font-size: 21px;\n    margin-top: 20px;\n    margin-bottom: 20px;\n    text-align: center;\n  }\n\n  /* FIXME: Remove the '!important' hack below and move\n  This to the correct stylesheet in the new homepage.\n   */\n  .social-media-link {\n    font-size: 16px !important;\n    text-decoration: none !important;\n  }\n}\n"},{"size":3026,"relativepath":"h/static/styles/help-page.scss","filename":"help-page.scss","extension":".scss","content":"$base-font-size: 16px;\n$base-line-height: 22px;\n\n@import 'partials/base';\n@import 'partials/reset';\n@import 'partials/forms';\n@import 'partials/grid';\n@import 'partials/elements';\n\n@import 'partials/styled-text';\n\n// FIXME: unify this partial and this entrypoint\n@import 'partials/help-page';\n\nbody {\n  background: #fff;\n}\n\n.help-page {\n  padding-top: 2.5em;\n  padding-bottom: 2.5em;\n  background: $body-background;\n  font-family: 'Lato', sans-serif !important;\n  font-weight: 300;\n\n  @include breakpoint(920px) {\n    padding-right: 460px;\n  }\n\n  .masthead {\n    padding: 2.5em;\n    padding-top: 0;\n  }\n}\n\n.help-page-content {\n  margin: auto;\n  padding: 0 20px;\n  min-width: 480px;\n\n  @include breakpoint(1160px) {\n    padding: 0 5% 0 10%;\n  }\n\n  @include breakpoint(1400px) {\n    padding: 0 10% 0 20%;\n  }\n}\n\n.help-page-heading {\n  color: $gray-darker;\n  margin-bottom: 1em;\n  font-weight: 400;\n  font-size: 1.1em;\n}\n\n.help-page-lede {\n  font-style: italic;\n  margin-bottom: 2.5em;\n}\n\n.help-page-section {\n  padding: 2.5em;\n  border-top: 1px solid #EAEAEA;\n\n  &:first-child {\n    border-top: none;\n    padding-top: 0;\n  }\n}\n\n.help-page-sidebar {\n  position: fixed;\n  top: 20px;\n  right: 2.5em;\n  bottom: 20px;\n  width: 380px;\n  display: block;\n\n  @include breakpoint(920px) {\n    border: $gray-lighter dotted 2px;\n    border-radius: 3px;\n  }\n}\n\n@mixin help-icon {\n  border: 1px solid rgba(0, 0, 0, 0.2);\n  padding: 0.4em;\n  border-radius: 0.4em;\n  background: #FFF;\n  text-shadow: 0 0 2px #F9F9F9, 0 0 0 #777;\n  color: rgba(200, 200, 200, 0.3);\n  font-size: 10px;\n}\n\n#help-1 {\n  position: fixed;\n  top: 60px;\n  right: 60px;\n  width: 210px;\n  color: $gray-light;\n  text-align: right;\n\n  @include icons {\n    @include help-icon;\n    font-size: 14px;\n  }\n}\n\n#help-2 {\n  background: image-url(\"images/help-arrow.svg\") 0 0 no-repeat;\n  width: 60px;\n  height: 45px;\n  position: absolute;\n  top: -10px;\n  right: -10px;\n}\n\n.numbered-list {\n  counter-reset: numbered-list;\n}\n\n.numbered-list-item {\n  position: relative;\n  counter-increment: numbered-list;\n  padding-left: 3em;\n  padding-right: 1.25em;\n  margin-bottom: 2.5em;\n  list-style-type: none;\n\n  &:before {\n    content: counter(numbered-list);\n    display: block;\n    position: absolute;\n    top: .125em;\n    left: 0;\n    width: 2.125em;\n    height: 1.8125em;\n    border: .125em solid $brand-color;\n    border-radius: 50%;\n    text-align: center;\n    padding-top: .3125em; // 24px == Line height of text.\n  }\n}\n\n.feature {\n  margin-bottom: 1.5em;\n}\n\n.feature-heading {\n  color: $gray-darker;\n  font-size: 1em;\n  font-weight: 400;\n  margin-bottom: .555em;\n}\n\n.feature-icon {\n  font-size: .875em;\n  margin-right: .3em;\n}\n\n.help-icon {\n    @include help-icon;\n}\n\n.bookmarklet {\n  white-space: nowrap;\n  color: $gray-darker;\n  padding: 2px 4px;\n  border: 1px solid;\n  border-radius: 2px;\n  font-size: 13px;\n  cursor: move;\n\n  @include icons {\n    font-size: 12px;\n  }\n}\n\n/*\n  Mobile layout\n*/\n\n@media screen and (max-width: 30em) {\n  .help-page-sidebar {\n    display: none;\n  }\n}\n"},{"size":503,"relativepath":"h/static/styles/partials-v2/_form-container.scss","filename":"_form-container.scss","extension":".scss","content":"// A container for forms that are centered on a page.\n// Used for pages whose primary purpose is to display a form.\n// ---------------------------------------------------------\n\n.form-container {\n  margin-left: auto;\n  margin-right: auto;\n\n  // Max width of form fields should be 500px. It is set to 530px here to\n  // account for the padding\n  max-width: 530px;\n\n  // Account form padding is set to align left edge of form with left edge of\n  // masthead\n  padding-left: 15px;\n  padding-right: 15px;\n}\n"},{"size":573,"relativepath":"h/static/styles/partials-v2/_form-actions.scss","filename":"_form-actions.scss","extension":".scss","content":"// Form footer\n// -----------\n// Styles for the bar at the bottom of forms defining the overall actions\n// (eg. Save, Cancel) for the form and help messages (eg. \"Forgot your password?\"\n// on a login form).\n\n.form-actions {\n  margin-top: 20px;\n  margin-bottom: 30px;\n\n  display: flex;\n  flex-direction: row-reverse;\n  align-items: center;\n  position: relative;\n  z-index: $zindex-modal-content;\n\n  &.is-hidden {\n    display: none;\n  }\n}\n\n.form-actions.is-saving {\n  opacity: .5;\n}\n\n.form-actions__message {\n  @include font-small;\n\n  color: $grey-4;\n  padding-left: 15px;\n}\n"},{"size":191,"relativepath":"h/static/styles/partials-v2/_api-token.scss","filename":"_api-token.scss","extension":".scss","content":".api-token {\n  border: 1px solid $grey-3;\n  border-radius: 3px;\n  display: block;\n  min-height: 50px;\n  width: 100%;\n\n  color: $grey-6;\n  text-align: center;\n  font-size: $input-font-size;\n}\n"},{"size":1225,"relativepath":"h/static/styles/partials-v2/_tooltip.scss","filename":"_tooltip.scss","extension":".scss","content":"@mixin tooltip-arrow($rotation) {\n  background: $grey-7;\n  border-bottom: 1px solid rgba(0,0,0,0.20);\n  border-right: 1px solid rgba(0,0,0,0.20);\n  content: \"\";\n  display: none;\n  height: 6px;\n  left: 0;\n  margin-left: auto;\n  margin-right: 7px;\n  position: absolute;\n  right: 0;\n  transform: rotate($rotation);\n  width: 6px;\n\n  .env-js-capable & {\n    display: block;\n  }\n\n  .env-js-timeout & {\n    display: none;\n  }\n}\n\n.tooltip {\n  @include font-small;\n\n  border-radius: 2px;\n  background-color: $grey-7;\n  color: white;\n  display: none;\n  font-style: normal;\n  padding-left: 5px;\n  padding-right: 5px;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  position: absolute;\n  left: calc(100% - 12px);\n  width: 220px;\n  z-index: $zindex-tooltip;\n\n  .env-js-capable & {\n    display: block;\n  }\n\n  .env-js-timeout & {\n    display: none;\n  }\n}\n\n// Arrow at the bottom of the tooltip pointing down at the target element.\n.tooltip:before {\n  @include tooltip-arrow(45deg);\n  content: \"\";\n  top: calc(100% - 5px);\n  right: calc(100% - 16.5px);\n}\n\n.tooltip-label {\n  // Make the label a positioned element so that it appears _above_ the\n  // tooltip's arrow, which partially overlaps the content of the tooltip.\n  position: relative;\n}\n"},{"size":377,"relativepath":"h/static/styles/partials-v2/_tabs.scss","filename":"_tabs.scss","extension":".scss","content":".tabs__link {\n  color: inherit;\n}\n\n.tabs__item {\n  display: inline;\n  color: $grey-4;\n  font-size: $title-font-size;\n\n  &:not(:last-of-type)::after {\n    content: \" / \";\n  }\n\n  .is-active {\n    color: $grey-6;\n  }\n}\n\n.tabs {\n  margin-top: 55px;\n  padding-bottom: 30px;\n}\n\n@media screen and (max-width: $max-phone-width) {\n  .tabs__item {\n    font-size: $input-font-size;\n  }\n}\n"},{"size":1208,"relativepath":"h/static/styles/partials-v2/_dropdown-menu.scss","filename":"_dropdown-menu.scss","extension":".scss","content":"// Dropdown menu\n// -------------\n// Specs: https://trello.com/c/atjT8T9p\n\n@at-root {\n  @mixin menu-item {\n    height: 25px;\n    margin: 0;\n\n    display: flex;\n    flex-direction: row;\n    align-items: center;\n    padding-left: 15px;\n    padding-right: 15px;\n  }\n\n  // Container holding the dropdown menu toggle link and the menu content\n  .dropdown-menu {\n    position: relative;\n  }\n\n  // The content of the dropdown menu\n  .dropdown-menu__menu {\n    position: absolute;\n    right: 0;\n    top: calc(100% + 5px);\n    display: none;\n    z-index: $zindex-dropdown-menu;\n\n    background-color: $white;\n    border: 1px solid $grey-3;\n    border-radius: 2px;\n  }\n\n  .dropdown-menu__menu.is-open {\n    display: block;\n  }\n\n  // Title displayed at the top of the menu\n  .dropdown-menu__title {\n    @include font-small;\n    @include menu-item;\n\n    color: $grey-5;\n    font-weight: bold;\n  }\n\n  .dropdown-menu__item {\n    @include menu-item;\n\n    color: $grey-6;\n    white-space: nowrap;\n  }\n\n  .dropdown-menu__item:hover {\n    background-color: $grey-2;\n  }\n\n  // Item at the bottom of the menu which is separated from the rest by a border\n  .dropdown-menu__item--footer {\n    border-top: 1px solid $grey-3;\n  }\n}\n"},{"size":464,"relativepath":"h/static/styles/partials-v2/_btn.scss","filename":"_btn.scss","extension":".scss","content":"// Form buttons\n// ------------\n\n.btn {\n  @include font-normal;\n\n  min-height: 30px;\n\n  background-color: $grey-6;\n  border: none;\n  border-radius: 2px;\n  color: $white;\n  font-weight: bold;\n  padding-left: 15px;\n  padding-right: 15px;\n  white-space: nowrap;\n}\n\n.btn.is-hidden {\n  display: none;\n}\n\n.btn--cancel {\n  background-color: $grey-4;\n}\n\n.btn:hover {\n  background-color: $brand;\n}\n\n@include touch-input {\n  .btn {\n    min-height: $touch-target-size;\n  }\n}\n"},{"size":416,"relativepath":"h/static/styles/partials-v2/_lozenge.scss","filename":"_lozenge.scss","extension":".scss","content":".lozenge {\n  display: flex;\n  background-color: $grey-3;\n  color: $grey-6;\n  border-radius: 2px;\n  margin-left: 10px;\n  margin-top: 15px;\n  margin-bottom: 15px;\n}\n\n.lozenge__content {\n  padding: 3px 5px 3px 5px;\n  white-space: nowrap;\n}\n\n.lozenge__close {\n  font-weight: bold;\n  padding: 3px 5px 3px 5px;\n  cursor: default;\n\n  &:hover {\n    background-color: $grey-4;\n  }\n}\n\n.is-disabled {\n  pointer-events: none;\n}\n"},{"size":476,"relativepath":"h/static/styles/partials-v2/_util.scss","filename":"_util.scss","extension":".scss","content":"// Utility classes\n\n// Stretch an element to fill available space in its container.\n// Also useful for creating spacers\n.u-stretch {\n  flex-grow: 1;\n}\n\n// Utility class that hides an element during initial page load until its\n// containing element is upgraded, or JS load times out.\n//\n// This class is an exception to the rule that is-* state classes can only be\n// used with specific components.\n@include js {\n  .is-hidden-when-loading {\n    display: none !important;\n  }\n}\n"},{"size":4465,"relativepath":"h/static/styles/partials-v2/_search.scss","filename":"_search.scss","extension":".scss","content":"// Search page\n// -----------\n// Styles for the search page which displays the results\n// of activity queries.\n\n.search-result-container {\n  font-size: $normal-font-size;\n  margin-top: 20px;\n  color: $grey-6;\n}\n\n.search-result-list {\n  max-width: 950px;\n\n  // Remove default padding from <ol>\n  list-style: none;\n  padding-left: 0;\n  padding-right: 0;\n\n  // These margins are set so that the left edge of the search result list\n  // aligns with the left edge of the navbar content\n  margin-left: 30px;\n  margin-right: 30px;\n}\n\n.search-result__timeframe {\n  font-weight: bold;\n  padding-bottom: 10px;\n  border-bottom: 1px solid $grey-2;\n  margin-top: 30px;\n}\n\n// A group of search results\n.search-result-bucket {\n  background-color: $grey-2;\n  border-bottom: 1px solid $grey-3;\n\n  .env-js-capable & {\n    background-color: white;\n    &:hover, &.is-expanded {\n      background-color: $grey-2;\n    }\n  }\n}\n\n.search-result-bucket__header {\n  display: flex;\n  flex-direction: row;\n  padding: 10px 10px;\n\n  cursor: pointer;\n  user-select: none;\n}\n\n.search-result-bucket__domain {\n  flex-grow: 0;\n  flex-shrink: 0;\n  width: 120px;\n  color: $grey-4;\n  margin-right: 10px;\n  word-wrap: break-word;\n}\n\n.search-result-bucket__title-and-annotations-count {\n  display: flex;\n  flex-grow: 1;\n  min-width: 0;  // Without this min-width document titles containing really\n                 // long words won't be wrapped (overflow-wrap: break-word\n                 // won't work), see https://github.com/hypothesis/h/pull/3932\n}\n\n.search-result-bucket__title {\n  font-weight: bold;\n  flex-grow: 1;\n  margin-right: 5px;\n  overflow-wrap: break-word;\n  min-width: 0;  // Without this min-width document titles containing really\n                 // long words won't be wrapped (overflow-wrap: break-word\n                 // won't work), see https://github.com/hypothesis/h/pull/3932\n}\n\n.search-result-bucket__annotations-count {\n  font-weight: bold;\n  width: 75px;\n}\n\n.search-result-bucket__annotations-count-container {\n  width: 30px;\n  background-color: $grey-2;\n  text-align: center;\n  border-radius: 2px;\n  float: right;\n}\n\n.search-result-bucket__domain,\n.search-result-bucket__title,\n.search-result-bucket__annotations-count-container {\n  padding-top: 5px;\n  padding-bottom: 5px;\n}\n\n.search-result-bucket__content {\n  padding-left: 10px;\n  padding-right: 10px;\n}\n\n.search-result-bucket__annotation-cards-container {\n  display: flex;\n  padding-left: 130px;\n\n  &.is-hidden {\n    display: none;\n  }\n}\n\n.search-result-bucket__annotation-cards {\n  flex-grow: 1;\n  max-width: 500px;\n  flex-shrink: 0;\n  padding-left: 0;\n  padding-right: 0;\n}\n\n// Card displaying stats about a group of annotations in search results\n.search-bucket-stats {\n  @include font-normal;\n  margin-left: 30px;\n  word-wrap: break-word;\n  min-width: 0;  // Without this min-width stats containing really\n                 // long words won't be wrapped (word-wrap: break-word won't\n                 // work).\n}\n\n.search-bucket-stats__key {\n  color: $grey-4;\n}\n\n.search-bucket-stats__val {\n  color: $grey-6;\n  margin-bottom: 20px;\n}\n\n.search-bucket-stats__address,\n.search-bucket-stats__username {\n  word-break: break-all;\n}\n\n// On large tablets and below, display bucket titles beneath rather than\n// alongside the domain name.\n@media screen and (max-width: $tablet-width + 100px) {\n    .search-result-bucket__header {\n      flex-direction: column;\n\n      // Make domain and title containers stretch to the full width of the\n      // column\n      align-items: stretch;\n    }\n\n    .search-result-bucket__domain {\n      width: 100%;\n    }\n\n    .search-result-bucket__content {\n      margin-top: 10px;\n    }\n}\n\n// On large tablets and below left-align annotation cards in order to make more\n// space for the stats to the right of the annotation card.\n@media screen and (max-width: $tablet-width + 150px) {\n  .search-result-bucket__annotation-cards-container {\n    padding-left: 0;\n  }\n}\n\n// On normal tablets and below, display annotation stats below annotation list\n@media screen and (max-width: $tablet-width) {\n\n  // Reduce margins on tablet and below to match navbar left/right margins\n  // on these screen sizes\n  .search-result-list {\n    margin-left: 10px;\n    margin-right: 10px;\n  }\n\n  .search-result-bucket__annotation-cards-container {\n    flex-direction: column;\n  }\n\n  .search-result-bucket__annotation-cards {\n    width: 100%;\n  }\n\n  .search-bucket-stats {\n    margin-left: 5px;\n    margin-top: 10px;\n  }\n}\n"},{"size":1807,"relativepath":"h/static/styles/partials-v2/_search-bar.scss","filename":"_search-bar.scss","extension":".scss","content":"// Input field in the nav bar for searching annotations\n// ----------------------------------------------------\n// Specs: https://trello.com/c/atjT8T9p\n\n.search-bar {\n  border: 1px solid $grey-3;\n  border-radius: 2px;\n  display: flex;\n}\n\n.search-bar__input {\n  width: 100%;\n\n  border: none;\n\n  // Add spacing to left of input field for search icon\n  padding-left: 7px;\n  padding-top: 18px;\n  padding-bottom: 18px;\n  padding-right: 3px;\n}\n\n.search-bar__input:hover,\n.search-bar__input:focus {\n  border-color: $grey-4;\n  outline: none;\n}\n\n.search-bar__lozenges {\n  display: flex;\n}\n\n.search-bar__icon {\n  flex-shrink: 0;\n  height: 14px;\n  margin-left: 7px;\n  margin-top: 18px;\n  color: $grey-5;\n}\n\n.search-bar__input:hover + .search-bar__icon,\n.search-bar__input:focus + .search-bar__icon {\n  color: $grey-6;\n}\n\n.search-bar__dropdown-menu-container {\n  background: white;\n  border: 1px solid $grey-2;\n  border-top: none;\n  box-shadow: 0px 2px 3px 0px rgba(0, 0, 0, 0.15);\n  color: $grey-4;\n  display: none;\n  padding: 20px 0 0 0;\n  position: absolute;\n  margin-top: 52px;\n  width: 100%;\n  z-index: $zindex-dropdown-menu;\n  max-width: 650px;\n}\n\n.search-bar__dropdown-menu-header {\n  margin: 0 30px 7px 30px;\n}\n\n.search-bar__dropdown-menu-item {\n  padding: 6px 30px 6px 30px;\n  cursor: default;\n}\n\n.search-bar__dropdown-menu-item:last-child {\n  margin-bottom: 14px;\n}\n\n.js-search-bar-dropdown-menu-item--active {\n  background-color: $grey-2;\n}\n\n.search-bar__dropdown-menu-title {\n  color: $grey-6;\n  font-weight: bold;\n}\n\n.search-bar__dropdown-menu-explanation {\n  font-style: italic;\n}\n\n.search-bar__dropdown-menu-container.is-open {\n  display: block;\n}\n\n.search-bar__dropdown-menu-item.is-hidden {\n  display: none;\n}\n\n@include touch-input {\n  .search-bar__input {\n    font-size: $touch-input-font-size;\n  }\n}\n"},{"size":373,"relativepath":"h/static/styles/partials-v2/_form-checkbox.scss","filename":"_form-checkbox.scss","extension":".scss","content":".form-checkbox {\n  @include font-normal;\n  border: 1px solid $grey-3;\n  border-radius: 3px;\n  color: $grey-6;\n\n  max-width: 600px;\n  margin-left: auto;\n  margin-right: auto;\n}\n\n.form-checkbox__input {\n  margin-right: 15px;\n}\n\n.form-checkbox__label {\n  min-height: 50px;\n\n  display: flex;\n  flex-direction: row;\n  align-items: center;\n  padding: 15px;\n\n  cursor: pointer;\n}\n"},{"size":1280,"relativepath":"h/static/styles/partials-v2/_form.scss","filename":"_form.scss","extension":".scss","content":"// Standard layout for forms\n// -------------------------\n// Specs: https://goo.gl/pEV9E1\n\n// Backdrop which appears behind forms during inline editing\n.form__backdrop {\n  display: none;\n  position: fixed;\n  top: 0;\n  left: 0;\n  right: 0;\n  bottom: 0;\n  z-index: $zindex-modal-backdrop;\n\n  background-color: $white;\n  opacity: 0.5;\n}\n\n// Error message displayed if AJAX form submission fails for reasons other than\n// a validation error. When there is a validation error, the response is updated\n// markup for the form which replaces the original.\n.form__submit-error {\n  color: $brand;\n  display: none;\n  font-weight: bold;\n  margin-top: 5px;\n  margin-bottom: 5px;\n\n  &.is-visible {\n    display: block;\n  }\n}\n\n.form.is-editing > .form__backdrop {\n  display: block;\n}\n\n.form-header {\n  margin-top: 55px;\n  margin-bottom: 30px;\n\n  color: $grey-6;\n  font-weight: normal;\n  font-size: $title-font-size;\n}\n\n.form-description {\n  margin-bottom: 30px;\n\n  color: $grey-5;\n}\n\n.form-footer {\n  @include font-normal;\n\n  margin-top: 80px;\n\n  border-top: 1px solid $grey-3;\n  color: $grey-5;\n  padding-top: 15px;\n}\n\n.form-help-text {\n  color: $grey-5;\n}\n\n.form-footer__required {\n  display: flex;\n  justify-content: flex-end;\n}\n\n.form-footer__symbol {\n  color: $brand;\n  margin-right: 3px;\n}\n"},{"size":278,"relativepath":"h/static/styles/partials-v2/_link.scss","filename":"_link.scss","extension":".scss","content":"// Text links\n// ----------\n// Styling for text links. Note that these are not used for links to pages\n// for specific objects (eg. a document, a tag, a profile).\n\n.link {\n  color: inherit;\n  padding-bottom: 2px;\n  border-bottom: 1px dotted;\n}\n\n.link:hover {\n  color: $brand;\n}\n"},{"size":173,"relativepath":"h/static/styles/partials-v2/_masthead.scss","filename":"_masthead.scss","extension":".scss","content":"// The header at the top of the page displaying the\n// Hypothesis logo\n\n.masthead {\n  padding-bottom: 0;\n  padding-left: 15px;\n  padding-right: 15px;\n  padding-top: 15px;\n}\n"},{"size":516,"relativepath":"h/static/styles/partials-v2/_elements.scss","filename":"_elements.scss","extension":".scss","content":"// Basic standard styling for elements\n\na, a:active, a:focus, a:hover {\n  text-decoration: none;\n}\n\nol {\n  list-style-type: decimal;\n  padding-left: 3em;\n}\n\nsvg {\n  -webkit-tap-highlight-color: rgba(255, 255, 255, 0);\n}\n\n// Remove browser default styling for text input fields, such as the drop shadow\n// inside the field on iOS.\n// See http://stackoverflow.com/questions/23211656/remove-ios-input-shadow\ninput:not([type]),\ninput[type=email],\ninput[type=password],\ninput[type=text],\ntextarea {\n  appearance: none;\n}\n"},{"size":1391,"relativepath":"h/static/styles/partials-v2/_base.scss","filename":"_base.scss","extension":".scss","content":"// Color palette\n// -------------\n\n$white: white;\n$black: black;\n\n$grey-1: #f2f2f2;\n$grey-2: #ececec;\n$grey-3: #dbdbdb;\n$grey-4: #a6a6a6;\n$grey-5: #7a7a7a;\n$grey-6: #3f3f3f;\n$grey-7: #202020;\n\n$brand: #d00032;\n$highlight: #58cef4;\n\n// Typography\n// ----------\n\n$sans-font-family: \"Helvetica Neue\", Helvetica, Arial, \"Lucida Grande\", sans-serif !default;\n$mono-font-family: Open Sans Mono, Menlo, DejaVu Sans Mono, monospace !default;\n\n// Standard font sizes\n$normal-font-size: 13px;\n$normal-line-height: 15px;\n\n$small-font-size: 11px;\n$small-line-height: 12px;\n\n$title-font-size: 19px;\n\n// Font sizes for specific categories of control\n$input-font-size: 15px;\n\n// Minimum font size for <input> fields on iOS. If the font size is smaller than\n// this, iOS will zoom into the field when focused.\n$touch-input-font-size: 16px;\n\n// Z-index scale\n// -------------\n$zindex-modal-backdrop: 5; // Backdrop of a modal dialog or form\n$zindex-modal-content: 6;  // Content of a modal dialog or form\n$zindex-dropdown-menu: 10;\n$zindex-tooltip: 20;\n\n// Mobile device size breakpoints\n// ------------------------------\n// See the CSS width/height values at http://mydevice.io/devices/\n\n$max-phone-width: 500px;\n$tablet-width: 768px;\n$touch-target-size: 44px;\n\n// Include all mixins, making them available to the stylesheet. N.B. Mixins\n// should *never* output CSS, so this is safe.\n@import 'mixins/all';\n"},{"size":1933,"relativepath":"h/static/styles/partials-v2/_nav-bar.scss","filename":"_nav-bar.scss","extension":".scss","content":"// Navigation bar displayed at the top of the page\n// -----------------------------------------------\n// Specs: https://trello.com/c/atjT8T9p\n\n.nav-bar {\n  position: relative;\n\n  border-bottom: 1px solid $grey-3;\n  padding-top: 10px;\n  padding-bottom: 10px;\n}\n\n// Nav bar content which lays out nav bar items, except for the search input\n// on small screens\n.nav-bar__content {\n  display: flex;\n  flex-direction: row;\n}\n\n.nav-bar__logo-container {\n  display: flex;\n  justify-content: center;\n}\n\n.nav-bar__logo {\n  margin-left: 30px;\n  margin-right: 30px;\n}\n\n.nav-bar__search {\n  flex-grow: 2;\n  max-width: 650px;\n}\n\n.nav-bar-links {\n  margin-left: 10px;\n  margin-right: 60px;\n\n  display: flex;\n  flex-direction: row;\n  align-items: center;\n}\n\n// Containers for links and dropdown menus displayed on the right-hand side of\n// the nav bar\n.nav-bar-links__item {\n  height: 18px;\n  margin-left: 10px;\n  margin-right: 10px;\n}\n\n// Link text for links on the right-side of the nav bar\n.nav-bar-links__link {\n  display: flex;\n  flex-direction: row;\n  align-items: center;\n\n  @include font-normal;\n  color: $grey-5;\n}\n\n// Dropdown arrow indicator shown to the right of the 'Groups' and 'Settings'\n// menus\n.nav-bar-links__dropdown-arrow {\n  display: inline-block;\n  margin-left: 5px;\n\n  @include font-small;\n  color: $grey-4;\n}\n\n.nav-bar-links__item:first-child {\n  margin-left: 0;\n}\n\n.nav-bar-links__item:last-child {\n  margin-right: 0;\n}\n\n@media screen and (max-width: $tablet-width) {\n  // Reduce horizontal margins on smaller screens to provide more space for\n  // search bar\n  .nav-bar__logo {\n    margin-left: 10px;\n  }\n\n  .nav-bar-links {\n    margin-right: 10px;\n  }\n}\n\n@media screen and (max-width: $max-phone-width) {\n  // Display search bar full-width underneath nav links on phone-sized screens\n  .nav-bar {\n    height: 120px;\n  }\n\n  .nav-bar__search {\n    position: absolute;\n    top: 50px;\n    left: 10px;\n    right: 10px;\n  }\n}\n"},{"size":5022,"relativepath":"h/static/styles/partials-v2/_form-input.scss","filename":"_form-input.scss","extension":".scss","content":"// Form input fields\n// -----------------\n// Specs: https://goo.gl/pEV9E1\n\n@at-root {\n  $border-radius: 3px;\n\n  // Padding between top border of input and input text. This includes space\n  // for the field label\n  $top-padding: 35px;\n  // Padding between bottom border of input and input text.\n  $bottom-padding: 15px;\n\n  // Extra vertical padding added above input content for form fields displaying\n  // inline hints\n  $hint-height: 35px;\n\n  // Horizontal padding between focus ring and input field / validation messages\n  $h-padding: 10px;\n  // Max width of validation error messages when shown to the right of the\n  // input field\n  $validation-message-width: 200px;\n\n  .form-input {\n    // Margin between input fields\n    margin-bottom: 15px;\n    position: relative;\n\n    background-color: $white;\n  }\n\n  .form-input.is-editing {\n    z-index: $zindex-modal-content;\n  }\n\n  .form-input.is-error {\n    & > .form-input__label {\n      color: $brand;\n    }\n\n    & > .form-input__input {\n      color: $brand;\n    }\n\n    & > .form-input__error-list {\n      display: initial;\n    }\n  }\n\n  // Descriptive label above the input field\n  .form-input__label {\n    @include font-normal;\n\n    position: absolute;\n    top: 10px;\n    left: $h-padding;\n\n    color: $grey-5;\n\n    display: flex;\n    // The label is a sibling of the <input> field. Raise it above the <input>\n    // so that the field's tooltip appears above the focus ring\n    z-index: 1;\n  }\n\n  .form-input__character-counter {\n    @include font-normal;\n\n    // Show fallback \"counter\" if loading js times out.\n    .env-js-timeout & {\n      display: initial;\n    }\n\n    // Immediately hide counter if js capable - prevents momentary flash of\n    // unenhanced fallback counter before js kicks in.\n    .env-js-capable & {\n      display: none;\n    }\n\n    // The js controller adds this class when it's ready - show the now\n    // enhanced counter.\n    &.is-ready {\n      display: initial;\n    }\n\n    &.is-too-long {\n      color: $brand;\n      font-weight: bold;\n    }\n\n    position: absolute;\n    bottom: 10px;\n    right: $h-padding;\n\n    color: $grey-5;\n  }\n\n  .form-input__required {\n    color: $brand;\n  }\n\n  .form-input__hint-icon {\n    display: none;\n    margin-left: 6px;\n    margin-top: 1px;\n    position: relative;\n\n    .env-js-capable & {\n      display: block;\n    }\n\n    .env-js-timeout & {\n      display: none;\n    }\n  }\n\n  .form-input__hint {\n    @include font-normal;\n\n    color: $grey-5;\n    margin-top: -10px;\n\n    .env-js-capable & {\n      display: none;\n    }\n\n    .env-js-timeout & {\n      display: block;\n    }\n  }\n\n  // The actual <input> element for the field\n  .form-input__input {\n    padding-top: $top-padding;\n    padding-left: $h-padding;\n    padding-right: $h-padding;\n    padding-bottom: $bottom-padding;\n    width: 100%;\n\n    background: none;\n    color: $grey-6;\n    font-size: $input-font-size;\n    outline: none;\n    border: 1px solid $grey-3;\n    border-radius: 3px;\n  }\n\n  .form-input__input.has-hint {\n    .env-js-capable & {\n      padding-top: $top-padding;\n    }\n  }\n\n  .form-input__input:hover {\n    border: 1px solid $grey-4;\n  }\n\n  // Thicker border used when input field has focus or has a validation error\n  @mixin thick-border {\n    // Adjust position of <input> to keep input field content at the same\n    // position, given the thicker border. We adjust the position rather than\n    // the padding because there are other states (eg. whether the form field\n    // has a hint) that affect the amount of padding required and this avoids\n    // doubling the number of those states.\n    position: relative;\n    left: -1px;\n    top: -1px;\n    padding-bottom: $bottom-padding - 2px;\n    border-width: 2px;\n  }\n\n  .form-input__input:focus,\n  .form-input.is-editing > .form-input__input {\n    @include thick-border;\n    border-color: $grey-6;\n  }\n\n  .form-input.is-error > .form-input__input {\n    @include thick-border;\n    border-color: $brand;\n    padding-right: $validation-message-width + 10px;\n  }\n\n  .form-input__input:invalid {\n    // Disable default glow for invalid input fields in Firefox.\n    // See https://hyp.is/Z3bV7FV8EeaKSc_QAoTqRw\n    box-shadow: none;\n  }\n\n  // Validation error messages\n  .form-input__error-list {\n    // The error list is only shown when the input is in an `error` state\n    display: none;\n  }\n\n  .form-input__error-item {\n    max-width: $validation-message-width;\n    position: absolute;\n    right: $h-padding;\n    top: $h-padding;\n\n    color: $brand;\n  }\n\n  @include touch-input {\n    .form-input__input {\n      font-size: $touch-input-font-size;\n    }\n  }\n\n  // On narrow screens, display validation error messages underneath the\n  // input field.\n  @media screen and (max-width: $max-phone-width) {\n    .form-input.is-error > .form-input__input {\n      padding-bottom: $bottom-padding + 25px;\n      padding-right: $h-padding - 1px;\n    }\n\n    .form-input__error-item {\n      top: unset;\n      bottom: 10px;\n      left: $h-padding;\n      right: $h-padding;\n      max-width: unset;\n    }\n  }\n}\n"},{"size":1164,"relativepath":"h/static/styles/partials-v2/_annotation-card.scss","filename":"_annotation-card.scss","extension":".scss","content":"// Annotation card\n// ---------------\n// Styles for the annotation card which is displayed in the\n// results of activity queries.\n\n.annotation-card {\n  @include font-normal;\n  border: 1px solid $grey-2;\n  list-style: none;\n  padding: 15px;\n  margin-bottom: 10px;\n  box-shadow: 0px 1px 1px 0px rgba(0, 0, 0, 0.1);\n  background: white;\n}\n\n.annotation-card:hover {\n  box-shadow: 0px 2px 3px 0px rgba(0, 0, 0, 0.15);\n\n  .annotation-card__quote {\n    border-left: $highlight 3px solid;\n    color: $grey-5;\n  }\n\n  .annotation-card__timestamp {\n    color: $grey-5;\n  }\n}\n\n.annotation-card__header {\n  margin-bottom: 15px;\n  display: flex;\n  flex-direction: row;\n  align-items: baseline;\n  justify-content: space-between;\n}\n\n.annotation-card__username {\n  color: #202020;\n  font-weight: bold;\n}\n\n.annotation-card__timestamp {\n  @include font-small;\n  color: $grey-4;\n}\n\n.annotation-card__quote {\n  padding: 0 10px;\n  overflow-wrap: break-word;\n  color: $grey-4;\n  font-family: sans-serif;\n  font-size: 12px;\n  font-style: italic;\n  letter-spacing: 0.1px;\n  border-left: 3px solid $grey-3;\n}\n\n.annotation-card__text {\n  @include styled-text;\n  overflow-wrap: break-word;\n}\n"},{"size":315,"relativepath":"h/static/styles/partials-v2/_join-group-form.scss","filename":"_join-group-form.scss","extension":".scss","content":".join-group-form__label {\n  color: $grey-5;\n  margin-bottom: 15px;\n}\n\n.join-group-form__container {\n  border: 1px solid $grey-3;\n  padding: 15px 20px;\n  color: $grey-6;\n}\n\n.join-group-form__group-name {\n  font-weight: bold;\n}\n\n.join-group-form__group-description {\n  margin-bottom: 20px;\n  word-wrap: break-word;\n}\n"},{"size":997,"relativepath":"h/static/styles/partials-v2/_reset.scss","filename":"_reset.scss","extension":".scss","content":"/*\n  Consistency fixes\n  adopted from http://necolas.github.com/normalize.css/\n  */\n\n* {\n  box-sizing: border-box;\n}\n\nhtml {\n  height: 100%;\n  text-size-adjust: 100%;\n}\n\nbody {\n  min-height: 100%;\n  font-size: 100%;\n  margin: 0;\n}\n\nsub, sup {\n  font-size: 75%;\n  line-height: 0;\n  position: relative;\n}\n\nsup {\n  top: -.5em;\n}\n\nsub {\n  bottom: -.25em;\n}\n\npre {\n  white-space: pre;\n  white-space: pre-wrap;\n  word-wrap: break-word;\n}\n\nb, strong {\n  font-weight: bold;\n}\n\nabbr[title] {\n  border-bottom: 1px dotted;\n}\n\na img, img {\n  -ms-interpolation-mode: bicubic;\n}\n\ninput, textarea, button, select {\n  @include reset-font;\n  line-height: normal;\n  margin: 0;\n}\n\nbutton,\nhtml input[type=\"button\"],\ninput[type=\"reset\"],\ninput[type=\"submit\"] {\n  cursor: pointer;\n  -webkit-appearance: button;\n}\n\ntextarea {\n  overflow: auto;\n}\n\nimg::selection,\nimg::-moz-selection {\n  background: transparent;\n}\n\nul, ol, li {\n  @include reset-box-model;\n}\n\nul, ol {\n  list-style: none;\n}\n\nblockquote {\n  margin: 0;\n}\n"},{"size":894,"relativepath":"h/static/styles/partials-v2/_pager.scss","filename":"_pager.scss","extension":".scss","content":".pager {\n  display: flex;\n  flex-direction: row;\n  margin: 40px auto;\n  font-weight: bold;\n  justify-content: center;\n}\n\n.pager__item {\n  display: inline-block;\n  border-radius: 2px;\n  color: $grey-6;\n  padding: 7px 10px 7px 10px;\n}\n\n.pager__item:not(.is-disabled):hover {\n  background-color: $grey-3;\n}\n\n.pager__item--more {\n  color: $grey-4;\n}\n\n.pager__item--begin,\n.pager__item--end {\n  padding-top: 8px;\n  padding-bottom: 6px;\n  fill: currentColor;\n}\n\n\n.pager__item--begin {\n  background-color: $grey-3;\n  margin-right: 10px;\n}\n\n.pager__item--end {\n  background-color: $grey-3;\n  margin-left: 10px;\n}\n\n.pager__item--end:not(.is-disabled):hover,\n.pager__item--begin:not(.is-disabled):hover {\n  background-color: $brand;\n  color: $white;\n}\n\n.pager__item--link {\n  color: inherit;\n}\n\n.pager__item.is-highlighted {\n  background-color: $grey-3;\n}\n\n.pager__item.is-disabled {\n  color: $grey-4;\n}\n"},{"size":65168,"relativepath":"h/static/styles/legacy-site.css","filename":"legacy-site.css","extension":".css","content":"/*\n * This is a pre-built copy of `app.css` from the Hypothesis client.  It\n * provides styles that are used by the legacy login/signup and account\n * settings pages.\n *\n * This should be removed once Activity Pages has been released and the\n * new-style login forms and Account Settings pages are used by all users.\n */\n\n/*\n  Consistency fixes\n  adopted from http://necolas.github.com/normalize.css/\n  */\n* {\n  box-sizing: border-box; }\n\nhtml {\n  height: 100%;\n  -webkit-text-size-adjust: 100%;\n      -ms-text-size-adjust: 100%;\n          text-size-adjust: 100%; }\n\nbody {\n  min-height: 100%;\n  font-size: 100%;\n  margin: 0; }\n\nsub, sup {\n  font-size: 75%;\n  line-height: 0;\n  position: relative; }\n\nsup {\n  top: -.5em; }\n\nsub {\n  bottom: -.25em; }\n\npre {\n  white-space: pre;\n  white-space: pre-wrap;\n  word-wrap: break-word; }\n\nb, strong {\n  font-weight: bold; }\n\nabbr[title] {\n  border-bottom: 1px dotted; }\n\na img, img {\n  -ms-interpolation-mode: bicubic; }\n\ninput, textarea, button, select {\n  font: inherit;\n  font-size: 100%;\n  vertical-align: baseline;\n  line-height: normal;\n  margin: 0; }\n\nbutton,\nhtml input[type=\"button\"],\ninput[type=\"reset\"],\ninput[type=\"submit\"] {\n  cursor: pointer;\n  -webkit-appearance: button; }\n\ntextarea {\n  overflow: auto; }\n\nimg::-moz-selection,\nimg::-moz-selection {\n  background: transparent; }\n\nimg::selection,\nimg::-moz-selection {\n  background: transparent; }\n\nul, ol, li {\n  margin: 0;\n  padding: 0;\n  border: 0; }\n\nul, ol {\n  list-style: none; }\n\nblockquote {\n  margin: 0; }\n\nmarkdown {\n  display: block; }\n\na {\n  color: #bd1c2b;\n  text-decoration: none; }\n\na:active, a:focus {\n  text-decoration: none; }\n\na:hover {\n  text-decoration: none;\n  color: shade(#bd1c2b, 30%); }\n\nol {\n  list-style-type: decimal;\n  padding-left: 3em; }\n\nsvg {\n  -webkit-tap-highlight-color: rgba(255, 255, 255, 0); }\n\n.u-stretch {\n  -webkit-box-flex: 1;\n  -webkit-flex-grow: 1;\n      -ms-flex-positive: 1;\n          flex-grow: 1; }\n\n.u-layout-row {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row; }\n\n.u-center {\n  margin-left: auto;\n  margin-right: auto; }\n\n.u-align-right {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row;\n  -webkit-box-pack: end;\n  -webkit-justify-content: flex-end;\n      -ms-flex-pack: end;\n          justify-content: flex-end; }\n\n.u-strong {\n  font-weight: bold; }\n\n.u-hidden {\n  display: none; }\n\n/* Style input placeholders */\n/* Shadow mixins */\n.annotator-hide {\n  display: none;\n  visibility: hidden; }\n\n.u-stretch {\n  -webkit-box-flex: 1;\n  -webkit-flex-grow: 1;\n      -ms-flex-positive: 1;\n          flex-grow: 1; }\n\n.u-layout-row {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row; }\n\n.u-center {\n  margin-left: auto;\n  margin-right: auto; }\n\n.u-align-right {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row;\n  -webkit-box-pack: end;\n  -webkit-justify-content: flex-end;\n      -ms-flex-pack: end;\n          justify-content: flex-end; }\n\n.u-strong {\n  font-weight: bold; }\n\n.u-hidden {\n  display: none; }\n\n/* Style input placeholders */\n/* Shadow mixins */\n.annotator-hide {\n  display: none;\n  visibility: hidden; }\n\n.form-field {\n  clear: both;\n  margin-bottom: .75em; }\n  .form-field:after {\n    content: \"\";\n    display: table;\n    clear: both; }\n\n.form-heading {\n  position: relative;\n  text-transform: uppercase;\n  font-weight: bold;\n  font-size: 1em;\n  margin-top: 1.5em;\n  margin-bottom: 1.5em; }\n  .form-heading span {\n    position: relative;\n    background: white;\n    padding-right: .4em;\n    z-index: 1; }\n  .form-heading:after {\n    content: \"\";\n    display: block;\n    height: 1px;\n    background: #d3d3d3;\n    width: 100%;\n    position: absolute;\n    top: 50%;\n    left: 0;\n    margin-top: -1px;\n    z-index: 0; }\n\n.form-description {\n  margin-bottom: 1em; }\n\n.form-flash {\n  background: #626262;\n  color: #fff;\n  width: 100%;\n  font-weight: bold;\n  text-align: center;\n  margin: 1em 0 0 0;\n  padding: 0;\n  display: inline-block; }\n  .form-flash p {\n    margin: 0.75em; }\n\n.form-input,\n.form-label {\n  width: 100%;\n  display: block; }\n\n.form-label {\n  cursor: pointer;\n  font-weight: bold;\n  margin-bottom: .4em; }\n\n.form-label--light {\n  font-weight: normal; }\n\n.form-hint {\n  font-size: .833em;\n  margin-left: .25em;\n  color: #969696;\n  -webkit-font-smoothing: antialiased; }\n\n.form-required, .form-required[title] {\n  cursor: help;\n  color: #969696;\n  border-bottom: none;\n  -webkit-font-smoothing: antialiased; }\n\n.form-input {\n  font-size: 13px;\n  line-height: 17px;\n  font-weight: 400;\n  border: 1px solid #d3d3d3;\n  border-radius: 2px;\n  padding: .5em .75em;\n  font-weight: normal;\n  color: #777;\n  background-color: #FAFAFA; }\n  .form-input:focus, .form-input.js-focus {\n    outline: none;\n    background-color: #FFF;\n    border-color: #51A7E8;\n    box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.075) inset, 0px 0px 5px rgba(81, 167, 232, 0.5); }\n    .form-input:focus.placeholder, .form-input.js-focus.placeholder {\n      color: #777; }\n    .form-input:focus:placeholder, .form-input.js-focus:placeholder {\n      color: #777; }\n    .form-input:focus::-webkit-input-placeholder, .form-input.js-focus::-webkit-input-placeholder {\n      color: #777; }\n    .form-input:focus::-moz-placeholder, .form-input.js-focus::-moz-placeholder {\n      color: #777; }\n    .form-input:focus:-ms-input-placeholder, .form-input.js-focus:-ms-input-placeholder {\n      color: #777; }\n    .form-input:focus::placeholder, .form-input.js-focus::placeholder {\n      color: #777; }\n\n.form-textarea {\n  min-height: 8em;\n  max-width: 100%;\n  resize: vertical; }\n\n.form-field-error .form-input, .form-field-error .form-input:focus, .form-field-error .form-input.js-focus {\n  color: #f0480c;\n  border-color: #f57f55;\n  background-color: #fde4db; }\n  .form-field-error .form-input.placeholder, .form-field-error .form-input:focus.placeholder, .form-field-error .form-input.js-focus.placeholder {\n    color: #f15118; }\n  .form-field-error .form-input:placeholder, .form-field-error .form-input:focus:placeholder, .form-field-error .form-input.js-focus:placeholder {\n    color: #f15118; }\n  .form-field-error .form-input::-webkit-input-placeholder, .form-field-error .form-input:focus::-webkit-input-placeholder, .form-field-error .form-input.js-focus::-webkit-input-placeholder {\n    color: #f15118; }\n  .form-field-error .form-input::-moz-placeholder, .form-field-error .form-input:focus::-moz-placeholder, .form-field-error .form-input.js-focus::-moz-placeholder {\n    color: #f15118; }\n  .form-field-error .form-input:-ms-input-placeholder, .form-field-error .form-input:focus:-ms-input-placeholder, .form-field-error .form-input.js-focus:-ms-input-placeholder {\n    color: #f15118; }\n  .form-field-error .form-input::placeholder, .form-field-error .form-input:focus::placeholder, .form-field-error .form-input.js-focus::placeholder {\n    color: #f15118; }\n\n.form-field-error .form-error-list {\n  display: block; }\n\n.form-select {\n  display: block; }\n\n.form-error-list {\n  position: relative;\n  display: none;\n  background: #f0480c;\n  margin-top: .75em;\n  padding: .25em .75em;\n  float: left;\n  border-radius: 2px; }\n  .form-error-list .form-error {\n    font-size: .833em;\n    color: white; }\n  .form-error-list:after {\n    bottom: 100%;\n    left: 50%;\n    border: solid transparent;\n    content: \" \";\n    height: 0;\n    width: 0;\n    position: absolute;\n    pointer-events: none;\n    border-color: rgba(240, 72, 12, 0);\n    border-bottom-color: #f0480c;\n    border-width: 4px;\n    margin-left: -4px; }\n\n.form-error {\n  color: #f0480c; }\n\n.form-checkbox-item {\n  padding-left: 1.5em; }\n  .form-checkbox-item .form-checkbox, .form-checkbox-item [type=checkbox], .form-checkbox-item [type=radio] {\n    float: left;\n    margin-left: -1.5em;\n    margin-top: .25em; }\n  .form-checkbox-item .form-label {\n    display: inline; }\n\n.form-inline {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex; }\n  .form-inline .form-input {\n    -webkit-box-flex: 1;\n    -webkit-flex-grow: 1;\n        -ms-flex-positive: 1;\n            flex-grow: 1;\n    width: auto; }\n  .form-inline .btn {\n    margin-left: .5em; }\n\n.form-actions {\n  margin-top: .75em; }\n  .form-actions:after {\n    content: \"\";\n    display: table;\n    clear: both; }\n\n.form-actions-message {\n  font-size: .833em;\n  float: left;\n  margin-top: 1em; }\n\n.form-actions-buttons {\n  float: right; }\n  .form-actions-buttons:after {\n    content: \"\";\n    display: table;\n    clear: both; }\n  .form-actions-buttons > * {\n    margin-left: .75em; }\n    .form-actions-buttons > *:first-child {\n      margin-left: 0; }\n\n.form-actions-left {\n  float: left; }\n\n.form-actions-right {\n  float: right; }\n\n.btn {\n  box-shadow: 0 1px 0 rgba(0, 0, 0, 0.15);\n  background: -webkit-linear-gradient(top, #fff, #f0f0f0);\n  background: linear-gradient(to bottom, #fff, #f0f0f0);\n  display: inline-block;\n  font-weight: bold;\n  color: #585858;\n  text-shadow: 0 1px 0 #FFF;\n  border-radius: 2px;\n  border: 1px solid #969696;\n  padding: .5em .9em; }\n  .btn:hover, .btn:focus, .btn:active, .btn.js-hover, .btn.js-focus, .btn.js-active {\n    box-shadow: 0 1px 0 rgba(0, 0, 0, 0.05);\n    outline: none;\n    color: #585858;\n    background: #fff;\n    border-color: #bababa; }\n  .btn:focus, .btn.js-focus {\n    border-color: #51A7E8;\n    box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.075) inset, 0px 0px 5px rgba(81, 167, 232, 0.5); }\n  .btn:active, .btn.js-active {\n    box-shadow: inset 0 1px 0 rgba(0, 0, 0, 0.1);\n    background: #f0f0f0;\n    color: #424242;\n    border-color: #bababa; }\n  .btn[disabled], .btn.js-disabled {\n    box-shadow: none;\n    cursor: default;\n    background: #F0F0F0;\n    border-color: #CECECE;\n    color: #969696; }\n\n.btn-danger {\n  background: -webkit-linear-gradient(top, #f0480c, #e4440b);\n  background: linear-gradient(to bottom, #f0480c, #e4440b);\n  color: white;\n  border-color: #cc3d0a;\n  text-shadow: 0 -1px 0 rgba(0, 0, 0, 0.1); }\n  .btn-danger:focus, .btn-danger:hover, .btn-danger:active, .btn-danger.js-hover, .btn-danger.js-focus, .btn-danger.js-active {\n    box-shadow: 0 1px 0 rgba(0, 0, 0, 0.05);\n    color: white;\n    background: #f15118;\n    border-color: #f0480c; }\n  .btn-danger:active, .btn-danger.js-active {\n    box-shadow: inset 0 1px 0 rgba(0, 0, 0, 0.3);\n    color: white;\n    background: #d8410b;\n    border-color: #a83208; }\n\n.btn-clean {\n  border: none; }\n  .btn-clean, .btn-clean:focus, .btn-clean:hover, .btn-clean:active, .btn-clean[disabled], .btn-clean.js-hover, .btn-clean.js-focus, .btn-clean.js-active, .btn-clean.js-disabled {\n    box-shadow: none;\n    background: none; }\n  .btn-clean:focus, .btn-clean:hover, .btn-clean:active, .btn-clean.js-hover, .btn-clean.js-focus, .btn-clean.js-active {\n    color: #bd1c2b; }\n  .btn-clean:active, .btn-clean.js-active {\n    color: shade(#bd1c2b, 30%); }\n  .btn-clean[disabled], .btn-clean.js-disabled {\n    color: #585858; }\n\n.btn-icon {\n  display: inline-block;\n  font-size: 16px; }\n\n.btn-with-message {\n  position: relative; }\n\n.btn-message {\n  font-style: italic;\n  color: #969696;\n  margin-right: .5em;\n  position: absolute;\n  right: 100%;\n  top: 0;\n  white-space: nowrap; }\n\n.btn-message-icon {\n  display: inline-block;\n  background: #1cbd41;\n  border-radius: 50%;\n  color: #FFF;\n  padding: 2px; }\n\n.btn--cancel, .publish-annotation-cancel-btn {\n  color: #bbb; }\n  .btn--cancel:hover, .publish-annotation-cancel-btn:hover {\n    color: #959595; }\n\n[status-button-state] .btn-message {\n  top: -999em;\n  left: -999em;\n  right: auto; }\n\n[status-button-state=success] .btn-message-success,\n[status-button-state=loading] .btn-message-loading {\n  left: auto;\n  top: 0;\n  right: 100%; }\n\n[status-button-state] .btn-message-text {\n  -webkit-transition: opacity .2s .6s ease-in;\n  transition: opacity .2s .6s ease-in;\n  opacity: 0; }\n\n[status-button-state=success] .btn-message-success .btn-message-text {\n  opacity: 1; }\n\n[status-button-state] .btn-message-success .btn-message-icon {\n  -webkit-transform: scale(0);\n          transform: scale(0); }\n\n[status-button-state=success] .btn-message-success .btn-message-icon {\n  -webkit-transition: -webkit-transform 0.15s 0 cubic-bezier(0, 1.8, 1, 1.8);\n  transition: -webkit-transform 0.15s 0 cubic-bezier(0, 1.8, 1, 1.8);\n  transition: transform 0.15s 0 cubic-bezier(0, 1.8, 1, 1.8);\n  transition: transform 0.15s 0 cubic-bezier(0, 1.8, 1, 1.8), -webkit-transform 0.15s 0 cubic-bezier(0, 1.8, 1, 1.8);\n  -webkit-transform: scale(1);\n          transform: scale(1); }\n\n.account-form {\n  margin-top: 2.25em;\n  margin-bottom: 2.25em; }\n  .account-form:first-child {\n    margin-top: 1.2em; }\n  .account-form:last-child {\n    margin-bottom: 1.2em; }\n\n.grid {\n  margin: 0;\n  padding: 0;\n  margin-left: -20px;\n  letter-spacing: -0.31em;\n  text-rendering: optimizespeed;\n  display: -webkit-flex;\n  -webkit-flex-flow: row wrap;\n  display: -ms-flexbox;\n  -ms-flex-flow: row wrap; }\n\n[class^=\"column-\"], [class*=\" column-\"] {\n  display: inline-block;\n  vertical-align: top;\n  padding-left: 20px;\n  vertical-align: top;\n  width: 100%;\n  box-sizing: border-box;\n  letter-spacing: normal;\n  text-rendering: auto; }\n\n.column-1-1 {\n  width: 100%; }\n\n.column-1-2 {\n  width: 50%; }\n\n.column-1-3 {\n  width: 33.333%; }\n\n.column-2-3 {\n  width: 66.666%; }\n\n.column-1-4 {\n  width: 25%; }\n\n.column-3-4 {\n  width: 75%; }\n\n@media only screen and (min-width: 481px) {\n  .column-wide-handheld-1-1 {\n    width: 100%; }\n  .column-wide-handheld-1-2 {\n    width: 50%; }\n  .column-wide-handheld-1-3 {\n    width: 33.333%; }\n  .column-wide-handheld-2-3 {\n    width: 66.666%; }\n  .column-wide-handheld-1-4 {\n    width: 25%; }\n  .column-wide-handheld-3-4 {\n    width: 75%; } }\n\n@media only screen and (min-width: 769px) {\n  .column-tablet-1-1 {\n    width: 100%; }\n  .column-tablet-1-2 {\n    width: 50%; }\n  .column-tablet-1-3 {\n    width: 33.333%; }\n  .column-tablet-2-3 {\n    width: 66.666%; }\n  .column-tablet-1-4 {\n    width: 25%; }\n  .column-tablet-3-4 {\n    width: 75%; } }\n\n@media only screen and (min-width: 1025px) {\n  .column-desktop-1-1 {\n    width: 100%; }\n  .column-desktop-1-2 {\n    width: 50%; }\n  .column-desktop-1-3 {\n    width: 33.333%; }\n  .column-desktop-2-3 {\n    width: 66.666%; }\n  .column-desktop-1-4 {\n    width: 25%; }\n  .column-desktop-3-4 {\n    width: 75%; } }\n\n.u-stretch {\n  -webkit-box-flex: 1;\n  -webkit-flex-grow: 1;\n      -ms-flex-positive: 1;\n          flex-grow: 1; }\n\n.u-layout-row {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row; }\n\n.u-center {\n  margin-left: auto;\n  margin-right: auto; }\n\n.u-align-right {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row;\n  -webkit-box-pack: end;\n  -webkit-justify-content: flex-end;\n      -ms-flex-pack: end;\n          justify-content: flex-end; }\n\n.u-strong {\n  font-weight: bold; }\n\n.u-hidden {\n  display: none; }\n\n/* Style input placeholders */\n/* Shadow mixins */\n.annotator-hide {\n  display: none;\n  visibility: hidden; }\n\n.styled-text h1, .styled-text h2, .styled-text h3, .styled-text h4, .styled-text h5, .styled-text h6, .styled-text p, .styled-text ol, .styled-text ul, .styled-text img, .styled-text pre, .styled-text blockquote {\n  margin: .618em 0; }\n\n.styled-text h1, .styled-text h2, .styled-text h3, .styled-text h4, .styled-text h5, .styled-text h6 {\n  font-family: \"Helvetica Neue\", Helvetica, Arial, \"Lucida Grande\", sans-serif; }\n\n.styled-text h1 {\n  font-size: 2.618em;\n  font-weight: bold;\n  margin: .2327em 0; }\n\n.styled-text h2 {\n  font-size: 1.991em;\n  font-weight: bold;\n  margin: .309em 0; }\n\n.styled-text h3 {\n  font-size: 1.991em;\n  margin: .309em 0; }\n\n.styled-text h4 {\n  font-size: 1.618em;\n  margin: .3803em 0; }\n\n.styled-text h5 {\n  font-size: 1.231em;\n  margin: .4944em 0; }\n\n.styled-text h6 {\n  font-size: 1.231em;\n  margin: .4944em 0; }\n\n.styled-text ol, .styled-text ul {\n  list-style-position: inside;\n  padding-left: 0; }\n  .styled-text ol ol, .styled-text ol ul, .styled-text ul ol, .styled-text ul ul {\n    padding-left: 1em; }\n\n.styled-text ol {\n  list-style-type: decimal; }\n\n.styled-text ul {\n  list-style-type: disc; }\n\n.styled-text ol ul, .styled-text ul ul {\n  list-style-type: circle; }\n\n.styled-text li {\n  margin-bottom: .291em; }\n\n.styled-text li, .styled-text p {\n  line-height: 1.3; }\n\n.styled-text a {\n  text-decoration: underline; }\n\n.styled-text img {\n  display: block;\n  max-width: 100%; }\n\n.styled-text blockquote {\n  font-size: 13px;\n  line-height: 17px;\n  font-weight: 400;\n  border-left: 3px solid #d3d3d3;\n  color: #A6A6A6;\n  font-family: sans-serif;\n  font-size: 12px;\n  font-style: italic;\n  letter-spacing: 0.1px;\n  padding: 0 1em;\n  margin: 1em 0; }\n  .styled-text blockquote p, .styled-text blockquote ol, .styled-text blockquote ul, .styled-text blockquote img, .styled-text blockquote pre, .styled-text blockquote blockquote {\n    margin: .7063em 0; }\n  .styled-text blockquote p, .styled-text blockquote li {\n    line-height: 1.5; }\n\n.styled-text code {\n  font-family: Open Sans Mono, Menlo, DejaVu Sans Mono, monospace;\n  font-size: .875em;\n  color: black; }\n\n.styled-text pre code {\n  padding: 10px;\n  display: block;\n  background-color: #f9f9f9;\n  border-radius: 2px; }\n\n.page h1, .page h2, .page h3, .page h4, .page h5, .page h6 {\n  font-weight: normal; }\n\n.page h1 {\n  font-size: 1.991em;\n  margin: .618em 0 .309em; }\n\n.page h2 {\n  font-size: 1.618em;\n  margin: .7606em 0; }\n\n.page h3 {\n  font-size: 1.231em;\n  margin: .9888em 0 .4944em; }\n\nbody {\n  position: relative;\n  background-color: #fff;\n  color: #585858; }\n\np {\n  -webkit-hyphens: auto;\n     -moz-hyphens: auto;\n      -ms-hyphens: auto;\n          hyphens: auto; }\n  p + p {\n    margin: 1em 0 0; }\n\nem {\n  font-style: italic; }\n\nhtml {\n  font-size: 12px;\n  line-height: 20px; }\n\n.paper {\n  background: #fff;\n  border: solid 1px #d3d3d3;\n  border-radius: 2px;\n  padding: 1em; }\n\n.small {\n  font-size: 12px; }\n\n.btn-link {\n  box-shadow: none;\n  margin: 0;\n  padding: 0;\n  border: 0;\n  background: none;\n  background-color: transparent;\n  text-decoration: underline;\n  border: none;\n  cursor: pointer;\n  color: #bd1c2b;\n  position: static; }\n  .btn-link:hover, .btn-link:focus, .btn-link.js-focus, .btn-link.js-hover {\n    color: shade(#bd1c2b, 30%); }\n\n.red {\n  color: #bd1c2b; }\n\n.pull-left {\n  float: left; }\n\n.pull-right {\n  float: right; }\n\n.close {\n  cursor: pointer;\n  float: right;\n  opacity: .6; }\n  .close:active, .close:hover {\n    opacity: 1; }\n\n.share-links a {\n  font-size: 1.5em;\n  padding: .3em; }\n\n.form-horizontal {\n  display: inline-block; }\n  .form-horizontal .controls, .form-horizontal .control-group, .form-horizontal div, .form-horizontal fieldset,\n  .form-horizontal input, .form-horizontal button, .form-horizontal select, .form-horizontal textarea {\n    display: inline-block; }\n  .form-horizontal select, .form-horizontal textarea, .form-horizontal input, .form-horizontal button {\n    margin: .5em 0; }\n\n.form-inline .control-group {\n  margin-bottom: 0; }\n\n.form-vertical legend {\n  font-size: 12px;\n  line-height: 1.4em;\n  margin-top: 1.5em;\n  margin-bottom: 1.5em; }\n\n.form-vertical select, .form-vertical textarea, .form-vertical input, .form-vertical button {\n  display: block; }\n\n.req {\n  display: none; }\n\n.visuallyhidden, .alert-block span.errorMsgLbl, .alert-block span.errorMsg {\n  position: absolute;\n  overflow: hidden;\n  clip: rect(0 0 0 0);\n  height: 1px;\n  width: 1px;\n  margin: -1px;\n  padding: 0;\n  border: 0; }\n\n.dropdown {\n  position: relative; }\n  .dropdown span {\n    cursor: pointer; }\n    .dropdown span:hover {\n      color: black; }\n\n.dropdown-toggle {\n  cursor: pointer; }\n  .dropdown-toggle:active {\n    outline: 0; }\n\n.dropdown-menu {\n  visibility: hidden;\n  background: #fff;\n  border: solid 1px #d3d3d3;\n  margin-top: 6px;\n  top: 100%;\n  float: left;\n  position: absolute;\n  z-index: 2; }\n  .dropdown-menu__link {\n    color: inherit;\n    display: block;\n    line-height: 1;\n    white-space: nowrap;\n    font-size: 14px;\n    cursor: pointer; }\n    .dropdown-menu__link:hover {\n      color: #bd1c2b; }\n  .dropdown-menu__link--subtle {\n    color: #818181; }\n  .dropdown-menu:before, .dropdown-menu:after {\n    -webkit-transform: scale(0.9999);\n            transform: scale(0.9999);\n    border-color: transparent;\n    border-style: solid;\n    border-width: 0 7px 6px 7px;\n    content: '';\n    position: absolute;\n    height: 0;\n    left: 0;\n    width: 0; }\n  .dropdown-menu:before {\n    border-bottom-color: #d3d3d3;\n    top: -7px; }\n  .dropdown-menu:after {\n    border-bottom-color: #fff;\n    top: -6px;\n    z-index: 3; }\n  .dropdown-menu.pull-right {\n    right: 0;\n    left: auto;\n    text-align: right; }\n    .dropdown-menu.pull-right:before, .dropdown-menu.pull-right:after {\n      left: auto;\n      right: 0; }\n  .dropdown-menu.pull-center:before, .dropdown-menu.pull-center:after {\n    left: auto;\n    right: 50%; }\n  .dropdown-menu.pull-none:before, .dropdown-menu.pull-none:after {\n    display: none; }\n\n.open > .dropdown-menu {\n  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.1);\n  visibility: visible; }\n\n.dropdown-menu__top-arrow {\n  visibility: hidden;\n  width: 0px;\n  height: 0px;\n  border-top: none;\n  border-left: 7px solid transparent;\n  border-right: 7px solid transparent;\n  border-bottom: 7px solid #d3d3d3;\n  position: absolute;\n  right: 0px;\n  bottom: -6px;\n  z-index: 3; }\n  .dropdown-menu__top-arrow:after {\n    width: 0px;\n    height: 0px;\n    border-top: none;\n    border-left: 7px solid transparent;\n    border-right: 7px solid transparent;\n    border-bottom: 7px solid white;\n    content: \"\";\n    position: absolute;\n    left: -7px;\n    top: 1px; }\n\n.open > .dropdown-menu__top-arrow {\n  visibility: visible; }\n\n.dropdown-menu__row {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row;\n  -webkit-box-align: center;\n  -webkit-align-items: center;\n      -ms-flex-align: center;\n          align-items: center;\n  padding-left: 8px;\n  padding-right: 16px;\n  min-height: 40px;\n  min-width: 120px; }\n  .dropdown-menu__row:not(:first-child) {\n    border-top: dotted 1px #d3d3d3; }\n\n.dropdown-menu__row--unpadded {\n  padding-left: 0px;\n  padding-right: 0px; }\n\n.dropdown-menu-radio {\n  display: inline-block;\n  width: 12px;\n  height: 12px;\n  border-radius: 50%;\n  margin-left: 8px;\n  margin-right: 8px;\n  border: 1px solid #bbb; }\n\n.dropdown-menu-radio.is-selected {\n  border: 4px solid #626262; }\n\n.masthead {\n  margin-bottom: 1em; }\n  .masthead .masthead-heading {\n    color: #777;\n    font-size: 1.1em;\n    font-weight: 400; }\n    .masthead .masthead-heading:hover {\n      color: #585858; }\n\n.nav-tabs {\n  margin-bottom: .7em; }\n  .nav-tabs > li {\n    display: inline-block;\n    line-height: 1; }\n    .nav-tabs > li a {\n      font-family: \"Helvetica Neue\", Helvetica, Arial, \"Lucida Grande\", sans-serif;\n      font-weight: bold;\n      color: #585858;\n      cursor: pointer;\n      border-bottom: 3px solid transparent;\n      padding-left: .153em;\n      padding-right: .153em;\n      padding-bottom: .076em; }\n    .nav-tabs > li:active a {\n      position: relative;\n      top: .076em; }\n    .nav-tabs > li.active:active a {\n      top: 0; }\n    .nav-tabs > li.active a {\n      border-color: #d3d3d3; }\n    .nav-tabs > li:before {\n      content: \"/\";\n      margin: 0 .75em; }\n    .nav-tabs > li:first-child:before {\n      content: none; }\n\n.tab-content .tab-pane {\n  display: none; }\n  .tab-content .tab-pane.active {\n    display: inherit !important; }\n\n.annotation-card {\n  box-shadow: 0px 1px 1px 0px rgba(0, 0, 0, 0.1);\n  border-radius: 2px;\n  cursor: pointer;\n  padding: 15px;\n  background-color: #fff; }\n\n.annotation-card:hover {\n  box-shadow: 0px 2px 3px 0px rgba(0, 0, 0, 0.15); }\n  .annotation-card:hover .annotation-header__user {\n    color: #202020; }\n  .annotation-card:hover .annotation-quote {\n    border-left: #58CEF4 3px solid;\n    color: #7A7A7A; }\n\n.annotation-card:hover > .annotation .annotation-replies__link,\n.annotation-card:hover > .annotation .annotation-replies__count,\n.annotation-card:hover > .annotation .annotation-action-btn,\n.annotation:hover .annotation-replies__link,\n.annotation:hover .annotation-replies__count,\n.annotation:hover .annotation-action-btn {\n  color: #3F3F3F; }\n\n.annotation-card:hover > .annotation .annotation-header__timestamp,\n.annotation:hover .annotation-header__timestamp {\n  color: #7A7A7A; }\n\n.annotation {\n  display: block;\n  font-family: \"Helvetica Neue\", Helvetica, Arial, \"Lucida Grande\", sans-serif;\n  position: relative; }\n\n.annotation.is-dimmed .annotation-header__user,\n.annotation.is-dimmed .annotation-body {\n  color: #7A7A7A; }\n\n.annotation.is-highlighted .annotation-header__user,\n.annotation.is-highlighted .annotation-body {\n  color: #202020; }\n\n.annotation-link {\n  font-size: 11px;\n  line-height: 12px;\n  font-weight: 400;\n  color: #A6A6A6;\n  margin-top: -12px; }\n\n.annotation-replies:hover .annotation-replies__link {\n  text-decoration: underline; }\n\n.annotation-quote-list:after,\n.annotation-header:after,\n.annotation-footer:after {\n  content: \"\";\n  display: table;\n  clear: both; }\n\n.annotation-header {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row;\n  -webkit-box-align: baseline;\n  -webkit-align-items: baseline;\n      -ms-flex-align: baseline;\n          align-items: baseline;\n  margin-top: -5px; }\n\n.annotation-header__share-info {\n  color: #7A7A7A;\n  font-size: 13px;\n  line-height: 17px;\n  font-weight: 400; }\n\n.annotation-header__group {\n  color: #818181;\n  font-size: 12px; }\n\n.annotation-header__group-name {\n  display: inline-block;\n  margin-left: 5px; }\n\n.annotation-body {\n  font-size: 13px;\n  line-height: 17px;\n  font-weight: 400;\n  color: #3F3F3F;\n  margin-top: 10px;\n  margin-bottom: 15px;\n  margin-right: 0px;\n  margin-left: 0px; }\n\n.annotation-footer {\n  font-size: 13px;\n  line-height: 17px;\n  font-weight: 400;\n  color: #7A7A7A;\n  margin-top: 15px; }\n\n.u-flex-spacer {\n  -webkit-box-flex: 1;\n  -webkit-flex-grow: 1;\n      -ms-flex-positive: 1;\n          flex-grow: 1; }\n\n.annotation-quote-list {\n  margin-top: 10px;\n  margin-bottom: 12px; }\n\n.annotation-quote-list.is-orphan {\n  text-decoration: line-through; }\n\n.annotation-media-embed {\n  width: 369px;\n  height: 208px; }\n\n.annotation-header__user {\n  font-size: 13px;\n  line-height: 17px;\n  font-weight: 400;\n  color: #202020;\n  font-weight: bold; }\n\n.annotation-replies {\n  float: left;\n  margin-top: 2px; }\n\n.annotation-replies__link,\n.annotation-replies__count {\n  font-size: 13px;\n  line-height: 17px;\n  font-weight: 400;\n  color: #7A7A7A; }\n\n.annotation-header__timestamp {\n  font-size: 11px;\n  line-height: 12px;\n  font-weight: 400;\n  color: #A6A6A6; }\n\n.annotation-actions {\n  float: right;\n  margin-top: 0;\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex; }\n\n.annotation-action-btn {\n  color: #7A7A7A;\n  font-weight: normal;\n  padding: 0;\n  margin: 0px 0px 0px 12px; }\n\n.annotation-action-btn__label {\n  margin: 0px 0px 0px 3px; }\n\n.annotation-quote {\n  font-size: 13px;\n  line-height: 17px;\n  font-weight: 400;\n  border-left: 3px solid #d3d3d3;\n  color: #A6A6A6;\n  font-family: sans-serif;\n  font-size: 12px;\n  font-style: italic;\n  letter-spacing: 0.1px;\n  padding: 0 1em;\n  overflow-wrap: break-word; }\n\n.annotation-citation-domain {\n  color: #969696;\n  font-size: 12px; }\n\n.annotation-license {\n  clear: both;\n  border-top: #cccccc 1px solid;\n  font-size: 0.8em;\n  padding-top: 0.583em; }\n  .annotation-license [class^=\"h-icon-\"], .annotation-license [class*=\" h-icon-\"] {\n    font-size: 13px;\n    vertical-align: -2px;\n    margin-right: 1px; }\n\n.annotation-license__link {\n  color: #969696;\n  display: block; }\n\n.annotation-collapsed-replies {\n  display: none; }\n\n.annotation--reply.is-collapsed {\n  margin-bottom: 0; }\n  .annotation--reply.is-collapsed .annotation-header {\n    margin: 0; }\n  .annotation--reply.is-collapsed .annotation-body, .annotation--reply.is-collapsed .annotation-footer {\n    display: none; }\n  .annotation--reply.is-collapsed .annotation-collapsed-replies {\n    display: inline;\n    margin-left: .25em; }\n\n.annotation-share-dialog-wrapper {\n  position: relative; }\n\n.annotation-form-actions {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row;\n  margin-bottom: 10px; }\n\n.annotation--reply .annotation-action-btn {\n  color: #A6A6A6; }\n\n.annotation--reply .annotation-footer {\n  margin-top: 7px; }\n\n.annotation--reply .annotation-header {\n  margin-top: 0px; }\n\n.annotation--reply .annotation-body {\n  margin-top: 7px;\n  margin-bottom: 12px; }\n\n.annotation-share-dialog.is-open {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: vertical;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: column;\n      -ms-flex-direction: column;\n          flex-direction: column; }\n\n.annotation-share-dialog {\n  display: none;\n  position: absolute;\n  right: 0;\n  bottom: 130%;\n  z-index: 1;\n  background: #fff;\n  border: 1px solid #d3d3d3;\n  border-radius: 2px;\n  width: 200px;\n  font-size: 12px;\n  cursor: default;\n  box-shadow: 0px 0px 4px 0px rgba(0, 0, 0, 0.15); }\n  .annotation-share-dialog:after, .annotation-share-dialog:before {\n    top: 100%;\n    right: 10px;\n    border: solid transparent;\n    content: \" \";\n    height: 0;\n    width: 0;\n    position: absolute;\n    pointer-events: none; }\n  .annotation-share-dialog:after {\n    border-color: rgba(255, 255, 255, 0);\n    border-top-color: #fff;\n    border-width: 5px;\n    margin-right: -5px; }\n  .annotation-share-dialog:before {\n    border-color: rgba(211, 211, 211, 0);\n    border-top-color: #d3d3d3;\n    border-width: 6px;\n    margin-right: -6px; }\n\n.annotation-share-dialog-msg {\n  color: #969696;\n  margin: -5px 10px 10px 10px;\n  line-height: 15px;\n  font-size: 11px; }\n\n.annotation-share-dialog-msg__audience {\n  font-style: italic; }\n\n.annotation-share-dialog-link {\n  position: relative;\n  font-size: 12px;\n  margin: 10px;\n  padding: 5px;\n  color: #585858;\n  border: 1px solid #d3d3d3;\n  border-radius: 2px;\n  background: #F2F2F2;\n  white-space: nowrap;\n  overflow: hidden;\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row; }\n\n.annotation-share-dialog-link:hover {\n  color: #585858; }\n\n.annotation-share-dialog-link__text {\n  overflow: hidden;\n  border: none;\n  width: 100%;\n  background: inherit;\n  height: 22px; }\n\n.annotation-share-dialog-link__btn {\n  color: #7A7A7A;\n  padding: 0px;\n  margin-left: 7px; }\n\n.annotation-share-dialog-link__btn:hover {\n  color: #202020; }\n\n.annotation-share-dialog-target {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row;\n  -webkit-box-pack: justify;\n  -webkit-justify-content: space-between;\n      -ms-flex-pack: justify;\n          justify-content: space-between;\n  border-bottom: 1px solid #d3d3d3;\n  font-size: 12px;\n  padding: 10px; }\n\n.annotation-share-dialog-target__label {\n  font-weight: bold; }\n\n.annotation-share-dialog-target__icon {\n  color: #7A7A7A;\n  text-decoration: none;\n  font-size: 20px;\n  cursor: pointer; }\n\n.annotation-share-dialog-target__icon:hover {\n  color: #202020; }\n\n.annotation-share-dialog-link__feedback {\n  position: absolute;\n  left: 5px;\n  top: 5px;\n  bottom: 5px;\n  right: 28px;\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row;\n  -webkit-box-pack: center;\n  -webkit-justify-content: center;\n      -ms-flex-pack: center;\n          justify-content: center;\n  font-size: 11px;\n  background: white;\n  border: 1px solid #d3d3d3;\n  border-radius: 2px; }\n\n.annotation-thread {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row; }\n\n.annotation-thread--reply {\n  margin-left: -5px; }\n\n.annotation-thread--top-reply {\n  padding-top: 5px;\n  padding-bottom: 5px; }\n\nli:first-child .annotation-thread--top-reply {\n  margin-top: 5px; }\n\n.annotation-thread__thread-edge {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: vertical;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: column;\n      -ms-flex-direction: column;\n          flex-direction: column;\n  width: 8px;\n  margin-right: 13px; }\n\n.annotation-thread__thread-line {\n  border-right: 1px dashed #DBDBDB;\n  -webkit-box-flex: 1;\n  -webkit-flex-grow: 1;\n      -ms-flex-positive: 1;\n          flex-grow: 1; }\n\n.annotation-thread__content {\n  -webkit-box-flex: 1;\n  -webkit-flex-grow: 1;\n      -ms-flex-positive: 1;\n          flex-grow: 1;\n  max-width: 100%; }\n\n.annotation-thread__collapse-toggle:hover,\n.annotation-thread__collapse-toggle.is-hovered {\n  color: #202020; }\n\n.annotation-thread__collapse-toggle {\n  width: 10px;\n  color: #A6A6A6;\n  display: block;\n  text-align: center;\n  font-size: 15px;\n  line-height: 22px;\n  height: 100%; }\n  .annotation-thread__collapse-toggle.is-open {\n    height: 24px; }\n\n.api-token-input {\n  width: 100%;\n  line-height: 3em;\n  text-align: center; }\n\n.primary-action-btn {\n  color: #f1f1f1;\n  background-color: #626262;\n  height: 35px;\n  border: none;\n  border-radius: 2px;\n  font-weight: bold;\n  font-size: 12px;\n  padding-left: 12px;\n  padding-right: 12px; }\n  .primary-action-btn:disabled {\n    color: #969696; }\n  .primary-action-btn:hover:enabled {\n    background-color: #3A3A3A; }\n\n.primary-action-btn--short {\n  height: 30px; }\n\n.primary-action-btn__icon {\n  color: #a6a6a6;\n  display: inline-block;\n  font-weight: bold;\n  margin-left: -3px;\n  margin-right: 3px;\n  -webkit-transform: translateY(1px);\n          transform: translateY(1px); }\n\n.dropdown-menu-btn {\n  height: 35px;\n  position: relative; }\n  .dropdown-menu-btn__btn {\n    color: #f1f1f1;\n    background-color: #626262;\n    height: 35px;\n    border: none;\n    border-radius: 2px;\n    font-weight: bold;\n    font-size: 12px;\n    padding-left: 12px;\n    padding-right: 12px;\n    width: 100%;\n    height: 100%;\n    text-align: left;\n    padding-left: 9px;\n    padding-right: 34px; }\n    .dropdown-menu-btn__btn:disabled {\n      color: #969696; }\n    .dropdown-menu-btn__btn:hover:enabled {\n      background-color: #3A3A3A; }\n  .dropdown-menu-btn__dropdown-arrow {\n    position: absolute;\n    right: 0px;\n    top: 0px;\n    height: 100%;\n    width: 26px;\n    padding-left: 0px;\n    padding-right: 9px;\n    margin-left: 8px;\n    border: none;\n    background-color: transparent;\n    border-top-right-radius: 2px;\n    border-bottom-right-radius: 2px; }\n    .dropdown-menu-btn__dropdown-arrow:hover {\n      background-color: #3A3A3A; }\n    .dropdown-menu-btn__dropdown-arrow:hover .dropdown-menu-btn__dropdown-arrow-separator {\n      background-color: transparent; }\n    .dropdown-menu-btn__dropdown-arrow-separator {\n      position: absolute;\n      top: 0px;\n      bottom: 0px;\n      margin-top: auto;\n      margin-bottom: auto;\n      width: 1px;\n      height: 15px;\n      background-color: #818181; }\n    .dropdown-menu-btn__dropdown-arrow-indicator {\n      color: #f1f1f1;\n      position: absolute;\n      left: 0px;\n      right: 0px;\n      top: 0px;\n      bottom: 0px;\n      line-height: 35px;\n      text-align: center; }\n      .dropdown-menu-btn__dropdown-arrow-indicator > div {\n        -webkit-transform: scaleY(0.7);\n                transform: scaleY(0.7); }\n\n.excerpt {\n  -webkit-transition: max-height 0.15s ease-in;\n  transition: max-height 0.15s ease-in;\n  overflow: hidden; }\n\n.excerpt__container {\n  position: relative; }\n\n.excerpt__inline-controls {\n  display: block;\n  position: absolute;\n  right: 0;\n  bottom: 0; }\n\n.excerpt__toggle-link {\n  padding-left: 15px;\n  background-image: -webkit-linear-gradient(left, transparent 0px, white 12px);\n  background-image: linear-gradient(to right, transparent 0px, white 12px);\n  line-height: 17px; }\n\n.excerpt__toggle-link > a {\n  color: #585858;\n  font-style: italic;\n  font-weight: normal; }\n\n.excerpt__shadow {\n  position: absolute;\n  left: -12px;\n  right: -12px;\n  bottom: 0;\n  height: 40px;\n  background-image: -webkit-linear-gradient(top, transparent 50%, rgba(0, 0, 0, 0.08) 95%, rgba(0, 0, 0, 0.13) 100%);\n  background-image: linear-gradient(to bottom, transparent 50%, rgba(0, 0, 0, 0.08) 95%, rgba(0, 0, 0, 0.13) 100%);\n  -webkit-transition: opacity 0.15s linear;\n  transition: opacity 0.15s linear; }\n\n.excerpt__shadow--transparent {\n  background-image: none; }\n\n.excerpt__shadow.is-hidden {\n  opacity: 0;\n  pointer-events: none; }\n\n/* The groups dropdown list. */\n.group-list .dropdown {\n  white-space: nowrap; }\n\n.group-list .dropdown-menu {\n  width: 270px;\n  max-height: 500px;\n  max-height: calc(100vh - 40px - 50px);\n  overflow-y: auto; }\n  .group-list .dropdown-menu .group-name {\n    overflow: hidden;\n    text-overflow: ellipsis;\n    width: 240px; }\n\n.group-list .group-item {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row;\n  -webkit-box-flex: 1;\n  -webkit-flex-grow: 1;\n      -ms-flex-positive: 1;\n          flex-grow: 1;\n  padding: 10px;\n  cursor: pointer; }\n  .group-list .group-item:hover .group-name-link {\n    color: #bd1c2b; }\n  .group-list .group-item.selected .group-name-link {\n    font-size: 14px;\n    font-weight: 600; }\n\n.group-list .group-icon-container {\n  margin-right: 10px; }\n\n.group-list .group-cancel-icon-container {\n  padding-top: 3px;\n  margin-right: 2px; }\n\n.group-list .group-details {\n  -webkit-box-flex: 1;\n  -webkit-flex-grow: 1;\n      -ms-flex-positive: 1;\n          flex-grow: 1;\n  -webkit-flex-shrink: 1;\n      -ms-flex-negative: 1;\n          flex-shrink: 1; }\n\n.group-list .new-group-btn {\n  background-color: #f9f9f9; }\n  .group-list .new-group-btn .group-item {\n    padding-top: 12px;\n    padding-bottom: 12px; }\n  .group-list .new-group-btn .h-icon-add {\n    font-weight: bold; }\n\n.group-list-label__icon {\n  color: #818181;\n  display: inline-block;\n  margin-right: 4px;\n  vertical-align: baseline;\n  -webkit-transform: translateY(1px);\n          transform: translateY(1px); }\n\n.group-list-label__label {\n  font-size: 14px;\n  font-weight: bold; }\n\n.group-name-link {\n  white-space: nowrap;\n  color: inherit; }\n\n.help-panel {\n  font-size: 13px;\n  line-height: 17px;\n  font-weight: 400;\n  background: #DBDBDB;\n  margin-bottom: .72em;\n  padding: 15px;\n  border-radius: 2px; }\n\n.help-panel-title {\n  color: #3F3F3F;\n  font-weight: bold;\n  margin-top: -5px; }\n\n.help-panel-content {\n  margin-top: 11px; }\n\n.help-panel-content__key {\n  width: 100px;\n  float: left;\n  color: #A6A6A6; }\n\n.help-panel-content__val {\n  word-wrap: break-word;\n  margin-left: 100px; }\n\n.help-panel-content {\n  margin-top: 10px;\n  margin-bottom: 15px; }\n\n.help-panel-content__link {\n  color: #3F3F3F;\n  text-decoration: underline; }\n  .help-panel-content__link:hover {\n    text-decoration: underline; }\n\n.loggedout-message {\n  margin: 25px auto;\n  width: 70%;\n  text-align: center;\n  color: #7A7A7A;\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: vertical;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: column;\n      -ms-flex-direction: column;\n          flex-direction: column; }\n\n.loggedout-message__link {\n  text-decoration: underline;\n  color: #7A7A7A; }\n  .loggedout-message__link:hover {\n    color: #202020; }\n\n.loggedout-message-logo {\n  margin-top: 25px; }\n\n.loggedout-message-logo__icon {\n  font-size: 30px;\n  color: #A6A6A6; }\n  .loggedout-message-logo__icon:hover {\n    color: #202020; }\n\n.login-control {\n  -webkit-flex-shrink: 0;\n      -ms-flex-negative: 0;\n          flex-shrink: 0; }\n\n.login-text {\n  font-size: 14px;\n  padding-left: 6px; }\n\n/* The user account dropdown menu */\n.login-control-menu .avatar {\n  border-radius: 2px; }\n\n.login-control-menu .dropdown-toggle .provider {\n  color: #969696;\n  display: none; }\n\n.login-control-menu .dropdown-toggle:hover .provider {\n  display: inline; }\n\n.login-control-menu .dropdown.open .provider {\n  display: inline; }\n\n.markdown-preview {\n  overflow: auto;\n  border: 0.1em solid #d3d3d3;\n  background-color: #f9f9f9;\n  min-height: 120px;\n  padding-left: 0.9em;\n  resize: vertical; }\n\n.markdown-tools {\n  background-color: #fff;\n  border-top: .1em solid #D3D3D3;\n  border-left: .1em solid #D3D3D3;\n  border-right: .1em solid #D3D3D3;\n  border-radius: .15em .15em 0 0;\n  width: 100%;\n  margin-bottom: -.1em;\n  padding: .7em .7em .7em .5em;\n  -webkit-user-select: none;\n     -moz-user-select: none;\n      -ms-user-select: none;\n          user-select: none; }\n  .markdown-tools.disable .markdown-tools-button {\n    color: #d3d3d3;\n    pointer-events: none; }\n  .markdown-tools .markdown-tools-button {\n    padding: .4em; }\n  .markdown-tools .markdown-tools-button, .markdown-tools .markdown-tools-toggle, .markdown-tools .markdown-tools-badge {\n    color: #777; }\n    .markdown-tools .markdown-tools-button:hover, .markdown-tools .markdown-tools-button:focus, .markdown-tools .markdown-tools-toggle:hover, .markdown-tools .markdown-tools-toggle:focus, .markdown-tools .markdown-tools-badge:hover, .markdown-tools .markdown-tools-badge:focus {\n      color: black; }\n  .markdown-tools .markdown-preview-toggle {\n    float: right; }\n\n.markdown-body {\n  cursor: text;\n  overflow-wrap: break-word; }\n  .markdown-body h1, .markdown-body h2, .markdown-body h3, .markdown-body h4, .markdown-body h5, .markdown-body h6, .markdown-body p, .markdown-body ol, .markdown-body ul, .markdown-body img, .markdown-body pre, .markdown-body blockquote {\n    margin: .618em 0; }\n  .markdown-body h1, .markdown-body h2, .markdown-body h3, .markdown-body h4, .markdown-body h5, .markdown-body h6 {\n    font-family: \"Helvetica Neue\", Helvetica, Arial, \"Lucida Grande\", sans-serif; }\n  .markdown-body h1 {\n    font-size: 2.618em;\n    font-weight: bold;\n    margin: .2327em 0; }\n  .markdown-body h2 {\n    font-size: 1.991em;\n    font-weight: bold;\n    margin: .309em 0; }\n  .markdown-body h3 {\n    font-size: 1.991em;\n    margin: .309em 0; }\n  .markdown-body h4 {\n    font-size: 1.618em;\n    margin: .3803em 0; }\n  .markdown-body h5 {\n    font-size: 1.231em;\n    margin: .4944em 0; }\n  .markdown-body h6 {\n    font-size: 1.231em;\n    margin: .4944em 0; }\n  .markdown-body ol, .markdown-body ul {\n    list-style-position: inside;\n    padding-left: 0; }\n    .markdown-body ol ol, .markdown-body ol ul, .markdown-body ul ol, .markdown-body ul ul {\n      padding-left: 1em; }\n  .markdown-body ol {\n    list-style-type: decimal; }\n  .markdown-body ul {\n    list-style-type: disc; }\n  .markdown-body ol ul, .markdown-body ul ul {\n    list-style-type: circle; }\n  .markdown-body li {\n    margin-bottom: .291em; }\n  .markdown-body li, .markdown-body p {\n    line-height: 1.3; }\n  .markdown-body a {\n    text-decoration: underline; }\n  .markdown-body img {\n    display: block;\n    max-width: 100%; }\n  .markdown-body blockquote {\n    font-size: 13px;\n    line-height: 17px;\n    font-weight: 400;\n    border-left: 3px solid #d3d3d3;\n    color: #A6A6A6;\n    font-family: sans-serif;\n    font-size: 12px;\n    font-style: italic;\n    letter-spacing: 0.1px;\n    padding: 0 1em;\n    margin: 1em 0; }\n    .markdown-body blockquote p, .markdown-body blockquote ol, .markdown-body blockquote ul, .markdown-body blockquote img, .markdown-body blockquote pre, .markdown-body blockquote blockquote {\n      margin: .7063em 0; }\n    .markdown-body blockquote p, .markdown-body blockquote li {\n      line-height: 1.5; }\n  .markdown-body code {\n    font-family: Open Sans Mono, Menlo, DejaVu Sans Mono, monospace;\n    font-size: .875em;\n    color: black; }\n  .markdown-body pre code {\n    padding: 10px;\n    display: block;\n    background-color: #f9f9f9;\n    border-radius: 2px; }\n  .markdown-body p:first-child {\n    margin-top: 0; }\n  .markdown-body p:last-child {\n    margin-bottom: 1px; }\n\n.primary-action-btn {\n  color: #f1f1f1;\n  background-color: #626262;\n  height: 35px;\n  border: none;\n  border-radius: 2px;\n  font-weight: bold;\n  font-size: 12px;\n  padding-left: 12px;\n  padding-right: 12px; }\n  .primary-action-btn:disabled {\n    color: #969696; }\n  .primary-action-btn:hover:enabled {\n    background-color: #3A3A3A; }\n\n.primary-action-btn--short {\n  height: 30px; }\n\n.primary-action-btn__icon {\n  color: #a6a6a6;\n  display: inline-block;\n  font-weight: bold;\n  margin-left: -3px;\n  margin-right: 3px;\n  -webkit-transform: translateY(1px);\n          transform: translateY(1px); }\n\n.publish-annotation-btn {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex; }\n  .publish-annotation-btn__btn {\n    position: relative; }\n  .publish-annotation-btn__dropdown-container {\n    position: absolute;\n    left: 100%; }\n  .publish-annotation-btn__dropdown-menu {\n    position: relative;\n    left: calc(-50% - 6px); }\n\n.open .publish-annotation-btn__dropdown-menu {\n  visibility: visible; }\n\n.publish-annotation-cancel-btn {\n  margin-left: 5px;\n  font-weight: normal; }\n  .publish-annotation-cancel-btn__icon {\n    margin-right: 3px;\n    -webkit-transform: translateY(10%);\n            transform: translateY(10%); }\n\n.search-status-bar {\n  margin-bottom: 10px; }\n\n.search-status-bar > button {\n  margin-right: 10px; }\n\n.selection-tabs {\n  background: #ECECEC;\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row;\n  color: #7A7A7A;\n  font-size: 13px;\n  line-height: 17px;\n  font-weight: 400;\n  padding-bottom: 10px; }\n  .selection-tabs:hover {\n    color: #3F3F3F; }\n\n.selection-tabs__type {\n  color: #3F3F3F;\n  margin-right: 20px;\n  cursor: pointer;\n  min-width: 85px;\n  min-height: 18px;\n  outline: none;\n  -webkit-user-select: none;\n     -moz-user-select: none;\n      -ms-user-select: none;\n          user-select: none; }\n\n.selection-tabs__type.is-selected {\n  font-weight: bold; }\n\n.selection-tabs__count {\n  position: relative;\n  bottom: 3px;\n  font-size: 10px; }\n\n.selection-tabs__empty-message {\n  position: relative;\n  top: 10px; }\n\n.selection-tabs__type--orphan {\n  margin-left: -5px; }\n\n.share-link-container {\n  font-size: 12px;\n  line-height: 1.4em;\n  margin-top: 1px;\n  white-space: normal; }\n\n.share-link {\n  color: #969696; }\n\n.share-link:hover {\n  width: 100%;\n  color: #585858; }\n\n.share-link-field {\n  padding: 3px;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  margin-top: 12px;\n  margin-bottom: 8px;\n  border: 1px solid #d3d3d3;\n  border-radius: 2px;\n  width: 100%; }\n\n.share-link-icons {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row;\n  -webkit-box-pack: center;\n  -webkit-justify-content: center;\n      -ms-flex-pack: center;\n          justify-content: center; }\n\n.share-link-icon {\n  color: #626262;\n  display: inline-block;\n  font-size: 24px;\n  text-decoration: none;\n  margin-left: 5px;\n  margin-right: 5px; }\n  .share-link-icon:hover {\n    color: #bd1c2b; }\n\n.sidebar-tutorial__header {\n  color: #bd1c2b;\n  font-size: 12px;\n  font-weight: bold; }\n\n/* We want an ordered list in which the numbers are aligned with the text\n   above (not indented or dedented), and wrapped lines in list items are\n   aligned with the first character of the list item (not the number, i.e\n   they're indented):\n\n       This is a list:\n\n       1. This is a list item.\n       2. This is a long list item\n          that wraps.\n       3. This is another list item.\n\n   What's more, we want the numbers to be a different color to the text of the\n   list items, which means we need to use ::before content for them.\n\n   This appears to be much harder than you'd think.\n\n   The code below comes from this Stack Overflow answer:\n   http://stackoverflow.com/questions/10428720/how-to-keep-indent-for-second-line-in-ordered-lists-via-css/17515230#17515230\n*/\n.sidebar-tutorial__list {\n  counter-reset: sidebar-tutorial__list;\n  display: table;\n  padding: 0; }\n\n.sidebar-tutorial__list-item {\n  list-style: none;\n  counter-increment: sidebar-tutorial__list;\n  display: table-row; }\n\n.sidebar-tutorial__list-item::before {\n  content: counter(sidebar-tutorial__list) \".\";\n  display: table-cell;\n  /* aha! */\n  text-align: right;\n  padding-right: .3em;\n  color: #969696; }\n\n.sidebar-tutorial__list-item-content {\n  margin-top: 1em;\n  /* Put vertical space in-between list items, equal to the\n                      space between normal paragraphs.\n                      Note: This also puts the same amount of space above the\n                      first list item (i.e. between the list and whatever's\n                      above it). */ }\n\n.u-stretch {\n  -webkit-box-flex: 1;\n  -webkit-flex-grow: 1;\n      -ms-flex-positive: 1;\n          flex-grow: 1; }\n\n.u-layout-row {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row; }\n\n.u-center {\n  margin-left: auto;\n  margin-right: auto; }\n\n.u-align-right {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row;\n  -webkit-box-pack: end;\n  -webkit-justify-content: flex-end;\n      -ms-flex-pack: end;\n          justify-content: flex-end; }\n\n.u-strong {\n  font-weight: bold; }\n\n.u-hidden {\n  display: none; }\n\n/* Style input placeholders */\n/* Shadow mixins */\n.annotator-hide {\n  display: none;\n  visibility: hidden; }\n\n.simple-search-form {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-flex-flow: row nowrap;\n      -ms-flex-flow: row nowrap;\n          flex-flow: row nowrap;\n  position: relative;\n  color: #585858; }\n\n.simple-search-icon {\n  -webkit-box-ordinal-group: 1;\n  -webkit-order: 0;\n      -ms-flex-order: 0;\n          order: 0; }\n\n:not(:focus) ~ .simple-search-icon {\n  color: #969696; }\n\n.simple-search-input {\n  -webkit-box-flex: 1;\n  -webkit-flex-grow: 1;\n      -ms-flex-positive: 1;\n          flex-grow: 1;\n  -webkit-box-ordinal-group: 2;\n  -webkit-order: 1;\n      -ms-flex-order: 1;\n          order: 1;\n  color: #585858;\n  border: none;\n  outline: none;\n  padding: 0px;\n  width: 100%;\n  max-width: 0.1px;\n  -webkit-transition: max-width .3s ease-out, padding-left .3s ease-out;\n  transition: max-width .3s ease-out, padding-left .3s ease-out; }\n  .simple-search-input:disabled {\n    background: none;\n    color: #969696; }\n  .simple-search-input:focus, .simple-search-input.is-expanded {\n    max-width: 150px;\n    padding-left: 6px; }\n\n@-webkit-keyframes (spin) {\n  to {\n    -webkit-transform: rotate(1turn);\n            transform: rotate(1turn); } }\n\n@keyframes (spin) {\n  to {\n    -webkit-transform: rotate(1turn);\n            transform: rotate(1turn); } }\n\n.spinner {\n  position: relative;\n  display: inline-block;\n  width: 1em;\n  height: 1em;\n  text-indent: 999em;\n  overflow: hidden;\n  -webkit-animation: spin 1.25s infinite steps(12);\n          animation: spin 1.25s infinite steps(12); }\n\n.spinner:before,\n.spinner:after,\n.spinner > span:before,\n.spinner > span:after,\n.spinner > span > span:before,\n.spinner > span > span:after {\n  content: '';\n  position: absolute;\n  top: 0;\n  left: 0.45em;\n  width: 0.1em;\n  height: 0.3em;\n  border-radius: 0.1em;\n  background: #eee;\n  box-shadow: 0 0.7em rgba(0, 0, 0, 0.15);\n  -webkit-transform-origin: 50% 0.5em;\n          transform-origin: 50% 0.5em; }\n\n.spinner:before {\n  background: rgba(0, 0, 0, 0.65); }\n\n.spinner:after {\n  -webkit-transform: rotate(-30deg);\n          transform: rotate(-30deg);\n  background: rgba(0, 0, 0, 0.6); }\n\n.spinner > span:before {\n  -webkit-transform: rotate(-60deg);\n          transform: rotate(-60deg);\n  background: rgba(0, 0, 0, 0.5); }\n\n.spinner > span:after {\n  -webkit-transform: rotate(-90deg);\n          transform: rotate(-90deg);\n  background: rgba(0, 0, 0, 0.4); }\n\n.spinner > span > span:before {\n  -webkit-transform: rotate(-120deg);\n          transform: rotate(-120deg);\n  background: rgba(0, 0, 0, 0.3); }\n\n.spinner > span > span:after {\n  -webkit-transform: rotate(-150deg);\n          transform: rotate(-150deg);\n  background: rgba(0, 0, 0, 0.2); }\n\n.u-stretch {\n  -webkit-box-flex: 1;\n  -webkit-flex-grow: 1;\n      -ms-flex-positive: 1;\n          flex-grow: 1; }\n\n.u-layout-row {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row; }\n\n.u-center {\n  margin-left: auto;\n  margin-right: auto; }\n\n.u-align-right {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row;\n  -webkit-box-pack: end;\n  -webkit-justify-content: flex-end;\n      -ms-flex-pack: end;\n          justify-content: flex-end; }\n\n.u-strong {\n  font-weight: bold; }\n\n.u-hidden {\n  display: none; }\n\n/* Style input placeholders */\n/* Shadow mixins */\n.annotator-hide {\n  display: none;\n  visibility: hidden; }\n\ntags-input .host {\n  outline: none; }\n\ntags-input .tags {\n  font-size: 13px;\n  line-height: 17px;\n  font-weight: 400;\n  border: 1px solid #d3d3d3;\n  border-radius: 2px;\n  padding: .5em .75em;\n  font-weight: normal;\n  color: #777;\n  background-color: #FAFAFA; }\n  tags-input .tags:after {\n    content: \"\";\n    display: table;\n    clear: both; }\n  tags-input .tags.focused {\n    outline: none;\n    background-color: #FFF;\n    border-color: #51A7E8;\n    box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.075) inset, 0px 0px 5px rgba(81, 167, 232, 0.5); }\n    tags-input .tags.focused.placeholder {\n      color: #777; }\n    tags-input .tags.focused:placeholder {\n      color: #777; }\n    tags-input .tags.focused::-webkit-input-placeholder {\n      color: #777; }\n    tags-input .tags.focused::-moz-placeholder {\n      color: #777; }\n    tags-input .tags.focused:-ms-input-placeholder {\n      color: #777; }\n    tags-input .tags.focused::placeholder {\n      color: #777; }\n  tags-input .tags .input {\n    float: left;\n    padding: .1333em 0;\n    outline: none;\n    border: none !important;\n    background: none;\n    color: #777;\n    height: 1.4667em; }\n\ntags-input .tag-list {\n  margin-top: -.33em;\n  float: left; }\n\ntags-input .tag-item {\n  float: left;\n  position: relative;\n  padding: .0769em 1.307em .0769em .538em;\n  margin-top: .384em;\n  margin-right: .384em;\n  font-size: .866em;\n  color: #585858;\n  border: 1px solid #d3d3d3;\n  border-radius: 2px; }\n  tags-input .tag-item.selected {\n    box-shadow: 0 1px 0 rgba(0, 0, 0, 0.05);\n    outline: none;\n    color: #585858;\n    background: #fff;\n    border-color: #bababa;\n    border-color: #51A7E8;\n    box-shadow: 0px 1px 2px rgba(0, 0, 0, 0.075) inset, 0px 0px 5px rgba(81, 167, 232, 0.5); }\n  tags-input .tag-item .remove-button {\n    -webkit-user-select: none;\n       -moz-user-select: none;\n        -ms-user-select: none;\n            user-select: none;\n    display: block;\n    position: absolute;\n    top: 0;\n    right: 0;\n    bottom: 0;\n    width: .9412em;\n    font-size: 1.3077em;\n    font-weight: bold;\n    line-height: 1;\n    text-align: center;\n    color: #585858;\n    cursor: pointer; }\n\n.tags-read-only {\n  font-size: .8461em;\n  margin: .4545em 0; }\n  .tags-read-only .tag-list {\n    margin-top: -5px;\n    margin-bottom: 5px; }\n    .tags-read-only .tag-list:after {\n      content: \"\";\n      display: table;\n      clear: both; }\n    .tags-read-only .tag-list .tag-item {\n      float: left;\n      margin-right: .4545em; }\n      .tags-read-only .tag-list .tag-item a {\n        text-decoration: none;\n        border: 1px solid #d3d3d3;\n        border-radius: 2px;\n        padding: 0 .4545em .1818em;\n        color: #969696;\n        background: #f9f9f9; }\n        .tags-read-only .tag-list .tag-item a:hover, .tags-read-only .tag-list .tag-item a:focus {\n          color: shade(#bd1c2b, 30%); }\n\ntags-input .autocomplete {\n  margin-top: .3em;\n  position: absolute;\n  padding: .3em 0;\n  z-index: 999;\n  width: 100%;\n  background-color: white;\n  border: thin solid rgba(0, 0, 0, 0.2);\n  box-shadow: 0 0.3em 0.6em rgba(0, 0, 0, 0.2); }\n  tags-input .autocomplete .suggestion-list {\n    margin: 0;\n    padding: 0;\n    list-style-type: none; }\n  tags-input .autocomplete .suggestion-item {\n    padding: .3em .6em;\n    cursor: pointer;\n    white-space: nowrap;\n    overflow: hidden;\n    text-overflow: ellipsis;\n    font-family: \"Helvetica Neue\", Helvetica, Arial, \"Lucida Grande\", sans-serif;\n    color: black;\n    background-color: white; }\n    tags-input .autocomplete .suggestion-item em {\n      font-family: \"Helvetica Neue\", Helvetica, Arial, \"Lucida Grande\", sans-serif;\n      font-weight: bold;\n      font-style: normal;\n      color: black;\n      background-color: white; }\n    tags-input .autocomplete .suggestion-item.selected {\n      color: white;\n      background-color: #0097cf; }\n      tags-input .autocomplete .suggestion-item.selected em {\n        color: white;\n        background-color: #0097cf; }\n\n.tooltip {\n  font-size: 11px;\n  line-height: 12px;\n  font-weight: 400;\n  border-radius: 2px;\n  position: fixed;\n  background-color: #202020;\n  color: white;\n  font-weight: bold;\n  padding-left: 5px;\n  padding-right: 5px;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  z-index: 20; }\n\n.tooltip:before {\n  -webkit-transform: rotate(45deg);\n          transform: rotate(45deg);\n  background: #202020;\n  border-bottom: 1px solid rgba(0, 0, 0, 0.2);\n  border-right: 1px solid rgba(0, 0, 0, 0.2);\n  content: \"\";\n  display: block;\n  height: 6px;\n  left: 0;\n  margin-left: auto;\n  margin-right: 5px;\n  position: absolute;\n  right: 0;\n  width: 6px;\n  content: \"\";\n  top: calc(100% - 5px); }\n\n.tooltip-label {\n  position: relative; }\n\n.u-stretch {\n  -webkit-box-flex: 1;\n  -webkit-flex-grow: 1;\n      -ms-flex-positive: 1;\n          flex-grow: 1; }\n\n.u-layout-row {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row; }\n\n.u-center {\n  margin-left: auto;\n  margin-right: auto; }\n\n.u-align-right {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: horizontal;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: row;\n      -ms-flex-direction: row;\n          flex-direction: row;\n  -webkit-box-pack: end;\n  -webkit-justify-content: flex-end;\n      -ms-flex-pack: end;\n          justify-content: flex-end; }\n\n.u-strong {\n  font-weight: bold; }\n\n.u-hidden {\n  display: none; }\n\n/* Style input placeholders */\n/* Shadow mixins */\n.annotator-hide {\n  display: none;\n  visibility: hidden; }\n\n.top-bar {\n  background: #fff;\n  border-bottom: solid 1px #d3d3d3;\n  height: 40px;\n  font-size: 15px;\n  position: fixed;\n  left: 0;\n  right: 0;\n  top: 0;\n  z-index: 5;\n  -webkit-transform: translate3d(0, 0, 0);\n          transform: translate3d(0, 0, 0); }\n\n.top-bar__inner {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-flex-flow: row nowrap;\n      -ms-flex-flow: row nowrap;\n          flex-flow: row nowrap;\n  -webkit-box-align: center;\n  -webkit-align-items: center;\n      -ms-flex-align: center;\n          align-items: center;\n  -webkit-box-pack: end;\n  -webkit-justify-content: flex-end;\n      -ms-flex-pack: end;\n          justify-content: flex-end;\n  padding-left: 9px;\n  padding-right: 9px;\n  height: 100%; }\n\n.top-bar__inner .group-list {\n  margin-right: .75em;\n  white-space: nowrap; }\n\n.top-bar__expander {\n  -webkit-box-flex: 1;\n  -webkit-flex-grow: 1;\n      -ms-flex-positive: 1;\n          flex-grow: 1; }\n\n.top-bar__btn {\n  padding: 0px;\n  margin: 0px;\n  background-color: transparent;\n  border-style: none;\n  outline: none;\n  color: #969696;\n  display: inline-block;\n  cursor: pointer;\n  padding: 0 3px; }\n  .top-bar__btn:hover {\n    color: #585858; }\n\n.top-bar__dropdown-arrow {\n  color: #626262; }\n\nbody {\n  background: #ECECEC;\n  font-family: \"Helvetica Neue\", Helvetica, Arial, \"Lucida Grande\", sans-serif;\n  font-weight: normal;\n  padding: 9px;\n  padding-top: 49px;\n  -webkit-overflow-scrolling: touch; }\n  @media only screen and (min-width: 767px) and (max-width: 1024px) {\n    body {\n      padding-bottom: 4rem; } }\n  @media only screen and (min-width: 1025px) {\n    body {\n      padding-bottom: 4rem; } }\n\nnest(\"hgroup\")nest(\"headings()\") {\n  margin: 0; }\n\n.content {\n  margin-left: auto;\n  margin-right: auto; }\n  @media only screen and (min-width: 767px) and (max-width: 1024px) {\n    .content {\n      margin: auto;\n      max-width: 768px;\n      padding-left: 4rem;\n      padding-right: 4rem; } }\n  @media only screen and (min-width: 1025px) {\n    .content {\n      margin: auto;\n      max-width: 768px;\n      padding-left: 4rem;\n      padding-right: 4rem; } }\n\n.create-account-banner {\n  background-color: #585858;\n  border-radius: 2px;\n  color: #a6a6a6;\n  font-weight: bold;\n  height: 34px;\n  line-height: 34px;\n  margin-bottom: .72em;\n  margin-left: auto;\n  margin-right: auto;\n  text-align: center;\n  width: 100%; }\n\n.create-account-banner a {\n  color: #fff; }\n\n.sheet {\n  border: solid 1px #d3d3d3;\n  border-radius: 2px;\n  font-family: \"Helvetica Neue\", Helvetica, Arial, \"Lucida Grande\", sans-serif;\n  font-weight: 300;\n  margin-bottom: .72em;\n  padding: 1em;\n  position: relative;\n  background-color: #fff; }\n  .sheet .nav-tabs {\n    border: 1px none #d3d3d3;\n    border-bottom-style: solid;\n    padding: 0 0 1.1em; }\n    .sheet .nav-tabs li a {\n      padding-bottom: .231em; }\n  .sheet .close {\n    position: absolute;\n    right: 1em;\n    top: 1em; }\n\n.thread-list > * {\n  margin-bottom: .72em; }\n\n.thread-list__spacer {\n  margin: 0; }\n\n.annotation-unavailable-message {\n  display: -webkit-box;\n  display: -webkit-flex;\n  display: -ms-flexbox;\n  display: flex;\n  -webkit-box-orient: vertical;\n  -webkit-box-direction: normal;\n  -webkit-flex-direction: column;\n      -ms-flex-direction: column;\n          flex-direction: column;\n  border: 1px solid #d3d3d3;\n  padding-top: 30px;\n  padding-bottom: 30px;\n  border-radius: 3px;\n  -webkit-box-align: center;\n  -webkit-align-items: center;\n      -ms-flex-align: center;\n          align-items: center; }\n  .annotation-unavailable-message__label {\n    text-align: center; }\n  .annotation-unavailable-message__icon {\n    background-image: url(../images/icons/lock.svg);\n    background-repeat: no-repeat;\n    width: 56px;\n    height: 48px; }\n\n/*# sourceMappingURL=app.css.map */\n"},{"size":823,"relativepath":"h/static/styles/site-v2.scss","filename":"site-v2.scss","extension":".scss","content":"@import 'partials-v2/base';\n@import 'partials-v2/reset';\n@import 'partials-v2/elements';\n@import 'partials-v2/util';\n\n// Components\n@import 'partials-v2/api-token';\n@import 'partials-v2/annotation-card';\n@import 'partials-v2/btn';\n@import 'partials-v2/dropdown-menu';\n@import 'partials-v2/form-actions';\n@import 'partials-v2/form-checkbox';\n@import 'partials-v2/form-container';\n@import 'partials-v2/form-input';\n@import 'partials-v2/form';\n@import 'partials-v2/join-group-form';\n@import 'partials-v2/link';\n@import 'partials-v2/lozenge';\n@import 'partials-v2/masthead';\n@import 'partials-v2/nav-bar';\n@import 'partials-v2/pager';\n@import 'partials-v2/search';\n@import 'partials-v2/search-bar';\n@import 'partials-v2/tooltip';\n@import 'partials-v2/tabs';\n\nbody {\n  @include font-normal;\n\n  font-family: $sans-font-family;\n}\n"},{"size":211,"relativepath":"h/static/styles/admin.scss","filename":"admin.scss","extension":".scss","content":"body {\n  padding-top: 50px;\n}\n\n.flashbar {\n  margin-top: 20px;\n}\n\n.table-auto {\n  table-layout: auto;\n  width: auto;\n}\n\n.users-activate-form {\n  display: inline;\n}\n\n.pager .pager__item--more {\n  border: none;\n}\n"},{"size":1672,"relativepath":"h/static/styles/mixins/_styled-text.scss","filename":"_styled-text.scss","extension":".scss","content":"@mixin styled-text() {\n  h1, h2, h3, h4, h5, h6, p, ol, ul, img, pre, blockquote {\n    margin: .618em 0;\n  }\n\n  h1, h2, h3, h4, h5, h6 {\n    font-family: $sans-font-family;\n  }\n\n  // Use a modular scale for headings:\n  // http://modularscale.com/scale/?px1=13&px2=16&ra1=1.618&ra2=0\n  h1 {\n    font-size: 2.618em;\n    font-weight: bold;\n    margin: .2327em 0;\n  }\n\n  h2 {\n    font-size: 1.991em;\n    font-weight: bold;\n    margin: .309em 0;\n  }\n\n  h3 {\n    font-size: 1.991em;\n    margin: .309em 0;\n  }\n\n  h4 {\n    font-size: 1.618em;\n    margin: .3803em 0;\n  }\n\n  h5 {\n    font-size: 1.231em;\n    margin: .4944em 0;\n  }\n\n  h6 {\n    font-size: 1.231em;\n    margin: .4944em 0;\n  }\n\n  ol, ul {\n    list-style-position: inside;\n    padding-left: 0;\n\n    ol, ul {\n      padding-left: 1em;\n    }\n  }\n\n  ol {\n    list-style-type: decimal;\n  }\n\n  ul {\n    list-style-type: disc;\n  }\n\n  ol, ul {\n    ul {\n      list-style-type: circle;\n    }\n  }\n\n  li {\n    margin-bottom: .291em;\n  }\n\n  li, p {\n    line-height: 1.3;\n  }\n\n  a {\n    text-decoration: underline;\n  }\n\n  img {\n    display: block;\n    max-width: 100%;\n  }\n\n  blockquote {\n    @include font-normal;\n\n    border-left: 3px solid $grey-3;\n    color: $grey-4;\n    font-family: sans-serif;\n    font-size: 12px;\n    font-style: italic;\n    letter-spacing: 0.1px;\n    padding: 0 1em;\n    margin: 1em 0;\n\n    p, ol, ul, img, pre, blockquote {\n      margin: .7063em 0;\n    }\n\n    p, li {\n      line-height: 1.5;\n    }\n  }\n\n  code {\n    font-family: $mono-font-family;\n    font-size: .875em;\n    color: black;\n  }\n\n  pre code {\n    padding: 10px;\n    display: block;\n    background-color: $grey-1;\n    border-radius: 2px;\n  }\n}\n"},{"size":721,"relativepath":"h/static/styles/mixins/_js.scss","filename":"_js.scss","extension":".scss","content":"// Helpers for changing element style or behavior depending on whether scripting\n// support is available and successfully loaded\n\n/**\n * Mixin which enables styles if the user agent is JavaScript-capable and\n * scripts are either loading or successfully loaded.\n *\n * Usage:\n *   @include js {\n *     // If JS is enabled, hide `thing` until the user performs some action\n *     // which sets the 'is-expanded' state on the element.\n *     //\n *     // If JS is not enabled or failed to load, this selector will not apply\n *     // and the element will not be hidden in the first place.\n *     .thing:not(.is-expanded) { display: none };\n *   }\n */\n@mixin js {\n  .env-js-capable:not(.env-js-timeout) {\n    @content;\n  }\n}\n"},{"size":1736,"relativepath":"h/static/styles/mixins/_grid.scss","filename":"_grid.scss","extension":".scss","content":"// Mixins for working with grids. A grid consists of an outer grid container\n// and internal columns. Each column has a gutter defined by $grid-gutter.\n// The implementation is largely based on the grid system created by\n// Harry Roberts <http://csswizardry.com/csswizardry-grids/> and the Yahoo\n// Pure system <http://git.io/ogODXA>\n\n// Sets up styles for the grid wrapper.\n@mixin grid-row($gutter: 0) {\n  margin: 0;\n  padding: 0;\n  // Remove the margin from the first column.\n  margin-left: -$gutter;\n  // Removes whitespace on browsers that do not support flexbox.\n  letter-spacing: -0.31em;\n  // Remove optimizeLegibility if applied.\n  text-rendering: optimizespeed;\n\n  // Removes whitespaec between elements in supporting browsers.\n  display: -webkit-flex;\n  -webkit-flex-flow: row wrap;\n  display: -ms-flexbox;\n  -ms-flex-flow: row wrap;\n\n  @content;\n}\n\n// Defines a column, can be included in any selector, widths can be provided\n// by passing a @content block.\n//\n// Example\n//\n// .my-awkward-item {\n//   @include grid-column($default-gutter) { width: 43%; }\n// }\n@mixin grid-column($gutter: 0) {\n  display: inline-block;\n  vertical-align: top;\n  padding-left: $gutter;\n  vertical-align: top;\n  width: 100%;\n  box-sizing: border-box;\n\n  // Reset letter spacing.\n  letter-spacing: normal;\n  text-rendering: auto;\n\n  @content;\n}\n\n// Defines selectors for a class based grid system. Only includes a few common\n// sizes at the moment, but can be expanded as necessary.\n@mixin grid-setup($namespace: \"\") {\n  .#{$namespace}1-1 { width: 100%; }\n  .#{$namespace}1-2 { width: 50%; }\n  .#{$namespace}1-3 { width: 33.333%; }\n  .#{$namespace}2-3 { width: 66.666%; }\n  .#{$namespace}1-4 { width: 25%; }\n  .#{$namespace}3-4 { width: 75%; }\n}\n"},{"size":457,"relativepath":"h/static/styles/mixins/_icons.scss","filename":"_icons.scss","extension":".scss","content":"// Mixin for targeting icomoon fonts. This keeps the class namespace in one\n// place rather than spreading it through individual files.\n// NOTE: If you want to target a specific icon in a component give it a\n// distinct class name rather than using the icon class.\n//\n// Usage:\n//\n//  .my-element {\n//    @include icons {\n//      color: red; // Make any icon red.\n//    }\n//  }\n@mixin icons {\n  [class^=\"h-icon-\"], [class*=\" h-icon-\"] {\n    @content;\n  }\n}\n"},{"size":483,"relativepath":"h/static/styles/mixins/_all.scss","filename":"_all.scss","extension":".scss","content":"// Base mixins: these depend on nothing external to themselves.\n@import 'mixins/grid';\n@import 'mixins/reset';\n@import 'mixins/shadows';\n\n// Core mixins: these may depend on externally defined variables & base mixins.\n@import 'mixins/icons';\n@import 'mixins/js';\n@import 'mixins/responsive';\n@import 'mixins/typography';\n\n// Component mixins: these may depend on core and base mixins, as well as\n// externally defined variables.\n@import 'mixins/forms';\n@import 'mixins/styled-text';\n"},{"size":2045,"relativepath":"h/static/styles/mixins/_forms.scss","filename":"_forms.scss","extension":".scss","content":"// See http://compass-style.org/reference/compass/utilities/general/clearfix/#mixin-pie-clearfix\n@mixin pie-clearfix {\n  &:after {\n    content: \"\";\n    display: table;\n    clear: both;\n  }\n}\n\n/* Style input placeholders */\n@mixin placeholder {\n  &.placeholder { @content; }\n  &:placeholder { @content; }\n  &::placeholder { @content; }\n}\n\n@mixin focus-outline {\n  border-color: #51A7E8;\n  box-shadow: 0px 1px 2px rgba(0, 0, 0, .075) inset, 0px 0px 5px rgba(81, 167, 232, .5);\n}\n\n@mixin form-input {\n  @include font-normal;\n  border: 1px solid $gray-lighter;\n  border-radius: 2px;\n  padding: .5em .75em;\n  font-weight: normal;\n  color: $gray;\n  background-color: #FAFAFA;\n}\n\n@mixin form-input-focus {\n  outline: none;\n  background-color: #FFF;\n\n  @include focus-outline;\n  @include placeholder {\n    color: $gray;\n  }\n}\n\n@mixin form-input-error {\n  color: $error-color;\n  border-color: color-weight($error-color, 300);\n  background-color: color-weight($error-color, 50);\n\n  @include placeholder {\n    color: tint($error-color, 5%);\n  }\n}\n\n@mixin btn {\n  box-shadow: 0 1px 0 rgba(0, 0, 0, .15);\n\n  background: linear-gradient($button-background-gradient);\n  display: inline-block;\n  font-weight: bold;\n  color: $button-text-color;\n  text-shadow: 0 1px 0 #FFF;\n  border-radius: 2px;\n  border: 1px solid $gray-light;\n  padding: .5em .9em;\n}\n\n@mixin btn-hover {\n  box-shadow: 0 1px 0 rgba(0, 0, 0, .05);\n  outline: none;\n  color: $button-text-color;\n  background: $button-background-start;\n  border-color: #bababa;\n}\n\n@mixin btn-active {\n  box-shadow: inset 0 1px 0 rgba(0, 0, 0, .1);\n  background: $button-background-end;\n  color: #424242;\n  border-color: #bababa;\n}\n\n@mixin btn-disabled {\n  box-shadow: none;\n  cursor: default;\n  background: #F0F0F0;\n  border-color: #CECECE;\n  color: $gray-light;\n}\n\n// Tint and shade functions from\n// https://css-tricks.com/snippets/sass/tint-shade-functions\n@function tint($color, $percent){\n  @return mix(white, $color, $percent);\n}\n\n@function shade($color, $percent){\n  @return mix(black, $color, $percent);\n}\n"},{"size":92,"relativepath":"h/static/styles/mixins/_shadows.scss","filename":"_shadows.scss","extension":".scss","content":"@mixin smallshadow($a: 0, $b: 1px, $c: .1) {\n  box-shadow: $a $b 1px hsla(0, 0%, 0%, $c);\n}\n"},{"size":1019,"relativepath":"h/static/styles/mixins/_responsive.scss","filename":"_responsive.scss","extension":".scss","content":"$break-wide-handheld: 480px !default;\n$break-tablet: 768px !default;\n$break-desktop: 1024px !default;\n\n@mixin breakpoint($min) {\n  @media only screen and (min-width: $min) {\n    @content;\n  }\n}\n\n// Mobile first media queries. Encourages development to work with mobile and\n// modify as the viewport grows rather than designing for individual bands.\n@mixin wide-handheld-and-up {\n  @include breakpoint($break-wide-handheld + 1) {\n    @content;\n  }\n}\n\n@mixin tablet-and-up {\n  @include breakpoint($break-tablet + 1) {\n    @content;\n  }\n}\n\n@mixin desktop-and-up {\n  @include breakpoint($break-desktop + 1) {\n    @content;\n  }\n}\n\n// Mixin for styling elements to make them more finger-friendly on touch-input\n// devices.\n//\n// Use interaction media queries where available (see\n// http://caniuse.com/#feat=css-media-interaction) or fall back to relying on a\n// JS-added class on the <html> or <body> elements otherwise.\n@mixin touch-input {\n  @media (pointer: coarse) {\n    @content;\n  }\n  .env-touch {\n    @content;\n  }\n}\n"},{"size":245,"relativepath":"h/static/styles/mixins/_typography.scss","filename":"_typography.scss","extension":".scss","content":"@mixin font-small {\n  font-size: $small-font-size;\n  line-height: $small-line-height;\n  font-weight: 400;\n  letter-spacing: 0.2px;\n}\n\n@mixin font-normal {\n  font-size: $normal-font-size;\n  line-height: $normal-line-height;\n  font-weight: 400;\n}\n"},{"size":155,"relativepath":"h/static/styles/mixins/_reset.scss","filename":"_reset.scss","extension":".scss","content":"@mixin reset-font {\n  font: inherit;\n  font-size: 100%;\n  vertical-align: baseline;\n}\n\n@mixin reset-box-model {\n  margin: 0;\n  padding: 0;\n  border: 0;\n}\n\n"},{"size":146213,"relativepath":"h/static/styles/front-page.css","filename":"front-page.css","extension":".css","content":"hr,img{border:0}.btn-group>.btn-group,.btn-toolbar .btn-group,.btn-toolbar .input-group,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9,.dropdown-menu{float:left}.img-responsive,.img-thumbnail,.table,label{max-width:100%}.navbar-fixed-bottom .navbar-collapse,.navbar-fixed-top .navbar-collapse,.pre-scrollable{max-height:340px}@font-face{font-family:Lato;font-style:normal;font-weight:300;src:local('Lato Light'),local('Lato-Light'),url(//fonts.gstatic.com/s/lato/v11/nj47mAZe0mYUIySgfn0wpQ.ttf) format('truetype')}@font-face{font-family:Lato;font-style:normal;font-weight:400;src:local('Lato Regular'),local('Lato-Regular'),url(//fonts.gstatic.com/s/lato/v11/v0SdcGFAl2aezM9Vq_aFTQ.ttf) format('truetype')}@font-face{font-family:Lato;font-style:italic;font-weight:300;src:local('Lato Light Italic'),local('Lato-LightItalic'),url(//fonts.gstatic.com/s/lato/v11/2HG_tEPiQ4Z6795cGfdivKCWcynf_cDxXwCLxiixG1c.ttf) format('truetype')}article,aside,details,figcaption,figure,footer,header,hgroup,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block;vertical-align:baseline}audio:not([controls]){display:none;height:0}[hidden],template{display:none}a{background-color:transparent}a:active,a:hover{outline:0}b,optgroup,strong{font-weight:700}dfn{font-style:italic}h1{margin:.67em 0}mark{background:#ff0;color:#000}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sup{top:-.5em}sub{bottom:-.25em}img{vertical-align:middle}svg:not(:root){overflow:hidden}hr{-webkit-box-sizing:content-box;box-sizing:content-box;height:0}pre,textarea{overflow:auto}code,kbd,pre,samp{font-size:1em}button,input,optgroup,select,textarea{color:inherit;font:inherit;margin:0}.glyphicon,address{font-style:normal}button{overflow:visible}button,select{text-transform:none}button,html input[type=button],input[type=submit],input[type=reset]{-webkit-appearance:button;cursor:pointer}button[disabled],html input[disabled]{cursor:default}button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}input[type=checkbox],input[type=radio]{-webkit-box-sizing:border-box;box-sizing:border-box;padding:0}input[type=number]::-webkit-inner-spin-button,input[type=number]::-webkit-outer-spin-button{height:auto}input[type=search]::-webkit-search-cancel-button,input[type=search]::-webkit-search-decoration{-webkit-appearance:none}table{border-collapse:collapse;border-spacing:0}td,th{padding:0}@media print{blockquote,img,pre,tr{page-break-inside:avoid}*,:after,:before{background:0 0!important;color:#000!important;-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}a,a:visited{text-decoration:underline}a[href]:after{content:\" (\" attr(href) \")\"}abbr[title]:after{content:\" (\" attr(title) \")\"}a[href^=\"#\"]:after,a[href^=\"javascript:\"]:after{content:\"\"}blockquote,pre{border:1px solid #999}thead{display:table-header-group}img{max-width:100%!important}h2,h3,p{orphans:3;widows:3}h2,h3{page-break-after:avoid}select{background:#fff!important}.navbar{display:none}.btn>.caret,.comment-form .dropup>input[type=submit]>.caret,.comment-form input[type=submit]>.caret,.dropup>.btn>.caret{border-top-color:#000!important}.label{border:1px solid #000}.table{border-collapse:collapse!important}.table td,.table th{background-color:#fff!important}.table-bordered td,.table-bordered th{border:1px solid #ddd!important}}.img-thumbnail,body{background-color:#fff}@font-face{font-family:'Glyphicons Halflings';src:url(../fonts/bootstrap/glyphicons-halflings-regular.eot);src:url(../fonts/bootstrap/glyphicons-halflings-regular.eot?#iefix) format('embedded-opentype'),url(../fonts/bootstrap/glyphicons-halflings-regular.woff2) format('woff2'),url(../fonts/bootstrap/glyphicons-halflings-regular.woff) format('woff'),url(../fonts/bootstrap/glyphicons-halflings-regular.ttf) format('truetype'),url(../fonts/bootstrap/glyphicons-halflings-regular.svg#glyphicons_halflingsregular) format('svg')}.glyphicon{position:relative;top:1px;display:inline-block;font-family:'Glyphicons Halflings';font-weight:400;line-height:1;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.glyphicon-asterisk:before{content:\"\\2a\"}.glyphicon-plus:before{content:\"\\2b\"}.glyphicon-eur:before,.glyphicon-euro:before{content:\"\\20ac\"}.glyphicon-minus:before{content:\"\\2212\"}.glyphicon-cloud:before{content:\"\\2601\"}.glyphicon-envelope:before{content:\"\\2709\"}.glyphicon-pencil:before{content:\"\\270f\"}.glyphicon-glass:before{content:\"\\e001\"}.glyphicon-music:before{content:\"\\e002\"}.glyphicon-search:before{content:\"\\e003\"}.glyphicon-heart:before{content:\"\\e005\"}.glyphicon-star:before{content:\"\\e006\"}.glyphicon-star-empty:before{content:\"\\e007\"}.glyphicon-user:before{content:\"\\e008\"}.glyphicon-film:before{content:\"\\e009\"}.glyphicon-th-large:before{content:\"\\e010\"}.glyphicon-th:before{content:\"\\e011\"}.glyphicon-th-list:before{content:\"\\e012\"}.glyphicon-ok:before{content:\"\\e013\"}.glyphicon-remove:before{content:\"\\e014\"}.glyphicon-zoom-in:before{content:\"\\e015\"}.glyphicon-zoom-out:before{content:\"\\e016\"}.glyphicon-off:before{content:\"\\e017\"}.glyphicon-signal:before{content:\"\\e018\"}.glyphicon-cog:before{content:\"\\e019\"}.glyphicon-trash:before{content:\"\\e020\"}.glyphicon-home:before{content:\"\\e021\"}.glyphicon-file:before{content:\"\\e022\"}.glyphicon-time:before{content:\"\\e023\"}.glyphicon-road:before{content:\"\\e024\"}.glyphicon-download-alt:before{content:\"\\e025\"}.glyphicon-download:before{content:\"\\e026\"}.glyphicon-upload:before{content:\"\\e027\"}.glyphicon-inbox:before{content:\"\\e028\"}.glyphicon-play-circle:before{content:\"\\e029\"}.glyphicon-repeat:before{content:\"\\e030\"}.glyphicon-refresh:before{content:\"\\e031\"}.glyphicon-list-alt:before{content:\"\\e032\"}.glyphicon-lock:before{content:\"\\e033\"}.glyphicon-flag:before{content:\"\\e034\"}.glyphicon-headphones:before{content:\"\\e035\"}.glyphicon-volume-off:before{content:\"\\e036\"}.glyphicon-volume-down:before{content:\"\\e037\"}.glyphicon-volume-up:before{content:\"\\e038\"}.glyphicon-qrcode:before{content:\"\\e039\"}.glyphicon-barcode:before{content:\"\\e040\"}.glyphicon-tag:before{content:\"\\e041\"}.glyphicon-tags:before{content:\"\\e042\"}.glyphicon-book:before{content:\"\\e043\"}.glyphicon-bookmark:before{content:\"\\e044\"}.glyphicon-print:before{content:\"\\e045\"}.glyphicon-camera:before{content:\"\\e046\"}.glyphicon-font:before{content:\"\\e047\"}.glyphicon-bold:before{content:\"\\e048\"}.glyphicon-italic:before{content:\"\\e049\"}.glyphicon-text-height:before{content:\"\\e050\"}.glyphicon-text-width:before{content:\"\\e051\"}.glyphicon-align-left:before{content:\"\\e052\"}.glyphicon-align-center:before{content:\"\\e053\"}.glyphicon-align-right:before{content:\"\\e054\"}.glyphicon-align-justify:before{content:\"\\e055\"}.glyphicon-list:before{content:\"\\e056\"}.glyphicon-indent-left:before{content:\"\\e057\"}.glyphicon-indent-right:before{content:\"\\e058\"}.glyphicon-facetime-video:before{content:\"\\e059\"}.glyphicon-picture:before{content:\"\\e060\"}.glyphicon-map-marker:before{content:\"\\e062\"}.glyphicon-adjust:before{content:\"\\e063\"}.glyphicon-tint:before{content:\"\\e064\"}.glyphicon-edit:before{content:\"\\e065\"}.glyphicon-share:before{content:\"\\e066\"}.glyphicon-check:before{content:\"\\e067\"}.glyphicon-move:before{content:\"\\e068\"}.glyphicon-step-backward:before{content:\"\\e069\"}.glyphicon-fast-backward:before{content:\"\\e070\"}.glyphicon-backward:before{content:\"\\e071\"}.glyphicon-play:before{content:\"\\e072\"}.glyphicon-pause:before{content:\"\\e073\"}.glyphicon-stop:before{content:\"\\e074\"}.glyphicon-forward:before{content:\"\\e075\"}.glyphicon-fast-forward:before{content:\"\\e076\"}.glyphicon-step-forward:before{content:\"\\e077\"}.glyphicon-eject:before{content:\"\\e078\"}.glyphicon-chevron-left:before{content:\"\\e079\"}.glyphicon-chevron-right:before{content:\"\\e080\"}.glyphicon-plus-sign:before{content:\"\\e081\"}.glyphicon-minus-sign:before{content:\"\\e082\"}.glyphicon-remove-sign:before{content:\"\\e083\"}.glyphicon-ok-sign:before{content:\"\\e084\"}.glyphicon-question-sign:before{content:\"\\e085\"}.glyphicon-info-sign:before{content:\"\\e086\"}.glyphicon-screenshot:before{content:\"\\e087\"}.glyphicon-remove-circle:before{content:\"\\e088\"}.glyphicon-ok-circle:before{content:\"\\e089\"}.glyphicon-ban-circle:before{content:\"\\e090\"}.glyphicon-arrow-left:before{content:\"\\e091\"}.glyphicon-arrow-right:before{content:\"\\e092\"}.glyphicon-arrow-up:before{content:\"\\e093\"}.glyphicon-arrow-down:before{content:\"\\e094\"}.glyphicon-share-alt:before{content:\"\\e095\"}.glyphicon-resize-full:before{content:\"\\e096\"}.glyphicon-resize-small:before{content:\"\\e097\"}.glyphicon-exclamation-sign:before{content:\"\\e101\"}.glyphicon-gift:before{content:\"\\e102\"}.glyphicon-leaf:before{content:\"\\e103\"}.glyphicon-fire:before{content:\"\\e104\"}.glyphicon-eye-open:before{content:\"\\e105\"}.glyphicon-eye-close:before{content:\"\\e106\"}.glyphicon-warning-sign:before{content:\"\\e107\"}.glyphicon-plane:before{content:\"\\e108\"}.glyphicon-calendar:before{content:\"\\e109\"}.glyphicon-random:before{content:\"\\e110\"}.glyphicon-comment:before{content:\"\\e111\"}.glyphicon-magnet:before{content:\"\\e112\"}.glyphicon-chevron-up:before{content:\"\\e113\"}.glyphicon-chevron-down:before{content:\"\\e114\"}.glyphicon-retweet:before{content:\"\\e115\"}.glyphicon-shopping-cart:before{content:\"\\e116\"}.glyphicon-folder-close:before{content:\"\\e117\"}.glyphicon-folder-open:before{content:\"\\e118\"}.glyphicon-resize-vertical:before{content:\"\\e119\"}.glyphicon-resize-horizontal:before{content:\"\\e120\"}.glyphicon-hdd:before{content:\"\\e121\"}.glyphicon-bullhorn:before{content:\"\\e122\"}.glyphicon-bell:before{content:\"\\e123\"}.glyphicon-certificate:before{content:\"\\e124\"}.glyphicon-thumbs-up:before{content:\"\\e125\"}.glyphicon-thumbs-down:before{content:\"\\e126\"}.glyphicon-hand-right:before{content:\"\\e127\"}.glyphicon-hand-left:before{content:\"\\e128\"}.glyphicon-hand-up:before{content:\"\\e129\"}.glyphicon-hand-down:before{content:\"\\e130\"}.glyphicon-circle-arrow-right:before{content:\"\\e131\"}.glyphicon-circle-arrow-left:before{content:\"\\e132\"}.glyphicon-circle-arrow-up:before{content:\"\\e133\"}.glyphicon-circle-arrow-down:before{content:\"\\e134\"}.glyphicon-globe:before{content:\"\\e135\"}.glyphicon-wrench:before{content:\"\\e136\"}.glyphicon-tasks:before{content:\"\\e137\"}.glyphicon-filter:before{content:\"\\e138\"}.glyphicon-briefcase:before{content:\"\\e139\"}.glyphicon-fullscreen:before{content:\"\\e140\"}.glyphicon-dashboard:before{content:\"\\e141\"}.glyphicon-paperclip:before{content:\"\\e142\"}.glyphicon-heart-empty:before{content:\"\\e143\"}.glyphicon-link:before{content:\"\\e144\"}.glyphicon-phone:before{content:\"\\e145\"}.glyphicon-pushpin:before{content:\"\\e146\"}.glyphicon-usd:before{content:\"\\e148\"}.glyphicon-gbp:before{content:\"\\e149\"}.glyphicon-sort:before{content:\"\\e150\"}.glyphicon-sort-by-alphabet:before{content:\"\\e151\"}.glyphicon-sort-by-alphabet-alt:before{content:\"\\e152\"}.glyphicon-sort-by-order:before{content:\"\\e153\"}.glyphicon-sort-by-order-alt:before{content:\"\\e154\"}.glyphicon-sort-by-attributes:before{content:\"\\e155\"}.glyphicon-sort-by-attributes-alt:before{content:\"\\e156\"}.glyphicon-unchecked:before{content:\"\\e157\"}.glyphicon-expand:before{content:\"\\e158\"}.glyphicon-collapse-down:before{content:\"\\e159\"}.glyphicon-collapse-up:before{content:\"\\e160\"}.glyphicon-log-in:before{content:\"\\e161\"}.glyphicon-flash:before{content:\"\\e162\"}.glyphicon-log-out:before{content:\"\\e163\"}.glyphicon-new-window:before{content:\"\\e164\"}.glyphicon-record:before{content:\"\\e165\"}.glyphicon-save:before{content:\"\\e166\"}.glyphicon-open:before{content:\"\\e167\"}.glyphicon-saved:before{content:\"\\e168\"}.glyphicon-import:before{content:\"\\e169\"}.glyphicon-export:before{content:\"\\e170\"}.glyphicon-send:before{content:\"\\e171\"}.glyphicon-floppy-disk:before{content:\"\\e172\"}.glyphicon-floppy-saved:before{content:\"\\e173\"}.glyphicon-floppy-remove:before{content:\"\\e174\"}.glyphicon-floppy-save:before{content:\"\\e175\"}.glyphicon-floppy-open:before{content:\"\\e176\"}.glyphicon-credit-card:before{content:\"\\e177\"}.glyphicon-transfer:before{content:\"\\e178\"}.glyphicon-cutlery:before{content:\"\\e179\"}.glyphicon-header:before{content:\"\\e180\"}.glyphicon-compressed:before{content:\"\\e181\"}.glyphicon-earphone:before{content:\"\\e182\"}.glyphicon-phone-alt:before{content:\"\\e183\"}.glyphicon-tower:before{content:\"\\e184\"}.glyphicon-stats:before{content:\"\\e185\"}.glyphicon-sd-video:before{content:\"\\e186\"}.glyphicon-hd-video:before{content:\"\\e187\"}.glyphicon-subtitles:before{content:\"\\e188\"}.glyphicon-sound-stereo:before{content:\"\\e189\"}.glyphicon-sound-dolby:before{content:\"\\e190\"}.glyphicon-sound-5-1:before{content:\"\\e191\"}.glyphicon-sound-6-1:before{content:\"\\e192\"}.glyphicon-sound-7-1:before{content:\"\\e193\"}.glyphicon-copyright-mark:before{content:\"\\e194\"}.glyphicon-registration-mark:before{content:\"\\e195\"}.glyphicon-cloud-download:before{content:\"\\e197\"}.glyphicon-cloud-upload:before{content:\"\\e198\"}.glyphicon-tree-conifer:before{content:\"\\e199\"}.glyphicon-tree-deciduous:before{content:\"\\e200\"}.glyphicon-cd:before{content:\"\\e201\"}.glyphicon-save-file:before{content:\"\\e202\"}.glyphicon-open-file:before{content:\"\\e203\"}.glyphicon-level-up:before{content:\"\\e204\"}.glyphicon-copy:before{content:\"\\e205\"}.glyphicon-paste:before{content:\"\\e206\"}.glyphicon-alert:before{content:\"\\e209\"}.glyphicon-equalizer:before{content:\"\\e210\"}.glyphicon-king:before{content:\"\\e211\"}.glyphicon-queen:before{content:\"\\e212\"}.glyphicon-pawn:before{content:\"\\e213\"}.glyphicon-bishop:before{content:\"\\e214\"}.glyphicon-knight:before{content:\"\\e215\"}.glyphicon-baby-formula:before{content:\"\\e216\"}.glyphicon-tent:before{content:\"\\26fa\"}.glyphicon-blackboard:before{content:\"\\e218\"}.glyphicon-bed:before{content:\"\\e219\"}.glyphicon-apple:before{content:\"\\f8ff\"}.glyphicon-erase:before{content:\"\\e221\"}.glyphicon-hourglass:before{content:\"\\231b\"}.glyphicon-lamp:before{content:\"\\e223\"}.glyphicon-duplicate:before{content:\"\\e224\"}.glyphicon-piggy-bank:before{content:\"\\e225\"}.glyphicon-scissors:before{content:\"\\e226\"}.glyphicon-bitcoin:before,.glyphicon-btc:before,.glyphicon-xbt:before{content:\"\\e227\"}.glyphicon-jpy:before,.glyphicon-yen:before{content:\"\\00a5\"}.glyphicon-rub:before,.glyphicon-ruble:before{content:\"\\20bd\"}.glyphicon-scale:before{content:\"\\e230\"}.glyphicon-ice-lolly:before{content:\"\\e231\"}.glyphicon-ice-lolly-tasted:before{content:\"\\e232\"}.glyphicon-education:before{content:\"\\e233\"}.glyphicon-option-horizontal:before{content:\"\\e234\"}.glyphicon-option-vertical:before{content:\"\\e235\"}.glyphicon-menu-hamburger:before{content:\"\\e236\"}.glyphicon-modal-window:before{content:\"\\e237\"}.glyphicon-oil:before{content:\"\\e238\"}.glyphicon-grain:before{content:\"\\e239\"}.glyphicon-sunglasses:before{content:\"\\e240\"}.glyphicon-text-size:before{content:\"\\e241\"}.glyphicon-text-color:before{content:\"\\e242\"}.glyphicon-text-background:before{content:\"\\e243\"}.glyphicon-object-align-top:before{content:\"\\e244\"}.glyphicon-object-align-bottom:before{content:\"\\e245\"}.glyphicon-object-align-horizontal:before{content:\"\\e246\"}.glyphicon-object-align-left:before{content:\"\\e247\"}.glyphicon-object-align-vertical:before{content:\"\\e248\"}.glyphicon-object-align-right:before{content:\"\\e249\"}.glyphicon-triangle-right:before{content:\"\\e250\"}.glyphicon-triangle-left:before{content:\"\\e251\"}.glyphicon-triangle-bottom:before{content:\"\\e252\"}.glyphicon-triangle-top:before{content:\"\\e253\"}.glyphicon-console:before{content:\"\\e254\"}.glyphicon-superscript:before{content:\"\\e255\"}.glyphicon-subscript:before{content:\"\\e256\"}.glyphicon-menu-left:before{content:\"\\e257\"}.glyphicon-menu-right:before{content:\"\\e258\"}.glyphicon-menu-down:before{content:\"\\e259\"}.glyphicon-menu-up:before{content:\"\\e260\"}*,:after,:before{-webkit-box-sizing:border-box;box-sizing:border-box}html{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;font-size:10px;-webkit-tap-highlight-color:transparent}body{font-size:14px;line-height:1.428571429;color:#333}button,input,select,textarea{font-family:inherit;font-size:inherit;line-height:inherit}a{color:#bd1c2b;text-decoration:none}a:focus,a:hover{color:#7a121c;text-decoration:underline}a:focus{outline:dotted thin;outline:-webkit-focus-ring-color auto 5px;outline-offset:-2px}figure{margin:0}.img-responsive{display:block;height:auto}.img-rounded{border-radius:6px}.img-thumbnail{padding:4px;line-height:1.428571429;border:1px solid #ddd;border-radius:4px;-webkit-transition:all .2s ease-in-out;-o-transition:all .2s ease-in-out;transition:all .2s ease-in-out;display:inline-block;height:auto}.img-circle{border-radius:50%}hr{margin-top:20px;margin-bottom:20px;border-top:1px solid #eee}.screen-reader-text,.sr-only{position:absolute;width:1px;height:1px;margin:-1px;padding:0;overflow:hidden;clip:rect(0,0,0,0);border:0}.screen-reader-text:active,.screen-reader-text:focus,.sr-only-focusable:active,.sr-only-focusable:focus{position:static;width:auto;height:auto;margin:0;overflow:visible;clip:auto}[role=button]{cursor:pointer}.h1,.h2,.h3,.h4,.h5,.h6,h1,h2,h3,h4,h5,h6{font-family:inherit;font-weight:500;line-height:1.1;color:inherit}.h1 .small,.h1 small,.h2 .small,.h2 small,.h3 .small,.h3 small,.h4 .small,.h4 small,.h5 .small,.h5 small,.h6 .small,.h6 small,h1 .small,h1 small,h2 .small,h2 small,h3 .small,h3 small,h4 .small,h4 small,h5 .small,h5 small,h6 .small,h6 small{font-weight:400;line-height:1;color:#777}.h1,.h2,.h3,h1,h2,h3{margin-top:20px;margin-bottom:10px}.h1 .small,.h1 small,.h2 .small,.h2 small,.h3 .small,.h3 small,h1 .small,h1 small,h2 .small,h2 small,h3 .small,h3 small{font-size:65%}.h4,.h5,.h6,h4,h5,h6{margin-top:10px;margin-bottom:10px}.h4 .small,.h4 small,.h5 .small,.h5 small,.h6 .small,.h6 small,h4 .small,h4 small,h5 .small,h5 small,h6 .small,h6 small{font-size:75%}.h1,h1{font-size:36px}.h2,h2{font-size:30px}.h3,h3{font-size:24px}.h4,h4{font-size:18px}.h5,h5{font-size:14px}.h6,h6{font-size:12px}p{margin:0 0 10px}.lead{margin-bottom:20px;font-size:16px;font-weight:300;line-height:1.4}dt,kbd kbd,label{font-weight:700}address,blockquote .small,blockquote footer,blockquote small,dd,dt,pre{line-height:1.428571429}@media (min-width:768px){.lead{font-size:21px}}.small,small{font-size:85%}.mark,mark{background-color:#fcf8e3;padding:.2em}.list-inline,.list-unstyled{padding-left:0;list-style:none}.text-left{text-align:left}.text-right{text-align:right}.text-center{text-align:center}.text-justify{text-align:justify}.text-nowrap{white-space:nowrap}.text-lowercase{text-transform:lowercase}.initialism,.text-uppercase{text-transform:uppercase}.text-capitalize{text-transform:capitalize}.text-muted{color:#777}.text-primary{color:#bd1c2b}a.text-primary:hover{color:#911521}.text-success{color:#3c763d}a.text-success:hover{color:#2b542c}.text-info{color:#31708f}a.text-info:hover{color:#245269}.text-warning{color:#8a6d3b}a.text-warning:hover{color:#66512c}.text-danger{color:#a94442}a.text-danger:hover{color:#843534}.bg-primary{color:#fff;background-color:#bd1c2b}a.bg-primary:hover{background-color:#911521}.bg-success{background-color:#dff0d8}a.bg-success:hover{background-color:#c1e2b3}.bg-info{background-color:#d9edf7}a.bg-info:hover{background-color:#afd9ee}.bg-warning{background-color:#fcf8e3}a.bg-warning:hover{background-color:#f7ecb5}.bg-danger{background-color:#f2dede}a.bg-danger:hover{background-color:#e4b9b9}pre code,table{background-color:transparent}.page-header{padding-bottom:9px;margin:40px 0 20px;border-bottom:1px solid #eee}dl,ol,ul{margin-top:0}blockquote ol:last-child,blockquote p:last-child,blockquote ul:last-child,ol ol,ol ul,ul ol,ul ul{margin-bottom:0}address,dl{margin-bottom:20px}ol,ul{margin-bottom:10px}.list-inline{margin-left:-5px}.list-inline>li{display:inline-block;padding-left:5px;padding-right:5px}dd{margin-left:0}.dl-horizontal dd:after,.dl-horizontal dd:before{content:\" \";display:table}.dl-horizontal dd:after{clear:both}@media (min-width:768px){.dl-horizontal dt{float:left;width:160px;clear:left;text-align:right;overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.dl-horizontal dd{margin-left:180px}.container{width:750px}}.btn-group-vertical>.btn-group:after,.btn-toolbar:after,.clearfix:after,.comment-form .form-horizontal p:after,.container-fluid:after,.container:after,.dropdown-menu>li>a,.form-horizontal .comment-form p:after,.form-horizontal .form-group:after,.modal-footer:after,.navbar-collapse:after,.navbar-header:after,.navbar:after,.pager:after,.panel-body:after,.row:after{clear:both}abbr[data-original-title],abbr[title]{cursor:help;border-bottom:1px dotted #777}.initialism{font-size:90%}blockquote{padding:10px 20px;margin:0 0 20px;font-size:17.5px;border-left:5px solid #eee}blockquote .small,blockquote footer,blockquote small{display:block;font-size:80%;color:#777}legend,pre{color:#333}blockquote .small:before,blockquote footer:before,blockquote small:before{content:'\\2014 \\00A0'}.blockquote-reverse,blockquote.pull-right{padding-right:15px;padding-left:0;border-right:5px solid #eee;border-left:0;text-align:right}code,kbd{padding:2px 4px;font-size:90%}caption,th{text-align:left}.blockquote-reverse .small:before,.blockquote-reverse footer:before,.blockquote-reverse small:before,blockquote.pull-right .small:before,blockquote.pull-right footer:before,blockquote.pull-right small:before{content:''}.blockquote-reverse .small:after,.blockquote-reverse footer:after,.blockquote-reverse small:after,blockquote.pull-right .small:after,blockquote.pull-right footer:after,blockquote.pull-right small:after{content:'\\00A0 \\2014'}code,kbd,pre,samp{font-family:Menlo,Monaco,Consolas,\"Courier New\",monospace}code{color:#c7254e;background-color:#f9f2f4;border-radius:4px}kbd{color:#fff;background-color:#333;border-radius:3px;-webkit-box-shadow:inset 0 -1px 0 rgba(0,0,0,.25);box-shadow:inset 0 -1px 0 rgba(0,0,0,.25)}kbd kbd{padding:0;font-size:100%;-webkit-box-shadow:none;box-shadow:none}pre{display:block;padding:9.5px;margin:0 0 10px;font-size:13px;word-break:break-all;word-wrap:break-word;background-color:#f5f5f5;border:1px solid #ccc;border-radius:4px}.container-fluid:after,.container-fluid:before,.container:after,.container:before,.row:after,.row:before{display:table;content:\" \"}.container,.container-fluid{margin-right:auto;margin-left:auto}pre code{padding:0;font-size:inherit;color:inherit;white-space:pre-wrap;border-radius:0}.container,.container-fluid{padding-left:15px;padding-right:15px}.pre-scrollable{overflow-y:scroll}@media (min-width:992px){.container{width:970px}}@media (min-width:1200px){.container{width:1170px}}.row{margin-left:-15px;margin-right:-15px}.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9{position:relative;min-height:1px;padding-left:15px;padding-right:15px}.col-xs-1{width:8.3333333333%}.col-xs-2{width:16.6666666667%}.col-xs-3{width:25%}.col-xs-4{width:33.3333333333%}.col-xs-5{width:41.6666666667%}.col-xs-6{width:50%}.col-xs-7{width:58.3333333333%}.col-xs-8{width:66.6666666667%}.col-xs-9{width:75%}.col-xs-10{width:83.3333333333%}.col-xs-11{width:91.6666666667%}.col-xs-12{width:100%}.col-xs-pull-0{right:auto}.col-xs-pull-1{right:8.3333333333%}.col-xs-pull-2{right:16.6666666667%}.col-xs-pull-3{right:25%}.col-xs-pull-4{right:33.3333333333%}.col-xs-pull-5{right:41.6666666667%}.col-xs-pull-6{right:50%}.col-xs-pull-7{right:58.3333333333%}.col-xs-pull-8{right:66.6666666667%}.col-xs-pull-9{right:75%}.col-xs-pull-10{right:83.3333333333%}.col-xs-pull-11{right:91.6666666667%}.col-xs-pull-12{right:100%}.col-xs-push-0{left:auto}.col-xs-push-1{left:8.3333333333%}.col-xs-push-2{left:16.6666666667%}.col-xs-push-3{left:25%}.col-xs-push-4{left:33.3333333333%}.col-xs-push-5{left:41.6666666667%}.col-xs-push-6{left:50%}.col-xs-push-7{left:58.3333333333%}.col-xs-push-8{left:66.6666666667%}.col-xs-push-9{left:75%}.col-xs-push-10{left:83.3333333333%}.col-xs-push-11{left:91.6666666667%}.col-xs-push-12{left:100%}.col-xs-offset-0{margin-left:0}.col-xs-offset-1{margin-left:8.3333333333%}.col-xs-offset-2{margin-left:16.6666666667%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-4{margin-left:33.3333333333%}.col-xs-offset-5{margin-left:41.6666666667%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-7{margin-left:58.3333333333%}.col-xs-offset-8{margin-left:66.6666666667%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-10{margin-left:83.3333333333%}.col-xs-offset-11{margin-left:91.6666666667%}.col-xs-offset-12{margin-left:100%}@media (min-width:768px){.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9{float:left}.col-sm-1{width:8.3333333333%}.col-sm-2{width:16.6666666667%}.col-sm-3{width:25%}.col-sm-4{width:33.3333333333%}.col-sm-5{width:41.6666666667%}.col-sm-6{width:50%}.col-sm-7{width:58.3333333333%}.col-sm-8{width:66.6666666667%}.col-sm-9{width:75%}.col-sm-10{width:83.3333333333%}.col-sm-11{width:91.6666666667%}.col-sm-12{width:100%}.col-sm-pull-0{right:auto}.col-sm-pull-1{right:8.3333333333%}.col-sm-pull-2{right:16.6666666667%}.col-sm-pull-3{right:25%}.col-sm-pull-4{right:33.3333333333%}.col-sm-pull-5{right:41.6666666667%}.col-sm-pull-6{right:50%}.col-sm-pull-7{right:58.3333333333%}.col-sm-pull-8{right:66.6666666667%}.col-sm-pull-9{right:75%}.col-sm-pull-10{right:83.3333333333%}.col-sm-pull-11{right:91.6666666667%}.col-sm-pull-12{right:100%}.col-sm-push-0{left:auto}.col-sm-push-1{left:8.3333333333%}.col-sm-push-2{left:16.6666666667%}.col-sm-push-3{left:25%}.col-sm-push-4{left:33.3333333333%}.col-sm-push-5{left:41.6666666667%}.col-sm-push-6{left:50%}.col-sm-push-7{left:58.3333333333%}.col-sm-push-8{left:66.6666666667%}.col-sm-push-9{left:75%}.col-sm-push-10{left:83.3333333333%}.col-sm-push-11{left:91.6666666667%}.col-sm-push-12{left:100%}.col-sm-offset-0{margin-left:0}.col-sm-offset-1{margin-left:8.3333333333%}.col-sm-offset-2{margin-left:16.6666666667%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-4{margin-left:33.3333333333%}.col-sm-offset-5{margin-left:41.6666666667%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-7{margin-left:58.3333333333%}.col-sm-offset-8{margin-left:66.6666666667%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-10{margin-left:83.3333333333%}.col-sm-offset-11{margin-left:91.6666666667%}.col-sm-offset-12{margin-left:100%}}@media (min-width:992px){.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9{float:left}.col-md-1{width:8.3333333333%}.col-md-2{width:16.6666666667%}.col-md-3{width:25%}.col-md-4{width:33.3333333333%}.col-md-5{width:41.6666666667%}.col-md-6{width:50%}.col-md-7{width:58.3333333333%}.col-md-8{width:66.6666666667%}.col-md-9{width:75%}.col-md-10{width:83.3333333333%}.col-md-11{width:91.6666666667%}.col-md-12{width:100%}.col-md-pull-0{right:auto}.col-md-pull-1{right:8.3333333333%}.col-md-pull-2{right:16.6666666667%}.col-md-pull-3{right:25%}.col-md-pull-4{right:33.3333333333%}.col-md-pull-5{right:41.6666666667%}.col-md-pull-6{right:50%}.col-md-pull-7{right:58.3333333333%}.col-md-pull-8{right:66.6666666667%}.col-md-pull-9{right:75%}.col-md-pull-10{right:83.3333333333%}.col-md-pull-11{right:91.6666666667%}.col-md-pull-12{right:100%}.col-md-push-0{left:auto}.col-md-push-1{left:8.3333333333%}.col-md-push-2{left:16.6666666667%}.col-md-push-3{left:25%}.col-md-push-4{left:33.3333333333%}.col-md-push-5{left:41.6666666667%}.col-md-push-6{left:50%}.col-md-push-7{left:58.3333333333%}.col-md-push-8{left:66.6666666667%}.col-md-push-9{left:75%}.col-md-push-10{left:83.3333333333%}.col-md-push-11{left:91.6666666667%}.col-md-push-12{left:100%}.col-md-offset-0{margin-left:0}.col-md-offset-1{margin-left:8.3333333333%}.col-md-offset-2{margin-left:16.6666666667%}.col-md-offset-3{margin-left:25%}.col-md-offset-4{margin-left:33.3333333333%}.col-md-offset-5{margin-left:41.6666666667%}.col-md-offset-6{margin-left:50%}.col-md-offset-7{margin-left:58.3333333333%}.col-md-offset-8{margin-left:66.6666666667%}.col-md-offset-9{margin-left:75%}.col-md-offset-10{margin-left:83.3333333333%}.col-md-offset-11{margin-left:91.6666666667%}.col-md-offset-12{margin-left:100%}}@media (min-width:1200px){.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9{float:left}.col-lg-1{width:8.3333333333%}.col-lg-2{width:16.6666666667%}.col-lg-3{width:25%}.col-lg-4{width:33.3333333333%}.col-lg-5{width:41.6666666667%}.col-lg-6{width:50%}.col-lg-7{width:58.3333333333%}.col-lg-8{width:66.6666666667%}.col-lg-9{width:75%}.col-lg-10{width:83.3333333333%}.col-lg-11{width:91.6666666667%}.col-lg-12{width:100%}.col-lg-pull-0{right:auto}.col-lg-pull-1{right:8.3333333333%}.col-lg-pull-2{right:16.6666666667%}.col-lg-pull-3{right:25%}.col-lg-pull-4{right:33.3333333333%}.col-lg-pull-5{right:41.6666666667%}.col-lg-pull-6{right:50%}.col-lg-pull-7{right:58.3333333333%}.col-lg-pull-8{right:66.6666666667%}.col-lg-pull-9{right:75%}.col-lg-pull-10{right:83.3333333333%}.col-lg-pull-11{right:91.6666666667%}.col-lg-pull-12{right:100%}.col-lg-push-0{left:auto}.col-lg-push-1{left:8.3333333333%}.col-lg-push-2{left:16.6666666667%}.col-lg-push-3{left:25%}.col-lg-push-4{left:33.3333333333%}.col-lg-push-5{left:41.6666666667%}.col-lg-push-6{left:50%}.col-lg-push-7{left:58.3333333333%}.col-lg-push-8{left:66.6666666667%}.col-lg-push-9{left:75%}.col-lg-push-10{left:83.3333333333%}.col-lg-push-11{left:91.6666666667%}.col-lg-push-12{left:100%}.col-lg-offset-0{margin-left:0}.col-lg-offset-1{margin-left:8.3333333333%}.col-lg-offset-2{margin-left:16.6666666667%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-4{margin-left:33.3333333333%}.col-lg-offset-5{margin-left:41.6666666667%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-7{margin-left:58.3333333333%}.col-lg-offset-8{margin-left:66.6666666667%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-10{margin-left:83.3333333333%}.col-lg-offset-11{margin-left:91.6666666667%}.col-lg-offset-12{margin-left:100%}}caption{padding-top:8px;padding-bottom:8px;color:#777}.table{width:100%;margin-bottom:20px}.table>tbody>tr>td,.table>tbody>tr>th,.table>tfoot>tr>td,.table>tfoot>tr>th,.table>thead>tr>td,.table>thead>tr>th{padding:8px;line-height:1.428571429;vertical-align:top;border-top:1px solid #ddd}.table>thead>tr>th{vertical-align:bottom;border-bottom:2px solid #ddd}.table>caption+thead>tr:first-child>td,.table>caption+thead>tr:first-child>th,.table>colgroup+thead>tr:first-child>td,.table>colgroup+thead>tr:first-child>th,.table>thead:first-child>tr:first-child>td,.table>thead:first-child>tr:first-child>th{border-top:0}.table>tbody+tbody{border-top:2px solid #ddd}.table .table{background-color:#fff}.table-condensed>tbody>tr>td,.table-condensed>tbody>tr>th,.table-condensed>tfoot>tr>td,.table-condensed>tfoot>tr>th,.table-condensed>thead>tr>td,.table-condensed>thead>tr>th{padding:5px}.table-bordered,.table-bordered>tbody>tr>td,.table-bordered>tbody>tr>th,.table-bordered>tfoot>tr>td,.table-bordered>tfoot>tr>th,.table-bordered>thead>tr>td,.table-bordered>thead>tr>th{border:1px solid #ddd}.table-bordered>thead>tr>td,.table-bordered>thead>tr>th{border-bottom-width:2px}.table-striped>tbody>tr:nth-of-type(odd){background-color:#f9f9f9}.table-hover>tbody>tr:hover,.table>tbody>tr.active>td,.table>tbody>tr.active>th,.table>tbody>tr>td.active,.table>tbody>tr>th.active,.table>tfoot>tr.active>td,.table>tfoot>tr.active>th,.table>tfoot>tr>td.active,.table>tfoot>tr>th.active,.table>thead>tr.active>td,.table>thead>tr.active>th,.table>thead>tr>td.active,.table>thead>tr>th.active{background-color:#f5f5f5}table col[class*=col-]{position:static;float:none;display:table-column}table td[class*=col-],table th[class*=col-]{position:static;float:none;display:table-cell}.table-hover>tbody>tr.active:hover>td,.table-hover>tbody>tr.active:hover>th,.table-hover>tbody>tr:hover>.active,.table-hover>tbody>tr>td.active:hover,.table-hover>tbody>tr>th.active:hover{background-color:#e8e8e8}.table>tbody>tr.success>td,.table>tbody>tr.success>th,.table>tbody>tr>td.success,.table>tbody>tr>th.success,.table>tfoot>tr.success>td,.table>tfoot>tr.success>th,.table>tfoot>tr>td.success,.table>tfoot>tr>th.success,.table>thead>tr.success>td,.table>thead>tr.success>th,.table>thead>tr>td.success,.table>thead>tr>th.success{background-color:#dff0d8}.table-hover>tbody>tr.success:hover>td,.table-hover>tbody>tr.success:hover>th,.table-hover>tbody>tr:hover>.success,.table-hover>tbody>tr>td.success:hover,.table-hover>tbody>tr>th.success:hover{background-color:#d0e9c6}.table>tbody>tr.info>td,.table>tbody>tr.info>th,.table>tbody>tr>td.info,.table>tbody>tr>th.info,.table>tfoot>tr.info>td,.table>tfoot>tr.info>th,.table>tfoot>tr>td.info,.table>tfoot>tr>th.info,.table>thead>tr.info>td,.table>thead>tr.info>th,.table>thead>tr>td.info,.table>thead>tr>th.info{background-color:#d9edf7}.table-hover>tbody>tr.info:hover>td,.table-hover>tbody>tr.info:hover>th,.table-hover>tbody>tr:hover>.info,.table-hover>tbody>tr>td.info:hover,.table-hover>tbody>tr>th.info:hover{background-color:#c4e3f3}.table>tbody>tr.warning>td,.table>tbody>tr.warning>th,.table>tbody>tr>td.warning,.table>tbody>tr>th.warning,.table>tfoot>tr.warning>td,.table>tfoot>tr.warning>th,.table>tfoot>tr>td.warning,.table>tfoot>tr>th.warning,.table>thead>tr.warning>td,.table>thead>tr.warning>th,.table>thead>tr>td.warning,.table>thead>tr>th.warning{background-color:#fcf8e3}.table-hover>tbody>tr.warning:hover>td,.table-hover>tbody>tr.warning:hover>th,.table-hover>tbody>tr:hover>.warning,.table-hover>tbody>tr>td.warning:hover,.table-hover>tbody>tr>th.warning:hover{background-color:#faf2cc}.table>tbody>tr.danger>td,.table>tbody>tr.danger>th,.table>tbody>tr>td.danger,.table>tbody>tr>th.danger,.table>tfoot>tr.danger>td,.table>tfoot>tr.danger>th,.table>tfoot>tr>td.danger,.table>tfoot>tr>th.danger,.table>thead>tr.danger>td,.table>thead>tr.danger>th,.table>thead>tr>td.danger,.table>thead>tr>th.danger{background-color:#f2dede}.table-hover>tbody>tr.danger:hover>td,.table-hover>tbody>tr.danger:hover>th,.table-hover>tbody>tr:hover>.danger,.table-hover>tbody>tr>td.danger:hover,.table-hover>tbody>tr>th.danger:hover{background-color:#ebcccc}.table-responsive{overflow-x:auto;min-height:.01%}@media screen and (max-width:767px){.table-responsive{width:100%;margin-bottom:15px;overflow-y:hidden;-ms-overflow-style:-ms-autohiding-scrollbar;border:1px solid #ddd}.table-responsive>.table{margin-bottom:0}.table-responsive>.table>tbody>tr>td,.table-responsive>.table>tbody>tr>th,.table-responsive>.table>tfoot>tr>td,.table-responsive>.table>tfoot>tr>th,.table-responsive>.table>thead>tr>td,.table-responsive>.table>thead>tr>th{white-space:nowrap}.table-responsive>.table-bordered{border:0}.table-responsive>.table-bordered>tbody>tr>td:first-child,.table-responsive>.table-bordered>tbody>tr>th:first-child,.table-responsive>.table-bordered>tfoot>tr>td:first-child,.table-responsive>.table-bordered>tfoot>tr>th:first-child,.table-responsive>.table-bordered>thead>tr>td:first-child,.table-responsive>.table-bordered>thead>tr>th:first-child{border-left:0}.table-responsive>.table-bordered>tbody>tr>td:last-child,.table-responsive>.table-bordered>tbody>tr>th:last-child,.table-responsive>.table-bordered>tfoot>tr>td:last-child,.table-responsive>.table-bordered>tfoot>tr>th:last-child,.table-responsive>.table-bordered>thead>tr>td:last-child,.table-responsive>.table-bordered>thead>tr>th:last-child{border-right:0}.table-responsive>.table-bordered>tbody>tr:last-child>td,.table-responsive>.table-bordered>tbody>tr:last-child>th,.table-responsive>.table-bordered>tfoot>tr:last-child>td,.table-responsive>.table-bordered>tfoot>tr:last-child>th{border-bottom:0}}fieldset,legend{padding:0;border:0}fieldset{margin:0;min-width:0}legend{display:block;width:100%;margin-bottom:20px;font-size:21px;line-height:inherit;border-bottom:1px solid #e5e5e5}label{display:inline-block;margin-bottom:5px}input[type=search]{-webkit-box-sizing:border-box;box-sizing:border-box;-webkit-appearance:none}input[type=checkbox],input[type=radio]{margin:4px 0 0;margin-top:1px\\9;line-height:normal}input[type=file]{display:block}input[type=range]{display:block;width:100%}select[multiple],select[size]{height:auto}input[type=checkbox]:focus,input[type=radio]:focus,input[type=file]:focus{outline:dotted thin;outline:-webkit-focus-ring-color auto 5px;outline-offset:-2px}output{display:block;padding-top:7px;font-size:14px;line-height:1.428571429;color:#555}.comment-form input[type=text],.comment-form input[type=email],.comment-form input[type=url],.comment-form textarea,.form-control{display:block;width:100%;height:34px;padding:6px 12px;font-size:14px;line-height:1.428571429;color:#555;background-color:#fff;background-image:none;border:1px solid #ccc;border-radius:4px;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075);box-shadow:inset 0 1px 1px rgba(0,0,0,.075);-webkit-transition:border-color ease-in-out .15s,-webkit-box-shadow ease-in-out .15s;-o-transition:border-color ease-in-out .15s,box-shadow ease-in-out .15s;transition:border-color ease-in-out .15s,box-shadow ease-in-out .15s}.comment-form input[type=text]:focus,.comment-form input[type=email]:focus,.comment-form input[type=url]:focus,.comment-form textarea:focus,.form-control:focus{border-color:#66afe9;outline:0;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 8px rgba(102,175,233,.6);box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 8px rgba(102,175,233,.6)}.comment-form input[type=text]::-moz-placeholder,.comment-form input[type=email]::-moz-placeholder,.comment-form input[type=url]::-moz-placeholder,.comment-form textarea::-moz-placeholder,.form-control::-moz-placeholder{color:#999;opacity:1}.comment-form input[type=text]:-ms-input-placeholder,.comment-form input[type=email]:-ms-input-placeholder,.comment-form input[type=url]:-ms-input-placeholder,.comment-form textarea:-ms-input-placeholder,.form-control:-ms-input-placeholder{color:#999}.comment-form input[type=text]::-webkit-input-placeholder,.comment-form input[type=email]::-webkit-input-placeholder,.comment-form input[type=url]::-webkit-input-placeholder,.comment-form textarea::-webkit-input-placeholder,.form-control::-webkit-input-placeholder{color:#999}.has-success .checkbox,.has-success .checkbox-inline,.has-success .control-label,.has-success .form-control-feedback,.has-success .help-block,.has-success .radio,.has-success .radio-inline,.has-success.checkbox label,.has-success.checkbox-inline label,.has-success.radio label,.has-success.radio-inline label{color:#3c763d}.comment-form fieldset[disabled] input[type=text],.comment-form fieldset[disabled] input[type=email],.comment-form fieldset[disabled] input[type=url],.comment-form fieldset[disabled] textarea,.comment-form input[disabled][type=text],.comment-form input[disabled][type=email],.comment-form input[disabled][type=url],.comment-form input[readonly][type=text],.comment-form input[readonly][type=email],.comment-form input[readonly][type=url],.comment-form textarea[disabled],.comment-form textarea[readonly],.form-control[disabled],.form-control[readonly],fieldset[disabled] .comment-form input[type=text],fieldset[disabled] .comment-form input[type=email],fieldset[disabled] .comment-form input[type=url],fieldset[disabled] .comment-form textarea,fieldset[disabled] .form-control{background-color:#eee;opacity:1}.comment-form fieldset[disabled] input[type=text],.comment-form fieldset[disabled] input[type=email],.comment-form fieldset[disabled] input[type=url],.comment-form fieldset[disabled] textarea,.comment-form input[disabled][type=text],.comment-form input[disabled][type=email],.comment-form input[disabled][type=url],.comment-form textarea[disabled],.form-control[disabled],fieldset[disabled] .comment-form input[type=text],fieldset[disabled] .comment-form input[type=email],fieldset[disabled] .comment-form input[type=url],fieldset[disabled] .comment-form textarea,fieldset[disabled] .form-control{cursor:false}.comment-form textarea,textarea.form-control{height:auto}@media screen and (-webkit-min-device-pixel-ratio:0){input[type=date],input[type=time],input[type=datetime-local],input[type=month]{line-height:34px}.comment-form .input-group-sm>.input-group-btn>input[type=date][type=submit],.comment-form .input-group-sm>.input-group-btn>input[type=time][type=submit],.comment-form .input-group-sm>.input-group-btn>input[type=datetime-local][type=submit],.comment-form .input-group-sm>.input-group-btn>input[type=month][type=submit],.comment-form .input-group-sm>input[type=date][type=text],.comment-form .input-group-sm>input[type=date][type=email],.comment-form .input-group-sm>input[type=date][type=url],.comment-form .input-group-sm>input[type=time][type=text],.comment-form .input-group-sm>input[type=time][type=email],.comment-form .input-group-sm>input[type=time][type=url],.comment-form .input-group-sm>input[type=datetime-local][type=text],.comment-form .input-group-sm>input[type=datetime-local][type=email],.comment-form .input-group-sm>input[type=datetime-local][type=url],.comment-form .input-group-sm>input[type=month][type=text],.comment-form .input-group-sm>input[type=month][type=email],.comment-form .input-group-sm>input[type=month][type=url],.input-group-sm input[type=date],.input-group-sm input[type=time],.input-group-sm input[type=datetime-local],.input-group-sm input[type=month],.input-group-sm>.input-group-btn>input[type=date].btn,.input-group-sm>.input-group-btn>input[type=time].btn,.input-group-sm>.input-group-btn>input[type=datetime-local].btn,.input-group-sm>.input-group-btn>input[type=month].btn,.input-group-sm>input[type=date].form-control,.input-group-sm>input[type=date].input-group-addon,.input-group-sm>input[type=time].form-control,.input-group-sm>input[type=time].input-group-addon,.input-group-sm>input[type=datetime-local].form-control,.input-group-sm>input[type=datetime-local].input-group-addon,.input-group-sm>input[type=month].form-control,.input-group-sm>input[type=month].input-group-addon,input[type=date].input-sm,input[type=time].input-sm,input[type=datetime-local].input-sm,input[type=month].input-sm{line-height:30px}.comment-form .input-group-lg>.input-group-btn>input[type=date][type=submit],.comment-form .input-group-lg>.input-group-btn>input[type=time][type=submit],.comment-form .input-group-lg>.input-group-btn>input[type=datetime-local][type=submit],.comment-form .input-group-lg>.input-group-btn>input[type=month][type=submit],.comment-form .input-group-lg>input[type=date][type=text],.comment-form .input-group-lg>input[type=date][type=email],.comment-form .input-group-lg>input[type=date][type=url],.comment-form .input-group-lg>input[type=time][type=text],.comment-form .input-group-lg>input[type=time][type=email],.comment-form .input-group-lg>input[type=time][type=url],.comment-form .input-group-lg>input[type=datetime-local][type=text],.comment-form .input-group-lg>input[type=datetime-local][type=email],.comment-form .input-group-lg>input[type=datetime-local][type=url],.comment-form .input-group-lg>input[type=month][type=text],.comment-form .input-group-lg>input[type=month][type=email],.comment-form .input-group-lg>input[type=month][type=url],.input-group-lg input[type=date],.input-group-lg input[type=time],.input-group-lg input[type=datetime-local],.input-group-lg input[type=month],.input-group-lg>.input-group-btn>input[type=date].btn,.input-group-lg>.input-group-btn>input[type=time].btn,.input-group-lg>.input-group-btn>input[type=datetime-local].btn,.input-group-lg>.input-group-btn>input[type=month].btn,.input-group-lg>input[type=date].form-control,.input-group-lg>input[type=date].input-group-addon,.input-group-lg>input[type=time].form-control,.input-group-lg>input[type=time].input-group-addon,.input-group-lg>input[type=datetime-local].form-control,.input-group-lg>input[type=datetime-local].input-group-addon,.input-group-lg>input[type=month].form-control,.input-group-lg>input[type=month].input-group-addon,input[type=date].input-lg,input[type=time].input-lg,input[type=datetime-local].input-lg,input[type=month].input-lg{line-height:46px}}.comment-form p,.form-group{margin-bottom:15px}.checkbox,.radio{position:relative;display:block;margin-top:10px;margin-bottom:10px}.checkbox label,.radio label{min-height:20px;padding-left:20px;margin-bottom:0;font-weight:400;cursor:pointer}.checkbox input[type=checkbox],.checkbox-inline input[type=checkbox],.radio input[type=radio],.radio-inline input[type=radio]{position:absolute;margin-left:-20px;margin-top:4px\\9}.checkbox+.checkbox,.radio+.radio{margin-top:-5px}.checkbox-inline,.radio-inline{position:relative;display:inline-block;padding-left:20px;margin-bottom:0;vertical-align:middle;font-weight:400;cursor:pointer}.checkbox-inline+.checkbox-inline,.radio-inline+.radio-inline{margin-top:0;margin-left:10px}.checkbox-inline.disabled,.checkbox.disabled label,.radio-inline.disabled,.radio.disabled label,fieldset[disabled] .checkbox label,fieldset[disabled] .checkbox-inline,fieldset[disabled] .radio label,fieldset[disabled] .radio-inline,fieldset[disabled] input[type=checkbox],fieldset[disabled] input[type=radio],input[type=checkbox].disabled,input[type=checkbox][disabled],input[type=radio].disabled,input[type=radio][disabled]{cursor:false}.form-control-static{padding-top:7px;padding-bottom:7px;margin-bottom:0;min-height:34px}.comment-form .input-group-lg>.input-group-btn>input.form-control-static[type=submit],.comment-form .input-group-lg>input.form-control-static[type=text],.comment-form .input-group-lg>input.form-control-static[type=email],.comment-form .input-group-lg>input.form-control-static[type=url],.comment-form .input-group-lg>textarea.form-control-static,.comment-form .input-group-sm>.input-group-btn>input.form-control-static[type=submit],.comment-form .input-group-sm>input.form-control-static[type=text],.comment-form .input-group-sm>input.form-control-static[type=email],.comment-form .input-group-sm>input.form-control-static[type=url],.comment-form .input-group-sm>textarea.form-control-static,.form-control-static.input-lg,.form-control-static.input-sm,.input-group-lg>.form-control-static.form-control,.input-group-lg>.form-control-static.input-group-addon,.input-group-lg>.input-group-btn>.form-control-static.btn,.input-group-sm>.form-control-static.form-control,.input-group-sm>.form-control-static.input-group-addon,.input-group-sm>.input-group-btn>.form-control-static.btn{padding-left:0;padding-right:0}.comment-form .input-group-sm>.input-group-btn>input[type=submit],.comment-form .input-group-sm>input[type=text],.comment-form .input-group-sm>input[type=email],.comment-form .input-group-sm>input[type=url],.comment-form .input-group-sm>textarea,.input-group-sm>.form-control,.input-group-sm>.input-group-addon,.input-group-sm>.input-group-btn>.btn,.input-sm{height:30px;padding:5px 10px;font-size:12px;line-height:1.5;border-radius:3px}.input-group-sm>.input-group-btn>select.btn,.input-group-sm>select.form-control,.input-group-sm>select.input-group-addon,select.input-sm{height:30px;line-height:30px}.comment-form .input-group-sm>textarea,.input-group-sm>.input-group-btn>select[multiple].btn,.input-group-sm>.input-group-btn>textarea.btn,.input-group-sm>select[multiple].form-control,.input-group-sm>select[multiple].input-group-addon,.input-group-sm>textarea.form-control,.input-group-sm>textarea.input-group-addon,select[multiple].input-sm,textarea.input-sm{height:auto}.comment-form .form-group-sm input[type=text],.comment-form .form-group-sm input[type=email],.comment-form .form-group-sm input[type=url],.comment-form .form-group-sm textarea,.form-group-sm .comment-form input[type=text],.form-group-sm .comment-form input[type=email],.form-group-sm .comment-form input[type=url],.form-group-sm .comment-form textarea,.form-group-sm .form-control{height:30px;padding:5px 10px;font-size:12px;line-height:1.5;border-radius:3px}.form-group-sm select.form-control{height:30px;line-height:30px}.comment-form .form-group-sm textarea,.form-group-sm .comment-form textarea,.form-group-sm select[multiple].form-control,.form-group-sm textarea.form-control{height:auto}.form-group-sm .form-control-static{height:30px;padding:5px 10px;font-size:12px;line-height:1.5;min-height:32px}.comment-form .input-group-lg>.input-group-btn>input[type=submit],.comment-form .input-group-lg>input[type=text],.comment-form .input-group-lg>input[type=email],.comment-form .input-group-lg>input[type=url],.comment-form .input-group-lg>textarea,.input-group-lg>.form-control,.input-group-lg>.input-group-addon,.input-group-lg>.input-group-btn>.btn,.input-lg{height:46px;padding:10px 16px;font-size:18px;line-height:1.3333333;border-radius:6px}.input-group-lg>.input-group-btn>select.btn,.input-group-lg>select.form-control,.input-group-lg>select.input-group-addon,select.input-lg{height:46px;line-height:46px}.comment-form .input-group-lg>textarea,.input-group-lg>.input-group-btn>select[multiple].btn,.input-group-lg>.input-group-btn>textarea.btn,.input-group-lg>select[multiple].form-control,.input-group-lg>select[multiple].input-group-addon,.input-group-lg>textarea.form-control,.input-group-lg>textarea.input-group-addon,select[multiple].input-lg,textarea.input-lg{height:auto}.comment-form .form-group-lg input[type=text],.comment-form .form-group-lg input[type=email],.comment-form .form-group-lg input[type=url],.comment-form .form-group-lg textarea,.form-group-lg .comment-form input[type=text],.form-group-lg .comment-form input[type=email],.form-group-lg .comment-form input[type=url],.form-group-lg .comment-form textarea,.form-group-lg .form-control{height:46px;padding:10px 16px;font-size:18px;line-height:1.3333333;border-radius:6px}.form-group-lg select.form-control{height:46px;line-height:46px}.comment-form .form-group-lg textarea,.form-group-lg .comment-form textarea,.form-group-lg select[multiple].form-control,.form-group-lg textarea.form-control{height:auto}.form-group-lg .form-control-static{height:46px;padding:10px 16px;font-size:18px;line-height:1.3333333;min-height:38px}.has-feedback{position:relative}.comment-form .has-feedback input[type=text],.comment-form .has-feedback input[type=email],.comment-form .has-feedback input[type=url],.comment-form .has-feedback textarea,.has-feedback .comment-form input[type=text],.has-feedback .comment-form input[type=email],.has-feedback .comment-form input[type=url],.has-feedback .comment-form textarea,.has-feedback .form-control{padding-right:42.5px}.form-control-feedback{position:absolute;top:0;right:0;z-index:2;display:block;width:34px;height:34px;line-height:34px;text-align:center;pointer-events:none}.collapsing,.dropdown,.dropup{position:relative}.comment-form .input-group-lg>.input-group-btn>input[type=submit]+.form-control-feedback,.comment-form .input-group-lg>input[type=text]+.form-control-feedback,.comment-form .input-group-lg>input[type=email]+.form-control-feedback,.comment-form .input-group-lg>input[type=url]+.form-control-feedback,.comment-form .input-group-lg>textarea+.form-control-feedback,.input-group-lg>.form-control+.form-control-feedback,.input-group-lg>.input-group-addon+.form-control-feedback,.input-group-lg>.input-group-btn>.btn+.form-control-feedback,.input-lg+.form-control-feedback{width:46px;height:46px;line-height:46px}.comment-form .input-group-sm>.input-group-btn>input[type=submit]+.form-control-feedback,.comment-form .input-group-sm>input[type=text]+.form-control-feedback,.comment-form .input-group-sm>input[type=email]+.form-control-feedback,.comment-form .input-group-sm>input[type=url]+.form-control-feedback,.comment-form .input-group-sm>textarea+.form-control-feedback,.input-group-sm>.form-control+.form-control-feedback,.input-group-sm>.input-group-addon+.form-control-feedback,.input-group-sm>.input-group-btn>.btn+.form-control-feedback,.input-sm+.form-control-feedback{width:30px;height:30px;line-height:30px}.comment-form .has-success input[type=text],.comment-form .has-success input[type=email],.comment-form .has-success input[type=url],.comment-form .has-success textarea,.has-success .comment-form input[type=text],.has-success .comment-form input[type=email],.has-success .comment-form input[type=url],.has-success .comment-form textarea,.has-success .form-control{border-color:#3c763d;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075);box-shadow:inset 0 1px 1px rgba(0,0,0,.075)}.comment-form .has-success input[type=text]:focus,.comment-form .has-success input[type=email]:focus,.comment-form .has-success input[type=url]:focus,.comment-form .has-success textarea:focus,.has-success .comment-form input[type=text]:focus,.has-success .comment-form input[type=email]:focus,.has-success .comment-form input[type=url]:focus,.has-success .comment-form textarea:focus,.has-success .form-control:focus{border-color:#2b542c;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #67b168;box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #67b168}.has-success .input-group-addon{color:#3c763d;border-color:#3c763d;background-color:#dff0d8}.has-warning .checkbox,.has-warning .checkbox-inline,.has-warning .control-label,.has-warning .form-control-feedback,.has-warning .help-block,.has-warning .radio,.has-warning .radio-inline,.has-warning.checkbox label,.has-warning.checkbox-inline label,.has-warning.radio label,.has-warning.radio-inline label{color:#8a6d3b}.comment-form .has-warning input[type=text],.comment-form .has-warning input[type=email],.comment-form .has-warning input[type=url],.comment-form .has-warning textarea,.has-warning .comment-form input[type=text],.has-warning .comment-form input[type=email],.has-warning .comment-form input[type=url],.has-warning .comment-form textarea,.has-warning .form-control{border-color:#8a6d3b;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075);box-shadow:inset 0 1px 1px rgba(0,0,0,.075)}.comment-form .has-warning input[type=text]:focus,.comment-form .has-warning input[type=email]:focus,.comment-form .has-warning input[type=url]:focus,.comment-form .has-warning textarea:focus,.has-warning .comment-form input[type=text]:focus,.has-warning .comment-form input[type=email]:focus,.has-warning .comment-form input[type=url]:focus,.has-warning .comment-form textarea:focus,.has-warning .form-control:focus{border-color:#66512c;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #c0a16b;box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #c0a16b}.has-warning .input-group-addon{color:#8a6d3b;border-color:#8a6d3b;background-color:#fcf8e3}.has-error .checkbox,.has-error .checkbox-inline,.has-error .control-label,.has-error .form-control-feedback,.has-error .help-block,.has-error .radio,.has-error .radio-inline,.has-error.checkbox label,.has-error.checkbox-inline label,.has-error.radio label,.has-error.radio-inline label{color:#a94442}.comment-form .has-error input[type=text],.comment-form .has-error input[type=email],.comment-form .has-error input[type=url],.comment-form .has-error textarea,.has-error .comment-form input[type=text],.has-error .comment-form input[type=email],.has-error .comment-form input[type=url],.has-error .comment-form textarea,.has-error .form-control{border-color:#a94442;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075);box-shadow:inset 0 1px 1px rgba(0,0,0,.075)}.comment-form .has-error input[type=text]:focus,.comment-form .has-error input[type=email]:focus,.comment-form .has-error input[type=url]:focus,.comment-form .has-error textarea:focus,.has-error .comment-form input[type=text]:focus,.has-error .comment-form input[type=email]:focus,.has-error .comment-form input[type=url]:focus,.has-error .comment-form textarea:focus,.has-error .form-control:focus{border-color:#843534;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #ce8483;box-shadow:inset 0 1px 1px rgba(0,0,0,.075),0 0 6px #ce8483}.has-error .input-group-addon{color:#a94442;border-color:#a94442;background-color:#f2dede}.has-feedback label~.form-control-feedback{top:25px}.has-feedback label.screen-reader-text~.form-control-feedback,.has-feedback label.sr-only~.form-control-feedback{top:0}.help-block{display:block;margin-top:5px;margin-bottom:10px;color:#737373}@media (min-width:768px){.comment-form .form-inline p,.form-inline .comment-form p,.form-inline .form-group{display:inline-block;margin-bottom:0;vertical-align:middle}.comment-form .form-inline input[type=text],.comment-form .form-inline input[type=email],.comment-form .form-inline input[type=url],.comment-form .form-inline textarea,.form-inline .comment-form input[type=text],.form-inline .comment-form input[type=email],.form-inline .comment-form input[type=url],.form-inline .comment-form textarea,.form-inline .form-control{display:inline-block;width:auto;vertical-align:middle}.form-inline .form-control-static{display:inline-block}.form-inline .input-group{display:inline-table;vertical-align:middle}.comment-form .form-inline .input-group input[type=text],.comment-form .form-inline .input-group input[type=email],.comment-form .form-inline .input-group input[type=url],.comment-form .form-inline .input-group textarea,.form-inline .input-group .comment-form input[type=text],.form-inline .input-group .comment-form input[type=email],.form-inline .input-group .comment-form input[type=url],.form-inline .input-group .comment-form textarea,.form-inline .input-group .form-control,.form-inline .input-group .input-group-addon,.form-inline .input-group .input-group-btn{width:auto}.comment-form .form-inline .input-group>input[type=text],.comment-form .form-inline .input-group>input[type=email],.comment-form .form-inline .input-group>input[type=url],.comment-form .form-inline .input-group>textarea,.form-inline .comment-form .input-group>input[type=text],.form-inline .comment-form .input-group>input[type=email],.form-inline .comment-form .input-group>input[type=url],.form-inline .comment-form .input-group>textarea,.form-inline .input-group>.form-control{width:100%}.form-inline .control-label{margin-bottom:0;vertical-align:middle}.form-inline .checkbox,.form-inline .radio{display:inline-block;margin-top:0;margin-bottom:0;vertical-align:middle}.form-inline .checkbox label,.form-inline .radio label{padding-left:0}.form-inline .checkbox input[type=checkbox],.form-inline .radio input[type=radio]{position:relative;margin-left:0}.form-inline .has-feedback .form-control-feedback{top:0}.form-horizontal .control-label{text-align:right;margin-bottom:0;padding-top:7px}}.form-horizontal .checkbox,.form-horizontal .checkbox-inline,.form-horizontal .radio,.form-horizontal .radio-inline{margin-top:0;margin-bottom:0;padding-top:7px}.form-horizontal .checkbox,.form-horizontal .radio{min-height:27px}.comment-form .form-horizontal p,.form-horizontal .comment-form p,.form-horizontal .form-group{margin-left:-15px;margin-right:-15px}.comment-form .form-horizontal p:after,.comment-form .form-horizontal p:before,.form-horizontal .comment-form p:after,.form-horizontal .comment-form p:before,.form-horizontal .form-group:after,.form-horizontal .form-group:before{content:\" \";display:table}.form-horizontal .has-feedback .form-control-feedback{right:15px}@media (min-width:768px){.form-horizontal .form-group-lg .control-label{padding-top:14.33px}.form-horizontal .form-group-sm .control-label{padding-top:6px}}.btn,.comment-form input[type=submit]{display:inline-block;margin-bottom:0;font-weight:400;text-align:center;vertical-align:middle;-ms-touch-action:manipulation;touch-action:manipulation;cursor:pointer;background-image:none;border:1px solid transparent;white-space:nowrap;padding:6px 12px;font-size:14px;line-height:1.428571429;border-radius:4px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.btn.active.focus,.btn.active:focus,.btn.focus,.btn:active.focus,.btn:active:focus,.btn:focus,.comment-form input.active.focus[type=submit],.comment-form input.active[type=submit]:focus,.comment-form input.focus[type=submit],.comment-form input[type=submit]:active.focus,.comment-form input[type=submit]:active:focus,.comment-form input[type=submit]:focus{outline:dotted thin;outline:-webkit-focus-ring-color auto 5px;outline-offset:-2px}.btn.focus,.btn:focus,.btn:hover,.comment-form input.focus[type=submit],.comment-form input[type=submit]:focus,.comment-form input[type=submit]:hover{color:#333;text-decoration:none}.btn.active,.btn:active,.comment-form input.active[type=submit],.comment-form input[type=submit]:active{outline:0;background-image:none;-webkit-box-shadow:inset 0 3px 5px rgba(0,0,0,.125);box-shadow:inset 0 3px 5px rgba(0,0,0,.125)}.btn.disabled,.btn[disabled],.comment-form fieldset[disabled] input[type=submit],.comment-form input.disabled[type=submit],.comment-form input[disabled][type=submit],fieldset[disabled] .btn,fieldset[disabled] .comment-form input[type=submit]{cursor:false;pointer-events:none;opacity:.65;filter:alpha(opacity=65);-webkit-box-shadow:none;box-shadow:none}.btn-default{color:#333;background-color:#fff;border-color:#ccc}.btn-default.active,.btn-default.focus,.btn-default:active,.btn-default:focus,.btn-default:hover,.open>.btn-default.dropdown-toggle{color:#333;background-color:#e6e6e6;border-color:#adadad}.btn-default.active,.btn-default:active,.open>.btn-default.dropdown-toggle{background-image:none}.btn-default.disabled,.btn-default.disabled.active,.btn-default.disabled.focus,.btn-default.disabled:active,.btn-default.disabled:focus,.btn-default.disabled:hover,.btn-default[disabled],.btn-default[disabled].active,.btn-default[disabled].focus,.btn-default[disabled]:active,.btn-default[disabled]:focus,.btn-default[disabled]:hover,fieldset[disabled] .btn-default,fieldset[disabled] .btn-default.active,fieldset[disabled] .btn-default.focus,fieldset[disabled] .btn-default:active,fieldset[disabled] .btn-default:focus,fieldset[disabled] .btn-default:hover{background-color:#fff;border-color:#ccc}.btn-default .badge{color:#fff;background-color:#333}.btn-primary,.comment-form input[type=submit]{color:#fff;background-color:#bd1c2b;border-color:#a71926}.btn-primary.active,.btn-primary.focus,.btn-primary:active,.btn-primary:focus,.btn-primary:hover,.comment-form .open>input.dropdown-toggle[type=submit],.comment-form input.active[type=submit],.comment-form input.focus[type=submit],.comment-form input[type=submit]:active,.comment-form input[type=submit]:focus,.comment-form input[type=submit]:hover,.open>.btn-primary.dropdown-toggle{color:#fff;background-color:#911521;border-color:#71111a}.btn-primary.active,.btn-primary:active,.comment-form .open>input.dropdown-toggle[type=submit],.comment-form input.active[type=submit],.comment-form input[type=submit]:active,.open>.btn-primary.dropdown-toggle{background-image:none}.btn-primary.disabled,.btn-primary.disabled.active,.btn-primary.disabled.focus,.btn-primary.disabled:active,.btn-primary.disabled:focus,.btn-primary.disabled:hover,.btn-primary[disabled],.btn-primary[disabled].active,.btn-primary[disabled].focus,.btn-primary[disabled]:active,.btn-primary[disabled]:focus,.btn-primary[disabled]:hover,.comment-form fieldset[disabled] input.active[type=submit],.comment-form fieldset[disabled] input.focus[type=submit],.comment-form fieldset[disabled] input[type=submit],.comment-form fieldset[disabled] input[type=submit]:active,.comment-form fieldset[disabled] input[type=submit]:focus,.comment-form fieldset[disabled] input[type=submit]:hover,.comment-form input.disabled.active[type=submit],.comment-form input.disabled.focus[type=submit],.comment-form input.disabled[type=submit],.comment-form input.disabled[type=submit]:active,.comment-form input.disabled[type=submit]:focus,.comment-form input.disabled[type=submit]:hover,.comment-form input[disabled].active[type=submit],.comment-form input[disabled].focus[type=submit],.comment-form input[disabled][type=submit],.comment-form input[disabled][type=submit]:active,.comment-form input[disabled][type=submit]:focus,.comment-form input[disabled][type=submit]:hover,fieldset[disabled] .btn-primary,fieldset[disabled] .btn-primary.active,fieldset[disabled] .btn-primary.focus,fieldset[disabled] .btn-primary:active,fieldset[disabled] .btn-primary:focus,fieldset[disabled] .btn-primary:hover,fieldset[disabled] .comment-form input.active[type=submit],fieldset[disabled] .comment-form input.focus[type=submit],fieldset[disabled] .comment-form input[type=submit],fieldset[disabled] .comment-form input[type=submit]:active,fieldset[disabled] .comment-form input[type=submit]:focus,fieldset[disabled] .comment-form input[type=submit]:hover{background-color:#bd1c2b;border-color:#a71926}.btn-primary .badge,.comment-form input[type=submit] .badge{color:#bd1c2b;background-color:#fff}.btn-success{color:#fff;background-color:#5cb85c;border-color:#4cae4c}.btn-success.active,.btn-success.focus,.btn-success:active,.btn-success:focus,.btn-success:hover,.open>.btn-success.dropdown-toggle{color:#fff;background-color:#449d44;border-color:#398439}.btn-success.active,.btn-success:active,.open>.btn-success.dropdown-toggle{background-image:none}.btn-success.disabled,.btn-success.disabled.active,.btn-success.disabled.focus,.btn-success.disabled:active,.btn-success.disabled:focus,.btn-success.disabled:hover,.btn-success[disabled],.btn-success[disabled].active,.btn-success[disabled].focus,.btn-success[disabled]:active,.btn-success[disabled]:focus,.btn-success[disabled]:hover,fieldset[disabled] .btn-success,fieldset[disabled] .btn-success.active,fieldset[disabled] .btn-success.focus,fieldset[disabled] .btn-success:active,fieldset[disabled] .btn-success:focus,fieldset[disabled] .btn-success:hover{background-color:#5cb85c;border-color:#4cae4c}.btn-success .badge{color:#5cb85c;background-color:#fff}.btn-info{color:#fff;background-color:#5bc0de;border-color:#46b8da}.btn-info.active,.btn-info.focus,.btn-info:active,.btn-info:focus,.btn-info:hover,.open>.btn-info.dropdown-toggle{color:#fff;background-color:#31b0d5;border-color:#269abc}.btn-info.active,.btn-info:active,.open>.btn-info.dropdown-toggle{background-image:none}.btn-info.disabled,.btn-info.disabled.active,.btn-info.disabled.focus,.btn-info.disabled:active,.btn-info.disabled:focus,.btn-info.disabled:hover,.btn-info[disabled],.btn-info[disabled].active,.btn-info[disabled].focus,.btn-info[disabled]:active,.btn-info[disabled]:focus,.btn-info[disabled]:hover,fieldset[disabled] .btn-info,fieldset[disabled] .btn-info.active,fieldset[disabled] .btn-info.focus,fieldset[disabled] .btn-info:active,fieldset[disabled] .btn-info:focus,fieldset[disabled] .btn-info:hover{background-color:#5bc0de;border-color:#46b8da}.btn-info .badge{color:#5bc0de;background-color:#fff}.btn-warning{color:#fff;background-color:#f0ad4e;border-color:#eea236}.btn-warning.active,.btn-warning.focus,.btn-warning:active,.btn-warning:focus,.btn-warning:hover,.open>.btn-warning.dropdown-toggle{color:#fff;background-color:#ec971f;border-color:#d58512}.btn-warning.active,.btn-warning:active,.open>.btn-warning.dropdown-toggle{background-image:none}.btn-warning.disabled,.btn-warning.disabled.active,.btn-warning.disabled.focus,.btn-warning.disabled:active,.btn-warning.disabled:focus,.btn-warning.disabled:hover,.btn-warning[disabled],.btn-warning[disabled].active,.btn-warning[disabled].focus,.btn-warning[disabled]:active,.btn-warning[disabled]:focus,.btn-warning[disabled]:hover,fieldset[disabled] .btn-warning,fieldset[disabled] .btn-warning.active,fieldset[disabled] .btn-warning.focus,fieldset[disabled] .btn-warning:active,fieldset[disabled] .btn-warning:focus,fieldset[disabled] .btn-warning:hover{background-color:#f0ad4e;border-color:#eea236}.btn-warning .badge{color:#f0ad4e;background-color:#fff}.btn-danger{color:#fff;background-color:#d9534f;border-color:#d43f3a}.btn-danger.active,.btn-danger.focus,.btn-danger:active,.btn-danger:focus,.btn-danger:hover,.open>.btn-danger.dropdown-toggle{color:#fff;background-color:#c9302c;border-color:#ac2925}.btn-danger.active,.btn-danger:active,.open>.btn-danger.dropdown-toggle{background-image:none}.btn-danger.disabled,.btn-danger.disabled.active,.btn-danger.disabled.focus,.btn-danger.disabled:active,.btn-danger.disabled:focus,.btn-danger.disabled:hover,.btn-danger[disabled],.btn-danger[disabled].active,.btn-danger[disabled].focus,.btn-danger[disabled]:active,.btn-danger[disabled]:focus,.btn-danger[disabled]:hover,fieldset[disabled] .btn-danger,fieldset[disabled] .btn-danger.active,fieldset[disabled] .btn-danger.focus,fieldset[disabled] .btn-danger:active,fieldset[disabled] .btn-danger:focus,fieldset[disabled] .btn-danger:hover{background-color:#d9534f;border-color:#d43f3a}.btn-danger .badge{color:#d9534f;background-color:#fff}.btn-link{color:#bd1c2b;font-weight:400;border-radius:0}.btn-link,.btn-link.active,.btn-link:active,.btn-link[disabled],fieldset[disabled] .btn-link{background-color:transparent;-webkit-box-shadow:none;box-shadow:none}.btn-link,.btn-link:active,.btn-link:focus,.btn-link:hover{border-color:transparent}.btn-link:focus,.btn-link:hover{color:#7a121c;text-decoration:underline;background-color:transparent}.btn-link[disabled]:focus,.btn-link[disabled]:hover,fieldset[disabled] .btn-link:focus,fieldset[disabled] .btn-link:hover{color:#777;text-decoration:none}.btn-group-lg>.btn,.btn-lg,.comment-form .btn-group-lg>input[type=submit]{padding:10px 16px;font-size:18px;line-height:1.3333333;border-radius:6px}.btn-group-sm>.btn,.btn-sm,.comment-form .btn-group-sm>input[type=submit]{padding:5px 10px;font-size:12px;line-height:1.5;border-radius:3px}.btn-group-xs>.btn,.btn-xs,.comment-form .btn-group-xs>input[type=submit]{padding:1px 5px;font-size:12px;line-height:1.5;border-radius:3px}.btn-block{display:block;width:100%}.btn-block+.btn-block{margin-top:5px}input[type=submit].btn-block,input[type=button].btn-block,input[type=reset].btn-block{width:100%}.fade{opacity:0;-webkit-transition:opacity .15s linear;-o-transition:opacity .15s linear;transition:opacity .15s linear}.fade.in{opacity:1}.collapse{display:none}.collapse.in{display:block}tr.collapse.in{display:table-row}tbody.collapse.in{display:table-row-group}.collapsing{height:0;overflow:hidden;-webkit-transition-property:height,visibility;-o-transition-property:height,visibility;transition-property:height,visibility;-webkit-transition-duration:.35s;-o-transition-duration:.35s;transition-duration:.35s;-webkit-transition-timing-function:ease;-o-transition-timing-function:ease;transition-timing-function:ease}.caret{display:inline-block;width:0;height:0;margin-left:2px;vertical-align:middle;border-top:4px dashed;border-right:4px solid transparent;border-left:4px solid transparent}.dropdown-toggle:focus{outline:0}.dropdown-menu{position:absolute;top:100%;left:0;z-index:1000;display:none;min-width:160px;padding:5px 0;margin:2px 0 0;list-style:none;font-size:14px;text-align:left;background-color:#fff;border:1px solid #ccc;border:1px solid rgba(0,0,0,.15);border-radius:4px;-webkit-box-shadow:0 6px 12px rgba(0,0,0,.175);box-shadow:0 6px 12px rgba(0,0,0,.175);-webkit-background-clip:padding-box;background-clip:padding-box}.dropdown-menu-right,.dropdown-menu.pull-right{left:auto;right:0}.dropdown-header,.dropdown-menu>li>a{display:block;padding:3px 20px;line-height:1.428571429;white-space:nowrap}.btn-group-vertical>.btn:not(:first-child):not(:last-child),.btn-group>.btn-group:not(:first-child):not(:last-child)>.btn,.btn-group>.btn:not(:first-child):not(:last-child):not(.dropdown-toggle),.comment-form .btn-group-vertical>input[type=submit]:not(:first-child):not(:last-child),.comment-form .btn-group>.btn-group:not(:first-child):not(:last-child)>input[type=submit],.comment-form .btn-group>input[type=submit]:not(:first-child):not(:last-child):not(.dropdown-toggle){border-radius:0}.dropdown-menu .divider{height:1px;margin:9px 0;overflow:hidden;background-color:#e5e5e5}.dropdown-menu>li>a{font-weight:400;color:#333}.dropdown-menu>li>a:focus,.dropdown-menu>li>a:hover{text-decoration:none;color:#262626;background-color:#f5f5f5}.dropdown-menu>.active>a,.dropdown-menu>.active>a:focus,.dropdown-menu>.active>a:hover{color:#fff;text-decoration:none;outline:0;background-color:#bd1c2b}.dropdown-menu>.disabled>a,.dropdown-menu>.disabled>a:focus,.dropdown-menu>.disabled>a:hover{color:#777}.dropdown-menu>.disabled>a:focus,.dropdown-menu>.disabled>a:hover{text-decoration:none;background-color:transparent;background-image:none;filter:progid:DXImageTransform.Microsoft.gradient(enabled=false);cursor:false}.open>.dropdown-menu{display:block}.open>a{outline:0}.dropdown-menu-left{left:0;right:auto}.dropdown-header{font-size:12px;color:#777}.dropdown-backdrop{position:fixed;left:0;right:0;bottom:0;top:0;z-index:990}.pull-right>.dropdown-menu{right:0;left:auto}.dropup .caret,.navbar-fixed-bottom .dropdown .caret{border-top:0;border-bottom:4px solid;content:\"\"}.dropup .dropdown-menu,.navbar-fixed-bottom .dropdown .dropdown-menu{top:auto;bottom:100%;margin-bottom:2px}@media (min-width:768px){.navbar-right .dropdown-menu{right:0;left:auto}.navbar-right .dropdown-menu-left{left:0;right:auto}}.btn-group,.btn-group-vertical{position:relative;display:inline-block;vertical-align:middle}.btn-group-vertical>.btn,.btn-group>.btn,.comment-form .btn-group-vertical>input[type=submit],.comment-form .btn-group>input[type=submit]{position:relative;float:left}.btn-group-vertical>.btn.active,.btn-group-vertical>.btn:active,.btn-group-vertical>.btn:focus,.btn-group-vertical>.btn:hover,.btn-group>.btn.active,.btn-group>.btn:active,.btn-group>.btn:focus,.btn-group>.btn:hover,.comment-form .btn-group-vertical>input.active[type=submit],.comment-form .btn-group-vertical>input[type=submit]:active,.comment-form .btn-group-vertical>input[type=submit]:focus,.comment-form .btn-group-vertical>input[type=submit]:hover,.comment-form .btn-group>input.active[type=submit],.comment-form .btn-group>input[type=submit]:active,.comment-form .btn-group>input[type=submit]:focus,.comment-form .btn-group>input[type=submit]:hover{z-index:2}.btn-group .btn+.btn,.btn-group .btn+.btn-group,.btn-group .btn-group+.btn,.btn-group .btn-group+.btn-group,.btn-group .comment-form .btn+input[type=submit],.btn-group .comment-form .btn-group+input[type=submit],.btn-group .comment-form input[type=submit]+.btn,.btn-group .comment-form input[type=submit]+.btn-group,.btn-group .comment-form input[type=submit]+input[type=submit],.comment-form .btn-group .btn+input[type=submit],.comment-form .btn-group .btn-group+input[type=submit],.comment-form .btn-group input[type=submit]+.btn,.comment-form .btn-group input[type=submit]+.btn-group,.comment-form .btn-group input[type=submit]+input[type=submit]{margin-left:-1px}.btn-toolbar{margin-left:-5px}.btn-toolbar:after,.btn-toolbar:before{content:\" \";display:table}.btn-toolbar>.btn,.btn-toolbar>.btn-group,.btn-toolbar>.input-group,.comment-form .btn-toolbar>input[type=submit]{margin-left:5px}.btn .caret,.btn-group>.btn:first-child,.comment-form .btn-group>input[type=submit]:first-child,.comment-form input[type=submit] .caret{margin-left:0}.btn-group>.btn:first-child:not(:last-child):not(.dropdown-toggle),.comment-form .btn-group>input[type=submit]:first-child:not(:last-child):not(.dropdown-toggle){border-bottom-right-radius:0;border-top-right-radius:0}.btn-group>.btn:last-child:not(:first-child),.btn-group>.dropdown-toggle:not(:first-child),.comment-form .btn-group>input[type=submit]:last-child:not(:first-child){border-bottom-left-radius:0;border-top-left-radius:0}.btn-group>.btn-group:first-child:not(:last-child)>.btn:last-child,.btn-group>.btn-group:first-child:not(:last-child)>.dropdown-toggle,.comment-form .btn-group>.btn-group:first-child:not(:last-child)>input[type=submit]:last-child{border-bottom-right-radius:0;border-top-right-radius:0}.btn-group>.btn-group:last-child:not(:first-child)>.btn:first-child,.comment-form .btn-group>.btn-group:last-child:not(:first-child)>input[type=submit]:first-child{border-bottom-left-radius:0;border-top-left-radius:0}.btn-group .dropdown-toggle:active,.btn-group.open .dropdown-toggle{outline:0}.btn-group>.btn+.dropdown-toggle,.comment-form .btn-group>input[type=submit]+.dropdown-toggle{padding-left:8px;padding-right:8px}.btn-group-lg.btn-group>.btn+.dropdown-toggle,.btn-group>.btn-lg+.dropdown-toggle,.comment-form .btn-group-lg.btn-group>input[type=submit]+.dropdown-toggle{padding-left:12px;padding-right:12px}.btn-group.open .dropdown-toggle{-webkit-box-shadow:inset 0 3px 5px rgba(0,0,0,.125);box-shadow:inset 0 3px 5px rgba(0,0,0,.125)}.btn-group.open .dropdown-toggle.btn-link{-webkit-box-shadow:none;box-shadow:none}.btn-group-lg>.btn .caret,.btn-lg .caret,.comment-form .btn-group-lg>input[type=submit] .caret{border-width:5px 5px 0}.comment-form .dropup .btn-group-lg>input[type=submit] .caret,.dropup .btn-group-lg>.btn .caret,.dropup .btn-lg .caret,.dropup .comment-form .btn-group-lg>input[type=submit] .caret{border-width:0 5px 5px}.btn-group-vertical>.btn,.btn-group-vertical>.btn-group,.btn-group-vertical>.btn-group>.btn,.comment-form .btn-group-vertical>.btn-group>input[type=submit],.comment-form .btn-group-vertical>input[type=submit]{display:block;float:none;width:100%;max-width:100%}.btn-group-vertical>.btn-group:after,.btn-group-vertical>.btn-group:before{content:\" \";display:table}.btn-group-vertical>.btn-group>.btn,.comment-form .btn-group-vertical>.btn-group>input[type=submit]{float:none}.btn-group-vertical>.btn+.btn,.btn-group-vertical>.btn+.btn-group,.btn-group-vertical>.btn-group+.btn,.btn-group-vertical>.btn-group+.btn-group,.comment-form .btn-group-vertical>.btn+input[type=submit],.comment-form .btn-group-vertical>.btn-group+input[type=submit],.comment-form .btn-group-vertical>input[type=submit]+.btn,.comment-form .btn-group-vertical>input[type=submit]+.btn-group,.comment-form .btn-group-vertical>input[type=submit]+input[type=submit]{margin-top:-1px;margin-left:0}.comment-form .input-group-btn:last-child>input[type=submit],.comment-form .input-group-btn>.btn+input[type=submit],.comment-form .input-group-btn>input[type=submit]+.btn,.comment-form .input-group-btn>input[type=submit]+input[type=submit],.input-group-btn:last-child>.btn,.input-group-btn:last-child>.btn-group,.input-group-btn>.btn+.btn{margin-left:-1px}.btn-group-vertical>.btn:first-child:not(:last-child),.comment-form .btn-group-vertical>input[type=submit]:first-child:not(:last-child){border-top-right-radius:4px;border-bottom-right-radius:0;border-bottom-left-radius:0}.btn-group-vertical>.btn:last-child:not(:first-child),.comment-form .btn-group-vertical>input[type=submit]:last-child:not(:first-child){border-bottom-left-radius:4px;border-top-right-radius:0;border-top-left-radius:0}.btn-group-vertical>.btn-group:not(:first-child):not(:last-child)>.btn,.comment-form .btn-group-vertical>.btn-group:not(:first-child):not(:last-child)>input[type=submit],.comment-form .input-group input[type=text]:not(:first-child):not(:last-child),.comment-form .input-group input[type=email]:not(:first-child):not(:last-child),.comment-form .input-group input[type=url]:not(:first-child):not(:last-child),.comment-form .input-group textarea:not(:first-child):not(:last-child),.input-group .comment-form input[type=text]:not(:first-child):not(:last-child),.input-group .comment-form input[type=email]:not(:first-child):not(:last-child),.input-group .comment-form input[type=url]:not(:first-child):not(:last-child),.input-group .comment-form textarea:not(:first-child):not(:last-child),.input-group .form-control:not(:first-child):not(:last-child),.input-group-addon:not(:first-child):not(:last-child),.input-group-btn:not(:first-child):not(:last-child){border-radius:0}.btn-group-vertical>.btn-group:first-child:not(:last-child)>.btn:last-child,.btn-group-vertical>.btn-group:first-child:not(:last-child)>.dropdown-toggle,.comment-form .btn-group-vertical>.btn-group:first-child:not(:last-child)>input[type=submit]:last-child{border-bottom-right-radius:0;border-bottom-left-radius:0}.btn-group-vertical>.btn-group:last-child:not(:first-child)>.btn:first-child,.comment-form .btn-group-vertical>.btn-group:last-child:not(:first-child)>input[type=submit]:first-child{border-top-right-radius:0;border-top-left-radius:0}.btn-group-justified{display:table;width:100%;table-layout:fixed;border-collapse:separate}.btn-group-justified>.btn,.btn-group-justified>.btn-group,.comment-form .btn-group-justified>input[type=submit]{float:none;display:table-cell;width:1%}.btn-group-justified>.btn-group .btn,.btn-group-justified>.btn-group .comment-form input[type=submit],.comment-form .btn-group-justified>.btn-group input[type=submit]{width:100%}.btn-group-justified>.btn-group .dropdown-menu{left:auto}.comment-form [data-toggle=buttons]>.btn-group>input[type=submit] input[type=checkbox],.comment-form [data-toggle=buttons]>.btn-group>input[type=submit] input[type=radio],.comment-form [data-toggle=buttons]>input[type=submit] input[type=checkbox],.comment-form [data-toggle=buttons]>input[type=submit] input[type=radio],[data-toggle=buttons]>.btn input[type=checkbox],[data-toggle=buttons]>.btn input[type=radio],[data-toggle=buttons]>.btn-group>.btn input[type=checkbox],[data-toggle=buttons]>.btn-group>.btn input[type=radio]{position:absolute;clip:rect(0,0,0,0);pointer-events:none}.comment-form .input-group-btn>input[type=submit],.input-group,.input-group-btn,.input-group-btn>.btn{position:relative}.input-group{display:table;border-collapse:separate}.input-group[class*=col-]{float:none;padding-left:0;padding-right:0}.comment-form .input-group input[type=text],.comment-form .input-group input[type=email],.comment-form .input-group input[type=url],.comment-form .input-group textarea,.input-group .comment-form input[type=text],.input-group .comment-form input[type=email],.input-group .comment-form input[type=url],.input-group .comment-form textarea,.input-group .form-control{position:relative;z-index:2;float:left;width:100%;margin-bottom:0}.comment-form .input-group input[type=text],.comment-form .input-group input[type=email],.comment-form .input-group input[type=url],.comment-form .input-group textarea,.input-group .comment-form input[type=text],.input-group .comment-form input[type=email],.input-group .comment-form input[type=url],.input-group .comment-form textarea,.input-group .form-control,.input-group-addon,.input-group-btn{display:table-cell}.input-group-addon,.input-group-btn{width:1%;white-space:nowrap;vertical-align:middle}.input-group-addon{padding:6px 12px;font-size:14px;font-weight:400;line-height:1;color:#555;text-align:center;background-color:#eee;border:1px solid #ccc;border-radius:4px}.comment-form .input-group-sm>.input-group-btn>input.input-group-addon[type=submit],.comment-form .input-group-sm>input.input-group-addon[type=text],.comment-form .input-group-sm>input.input-group-addon[type=email],.comment-form .input-group-sm>input.input-group-addon[type=url],.input-group-addon.input-sm,.input-group-sm>.input-group-addon,.input-group-sm>.input-group-btn>.input-group-addon.btn{padding:5px 10px;font-size:12px;border-radius:3px}.comment-form .input-group-lg>.input-group-btn>input.input-group-addon[type=submit],.comment-form .input-group-lg>input.input-group-addon[type=text],.comment-form .input-group-lg>input.input-group-addon[type=email],.comment-form .input-group-lg>input.input-group-addon[type=url],.input-group-addon.input-lg,.input-group-lg>.input-group-addon,.input-group-lg>.input-group-btn>.input-group-addon.btn{padding:10px 16px;font-size:18px;border-radius:6px}.input-group-addon input[type=checkbox],.input-group-addon input[type=radio]{margin-top:0}.comment-form .input-group input[type=text]:first-child,.comment-form .input-group input[type=email]:first-child,.comment-form .input-group input[type=url]:first-child,.comment-form .input-group textarea:first-child,.comment-form .input-group-btn:first-child>.btn-group>input[type=submit],.comment-form .input-group-btn:first-child>input[type=submit],.comment-form .input-group-btn:last-child>.btn-group:not(:last-child)>input[type=submit],.comment-form .input-group-btn:last-child>input[type=submit]:not(:last-child):not(.dropdown-toggle),.input-group .comment-form input[type=text]:first-child,.input-group .comment-form input[type=email]:first-child,.input-group .comment-form input[type=url]:first-child,.input-group .comment-form textarea:first-child,.input-group .form-control:first-child,.input-group-addon:first-child,.input-group-btn:first-child>.btn,.input-group-btn:first-child>.btn-group>.btn,.input-group-btn:first-child>.dropdown-toggle,.input-group-btn:last-child>.btn-group:not(:last-child)>.btn,.input-group-btn:last-child>.btn:not(:last-child):not(.dropdown-toggle){border-bottom-right-radius:0;border-top-right-radius:0}.input-group-addon:first-child{border-right:0}.comment-form .input-group input[type=text]:last-child,.comment-form .input-group input[type=email]:last-child,.comment-form .input-group input[type=url]:last-child,.comment-form .input-group textarea:last-child,.comment-form .input-group-btn:first-child>.btn-group:not(:first-child)>input[type=submit],.comment-form .input-group-btn:first-child>input[type=submit]:not(:first-child),.comment-form .input-group-btn:last-child>.btn-group>input[type=submit],.comment-form .input-group-btn:last-child>input[type=submit],.input-group .comment-form input[type=text]:last-child,.input-group .comment-form input[type=email]:last-child,.input-group .comment-form input[type=url]:last-child,.input-group .comment-form textarea:last-child,.input-group .form-control:last-child,.input-group-addon:last-child,.input-group-btn:first-child>.btn-group:not(:first-child)>.btn,.input-group-btn:first-child>.btn:not(:first-child),.input-group-btn:last-child>.btn,.input-group-btn:last-child>.btn-group>.btn,.input-group-btn:last-child>.dropdown-toggle{border-bottom-left-radius:0;border-top-left-radius:0}.input-group-addon:last-child{border-left:0}.input-group-btn{font-size:0;white-space:nowrap}.comment-form .input-group-btn>input[type=submit]:active,.comment-form .input-group-btn>input[type=submit]:focus,.comment-form .input-group-btn>input[type=submit]:hover,.input-group-btn>.btn:active,.input-group-btn>.btn:focus,.input-group-btn>.btn:hover{z-index:2}.comment-form .input-group-btn:first-child>input[type=submit],.input-group-btn:first-child>.btn,.input-group-btn:first-child>.btn-group{margin-right:-1px}.nav{margin-bottom:0;padding-left:0;list-style:none}.nav:after,.nav:before{content:\" \";display:table}.nav>li,.nav>li>a{display:block;position:relative}.nav:after{clear:both}.nav>li>a{padding:10px 15px}.nav>li>a:focus,.nav>li>a:hover{background-color:#eee;text-decoration:none}.nav>li.disabled>a{color:#777}.nav>li.disabled>a:focus,.nav>li.disabled>a:hover{color:#777;text-decoration:none;background-color:transparent;cursor:false}.nav .open>a,.nav .open>a:focus,.nav .open>a:hover{background-color:#eee;border-color:#bd1c2b}.nav .nav-divider{height:1px;margin:9px 0;overflow:hidden;background-color:#e5e5e5}.nav>li>a>img{max-width:none}.nav-tabs{border-bottom:1px solid #ddd}.nav-tabs>li{float:left;margin-bottom:-1px}.nav-tabs>li>a{margin-right:2px;line-height:1.428571429;border:1px solid transparent;border-radius:4px 4px 0 0}.nav-tabs>li>a:hover{border-color:#eee #eee #ddd}.nav-tabs>li.active>a,.nav-tabs>li.active>a:focus,.nav-tabs>li.active>a:hover{color:#555;background-color:#fff;border:1px solid #ddd;border-bottom-color:transparent;cursor:default}.nav-pills>li{float:left}.nav-justified>li,.nav-stacked>li,.nav-tabs.nav-justified>li{float:none}.nav-pills>li>a{border-radius:4px}.nav-pills>li+li{margin-left:2px}.nav-pills>li.active>a,.nav-pills>li.active>a:focus,.nav-pills>li.active>a:hover{color:#fff;background-color:#bd1c2b}.nav-stacked>li+li{margin-top:2px;margin-left:0}.nav-justified,.nav-tabs.nav-justified{width:100%}.nav-justified>li>a,.nav-tabs.nav-justified>li>a{text-align:center;margin-bottom:5px}.nav-justified>.dropdown .dropdown-menu{top:auto;left:auto}.nav-tabs-justified,.nav-tabs.nav-justified{border-bottom:0}.nav-tabs-justified>li>a,.nav-tabs.nav-justified>li>a{margin-right:0;border-radius:4px}.nav-tabs-justified>.active>a,.nav-tabs-justified>.active>a:focus,.nav-tabs-justified>.active>a:hover,.nav-tabs.nav-justified>.active>a,.nav-tabs.nav-justified>.active>a:focus,.nav-tabs.nav-justified>.active>a:hover{border:1px solid #ddd}@media (min-width:768px){.nav-justified>li,.nav-tabs.nav-justified>li{display:table-cell;width:1%}.nav-justified>li>a,.nav-tabs.nav-justified>li>a{margin-bottom:0}.nav-tabs-justified>li>a,.nav-tabs.nav-justified>li>a{border-bottom:1px solid #ddd;border-radius:4px 4px 0 0}.nav-tabs-justified>.active>a,.nav-tabs-justified>.active>a:focus,.nav-tabs-justified>.active>a:hover,.nav-tabs.nav-justified>.active>a,.nav-tabs.nav-justified>.active>a:focus,.nav-tabs.nav-justified>.active>a:hover{border-bottom-color:#fff}}.tab-content>.tab-pane{display:none}.tab-content>.active{display:block}.navbar-collapse:after,.navbar-collapse:before,.navbar-header:after,.navbar-header:before,.navbar:after,.navbar:before{content:\" \";display:table}.nav-tabs .dropdown-menu{margin-top:-1px;border-top-right-radius:0;border-top-left-radius:0}.navbar{position:relative;min-height:50px;margin-bottom:20px;border:1px solid transparent}.navbar-collapse{overflow-x:visible;padding-right:15px;padding-left:15px;border-top:1px solid transparent;-webkit-box-shadow:inset 0 1px 0 rgba(255,255,255,.1);box-shadow:inset 0 1px 0 rgba(255,255,255,.1);-webkit-overflow-scrolling:touch}.navbar-collapse.in{overflow-y:auto}@media (min-width:768px){.navbar{border-radius:4px}.navbar-header{float:left}.navbar-collapse{width:auto;border-top:0;-webkit-box-shadow:none;box-shadow:none}.navbar-collapse.collapse{display:block!important;height:auto!important;padding-bottom:0;overflow:visible!important}.navbar-collapse.in{overflow-y:visible}.navbar-fixed-bottom .navbar-collapse,.navbar-fixed-top .navbar-collapse,.navbar-static-top .navbar-collapse{padding-left:0;padding-right:0}}.embed-responsive,.modal,.modal-open,.progress{overflow:hidden}@media (max-device-width:480px) and (orientation:landscape){.navbar-fixed-bottom .navbar-collapse,.navbar-fixed-top .navbar-collapse{max-height:200px}}.container-fluid>.navbar-collapse,.container-fluid>.navbar-header,.container>.navbar-collapse,.container>.navbar-header{margin-right:-15px;margin-left:-15px}.navbar-static-top{z-index:1000;border-width:0 0 1px}.navbar-fixed-bottom,.navbar-fixed-top{position:fixed;right:0;left:0;z-index:1030}.navbar-fixed-top{top:0;border-width:0 0 1px}.navbar-fixed-bottom{bottom:0;margin-bottom:0;border-width:1px 0 0}.navbar-brand{float:left;padding:15px;font-size:18px;line-height:20px;height:50px}.navbar-brand:focus,.navbar-brand:hover{text-decoration:none}.navbar-brand>img{display:block}@media (min-width:768px){.container-fluid>.navbar-collapse,.container-fluid>.navbar-header,.container>.navbar-collapse,.container>.navbar-header{margin-right:0;margin-left:0}.navbar-fixed-bottom,.navbar-fixed-top,.navbar-static-top{border-radius:0}.navbar>.container .navbar-brand,.navbar>.container-fluid .navbar-brand{margin-left:-15px}}.navbar-toggle{position:relative;float:right;margin-right:15px;padding:9px 10px;margin-top:8px;margin-bottom:8px;background-color:transparent;background-image:none;border:1px solid transparent;border-radius:4px}.navbar-toggle:focus{outline:0}.navbar-toggle .icon-bar{display:block;width:22px;height:2px;border-radius:1px}.navbar-toggle .icon-bar+.icon-bar{margin-top:4px}.navbar-nav{margin:7.5px -15px}.navbar-nav>li>a{padding-top:10px;padding-bottom:10px;line-height:20px}@media (max-width:767px){.navbar-nav .open .dropdown-menu{position:static;float:none;width:auto;margin-top:0;background-color:transparent;border:0;-webkit-box-shadow:none;box-shadow:none}.navbar-nav .open .dropdown-menu .dropdown-header,.navbar-nav .open .dropdown-menu>li>a{padding:5px 15px 5px 25px}.navbar-nav .open .dropdown-menu>li>a{line-height:20px}.navbar-nav .open .dropdown-menu>li>a:focus,.navbar-nav .open .dropdown-menu>li>a:hover{background-image:none}}.progress-bar-striped,.progress-striped .progress-bar,.progress-striped .progress-bar-success{background-image:-webkit-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:-o-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent)}@media (min-width:768px){.navbar-toggle{display:none}.navbar-nav{float:left;margin:0}.navbar-nav>li{float:left}.navbar-nav>li>a{padding-top:15px;padding-bottom:15px}}.navbar-form{padding:10px 15px;border-top:1px solid transparent;border-bottom:1px solid transparent;-webkit-box-shadow:inset 0 1px 0 rgba(255,255,255,.1),0 1px 0 rgba(255,255,255,.1);box-shadow:inset 0 1px 0 rgba(255,255,255,.1),0 1px 0 rgba(255,255,255,.1);margin:8px -15px}@media (min-width:768px){.comment-form .navbar-form p,.navbar-form .comment-form p,.navbar-form .form-group{display:inline-block;margin-bottom:0;vertical-align:middle}.comment-form .navbar-form input[type=text],.comment-form .navbar-form input[type=email],.comment-form .navbar-form input[type=url],.comment-form .navbar-form textarea,.navbar-form .comment-form input[type=text],.navbar-form .comment-form input[type=email],.navbar-form .comment-form input[type=url],.navbar-form .comment-form textarea,.navbar-form .form-control{display:inline-block;width:auto;vertical-align:middle}.navbar-form .form-control-static{display:inline-block}.navbar-form .input-group{display:inline-table;vertical-align:middle}.comment-form .navbar-form .input-group input[type=text],.comment-form .navbar-form .input-group input[type=email],.comment-form .navbar-form .input-group input[type=url],.comment-form .navbar-form .input-group textarea,.navbar-form .input-group .comment-form input[type=text],.navbar-form .input-group .comment-form input[type=email],.navbar-form .input-group .comment-form input[type=url],.navbar-form .input-group .comment-form textarea,.navbar-form .input-group .form-control,.navbar-form .input-group .input-group-addon,.navbar-form .input-group .input-group-btn{width:auto}.comment-form .navbar-form .input-group>input[type=text],.comment-form .navbar-form .input-group>input[type=email],.comment-form .navbar-form .input-group>input[type=url],.comment-form .navbar-form .input-group>textarea,.navbar-form .comment-form .input-group>input[type=text],.navbar-form .comment-form .input-group>input[type=email],.navbar-form .comment-form .input-group>input[type=url],.navbar-form .comment-form .input-group>textarea,.navbar-form .input-group>.form-control{width:100%}.navbar-form .control-label{margin-bottom:0;vertical-align:middle}.navbar-form .checkbox,.navbar-form .radio{display:inline-block;margin-top:0;margin-bottom:0;vertical-align:middle}.navbar-form .checkbox label,.navbar-form .radio label{padding-left:0}.navbar-form .checkbox input[type=checkbox],.navbar-form .radio input[type=radio]{position:relative;margin-left:0}.navbar-form .has-feedback .form-control-feedback{top:0}.navbar-form{width:auto;border:0;margin-left:0;margin-right:0;padding-top:0;padding-bottom:0;-webkit-box-shadow:none;box-shadow:none}}.breadcrumb>li,.pagination{display:inline-block}@media (max-width:767px){.comment-form .navbar-form p,.navbar-form .comment-form p,.navbar-form .form-group{margin-bottom:5px}.comment-form .navbar-form p:last-child,.navbar-form .comment-form p:last-child,.navbar-form .form-group:last-child{margin-bottom:0}}.navbar-nav>li>.dropdown-menu{margin-top:0;border-top-right-radius:0;border-top-left-radius:0}.navbar-fixed-bottom .navbar-nav>li>.dropdown-menu{margin-bottom:0;border-radius:4px 4px 0 0}.navbar-btn{margin-top:8px;margin-bottom:8px}.btn-group-sm>.navbar-btn.btn,.comment-form .btn-group-sm>input.navbar-btn[type=submit],.navbar-btn.btn-sm{margin-top:10px;margin-bottom:10px}.btn-group-xs>.navbar-btn.btn,.comment-form .btn-group-xs>input.navbar-btn[type=submit],.navbar-btn.btn-xs{margin-top:14px;margin-bottom:14px}.navbar-text{margin-top:15px;margin-bottom:15px}@media (min-width:768px){.navbar-text{float:left;margin-left:15px;margin-right:15px}.navbar-left{float:left!important}.navbar-right{float:right!important;margin-right:-15px}.navbar-right~.navbar-right{margin-right:0}}.navbar-default .navbar-brand{color:#777}.navbar-default .navbar-brand:focus,.navbar-default .navbar-brand:hover{color:#5e5e5e;background-color:transparent}.navbar-default .navbar-nav>li>a,.navbar-default .navbar-text{color:#777}.navbar-default .navbar-nav>li>a:focus,.navbar-default .navbar-nav>li>a:hover{color:#333;background-color:transparent}.navbar-default .navbar-nav>.active>a,.navbar-default .navbar-nav>.active>a:focus,.navbar-default .navbar-nav>.active>a:hover{color:#555;background-color:#e7e7e7}.navbar-default .navbar-nav>.disabled>a,.navbar-default .navbar-nav>.disabled>a:focus,.navbar-default .navbar-nav>.disabled>a:hover{color:#ccc;background-color:transparent}.navbar-default .navbar-toggle{border-color:#ddd}.navbar-default .navbar-toggle:focus,.navbar-default .navbar-toggle:hover{background-color:#ddd}.navbar-default .navbar-toggle .icon-bar{background-color:#888}.navbar-default .navbar-collapse,.navbar-default .navbar-form{border-color:#e7e7e7}.navbar-default .navbar-nav>.open>a,.navbar-default .navbar-nav>.open>a:focus,.navbar-default .navbar-nav>.open>a:hover{background-color:#e7e7e7;color:#555}@media (max-width:767px){.navbar-default .navbar-nav .open .dropdown-menu>li>a{color:#777}.navbar-default .navbar-nav .open .dropdown-menu>li>a:focus,.navbar-default .navbar-nav .open .dropdown-menu>li>a:hover{color:#333;background-color:transparent}.navbar-default .navbar-nav .open .dropdown-menu>.active>a,.navbar-default .navbar-nav .open .dropdown-menu>.active>a:focus,.navbar-default .navbar-nav .open .dropdown-menu>.active>a:hover{color:#555;background-color:#e7e7e7}.navbar-default .navbar-nav .open .dropdown-menu>.disabled>a,.navbar-default .navbar-nav .open .dropdown-menu>.disabled>a:focus,.navbar-default .navbar-nav .open .dropdown-menu>.disabled>a:hover{color:#ccc;background-color:transparent}}.navbar-default .navbar-link{color:#777}.navbar-default .navbar-link:hover{color:#333}.navbar-default .btn-link{color:#777}.navbar-default .btn-link:focus,.navbar-default .btn-link:hover{color:#333}.navbar-default .btn-link[disabled]:focus,.navbar-default .btn-link[disabled]:hover,fieldset[disabled] .navbar-default .btn-link:focus,fieldset[disabled] .navbar-default .btn-link:hover{color:#ccc}.navbar-inverse{background-color:#222;border-color:#090909}.navbar-inverse .navbar-brand{color:#9d9d9d}.navbar-inverse .navbar-brand:focus,.navbar-inverse .navbar-brand:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav>li>a,.navbar-inverse .navbar-text{color:#9d9d9d}.navbar-inverse .navbar-nav>li>a:focus,.navbar-inverse .navbar-nav>li>a:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav>.active>a,.navbar-inverse .navbar-nav>.active>a:focus,.navbar-inverse .navbar-nav>.active>a:hover{color:#fff;background-color:#090909}.navbar-inverse .navbar-nav>.disabled>a,.navbar-inverse .navbar-nav>.disabled>a:focus,.navbar-inverse .navbar-nav>.disabled>a:hover{color:#444;background-color:transparent}.navbar-inverse .navbar-toggle{border-color:#333}.navbar-inverse .navbar-toggle:focus,.navbar-inverse .navbar-toggle:hover{background-color:#333}.navbar-inverse .navbar-toggle .icon-bar{background-color:#fff}.navbar-inverse .navbar-collapse,.navbar-inverse .navbar-form{border-color:#101010}.navbar-inverse .navbar-nav>.open>a,.navbar-inverse .navbar-nav>.open>a:focus,.navbar-inverse .navbar-nav>.open>a:hover{background-color:#090909;color:#fff}@media (max-width:767px){.navbar-inverse .navbar-nav .open .dropdown-menu>.dropdown-header{border-color:#090909}.navbar-inverse .navbar-nav .open .dropdown-menu .divider{background-color:#090909}.navbar-inverse .navbar-nav .open .dropdown-menu>li>a{color:#9d9d9d}.navbar-inverse .navbar-nav .open .dropdown-menu>li>a:focus,.navbar-inverse .navbar-nav .open .dropdown-menu>li>a:hover{color:#fff;background-color:transparent}.navbar-inverse .navbar-nav .open .dropdown-menu>.active>a,.navbar-inverse .navbar-nav .open .dropdown-menu>.active>a:focus,.navbar-inverse .navbar-nav .open .dropdown-menu>.active>a:hover{color:#fff;background-color:#090909}.navbar-inverse .navbar-nav .open .dropdown-menu>.disabled>a,.navbar-inverse .navbar-nav .open .dropdown-menu>.disabled>a:focus,.navbar-inverse .navbar-nav .open .dropdown-menu>.disabled>a:hover{color:#444;background-color:transparent}}.navbar-inverse .navbar-link{color:#9d9d9d}.navbar-inverse .navbar-link:hover{color:#fff}.navbar-inverse .btn-link{color:#9d9d9d}.navbar-inverse .btn-link:focus,.navbar-inverse .btn-link:hover{color:#fff}.navbar-inverse .btn-link[disabled]:focus,.navbar-inverse .btn-link[disabled]:hover,fieldset[disabled] .navbar-inverse .btn-link:focus,fieldset[disabled] .navbar-inverse .btn-link:hover{color:#444}.breadcrumb{padding:8px 15px;margin-bottom:20px;list-style:none;background-color:#f5f5f5;border-radius:4px}.breadcrumb>li+li:before{content:\"/\\00a0\";padding:0 5px;color:#ccc}.modal-footer:after,.modal-footer:before,.pager:after,.pager:before,.panel-body:after,.panel-body:before,.popover.top>.arrow:after{content:\" \"}.breadcrumb>.active{color:#777}.pagination{padding-left:0;margin:20px 0;border-radius:4px}.pagination>li{display:inline}.pagination>li>a,.pagination>li>span{position:relative;float:left;padding:6px 12px;line-height:1.428571429;text-decoration:none;color:#bd1c2b;background-color:#fff;border:1px solid #ddd;margin-left:-1px}.badge,.label{font-weight:700;line-height:1;vertical-align:baseline;white-space:nowrap;text-align:center}.pagination>li:first-child>a,.pagination>li:first-child>span{margin-left:0;border-bottom-left-radius:4px;border-top-left-radius:4px}.pagination>li:last-child>a,.pagination>li:last-child>span{border-bottom-right-radius:4px;border-top-right-radius:4px}.pagination>li>a:focus,.pagination>li>a:hover,.pagination>li>span:focus,.pagination>li>span:hover{color:#7a121c;background-color:#eee;border-color:#ddd}.pagination>.active>a,.pagination>.active>a:focus,.pagination>.active>a:hover,.pagination>.active>span,.pagination>.active>span:focus,.pagination>.active>span:hover{z-index:2;color:#fff;background-color:#bd1c2b;border-color:#bd1c2b;cursor:default}.pagination>.disabled>a,.pagination>.disabled>a:focus,.pagination>.disabled>a:hover,.pagination>.disabled>span,.pagination>.disabled>span:focus,.pagination>.disabled>span:hover{color:#777;background-color:#fff;border-color:#ddd;cursor:false}.pagination-lg>li>a,.pagination-lg>li>span{padding:10px 16px;font-size:18px}.pagination-lg>li:first-child>a,.pagination-lg>li:first-child>span{border-bottom-left-radius:6px;border-top-left-radius:6px}.pagination-lg>li:last-child>a,.pagination-lg>li:last-child>span{border-bottom-right-radius:6px;border-top-right-radius:6px}.pagination-sm>li>a,.pagination-sm>li>span{padding:5px 10px;font-size:12px}.pagination-sm>li:first-child>a,.pagination-sm>li:first-child>span{border-bottom-left-radius:3px;border-top-left-radius:3px}.pagination-sm>li:last-child>a,.pagination-sm>li:last-child>span{border-bottom-right-radius:3px;border-top-right-radius:3px}.pager{padding-left:0;margin:20px 0;list-style:none;text-align:center}.pager:after,.pager:before{display:table}.pager li{display:inline}.pager li>a,.pager li>span{display:inline-block;padding:5px 14px;background-color:#fff;border:1px solid #ddd;border-radius:15px}.pager li>a:focus,.pager li>a:hover{text-decoration:none;background-color:#eee}.pager .next>a,.pager .next>span{float:right}.pager .previous>a,.pager .previous>span{float:left}.pager .disabled>a,.pager .disabled>a:focus,.pager .disabled>a:hover,.pager .disabled>span{color:#777;background-color:#fff;cursor:false}.label{display:inline;padding:.2em .6em .3em;font-size:75%;color:#fff;border-radius:.25em}.label:empty{display:none}.btn .label,.comment-form input[type=submit] .label{position:relative;top:-1px}a.label:focus,a.label:hover{color:#fff;text-decoration:none;cursor:pointer}.label-default{background-color:#777}.label-default[href]:focus,.label-default[href]:hover{background-color:#5e5e5e}.label-primary{background-color:#bd1c2b}.label-primary[href]:focus,.label-primary[href]:hover{background-color:#911521}.label-success{background-color:#5cb85c}.label-success[href]:focus,.label-success[href]:hover{background-color:#449d44}.label-info{background-color:#5bc0de}.label-info[href]:focus,.label-info[href]:hover{background-color:#31b0d5}.label-warning{background-color:#f0ad4e}.label-warning[href]:focus,.label-warning[href]:hover{background-color:#ec971f}.label-danger{background-color:#d9534f}.label-danger[href]:focus,.label-danger[href]:hover{background-color:#c9302c}.badge{display:inline-block;min-width:10px;padding:3px 7px;font-size:12px;color:#fff;background-color:#777;border-radius:10px}.badge:empty{display:none}.btn .badge,.comment-form input[type=submit] .badge{position:relative;top:-1px}.btn-group-xs>.btn .badge,.btn-xs .badge,.comment-form .btn-group-xs>input[type=submit] .badge{top:0;padding:1px 5px}.list-group-item.active>.badge,.nav-pills>.active>a>.badge{color:#bd1c2b;background-color:#fff}.list-group-item>.badge{float:right}.list-group-item>.badge+.badge{margin-right:5px}.nav-pills>li>a>.badge{margin-left:3px}a.badge:focus,a.badge:hover{color:#fff;text-decoration:none;cursor:pointer}.jumbotron,.jumbotron .h1,.jumbotron h1{color:inherit}.jumbotron{padding:30px 15px;margin-bottom:30px;background-color:#eee}.jumbotron p{margin-bottom:15px;font-size:21px;font-weight:200}.alert .alert-link,.close{font-weight:700}.jumbotron>hr{border-top-color:#d5d5d5}.container .jumbotron,.container-fluid .jumbotron{border-radius:6px}.jumbotron .container{max-width:100%}@media screen and (min-width:768px){.jumbotron{padding:48px 0}.container .jumbotron,.container-fluid .jumbotron{padding-left:60px;padding-right:60px}.jumbotron .h1,.jumbotron h1{font-size:63px}}.thumbnail,.wp-caption{display:block;padding:4px;margin-bottom:20px;line-height:1.428571429;background-color:#fff;border:1px solid #ddd;border-radius:4px;-webkit-transition:border .2s ease-in-out;-o-transition:border .2s ease-in-out;transition:border .2s ease-in-out}.thumbnail a>img,.thumbnail>img,.wp-caption a>img,.wp-caption>img{display:block;max-width:100%;height:auto;margin-left:auto;margin-right:auto}.thumbnail .caption,.wp-caption .caption{padding:9px;color:#333}a.active.wp-caption,a.thumbnail.active,a.thumbnail:focus,a.thumbnail:hover,a.wp-caption:focus,a.wp-caption:hover{border-color:#bd1c2b}.alert{padding:15px;margin-bottom:20px;border:1px solid transparent;border-radius:4px}.alert h4{margin-top:0;color:inherit}.alert>p,.alert>ul{margin-bottom:0}.alert>p+p{margin-top:5px}.alert-dismissable,.alert-dismissible{padding-right:35px}.alert-dismissable .close,.alert-dismissible .close{position:relative;top:-2px;right:-21px;color:inherit}.modal,.modal-backdrop{top:0;right:0;bottom:0;left:0}.alert-success{background-color:#dff0d8;border-color:#d6e9c6;color:#3c763d}.alert-success hr{border-top-color:#c9e2b3}.alert-success .alert-link{color:#2b542c}.alert-info{background-color:#d9edf7;border-color:#bce8f1;color:#31708f}.alert-info hr{border-top-color:#a6e1ec}.alert-info .alert-link{color:#245269}.alert-warning{background-color:#fcf8e3;border-color:#faebcc;color:#8a6d3b}.alert-warning hr{border-top-color:#f7e1b5}.alert-warning .alert-link{color:#66512c}.alert-danger{background-color:#f2dede;border-color:#ebccd1;color:#a94442}.alert-danger hr{border-top-color:#e4b9c0}.alert-danger .alert-link{color:#843534}@-webkit-keyframes progress-bar-stripes{from{background-position:40px 0}to{background-position:0 0}}@-o-keyframes progress-bar-stripes{from{background-position:40px 0}to{background-position:0 0}}@keyframes progress-bar-stripes{from{background-position:40px 0}to{background-position:0 0}}.progress{height:20px;margin-bottom:20px;background-color:#f5f5f5;border-radius:4px;-webkit-box-shadow:inset 0 1px 2px rgba(0,0,0,.1);box-shadow:inset 0 1px 2px rgba(0,0,0,.1)}.progress-bar{float:left;width:0;height:100%;font-size:12px;line-height:20px;color:#fff;text-align:center;background-color:#bd1c2b;-webkit-box-shadow:inset 0 -1px 0 rgba(0,0,0,.15);box-shadow:inset 0 -1px 0 rgba(0,0,0,.15);-webkit-transition:width .6s ease;-o-transition:width .6s ease;transition:width .6s ease}.progress-bar-striped,.progress-striped .progress-bar{background-image:linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);-webkit-background-size:40px 40px;background-size:40px 40px}.progress-bar.active,.progress.active .progress-bar{-webkit-animation:progress-bar-stripes 2s linear infinite;-o-animation:progress-bar-stripes 2s linear infinite;animation:progress-bar-stripes 2s linear infinite}.progress-bar-success{background-color:#5cb85c}.progress-striped .progress-bar-success{background-image:linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent)}.progress-striped .progress-bar-info,.progress-striped .progress-bar-warning{background-image:-webkit-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:-o-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent)}.progress-bar-info{background-color:#5bc0de}.progress-striped .progress-bar-info{background-image:linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent)}.progress-bar-warning{background-color:#f0ad4e}.progress-striped .progress-bar-warning{background-image:linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent)}.progress-bar-danger{background-color:#d9534f}.progress-striped .progress-bar-danger{background-image:-webkit-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:-o-linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent);background-image:linear-gradient(45deg,rgba(255,255,255,.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.15) 50%,rgba(255,255,255,.15) 75%,transparent 75%,transparent)}.media{margin-top:15px}.media:first-child{margin-top:0}.media,.media-body{zoom:1;overflow:hidden}.media-body{width:10000px}.media-object{display:block}.media-right,.media>.pull-right{padding-left:10px}.media-left,.media>.pull-left{padding-right:10px}.media-body,.media-left,.media-right{display:table-cell;vertical-align:top}.media-middle{vertical-align:middle}.media-bottom{vertical-align:bottom}.media-heading{margin-top:0;margin-bottom:5px}.media-list{padding-left:0;list-style:none}.list-group{margin-bottom:20px;padding-left:0}.list-group-item{position:relative;display:block;padding:10px 15px;margin-bottom:-1px;background-color:#fff;border:1px solid #ddd}.list-group-item:first-child{border-top-right-radius:4px;border-top-left-radius:4px}.list-group-item:last-child{margin-bottom:0;border-bottom-right-radius:4px;border-bottom-left-radius:4px}a.list-group-item{color:#555}a.list-group-item .list-group-item-heading{color:#333}a.list-group-item:focus,a.list-group-item:hover{text-decoration:none;color:#555;background-color:#f5f5f5}.list-group-item.disabled,.list-group-item.disabled:focus,.list-group-item.disabled:hover{background-color:#eee;color:#777;cursor:false}.list-group-item.disabled .list-group-item-heading,.list-group-item.disabled:focus .list-group-item-heading,.list-group-item.disabled:hover .list-group-item-heading{color:inherit}.list-group-item.disabled .list-group-item-text,.list-group-item.disabled:focus .list-group-item-text,.list-group-item.disabled:hover .list-group-item-text{color:#777}.list-group-item.active,.list-group-item.active:focus,.list-group-item.active:hover{z-index:2;color:#fff;background-color:#bd1c2b;border-color:#bd1c2b}.list-group-item.active .list-group-item-heading,.list-group-item.active .list-group-item-heading>.small,.list-group-item.active .list-group-item-heading>small,.list-group-item.active:focus .list-group-item-heading,.list-group-item.active:focus .list-group-item-heading>.small,.list-group-item.active:focus .list-group-item-heading>small,.list-group-item.active:hover .list-group-item-heading,.list-group-item.active:hover .list-group-item-heading>.small,.list-group-item.active:hover .list-group-item-heading>small{color:inherit}.list-group-item.active .list-group-item-text,.list-group-item.active:focus .list-group-item-text,.list-group-item.active:hover .list-group-item-text{color:#f4b1b8}.list-group-item-success{color:#3c763d;background-color:#dff0d8}a.list-group-item-success{color:#3c763d}a.list-group-item-success .list-group-item-heading{color:inherit}a.list-group-item-success:focus,a.list-group-item-success:hover{color:#3c763d;background-color:#d0e9c6}a.list-group-item-success.active,a.list-group-item-success.active:focus,a.list-group-item-success.active:hover{color:#fff;background-color:#3c763d;border-color:#3c763d}.list-group-item-info{color:#31708f;background-color:#d9edf7}a.list-group-item-info{color:#31708f}a.list-group-item-info .list-group-item-heading{color:inherit}a.list-group-item-info:focus,a.list-group-item-info:hover{color:#31708f;background-color:#c4e3f3}a.list-group-item-info.active,a.list-group-item-info.active:focus,a.list-group-item-info.active:hover{color:#fff;background-color:#31708f;border-color:#31708f}.list-group-item-warning{color:#8a6d3b;background-color:#fcf8e3}a.list-group-item-warning{color:#8a6d3b}a.list-group-item-warning .list-group-item-heading{color:inherit}a.list-group-item-warning:focus,a.list-group-item-warning:hover{color:#8a6d3b;background-color:#faf2cc}a.list-group-item-warning.active,a.list-group-item-warning.active:focus,a.list-group-item-warning.active:hover{color:#fff;background-color:#8a6d3b;border-color:#8a6d3b}.list-group-item-danger{color:#a94442;background-color:#f2dede}a.list-group-item-danger{color:#a94442}a.list-group-item-danger .list-group-item-heading{color:inherit}a.list-group-item-danger:focus,a.list-group-item-danger:hover{color:#a94442;background-color:#ebcccc}a.list-group-item-danger.active,a.list-group-item-danger.active:focus,a.list-group-item-danger.active:hover{color:#fff;background-color:#a94442;border-color:#a94442}.panel-heading>.dropdown .dropdown-toggle,.panel-title,.panel-title>.small,.panel-title>.small>a,.panel-title>a,.panel-title>small,.panel-title>small>a{color:inherit}.list-group-item-heading{margin-top:0;margin-bottom:5px}.list-group-item-text{margin-bottom:0;line-height:1.3}.panel{margin-bottom:20px;background-color:#fff;border:1px solid transparent;border-radius:4px;-webkit-box-shadow:0 1px 1px rgba(0,0,0,.05);box-shadow:0 1px 1px rgba(0,0,0,.05)}.panel-title,.panel>.list-group,.panel>.panel-collapse>.list-group,.panel>.panel-collapse>.table,.panel>.table,.panel>.table-responsive>.table{margin-bottom:0}.panel-body{padding:15px}.panel-body:after,.panel-body:before{display:table}.panel-heading{padding:10px 15px;border-bottom:1px solid transparent;border-top-right-radius:3px;border-top-left-radius:3px}.panel-title{margin-top:0;font-size:16px}.panel-footer{padding:10px 15px;background-color:#f5f5f5;border-top:1px solid #ddd;border-bottom-right-radius:3px;border-bottom-left-radius:3px}.panel>.list-group .list-group-item,.panel>.panel-collapse>.list-group .list-group-item{border-width:1px 0;border-radius:0}.panel-group .panel-heading,.panel>.table-bordered>tbody>tr:first-child>td,.panel>.table-bordered>tbody>tr:first-child>th,.panel>.table-bordered>tbody>tr:last-child>td,.panel>.table-bordered>tbody>tr:last-child>th,.panel>.table-bordered>tfoot>tr:last-child>td,.panel>.table-bordered>tfoot>tr:last-child>th,.panel>.table-bordered>thead>tr:first-child>td,.panel>.table-bordered>thead>tr:first-child>th,.panel>.table-responsive>.table-bordered>tbody>tr:first-child>td,.panel>.table-responsive>.table-bordered>tbody>tr:first-child>th,.panel>.table-responsive>.table-bordered>tbody>tr:last-child>td,.panel>.table-responsive>.table-bordered>tbody>tr:last-child>th,.panel>.table-responsive>.table-bordered>tfoot>tr:last-child>td,.panel>.table-responsive>.table-bordered>tfoot>tr:last-child>th,.panel>.table-responsive>.table-bordered>thead>tr:first-child>td,.panel>.table-responsive>.table-bordered>thead>tr:first-child>th{border-bottom:0}.panel>.table-responsive:first-child>.table:first-child,.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child,.panel>.table:first-child,.panel>.table:first-child>tbody:first-child>tr:first-child,.panel>.table:first-child>thead:first-child>tr:first-child{border-top-left-radius:3px;border-top-right-radius:3px}.panel>.table-responsive:last-child>.table:last-child,.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child,.panel>.table:last-child,.panel>.table:last-child>tbody:last-child>tr:last-child,.panel>.table:last-child>tfoot:last-child>tr:last-child{border-bottom-left-radius:3px;border-bottom-right-radius:3px}.panel>.list-group:first-child .list-group-item:first-child,.panel>.panel-collapse>.list-group:first-child .list-group-item:first-child{border-top:0;border-top-right-radius:3px;border-top-left-radius:3px}.panel>.list-group:last-child .list-group-item:last-child,.panel>.panel-collapse>.list-group:last-child .list-group-item:last-child{border-bottom:0;border-bottom-right-radius:3px;border-bottom-left-radius:3px}.list-group+.panel-footer,.panel-heading+.list-group .list-group-item:first-child{border-top-width:0}.panel>.panel-collapse>.table caption,.panel>.table caption,.panel>.table-responsive>.table caption{padding-left:15px;padding-right:15px}.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child td:first-child,.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child th:first-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child td:first-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child th:first-child,.panel>.table:first-child>tbody:first-child>tr:first-child td:first-child,.panel>.table:first-child>tbody:first-child>tr:first-child th:first-child,.panel>.table:first-child>thead:first-child>tr:first-child td:first-child,.panel>.table:first-child>thead:first-child>tr:first-child th:first-child{border-top-left-radius:3px}.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child td:last-child,.panel>.table-responsive:first-child>.table:first-child>tbody:first-child>tr:first-child th:last-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child td:last-child,.panel>.table-responsive:first-child>.table:first-child>thead:first-child>tr:first-child th:last-child,.panel>.table:first-child>tbody:first-child>tr:first-child td:last-child,.panel>.table:first-child>tbody:first-child>tr:first-child th:last-child,.panel>.table:first-child>thead:first-child>tr:first-child td:last-child,.panel>.table:first-child>thead:first-child>tr:first-child th:last-child{border-top-right-radius:3px}.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child td:first-child,.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child th:first-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child td:first-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child th:first-child,.panel>.table:last-child>tbody:last-child>tr:last-child td:first-child,.panel>.table:last-child>tbody:last-child>tr:last-child th:first-child,.panel>.table:last-child>tfoot:last-child>tr:last-child td:first-child,.panel>.table:last-child>tfoot:last-child>tr:last-child th:first-child{border-bottom-left-radius:3px}.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child td:last-child,.panel>.table-responsive:last-child>.table:last-child>tbody:last-child>tr:last-child th:last-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child td:last-child,.panel>.table-responsive:last-child>.table:last-child>tfoot:last-child>tr:last-child th:last-child,.panel>.table:last-child>tbody:last-child>tr:last-child td:last-child,.panel>.table:last-child>tbody:last-child>tr:last-child th:last-child,.panel>.table:last-child>tfoot:last-child>tr:last-child td:last-child,.panel>.table:last-child>tfoot:last-child>tr:last-child th:last-child{border-bottom-right-radius:3px}.panel>.panel-body+.table,.panel>.panel-body+.table-responsive,.panel>.table+.panel-body,.panel>.table-responsive+.panel-body{border-top:1px solid #ddd}.panel>.table>tbody:first-child>tr:first-child td,.panel>.table>tbody:first-child>tr:first-child th{border-top:0}.panel>.table-bordered,.panel>.table-responsive>.table-bordered{border:0}.panel>.table-bordered>tbody>tr>td:first-child,.panel>.table-bordered>tbody>tr>th:first-child,.panel>.table-bordered>tfoot>tr>td:first-child,.panel>.table-bordered>tfoot>tr>th:first-child,.panel>.table-bordered>thead>tr>td:first-child,.panel>.table-bordered>thead>tr>th:first-child,.panel>.table-responsive>.table-bordered>tbody>tr>td:first-child,.panel>.table-responsive>.table-bordered>tbody>tr>th:first-child,.panel>.table-responsive>.table-bordered>tfoot>tr>td:first-child,.panel>.table-responsive>.table-bordered>tfoot>tr>th:first-child,.panel>.table-responsive>.table-bordered>thead>tr>td:first-child,.panel>.table-responsive>.table-bordered>thead>tr>th:first-child{border-left:0}.panel>.table-bordered>tbody>tr>td:last-child,.panel>.table-bordered>tbody>tr>th:last-child,.panel>.table-bordered>tfoot>tr>td:last-child,.panel>.table-bordered>tfoot>tr>th:last-child,.panel>.table-bordered>thead>tr>td:last-child,.panel>.table-bordered>thead>tr>th:last-child,.panel>.table-responsive>.table-bordered>tbody>tr>td:last-child,.panel>.table-responsive>.table-bordered>tbody>tr>th:last-child,.panel>.table-responsive>.table-bordered>tfoot>tr>td:last-child,.panel>.table-responsive>.table-bordered>tfoot>tr>th:last-child,.panel>.table-responsive>.table-bordered>thead>tr>td:last-child,.panel>.table-responsive>.table-bordered>thead>tr>th:last-child{border-right:0}.panel>.table-responsive{border:0;margin-bottom:0}.panel-group{margin-bottom:20px}.panel-group .panel{margin-bottom:0;border-radius:4px}.panel-group .panel+.panel{margin-top:5px}.panel-group .panel-heading+.panel-collapse>.list-group,.panel-group .panel-heading+.panel-collapse>.panel-body{border-top:1px solid #ddd}.panel-group .panel-footer{border-top:0}.panel-group .panel-footer+.panel-collapse .panel-body{border-bottom:1px solid #ddd}.panel-default{border-color:#ddd}.panel-default>.panel-heading{color:#333;background-color:#f5f5f5;border-color:#ddd}.panel-default>.panel-heading+.panel-collapse>.panel-body{border-top-color:#ddd}.panel-default>.panel-heading .badge{color:#f5f5f5;background-color:#333}.panel-default>.panel-footer+.panel-collapse>.panel-body{border-bottom-color:#ddd}.panel-primary{border-color:#bd1c2b}.panel-primary>.panel-heading{color:#fff;background-color:#bd1c2b;border-color:#bd1c2b}.panel-primary>.panel-heading+.panel-collapse>.panel-body{border-top-color:#bd1c2b}.panel-primary>.panel-heading .badge{color:#bd1c2b;background-color:#fff}.panel-primary>.panel-footer+.panel-collapse>.panel-body{border-bottom-color:#bd1c2b}.panel-success{border-color:#d6e9c6}.panel-success>.panel-heading{color:#3c763d;background-color:#dff0d8;border-color:#d6e9c6}.panel-success>.panel-heading+.panel-collapse>.panel-body{border-top-color:#d6e9c6}.panel-success>.panel-heading .badge{color:#dff0d8;background-color:#3c763d}.panel-success>.panel-footer+.panel-collapse>.panel-body{border-bottom-color:#d6e9c6}.panel-info{border-color:#bce8f1}.panel-info>.panel-heading{color:#31708f;background-color:#d9edf7;border-color:#bce8f1}.panel-info>.panel-heading+.panel-collapse>.panel-body{border-top-color:#bce8f1}.panel-info>.panel-heading .badge{color:#d9edf7;background-color:#31708f}.panel-info>.panel-footer+.panel-collapse>.panel-body{border-bottom-color:#bce8f1}.panel-warning{border-color:#faebcc}.panel-warning>.panel-heading{color:#8a6d3b;background-color:#fcf8e3;border-color:#faebcc}.panel-warning>.panel-heading+.panel-collapse>.panel-body{border-top-color:#faebcc}.panel-warning>.panel-heading .badge{color:#fcf8e3;background-color:#8a6d3b}.panel-warning>.panel-footer+.panel-collapse>.panel-body{border-bottom-color:#faebcc}.panel-danger{border-color:#ebccd1}.panel-danger>.panel-heading{color:#a94442;background-color:#f2dede;border-color:#ebccd1}.panel-danger>.panel-heading+.panel-collapse>.panel-body{border-top-color:#ebccd1}.panel-danger>.panel-heading .badge{color:#f2dede;background-color:#a94442}.panel-danger>.panel-footer+.panel-collapse>.panel-body{border-bottom-color:#ebccd1}.embed-responsive{position:relative;display:block;height:0;padding:0}.embed-responsive .embed-responsive-item,.embed-responsive embed,.embed-responsive iframe,.embed-responsive object,.embed-responsive video{position:absolute;top:0;left:0;bottom:0;height:100%;width:100%;border:0}.embed-responsive-16by9{padding-bottom:56.25%}.embed-responsive-4by3{padding-bottom:75%}.well{min-height:20px;padding:19px;margin-bottom:20px;background-color:#f5f5f5;border:1px solid #e3e3e3;border-radius:4px;-webkit-box-shadow:inset 0 1px 1px rgba(0,0,0,.05);box-shadow:inset 0 1px 1px rgba(0,0,0,.05)}.well blockquote{border-color:#ddd;border-color:rgba(0,0,0,.15)}.well-lg{padding:24px;border-radius:6px}.well-sm{padding:9px;border-radius:3px}.close{float:right;font-size:21px;line-height:1;color:#000;text-shadow:0 1px 0 #fff;opacity:.2;filter:alpha(opacity=20)}.popover,.tooltip{font-family:\"Helvetica Neue\",Helvetica,Arial,sans-serif;font-weight:400}.carousel-caption,.carousel-control{text-shadow:0 1px 2px rgba(0,0,0,.6)}.close:focus,.close:hover{color:#000;text-decoration:none;cursor:pointer;opacity:.5;filter:alpha(opacity=50)}button.close{padding:0;cursor:pointer;background:0 0;border:0;-webkit-appearance:none}.modal{display:none;position:fixed;z-index:1050;-webkit-overflow-scrolling:touch;outline:0}.modal.fade .modal-dialog{-webkit-transform:translate(0,-25%);-ms-transform:translate(0,-25%);-o-transform:translate(0,-25%);transform:translate(0,-25%);-webkit-transition:-webkit-transform .3s ease-out;-o-transition:-o-transform .3s ease-out;transition:transform .3s ease-out}.modal.in .modal-dialog{-webkit-transform:translate(0,0);-ms-transform:translate(0,0);-o-transform:translate(0,0);transform:translate(0,0)}.modal-open .modal{overflow-x:hidden;overflow-y:auto}.modal-dialog{position:relative;width:auto;margin:10px}.modal-content{position:relative;background-color:#fff;border:1px solid #999;border:1px solid rgba(0,0,0,.2);border-radius:6px;-webkit-box-shadow:0 3px 9px rgba(0,0,0,.5);box-shadow:0 3px 9px rgba(0,0,0,.5);-webkit-background-clip:padding-box;background-clip:padding-box;outline:0}.modal-backdrop{position:fixed;z-index:1040;background-color:#000}.modal-backdrop.fade{opacity:0;filter:alpha(opacity=0)}.modal-backdrop.in{opacity:.5;filter:alpha(opacity=50)}.modal-header{padding:15px;border-bottom:1px solid #e5e5e5;min-height:16.43px}.modal-header .close{margin-top:-2px}.modal-title{margin:0;line-height:1.428571429}.modal-body{position:relative;padding:15px}.modal-footer{padding:15px;text-align:right;border-top:1px solid #e5e5e5}.modal-footer:after,.modal-footer:before{display:table}.comment-form .modal-footer .btn+input[type=submit],.comment-form .modal-footer input[type=submit]+.btn,.comment-form .modal-footer input[type=submit]+input[type=submit],.modal-footer .btn+.btn,.modal-footer .comment-form .btn+input[type=submit],.modal-footer .comment-form input[type=submit]+.btn,.modal-footer .comment-form input[type=submit]+input[type=submit]{margin-left:5px;margin-bottom:0}.comment-form .modal-footer .btn-group .btn+input[type=submit],.comment-form .modal-footer .btn-group input[type=submit]+.btn,.comment-form .modal-footer .btn-group input[type=submit]+input[type=submit],.modal-footer .btn-group .btn+.btn,.modal-footer .btn-group .comment-form .btn+input[type=submit],.modal-footer .btn-group .comment-form input[type=submit]+.btn,.modal-footer .btn-group .comment-form input[type=submit]+input[type=submit]{margin-left:-1px}.modal-footer .btn-block+.btn-block{margin-left:0}.modal-scrollbar-measure{position:absolute;top:-9999px;width:50px;height:50px;overflow:scroll}@media (min-width:768px){.modal-dialog{width:600px;margin:30px auto}.modal-content{-webkit-box-shadow:0 5px 15px rgba(0,0,0,.5);box-shadow:0 5px 15px rgba(0,0,0,.5)}.modal-sm{width:300px}}.tooltip.top-left .tooltip-arrow,.tooltip.top-right .tooltip-arrow{bottom:0;margin-bottom:-5px;border-width:5px 5px 0;border-top-color:#000}@media (min-width:992px){.modal-lg{width:900px}}.tooltip{position:absolute;z-index:1070;display:block;font-size:12px;line-height:1.4;opacity:0;filter:alpha(opacity=0)}.tooltip.in{opacity:.9;filter:alpha(opacity=90)}.tooltip.top{margin-top:-3px;padding:5px 0}.tooltip.right{margin-left:3px;padding:0 5px}.tooltip.bottom{margin-top:3px;padding:5px 0}.tooltip.left{margin-left:-3px;padding:0 5px}.tooltip-inner{max-width:200px;padding:3px 8px;color:#fff;text-align:center;text-decoration:none;background-color:#000;border-radius:4px}.tooltip-arrow{position:absolute;width:0;height:0;border-color:transparent;border-style:solid}.tooltip.top .tooltip-arrow{bottom:0;left:50%;margin-left:-5px;border-width:5px 5px 0;border-top-color:#000}.tooltip.top-left .tooltip-arrow{right:5px}.tooltip.top-right .tooltip-arrow{left:5px}.tooltip.right .tooltip-arrow{top:50%;left:0;margin-top:-5px;border-width:5px 5px 5px 0;border-right-color:#000}.tooltip.left .tooltip-arrow{top:50%;right:0;margin-top:-5px;border-width:5px 0 5px 5px;border-left-color:#000}.tooltip.bottom .tooltip-arrow,.tooltip.bottom-left .tooltip-arrow,.tooltip.bottom-right .tooltip-arrow{border-width:0 5px 5px;border-bottom-color:#000;top:0}.tooltip.bottom .tooltip-arrow{left:50%;margin-left:-5px}.tooltip.bottom-left .tooltip-arrow{right:5px;margin-top:-5px}.tooltip.bottom-right .tooltip-arrow{left:5px;margin-top:-5px}.popover{position:absolute;top:0;left:0;z-index:1060;display:none;max-width:276px;padding:1px;font-size:14px;line-height:1.428571429;text-align:left;background-color:#fff;-webkit-background-clip:padding-box;background-clip:padding-box;border:1px solid #ccc;border:1px solid rgba(0,0,0,.2);border-radius:6px;-webkit-box-shadow:0 5px 10px rgba(0,0,0,.2);box-shadow:0 5px 10px rgba(0,0,0,.2);white-space:normal}.popover.top{margin-top:-10px}.popover.right{margin-left:10px}.popover.bottom{margin-top:10px}.popover.left{margin-left:-10px}.popover-title{margin:0;padding:8px 14px;font-size:14px;background-color:#f7f7f7;border-bottom:1px solid #ebebeb;border-radius:5px 5px 0 0}.popover-content{padding:9px 14px}.carousel-indicators,.comment-list{padding-left:0;list-style:none}.popover>.arrow,.popover>.arrow:after{position:absolute;display:block;width:0;height:0;border-color:transparent;border-style:solid}.carousel,.carousel-inner{position:relative}.popover>.arrow{border-width:11px}.popover>.arrow:after{border-width:10px;content:\"\"}.popover.top>.arrow{left:50%;margin-left:-11px;border-bottom-width:0;border-top-color:#999;border-top-color:rgba(0,0,0,.25);bottom:-11px}.popover.top>.arrow:after{bottom:1px;margin-left:-10px;border-bottom-width:0;border-top-color:#fff}.popover.left>.arrow:after,.popover.right>.arrow:after{content:\" \";bottom:-10px}.popover.right>.arrow{top:50%;left:-11px;margin-top:-11px;border-left-width:0;border-right-color:#999;border-right-color:rgba(0,0,0,.25)}.popover.right>.arrow:after{left:1px;border-left-width:0;border-right-color:#fff}.popover.bottom>.arrow{left:50%;margin-left:-11px;border-top-width:0;border-bottom-color:#999;border-bottom-color:rgba(0,0,0,.25);top:-11px}.popover.bottom>.arrow:after{content:\" \";top:1px;margin-left:-10px;border-top-width:0;border-bottom-color:#fff}.popover.left>.arrow{top:50%;right:-11px;margin-top:-11px;border-right-width:0;border-left-color:#999;border-left-color:rgba(0,0,0,.25)}.popover.left>.arrow:after{right:1px;border-right-width:0;border-left-color:#fff}.carousel-inner{overflow:hidden;width:100%}.carousel-inner>.item{display:none;position:relative;-webkit-transition:.6s ease-in-out left;-o-transition:.6s ease-in-out left;transition:.6s ease-in-out left}.carousel-inner>.item>a>img,.carousel-inner>.item>img{display:block;max-width:100%;height:auto;line-height:1}@media all and (transform-3d),(-webkit-transform-3d){.carousel-inner>.item{-webkit-transition:-webkit-transform .6s ease-in-out;-o-transition:-o-transform .6s ease-in-out;transition:transform .6s ease-in-out;-webkit-backface-visibility:hidden;backface-visibility:hidden;-webkit-perspective:1000;perspective:1000}.carousel-inner>.item.active.right,.carousel-inner>.item.next{-webkit-transform:translate3d(100%,0,0);transform:translate3d(100%,0,0);left:0}.carousel-inner>.item.active.left,.carousel-inner>.item.prev{-webkit-transform:translate3d(-100%,0,0);transform:translate3d(-100%,0,0);left:0}.carousel-inner>.item.active,.carousel-inner>.item.next.left,.carousel-inner>.item.prev.right{-webkit-transform:translate3d(0,0,0);transform:translate3d(0,0,0);left:0}}.carousel-inner>.active,.carousel-inner>.next,.carousel-inner>.prev{display:block}.carousel-inner>.active{left:0}.carousel-inner>.next,.carousel-inner>.prev{position:absolute;top:0;width:100%}.carousel-inner>.next{left:100%}.carousel-inner>.prev{left:-100%}.carousel-inner>.next.left,.carousel-inner>.prev.right{left:0}.carousel-inner>.active.left{left:-100%}.carousel-inner>.active.right{left:100%}.carousel-control{position:absolute;top:0;left:0;bottom:0;width:15%;opacity:.5;filter:alpha(opacity=50);font-size:20px;color:#fff;text-align:center}.carousel-control.left{background-image:-webkit-linear-gradient(left,rgba(0,0,0,.5) 0,rgba(0,0,0,.0001) 100%);background-image:-o-linear-gradient(left,rgba(0,0,0,.5) 0,rgba(0,0,0,.0001) 100%);background-image:-webkit-gradient(linear,left top,right top,from(rgba(0,0,0,.5)),to(rgba(0,0,0,.0001)));background-image:linear-gradient(to right,rgba(0,0,0,.5) 0,rgba(0,0,0,.0001) 100%);background-repeat:repeat-x;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000',endColorstr='#00000000',GradientType=1)}.carousel-control.right{left:auto;right:0;background-image:-webkit-linear-gradient(left,rgba(0,0,0,.0001) 0,rgba(0,0,0,.5) 100%);background-image:-o-linear-gradient(left,rgba(0,0,0,.0001) 0,rgba(0,0,0,.5) 100%);background-image:-webkit-gradient(linear,left top,right top,from(rgba(0,0,0,.0001)),to(rgba(0,0,0,.5)));background-image:linear-gradient(to right,rgba(0,0,0,.0001) 0,rgba(0,0,0,.5) 100%);background-repeat:repeat-x;filter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000',endColorstr='#80000000',GradientType=1)}.carousel-control:focus,.carousel-control:hover{outline:0;color:#fff;text-decoration:none;opacity:.9;filter:alpha(opacity=90)}.carousel-control .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next,.carousel-control .icon-prev{position:absolute;top:50%;z-index:5;display:inline-block}.carousel-control .glyphicon-chevron-left,.carousel-control .icon-prev{left:50%;margin-left:-10px}.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next{right:50%;margin-right:-10px}.carousel-control .icon-next,.carousel-control .icon-prev{width:20px;height:20px;margin-top:-10px;line-height:1;font-family:serif}.carousel-control .icon-prev:before{content:'\\2039'}.carousel-control .icon-next:before{content:'\\203a'}.carousel-indicators{position:absolute;bottom:10px;left:50%;z-index:15;width:60%;margin-left:-30%;text-align:center}.carousel-indicators li{display:inline-block;width:10px;height:10px;margin:1px;text-indent:-999px;border:1px solid #fff;border-radius:10px;cursor:pointer;background-color:#000\\9;background-color:transparent}.carousel-indicators .active{margin:0;width:12px;height:12px;background-color:#fff}.carousel-caption{position:absolute;left:15%;right:15%;bottom:20px;z-index:10;padding-top:20px;padding-bottom:20px;color:#fff;text-align:center}.carousel-caption .btn,.carousel-caption .comment-form input[type=submit],.comment-form .carousel-caption input[type=submit],.text-hide{text-shadow:none}@media screen and (min-width:768px){.carousel-control .glyphicon-chevron-left,.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next,.carousel-control .icon-prev{width:30px;height:30px;margin-top:-15px;font-size:30px}.carousel-control .glyphicon-chevron-left,.carousel-control .icon-prev{margin-left:-15px}.carousel-control .glyphicon-chevron-right,.carousel-control .icon-next{margin-right:-15px}.carousel-caption{left:20%;right:20%;padding-bottom:30px}.carousel-indicators{bottom:20px}}.clearfix:after,.clearfix:before{content:\" \";display:table}.center-block{display:block;margin-left:auto;margin-right:auto}.pull-right{float:right!important}.pull-left{float:left!important}.hide{display:none!important}.show{display:block!important}.hidden,.visible-lg,.visible-lg-block,.visible-lg-inline,.visible-lg-inline-block,.visible-md,.visible-md-block,.visible-md-inline,.visible-md-inline-block,.visible-sm,.visible-sm-block,.visible-sm-inline,.visible-sm-inline-block,.visible-xs,.visible-xs-block,.visible-xs-inline,.visible-xs-inline-block{display:none!important}.invisible{visibility:hidden}.text-hide{font:0/0 a;color:transparent;background-color:transparent;border:0}.affix{position:fixed}@-ms-viewport{width:device-width}@media (max-width:767px){.visible-xs{display:block!important}table.visible-xs{display:table}tr.visible-xs{display:table-row!important}td.visible-xs,th.visible-xs{display:table-cell!important}.visible-xs-block{display:block!important}.visible-xs-inline{display:inline!important}.visible-xs-inline-block{display:inline-block!important}}@media (min-width:768px) and (max-width:991px){.visible-sm{display:block!important}table.visible-sm{display:table}tr.visible-sm{display:table-row!important}td.visible-sm,th.visible-sm{display:table-cell!important}.visible-sm-block{display:block!important}.visible-sm-inline{display:inline!important}.visible-sm-inline-block{display:inline-block!important}}@media (min-width:992px) and (max-width:1199px){.visible-md{display:block!important}table.visible-md{display:table}tr.visible-md{display:table-row!important}td.visible-md,th.visible-md{display:table-cell!important}.visible-md-block{display:block!important}.visible-md-inline{display:inline!important}.visible-md-inline-block{display:inline-block!important}}@media (min-width:1200px){.visible-lg{display:block!important}table.visible-lg{display:table}tr.visible-lg{display:table-row!important}td.visible-lg,th.visible-lg{display:table-cell!important}.visible-lg-block{display:block!important}.visible-lg-inline{display:inline!important}.visible-lg-inline-block{display:inline-block!important}.hidden-lg{display:none!important}}@media (max-width:767px){.hidden-xs{display:none!important}}@media (min-width:768px) and (max-width:991px){.hidden-sm{display:none!important}}@media (min-width:992px) and (max-width:1199px){.hidden-md{display:none!important}}.visible-print{display:none!important}@media print{.visible-print{display:block!important}table.visible-print{display:table}tr.visible-print{display:table-row!important}td.visible-print,th.visible-print{display:table-cell!important}}.visible-print-block{display:none!important}@media print{.visible-print-block{display:block!important}}.visible-print-inline{display:none!important}@media print{.visible-print-inline{display:inline!important}}.visible-print-inline-block{display:none!important}@media print{.visible-print-inline-block{display:inline-block!important}.hidden-print{display:none!important}}.main,.sidebar,.sidebar-primary .main{position:relative;min-height:1px;padding-left:15px;padding-right:15px}.comment-list ol{list-style:none}.alignnone{margin-left:0;margin-right:0;max-width:100%}.aligncenter{display:block;margin:10px auto}.alignleft,.alignright{margin-bottom:10px}@media (min-width:768px){.main{float:left;width:100%}.sidebar-primary .main{float:left;width:66.6666666667%}.sidebar{float:left;width:33.3333333333%}.alignleft{float:left;margin-right:10px}.alignright{float:right;margin-left:10px}}.wp-caption-text{padding:9px}@media (max-width:767px){header .navbar-nav{text-align:right}header .login{margin-top:-7px}footer .navbar li{display:inline-block}}.blog article{padding-bottom:2em}.numlist-padding,.picunit,.single article header{padding-bottom:1em}.blog .widget_categories{display:block;padding-top:1em;padding-left:3em}.page-header,.widget_categories{display:none}.hypo-press{margin-bottom:2em}.presspic img{width:200px!important;height:auto!important;margin-top:1.7em;margin-right:2em}.pic_placeholder{background:#000;height:435px}.picunitimg{-webkit-box-shadow:5px 5px 40px -10px rgba(0,0,0,.2);box-shadow:5px 5px 40px -10px rgba(0,0,0,.2)}.picunit{margin-right:0;padding-right:20px}.picunit img{border-bottom:3px solid #bd1c2b;width:100%;height:100%;-webkit-box-shadow:5px 5px 40px -10px rgba(0,0,0,.1);box-shadow:5px 5px 40px -10px rgba(0,0,0,.1)}@media (max-width:767px){.picunit .caption{font-size:.8em;line-height:1em;margin-top:.4em}img{max-width:100%;height:auto}}@media (min-width:767px){.picunit .caption{font-size:1em;line-height:1em;margin-top:.4em}}.hypo-responsive-modal-image img{max-width:100%;height:auto}.numlist-number{padding-right:1em;color:#bd1c2b;width:8%;min-width:55px}body,html{font-family:lato,sans-serif}body{margin:0}main{margin-bottom:88px}.list li,p{font-weight:300;font-size:1.2em}.list li p{font-size:1em}.red{color:#bd1c2b}.small{font-size:.9em!important}.navbar-default{background-color:transparent;border:none;padding-top:.5em;padding-bottom:2em}.nav>li>a{color:#777}.nav>li>a:hover{color:#333}.social-media a{color:#777;display:inline-block;font-size:18px;line-height:20px;padding:10px 5px}.social-media a:hover{color:#333}.hiring{padding:10px 0;background-color:#bd1c2b;color:#fff}.hiring a{color:#fff;text-decoration:underline}.installer{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex}.nav-browser-chrome .installer__section--bookmarklet{display:none}.installer__section--bookmarklet{display:block;font-size:.9em!important}.installer__section--bookmarklet p{font-size:16px}.installer__section--addtosite{display:block;padding-top:.3em;font-size:.9em!important}a.installer__button--draggable{cursor:move;border-style:dotted;margin-bottom:1em}.btn img,.comment-form input[type=submit] img{width:19px;margin-right:.3em;float:left}.via{width:20em}@media (max-width:768px){.via{width:100%}}@media (min-width:768px) and (max-width:991px){.via{width:13.7em}.nav-browser-firefox .call-to-action,.nav-browser-ie .call-to-action,.nav-browser-opera .call-to-action,.nav-browser-safari .call-to-action{margin-top:-15px}}.installer__section--chrome,.installer__section--firefox,.installer__section--safari{display:none}.nav-browser-chrome .installer__section--chrome,.nav-browser-firefox .installer__section--firefox,.nav-browser-safari .installer__section--safari{display:block}[class*=\" nav-browser-\"] .installer__browser-logo--default,[class^=nav-browser-] .installer__browser-logo--default{display:none}.nav-browser-chrome .installer__section--bookmarklet .installer__browser-logo--chrome,.nav-browser-firefox .installer__section--bookmarklet .installer__browser-logo--firefox,.nav-browser-ie .installer__section--bookmarklet .installer__browser-logo--ie,.nav-browser-opera .installer__section--bookmarklet .installer__browser-logo--opera,.nav-browser-safari .installer__section--bookmarklet .installer__browser-logo--safari{display:block}.or{display:inline-block;margin:.7em}.chrome-mobile-only{display:none!important}@media (max-width:767px){.nav-browser-chrome .chrome-mobile-only{display:block!important;padding-top:.3em;font-size:.9em!important}}.chrome-desktop-only{display:none}@media (min-width:767px){.nav-browser-chrome .chrome-desktop-only{display:block!important;padding-top:.3em;font-size:.9em!important}}#features .row{margin-top:7em}#features .row img{width:100%;height:auto;border:1px solid #DDD;max-width:425px}.container .jumbotron,.container-fluid .jumbotron{background-color:transparent;border:none;padding:48px 10px}.container .jumbotron .row>div,.container-fluid .jumbotron .row>div{padding:0 2em}@media (min-width:992px){.row>div{padding:1em 4em}}@media (max-width:767px){#features{padding-left:20px}#features p{padding-bottom:2em}#features img{max-width:300px}.jumbotron h2{font-size:26px}.jumbotron p{font-size:18px}.call-to-action{padding-left:15px}#video{padding-right:15px}}@media (min-width:768px) and (max-width:991px){.jumbotron{padding-left:10px!important;padding-right:10px!important}.jumbotron h2{font-size:20px}.jumbotron p{font-size:14px;font-weight:300}.call-to-action{padding-left:20px}#video{padding-right:20px}}@media (min-width:992px) and (max-width:1199px){.jumbotron{padding-left:10px!important;padding-right:10px!important}.jumbotron h2{font-size:25px}.jumbotron p{font-size:18px;font-weight:200}}@media (min-width:1200px){.jumbotron p{font-size:20px;font-weight:200}}@media (min-width:1440px){.jumbotron{padding-left:60px;padding-right:60px}.jumbotron p{font-size:21px;font-weight:200}}\n"},{"size":2548,"relativepath":"h/static/scripts/karma.config.js","filename":"karma.config.js","extension":".js","content":"'use strict';\n\nmodule.exports = function(config) {\n  config.set({\n\n    // base path that will be used to resolve all patterns (eg. files, exclude)\n    basePath: './',\n\n    // frameworks to use\n    // available frameworks: https://npmjs.org/browse/keyword/karma-adapter\n    frameworks: [\n      'browserify',\n      'mocha',\n      'chai',\n      'sinon',\n    ],\n\n    // list of files / patterns to load in the browser\n    files: [\n      // Polyfills for PhantomJS\n      './polyfills.js',\n\n      // Test setup\n      './tests/bootstrap.js',\n\n      // Karma watching is disabled for these files because they are\n      // bundled with karma-browserify which handles watching itself via\n      // watchify\n      { pattern: 'tests/**/*-test.js', watched: false, included: true, served: true },\n    ],\n\n    // list of files to exclude\n    exclude: [\n    ],\n\n    // preprocess matching files before serving them to the browser\n    // available preprocessors: https://npmjs.org/browse/keyword/karma-preprocessor\n    preprocessors: {\n      './polyfills.js': ['browserify'],\n      './tests/bootstrap.js': ['browserify'],\n      './tests/**/*-test.js': ['browserify'],\n    },\n\n    browserify: {\n      debug: true,\n      configure: function (bundle) {\n        bundle.plugin('proxyquire-universal');\n      },\n    },\n\n    mochaReporter: {\n      // Display a helpful diff when comparing complex objects\n      // See https://www.npmjs.com/package/karma-mocha-reporter#showdiff\n      showDiff: true,\n      // Only show the total test counts and details for failed tests\n      output: 'minimal',\n    },\n\n    // Use https://www.npmjs.com/package/karma-mocha-reporter\n    // for more helpful rendering of test failures\n    reporters: ['mocha'],\n\n    // web server port\n    port: 9876,\n\n    // enable / disable colors in the output (reporters and logs)\n    colors: true,\n\n    // level of logging\n    // possible values: config.LOG_DISABLE || config.LOG_ERROR || config.LOG_WARN || config.LOG_INFO || config.LOG_DEBUG\n    logLevel: config.LOG_INFO,\n\n    // enable / disable watching file and executing tests whenever any file changes\n    autoWatch: true,\n\n    // start these browsers\n    // available browser launchers: https://npmjs.org/browse/keyword/karma-launcher\n    browsers: ['PhantomJS'],\n    browserNoActivityTimeout: 20000, // Travis is slow...\n\n    // Continuous Integration mode\n    // if true, Karma captures browsers, runs the tests and exits\n    singleRun: false,\n\n    // Log slow tests so we can fix them before they timeout\n    reportSlowerThan: 500,\n  });\n};\n"},{"size":1609,"relativepath":"h/static/scripts/tests/base/raven-test.js","filename":"raven-test.js","extension":".js","content":"'use strict';\n\nvar proxyquire = require('proxyquire');\nvar noCallThru = require('../util').noCallThru;\n\ndescribe('raven', function () {\n  var fakeRavenJS;\n  var raven;\n\n  beforeEach(function () {\n    fakeRavenJS = {\n      config: sinon.stub().returns({\n        install: sinon.stub(),\n      }),\n\n      captureException: sinon.stub(),\n    };\n\n    raven = proxyquire('../../base/raven', noCallThru({\n      'raven-js': fakeRavenJS,\n    }));\n  });\n\n  describe('.install()', function () {\n    it('installs a handler for uncaught promises', function () {\n      raven.init({\n        dsn: 'dsn',\n        release: 'release',\n      });\n      var event = document.createEvent('Event');\n      event.initEvent('unhandledrejection', true /* bubbles */, true /* cancelable */);\n      event.reason = new Error('Some error');\n      window.dispatchEvent(event);\n\n      assert.calledWith(fakeRavenJS.captureException, event.reason,\n        sinon.match.any);\n    });\n  });\n\n  describe('.report()', function () {\n    it('extracts the message property from Error-like objects', function () {\n      raven.report({message: 'An error'}, 'context');\n      assert.calledWith(fakeRavenJS.captureException, 'An error', {\n        extra: {\n          when: 'context',\n        },\n      });\n    });\n\n    it('passes extra details through', function () {\n      var error = new Error('an error');\n      raven.report(error, 'some operation', { url: 'foobar.com' });\n      assert.calledWith(fakeRavenJS.captureException, error, {\n        extra: {\n          when: 'some operation',\n          url: 'foobar.com',\n        },\n      });\n    });\n  });\n});\n"},{"size":3055,"relativepath":"h/static/scripts/tests/base/environment-flags-test.js","filename":"environment-flags-test.js","extension":".js","content":"'use strict';\n\nvar EnvironmentFlags = require('../../base/environment-flags');\n\nvar TIMEOUT_DELAY = 10000;\n\ndescribe('EnvironmentFlags', function () {\n  var clock;\n  var el;\n  var flags;\n\n  beforeEach(function () {\n    el = document.createElement('div');\n    flags = new EnvironmentFlags(el);\n    clock = sinon.useFakeTimers();\n  });\n\n  afterEach(function () {\n    clock.restore();\n  });\n\n  describe('#init', function () {\n    it('should mark document as JS capable on load', function () {\n      flags.init();\n      assert.isTrue(el.classList.contains('env-js-capable'));\n    });\n\n    it('should mark JS load as failed after a timeout', function () {\n      flags.init();\n      clock.tick(TIMEOUT_DELAY);\n      assert.isTrue(el.classList.contains('env-js-timeout'));\n    });\n\n    it('should not add \"env-touch\" flag if touch events are not supported', function () {\n      flags.init();\n      assert.isFalse(el.classList.contains('env-touch'));\n    });\n\n    it('should add \"env-touch\" flag if touch events are available', function () {\n      el.ontouchstart = function () {};\n      flags.init();\n      assert.isTrue(el.classList.contains('env-touch'));\n    });\n\n    it('should add flags specified in the document URL', function () {\n      flags.init('http://example.org/?__env__=touch;js-timeout');\n      assert.isTrue(el.classList.contains('env-touch'));\n      assert.isTrue(el.classList.contains('env-js-timeout'));\n    });\n\n    it('should remove flags with a \"no-\" prefix specified in the document URL', function () {\n      flags.init('http://example.org/?__env__=no-js-capable');\n      assert.isFalse(el.classList.contains('env-js-capable'));\n    });\n\n    it('should remove \"js-capable\" flag if \"nojs=1\" is present in URL', function () {\n      flags.init('http://example.org/?nojs=1');\n      assert.isFalse(el.classList.contains('env-js-capable'));\n    });\n  });\n\n  describe('#ready', function () {\n    it('should prevent JS load timeout flag from being set', function () {\n      flags.init();\n      flags.ready();\n      clock.tick(TIMEOUT_DELAY);\n      assert.isFalse(el.classList.contains('env-js-timeout'));\n    });\n\n    it('should not clear timeout flag if already set', function () {\n      flags.init();\n      clock.tick(TIMEOUT_DELAY);\n      flags.ready();\n      assert.isTrue(el.classList.contains('env-js-timeout'));\n    });\n  });\n\n  describe('#set', function () {\n    it('should add a flag if `on` is true', function () {\n      flags.set('shiny-feature', true);\n      assert.isTrue(el.classList.contains('env-shiny-feature'));\n    });\n\n    it('should remove a flag if `on` is false', function () {\n      flags.set('shiny-feature', false);\n      assert.isFalse(el.classList.contains('env-shiny-feature'));\n    });\n  });\n\n  describe('#get', function () {\n    it('should return true if the flag is set', function () {\n      flags.set('shiny-feature', true);\n      assert.isTrue(flags.get('shiny-feature'));\n    });\n\n    it('should return false if the flag is set', function () {\n      assert.isFalse(flags.get('shiny-feature'));\n    });\n  });\n});\n"},{"size":1426,"relativepath":"h/static/scripts/tests/base/settings-test.js","filename":"settings-test.js","extension":".js","content":"'use strict';\n\nvar settings = require('../../base/settings');\n\nfunction createJSONScriptTag(obj, className) {\n  var el = document.createElement('script');\n  el.type = 'application/json';\n  el.textContent = JSON.stringify(obj);\n  el.classList.add(className);\n  el.classList.add('js-settings-test');\n  return el;\n}\n\nfunction removeJSONScriptTags() {\n  var elements = document.querySelectorAll('.js-settings-test');\n  for (var i=0; i < elements.length; i++) {\n    elements[i].parentNode.removeChild(elements[i]);\n  }\n}\n\ndescribe('settings', function () {\n  afterEach(removeJSONScriptTags);\n\n  it('reads config from .js-hypothesis-settings <script> tags', function () {\n    document.body.appendChild(createJSONScriptTag({key:'value'},\n      'js-hypothesis-settings'));\n    assert.deepEqual(settings(document), {key:'value'});\n  });\n\n  it('reads config from <script> tags with the specified class name', function () {\n    document.body.appendChild(createJSONScriptTag({foo:'bar'},\n      'js-custom-settings'));\n    assert.deepEqual(settings(document), {});\n    assert.deepEqual(settings(document, 'js-custom-settings'), {foo:'bar'});\n  });\n\n  it('merges settings from all config <script> tags', function () {\n    document.body.appendChild(createJSONScriptTag({a: 1}, 'settings'));\n    document.body.appendChild(createJSONScriptTag({b: 2}, 'settings'));\n    assert.deepEqual(settings(document, 'settings'), {a: 1, b: 2});\n  });\n});\n"},{"size":1264,"relativepath":"h/static/scripts/tests/base/controller-test.js","filename":"controller-test.js","extension":".js","content":"'use strict';\n\nvar Controller = require('../../base/controller');\n\nclass TestController extends Controller {\n  constructor(element, options) {\n    super(element, options);\n    this.update = sinon.stub();\n  }\n}\n\ndescribe('Controller', function () {\n  var ctrl;\n\n  beforeEach(function () {\n    var root = document.createElement('div');\n    root.innerHTML = '<div data-ref=\"test\"></div>';\n    document.body.appendChild(root);\n    ctrl = new TestController(root);\n  });\n\n  afterEach(function () {\n    ctrl.element.remove();\n  });\n\n  it('exposes controllers via the `.controllers` element property', function () {\n    assert.equal(ctrl.element.controllers.length, 1);\n    assert.instanceOf(ctrl.element.controllers[0], TestController);\n  });\n\n  it('exposes elements with \"data-ref\" attributes on the `refs` property', function () {\n    assert.deepEqual(ctrl.refs, {test: ctrl.element.children[0]});\n  });\n\n  describe('#setState', function () {\n    it('calls update() with new and previous state', function () {\n      ctrl.setState({open: true});\n      ctrl.update = sinon.stub();\n      ctrl.setState({open: true, saving: true});\n      assert.calledWith(ctrl.update, {\n        open: true,\n        saving: true,\n      }, {\n        open: true,\n      });\n    });\n  });\n});\n"},{"size":2848,"relativepath":"h/static/scripts/tests/base/upgrade-elements-test.js","filename":"upgrade-elements-test.js","extension":".js","content":"'use strict';\n\nvar Controller = require('../../base/controller');\nvar upgradeElements = require('../../base/upgrade-elements');\n\nclass TestController extends Controller {\n  constructor(element, options) {\n    super(element, options);\n  }\n}\n\ndescribe('upgradeElements', function () {\n  it('should upgrade elements matching selectors', function () {\n    var root = document.createElement('div');\n    root.innerHTML = '<div class=\"js-test\"></div>';\n\n    upgradeElements(root, {'.js-test': TestController});\n\n    assert.instanceOf(root.children[0].controllers[0], TestController);\n  });\n\n  it('should unhide elements hidden until upgrade', function () {\n    var root = document.createElement('div');\n    root.innerHTML = '<div class=\"js-test is-hidden-when-loading\"></div>';\n\n    upgradeElements(root, {'.js-test': TestController});\n\n    assert.equal(root.querySelectorAll('.is-hidden-when-loading').length, 0);\n  });\n\n  it('should unhide child elements hidden until upgrade', function () {\n    var root = document.createElement('div');\n    root.innerHTML = '<div class=\"js-test\">' +\n                     '<span class=\"is-hidden-when-loading\"></span>' +\n                     '</div>';\n\n    upgradeElements(root, {'.js-test': TestController});\n\n    assert.equal(root.querySelectorAll('.is-hidden-when-loading').length, 0);\n  });\n\n  describe('reload function', function () {\n    var newContent = '<div class=\"js-test\">Reloaded element</div>';\n\n    function setupAndReload() {\n      var root = document.createElement('div');\n      root.innerHTML = '<div class=\"js-test\">Original content</div>';\n      upgradeElements(root, {'.js-test': TestController});\n\n      var reloadFn = root.children[0].controllers[0].options.reload;\n      var reloadResult = reloadFn(newContent);\n      return {root: root, reloadResult: reloadResult};\n    }\n\n    it('replaces element markup', function () {\n      var root = setupAndReload().root;\n      assert.equal(root.innerHTML, newContent);\n    });\n\n    it('returns the replaced element', function () {\n      var result = setupAndReload();\n      assert.equal(result.root.children[0], result.reloadResult);\n    });\n\n    it('re-applies element upgrades', function () {\n      var root = setupAndReload().root;\n      var replacedElement = root.children[0];\n      var ctrl = replacedElement.controllers[0];\n      assert.instanceOf(ctrl, TestController);\n    });\n\n    it('calls #beforeRemove on the original controllers', function () {\n      var root = document.createElement('div');\n      root.innerHTML = '<div class=\"js-test\">Original content</div>';\n      upgradeElements(root, {'.js-test': TestController});\n      var ctrl = root.children[0].controllers[0];\n      ctrl.beforeRemove = sinon.stub();\n      var reloadFn = ctrl.options.reload;\n\n      reloadFn(newContent);\n\n      assert.called(ctrl.beforeRemove);\n    });\n  });\n});\n"},{"size":2970,"relativepath":"h/static/scripts/tests/util.js","filename":"util.js","extension":".js","content":"'use strict';\n\n/**\n * Utility function for use with 'proxyquire' that prevents calls to\n * stubs 'calling through' to the _original_ dependency if a particular\n * function or property is not set on a stub, which is proxyquire's default\n * but usually undesired behavior.\n *\n * See https://github.com/thlorenz/proxyquireify#nocallthru\n *\n * Usage:\n *   var moduleUnderTest = proxyquire('./module-under-test', noCallThru({\n *     './dependency-foo': fakeFoo,\n *   }));\n *\n * @param {Object} stubs - A map of dependency paths to stubs, or a single\n *   stub.\n */\nfunction noCallThru(stubs) {\n  // This function is trivial but serves as documentation for why\n  // '@noCallThru' is used.\n  return Object.assign(stubs, {'@noCallThru':true});\n}\n\n/**\n * Helper for writing parameterized tests.\n *\n * This is a wrapper around the `it()` function for creating a Mocha test case\n * which takes an array of fixture objects and calls it() once for each fixture,\n * passing in the fixture object as an argument to the test function.\n *\n * Usage:\n *   unroll('should return #output with #input', function (fixture) {\n *     assert.equal(functionUnderTest(fixture.input), fixture.output);\n *   },[\n *    {input: 'foo', output: 'bar'}\n *   ]);\n *\n * Based on https://github.com/lawrencec/Unroll with the following changes:\n *\n *  1. Support for test functions that return promises\n *  2. Mocha's `it()` is the only supported test function\n *  3. Fixtures are objects rather than arrays\n *\n * @param {string} description - Description with optional '#key' placeholders\n *        which are replaced by the values of the corresponding key from each\n *        fixture object.\n * @param {Function} testFn - Test function which can accept either `fixture`\n *        or `done, fixture` as arguments, where `done` is the callback for\n *        reporting completion of an async test and `fixture` is an object\n *        from the `fixtures` array.\n * @param {Array<T>} fixtures - Array of fixture objects.\n */\nfunction unroll(description, testFn, fixtures) {\n  fixtures.forEach(function (fixture) {\n    var caseDescription = Object.keys(fixture).reduce(function (desc, key) {\n      return desc.replace('#' + key, String(fixture[key]));\n    }, description);\n    it(caseDescription, function (done) {\n      if (testFn.length === 1) {\n        // Test case does not accept a 'done' callback argument, so we either\n        // call done() immediately if it returns a non-Promiselike object\n        // or when the Promise resolves otherwise\n        var result = testFn(fixture);\n        if (typeof result === 'object' && result.then) {\n          result.then(function () { done(); }, done);\n        } else {\n          done();\n        }\n      } else {\n        // Test case accepts a 'done' callback argument and takes responsibility\n        // for calling it when the test completes.\n        testFn(done, fixture);\n      }\n    });\n  });\n}\n\nmodule.exports = {\n  noCallThru: noCallThru,\n  unroll: unroll,\n};\n"},{"size":92,"relativepath":"h/static/scripts/tests/bootstrap.js","filename":"bootstrap.js","extension":".js","content":"'use strict';\n\n// Expose the sinon assertions.\nsinon.assert.expose(assert, {prefix: null});\n"},{"size":420,"relativepath":"h/static/scripts/tests/promise-util.js","filename":"promise-util.js","extension":".js","content":"'use strict';\n\n/**\n * Takes a Promise<T> and returns a Promise<Result>\n * where Result = { result: T } | { error: any }.\n *\n * This is useful for testing that promises are rejected\n * as expected in tests.\n */\nfunction toResult(promise) {\n  return promise.then(function (result) {\n    return { result: result };\n  }).catch(function (err) {\n    return { error: err };\n  });\n}\n\nmodule.exports = {\n  toResult: toResult,\n};\n"},{"size":720,"relativepath":"h/static/scripts/tests/util/string-test.js","filename":"string-test.js","extension":".js","content":"'use strict';\n\nvar stringUtil = require('../../util/string');\n\ndescribe('util/string', function () {\n  describe('hyphenate', function () {\n    it('converts input to kebab-case', function () {\n      assert.equal(stringUtil.hyphenate('fooBar'), 'foo-bar');\n      assert.equal(stringUtil.hyphenate('FooBar'), '-foo-bar');\n    });\n  });\n\n  describe('unhyphenate', function () {\n    it('converts input to camelCase', function () {\n      assert.equal(stringUtil.unhyphenate('foo-bar'), 'fooBar');\n      assert.equal(stringUtil.unhyphenate('foo-bar-'), 'fooBar');\n      assert.equal(stringUtil.unhyphenate('foo-bar-baz'), 'fooBarBaz');\n      assert.equal(stringUtil.unhyphenate('-foo-bar-baz'), 'FooBarBaz');\n    });\n  });\n});\n"},{"size":958,"relativepath":"h/static/scripts/tests/util/search-text-parser-test.js","filename":"search-text-parser-test.js","extension":".js","content":"'use strict';\n\nvar searchTextParser = require('../../util/search-text-parser');\nvar unroll = require('../util').unroll;\n\ndescribe('SearchTextParser', function () {\n  unroll('should create a lozenge #input', function (fixture) {\n    assert.isTrue(searchTextParser.shouldLozengify(fixture.input));\n  },[\n    {input: 'foo'},\n    {input: '    foo    '},\n    {input: '\"foo bar\"'},\n    {input: '\\'foo bar\\''},\n    {input: 'foo:\"bar\"'},\n    {input: 'foo:\\'bar\\''},\n    {input: 'foo:\\'bar1 bar2\\''},\n    {input: 'foo:\"bar1 bar2\"'},\n    {input: 'foo:'},\n    {input: '\\'foo\\':'},\n    {input: '\"foo\":'},\n    {input: 'foo\"bar:'},\n    {input: 'foo\\'bar:'},\n  ]);\n\n  unroll('should not create a lozenge for', function (fixture) {\n    assert.isFalse(searchTextParser.shouldLozengify(fixture.input));\n  },[\n    {input: 'foo\\''},\n    {input: 'foo\\\"'},\n    {input: '\\'foo'},\n    {input: '\\\"foo'},\n    {input: ''},\n    {input: 'foo:\\'bar'},\n    {input: 'foo:\\\"bar'},\n  ]);\n});\n"},{"size":1848,"relativepath":"h/static/scripts/tests/util/submit-form-test.js","filename":"submit-form-test.js","extension":".js","content":"'use strict';\n\nvar fetchMock = require('fetch-mock');\n\nvar submitForm = require('../../util/submit-form');\n\ndescribe('submitForm', function () {\n  var FORM_URL = 'http://example.org/things';\n\n  function mockResponse(response) {\n    fetchMock.post(FORM_URL, response);\n  }\n\n  function createForm() {\n    var form = document.createElement('form');\n    form.action = FORM_URL;\n    form.method = 'POST';\n    form.innerHTML = '<input name=\"field\" value=\"value\">';\n    return form;\n  }\n\n  it('submits the form data', function () {\n    var form = createForm();\n    mockResponse('<form><!-- updated form !--></form>');\n\n    return submitForm(form, fetchMock.fetchMock).then(function () {\n      var [,requestInit] = fetchMock.lastCall(FORM_URL);\n      assert.instanceOf(requestInit.body, FormData);\n    });\n  });\n\n  it('returns the markup for the updated form if validation succeeds', function () {\n    var form = createForm();\n    var responseBody = '<form><!-- updated form !--></form>';\n    mockResponse(responseBody);\n\n    return submitForm(form, fetchMock.fetchMock).then(function (response) {\n      assert.equal(response.form, responseBody);\n    });\n  });\n\n  it('rejects with the updated form markup if validation fails', function () {\n    var form = createForm();\n    mockResponse({status: 400, body: 'response'});\n\n    var done = submitForm(form, fetchMock.fetchMock);\n\n    return done.catch(err => {\n      assert.match(err, sinon.match({status: 400, form: 'response'}));\n    });\n  });\n\n  it('rejects with an error message if submission fails', function () {\n    var form = createForm();\n    mockResponse({status: 500, statusText: 'Internal Server Error'});\n\n    var done = submitForm(form, fetchMock.fetchMock);\n\n    return done.catch(err => {\n      assert.match(err, sinon.match({status: 500, reason: 'Internal Server Error'}));\n    });\n  });\n});\n"},{"size":1791,"relativepath":"h/static/scripts/tests/util/modal-focus-test.js","filename":"modal-focus-test.js","extension":".js","content":"'use strict';\n\nvar modalFocus = require('../../util/modal-focus');\n\ndescribe('util/modal-focus', function () {\n  // Elements inside the focus group\n  var insideEls;\n  // Element outside the focus group\n  var outsideEl;\n  var onFocusOut;\n  var releaseFocus;\n\n  beforeEach(function () {\n    insideEls = [1,2,3].map(() => document.createElement('input'));\n    insideEls.forEach(el => document.body.appendChild(el));\n\n    outsideEl = document.createElement('input');\n    document.body.appendChild(outsideEl);\n\n    onFocusOut = sinon.stub();\n    releaseFocus = modalFocus.trap(insideEls, onFocusOut);\n  });\n\n  afterEach(function () {\n    insideEls.forEach(el => el.remove());\n    releaseFocus();\n  });\n\n  describe('#trap', function () {\n    it('does not invoke the callback when an element in the group is focused', function () {\n      insideEls[0].focus();\n      insideEls[1].focus();\n      assert.notCalled(onFocusOut);\n    });\n\n    it('invokes the callback when an element outside the group is focused', function () {\n      outsideEl.focus();\n      assert.calledWith(onFocusOut, outsideEl);\n    });\n\n    it('does not prevent the focus change if the callback returns null', function () {\n      onFocusOut.returns(null);\n      outsideEl.focus();\n      assert.equal(document.activeElement, outsideEl);\n    });\n\n    it('prevents a focus change if the callback returns an element', function () {\n      onFocusOut.returns(insideEls[0]);\n      outsideEl.focus();\n      assert.equal(document.activeElement, insideEls[0]);\n    });\n\n    it('releases focus when returned function is called', function () {\n      onFocusOut.returns(insideEls[0]);\n\n      releaseFocus();\n      outsideEl.focus();\n\n      assert.notCalled(onFocusOut);\n      assert.equal(document.activeElement, outsideEl);\n    });\n  });\n});\n"},{"size":1648,"relativepath":"h/static/scripts/tests/util/dom-test.js","filename":"dom-test.js","extension":".js","content":"'use strict';\n\nvar domUtil = require('../../util/dom');\n\ndescribe('util/dom', function () {\n  function createDOM(html) {\n    var el = document.createElement('div');\n    el.innerHTML = html;\n    var child = el.children[0];\n    document.body.appendChild(child);\n    el.remove();\n    return child;\n  }\n\n  describe('findRefs', function () {\n    it('returns a map of name to DOM element', function () {\n      var root = createDOM(`\n        <div>\n          <label data-ref=\"label\">Input label</label>\n          <input data-ref=\"input\">\n        </div>\n      `);\n      var labelEl = root.querySelector('label');\n      var inputEl = root.querySelector('input');\n\n      assert.deepEqual(domUtil.findRefs(root), {\n        label: labelEl,\n        input: inputEl,\n      });\n    });\n\n    it('allows elements to have more than one name', function () {\n      var root = createDOM('<div><div data-ref=\"one two\"></div></div>');\n      assert.deepEqual(domUtil.findRefs(root), {\n        one: root.firstChild,\n        two: root.firstChild,\n      });\n    });\n  });\n\n  describe('setElementState', function () {\n    it('adds \"is-$state\" classes for keys with truthy values', function () {\n      var btn = createDOM('<button></button>');\n      domUtil.setElementState(btn, {\n        visible: true,\n      });\n      assert.deepEqual(Array.from(btn.classList), ['is-visible']);\n    });\n\n    it('removes \"is-$state\" classes for keys with falsey values', function () {\n      var btn = createDOM('<button class=\"is-hidden\"></button>');\n      domUtil.setElementState(btn, {\n        hidden: false,\n      });\n      assert.deepEqual(Array.from(btn.classList), []);\n    });\n  });\n});\n"},{"size":991,"relativepath":"h/static/scripts/tests/controllers/lozenge-controller-test.js","filename":"lozenge-controller-test.js","extension":".js","content":"'use strict';\n\nvar LozengeController = require('../../controllers/lozenge-controller');\n\ndescribe('LozengeController', function () {\n  var el;\n  var opts;\n  var lozengeEl;\n  var lozengeContentEl;\n  var lozengeDeleteEl;\n\n  beforeEach(function () {\n    el = document.createElement('div');\n    opts = {\n      content: 'foo',\n      deleteCallback: sinon.spy(),\n    };\n\n    new LozengeController(el, opts);\n    lozengeEl = el.querySelector('.js-lozenge');\n    lozengeContentEl = lozengeEl.querySelector('.js-lozenge__content');\n    lozengeDeleteEl = lozengeEl.querySelector('.js-lozenge__close');\n  });\n\n  it('creates a new lozenge inside the container provided', function () {\n    assert.equal(lozengeContentEl.textContent, opts.content);\n  });\n\n  it('removes the lozenge and executes the delete callback provided', function () {\n    lozengeDeleteEl.dispatchEvent(new Event('mousedown'));\n    assert(opts.deleteCallback.calledOnce);\n    assert.isNull(el.querySelector('.js-lozenge'));\n  });\n});\n"},{"size":739,"relativepath":"h/static/scripts/tests/controllers/util.js","filename":"util.js","extension":".js","content":"'use strict';\n\n/**\n * Helper to set up a component for a controller test\n *\n * @param {Document} document - Document to create component in\n * @param {string} template - HTML markup for the component\n * @param {Controller} controller - The controller class\n * @param {Object} [options] - Options to pass to the controller constructor\n * @return {Controller} - The controller instance\n */\nfunction setupComponent(document, template, ControllerClass, options) {\n  var container = document.createElement('div');\n  container.innerHTML = template;\n  var root = container.firstChild;\n  document.body.appendChild(root);\n  container.remove();\n  return new ControllerClass(root, options);\n}\n\nmodule.exports = {\n  setupComponent: setupComponent,\n};\n"},{"size":1383,"relativepath":"h/static/scripts/tests/controllers/dropdown-menu-controller-test.js","filename":"dropdown-menu-controller-test.js","extension":".js","content":"'use strict';\n\nvar DropdownMenuController = require('../../controllers/dropdown-menu-controller');\nvar util = require('./util');\n\nvar TEMPLATE = ['<div class=\"js-dropdown-menu\">',\n                '<span data-ref=\"dropdownMenuToggle\">Toggle</span>',\n                '<span data-ref=\"dropdownMenuContent\">Menu</span>',\n                '</div>'].join('\\n');\n\ndescribe('DropdownMenuController', function () {\n  var ctrl;\n  var toggleEl;\n  var menuEl;\n\n  beforeEach(function () {\n    ctrl = util.setupComponent(document, TEMPLATE, DropdownMenuController);\n    toggleEl = ctrl.refs.dropdownMenuToggle;\n    menuEl = ctrl.refs.dropdownMenuContent;\n  });\n\n  afterEach(function () {\n    ctrl.element.remove();\n  });\n\n  function isOpen() {\n    return menuEl.classList.contains('is-open');\n  }\n\n  it('should toggle menu on click', function () {\n    toggleEl.dispatchEvent(new Event('click'));\n    assert.isTrue(isOpen());\n    toggleEl.dispatchEvent(new Event('click'));\n    assert.isFalse(isOpen());\n  });\n\n  it('should close menu on click outside', function () {\n    toggleEl.dispatchEvent(new Event('click'));\n    document.body.dispatchEvent(new Event('click'));\n    assert.isFalse(isOpen());\n  });\n\n  it('should not close menu on click inside', function () {\n    toggleEl.dispatchEvent(new Event('click'));\n    menuEl.dispatchEvent(new Event('click'));\n    assert.isTrue(isOpen());\n  });\n});\n"},{"size":1753,"relativepath":"h/static/scripts/tests/controllers/search-bucket-controller-test.js","filename":"search-bucket-controller-test.js","extension":".js","content":"'use strict';\n\nvar SearchBucketController = require('../../controllers/search-bucket-controller');\nvar util = require('./util');\n\nvar TEMPLATE = [\n  '<div class=\"js-search-bucket\">',\n  '<div data-ref=\"header\"></div>',\n  '<div data-ref=\"content\"></div>',\n  '</div>',\n].join('\\n');\n\nclass FakeEnvFlags {\n  constructor (flags = []) {\n    this.flags = flags;\n  }\n\n  get(flag) {\n    return this.flags.indexOf(flag) !== -1;\n  }\n}\n\ndescribe('SearchBucketController', function () {\n  var ctrl;\n\n  beforeEach(function () {\n    ctrl = util.setupComponent(document, TEMPLATE, SearchBucketController, {\n      envFlags: new FakeEnvFlags(),\n    });\n  });\n\n  afterEach(function () {\n    ctrl.element.remove();\n  });\n\n  it('toggles content hidden state when clicked', function () {\n    ctrl.refs.header.dispatchEvent(new Event('click'));\n    assert.isFalse(ctrl.refs.content.classList.contains('is-hidden'));\n  });\n\n  it('scrolls element into view when expanded', function () {\n    ctrl.scrollTo = sinon.stub();\n    ctrl.refs.header.dispatchEvent(new Event('click'));\n    assert.calledWith(ctrl.scrollTo, ctrl.element);\n  });\n\n  it('collapses search results on initial load', function () {\n    assert.isFalse(ctrl.state.expanded);\n  });\n\n  context('when initial load times out', function () {\n    var scrollTo;\n\n    beforeEach(function () {\n      scrollTo = sinon.stub();\n      ctrl = util.setupComponent(document, TEMPLATE, SearchBucketController, {\n        scrollTo: scrollTo,\n        envFlags: new FakeEnvFlags(['js-timeout']),\n      });\n    });\n\n    it('does not scroll page on initial load', function () {\n      assert.notCalled(scrollTo);\n    });\n\n    it('expands bucket on initial load', function () {\n      assert.isTrue(ctrl.state.expanded);\n    });\n  });\n});\n"},{"size":10214,"relativepath":"h/static/scripts/tests/controllers/search-bar-controller-test.js","filename":"search-bar-controller-test.js","extension":".js","content":"'use strict';\n\nvar syn = require('syn');\n\nvar SearchBarController = require('../../controllers/search-bar-controller');\n\nfunction center(element) {\n  let rect = element.getBoundingClientRect();\n  return {\n    pageX: rect.left + (rect.width / 2),\n    pageY: rect.top + (rect.height / 2),\n  };\n}\n\nfunction isActiveItem(element) {\n  return element.classList.contains('js-search-bar-dropdown-menu-item--active');\n}\n\ndescribe('SearchBarController', function () {\n  describe('Dropdown', function () {\n    var testEl;\n    var input;\n    var dropdown;\n    var dropdownItems;\n    var ctrl;\n    var form;\n    var TEMPLATE = `\n      <form>\n        <div class=\"search-bar__lozenges\" data-ref=\"searchBarLozenges\">\n        </div>\n        <input data-ref=\"searchBarInput\" class=\"search-bar__input\" />\n        <input data-ref=\"searchBarInputHidden\" class=\"js-search-bar__input-hidden\" name=\"q\" value=\"foo\" />\n        <div data-ref=\"searchBarDropdown\">\n          <div>Narrow your search</div>\n          <ul>\n            <li data-ref=\"searchBarDropdownItem\">\n              <span data-ref=\"searchBarDropdownItemTitle\">\n                user:\n              </span>\n            </li>\n            <li data-ref=\"searchBarDropdownItem\">\n              <span data-ref=\"searchBarDropdownItemTitle\">\n                tag:\n              </span>\n            </li>\n            <li data-ref=\"searchBarDropdownItem\">\n              <span data-ref=\"searchBarDropdownItemTitle\">\n                url:\n              </span>\n            </li>\n            <li data-ref=\"searchBarDropdownItem\">\n              <span data-ref=\"searchBarDropdownItemTitle\">\n                group:\n              </span>\n            </li>\n          </ul>\n        </div>\n      </form>\n    `;\n\n    beforeEach(function () {\n      testEl = document.createElement('div');\n      testEl.innerHTML = TEMPLATE;\n      document.body.appendChild(testEl);\n\n      ctrl = new SearchBarController(testEl);\n\n      input = ctrl.refs.searchBarInput;\n      dropdown = ctrl.refs.searchBarDropdown;\n      dropdownItems = testEl.querySelectorAll('[data-ref=\"searchBarDropdownItem\"]');\n      form = testEl.querySelector('form');\n\n      form.addEventListener('submit', event => { event.preventDefault(); });\n    });\n\n    afterEach(function () {\n      document.body.removeChild(testEl);\n    });\n\n    it('dropdown appears when the input field has focus', function (done) {\n      syn\n        .click(input, () => {\n          assert.isTrue(dropdown.classList.contains('is-open'));\n          done();\n        });\n    });\n\n    it('dropdown is hidden when the input field loses focus', function (done) {\n      syn\n        .click(input)\n        .click(document.body, () => {\n          assert.isFalse(dropdown.classList.contains('is-open'));\n          done();\n        });\n    });\n\n    it('selects facet from dropdown on mousedown', function (done) {\n      syn\n        .click(input)\n        .click(dropdownItems[0], () => {\n          assert.equal(input.value, 'user:');\n          done();\n        });\n    });\n\n    it('highlights facet on up arrow', function (done) {\n      syn\n        .click(input)\n        .type('[up]', () => {\n          assert.isOk(isActiveItem(dropdownItems[3]));\n          done();\n        });\n    });\n\n    it('highlights facet on down arrow', function (done) {\n      syn\n        .click(input)\n        .type('[down]', () => {\n          assert.isOk(isActiveItem(dropdownItems[0]));\n          done();\n        });\n    });\n\n    it('highlights the correct facet for a combination of mouseover, up and down arrow keys', function (done) {\n      let itemThreeCenter = center(dropdownItems[2]);\n      syn\n        .click(input)\n        // Down arrow to select first item\n        .type('[down]', () => {\n          assert.isOk(isActiveItem(dropdownItems[0]));\n        })\n        // Move mouse from input to the middle of the third item.\n        .move({\n          from: center(input),\n          to: itemThreeCenter,\n          duration: 100,\n        }, () => {\n          assert.isNotOk(isActiveItem(dropdownItems[0]));\n          assert.isOk(isActiveItem(dropdownItems[2]));\n        })\n        // Up arrow to select second item.\n        .type('[up]', () => {\n          assert.isNotOk(isActiveItem(dropdownItems[2]));\n          assert.isOk(isActiveItem(dropdownItems[1]));\n        })\n        // Jiggle the mouse just a little over the third item.\n        .move({\n          from: itemThreeCenter,\n          to: {\n            pageX: itemThreeCenter.pageX + 1,\n            pageY: itemThreeCenter.pageY + 1,\n          },\n          duration: 10,\n        }, () => {\n          assert.isNotOk(isActiveItem(dropdownItems[1]));\n          assert.isOk(isActiveItem(dropdownItems[2]));\n        })\n        // Down arrow to select the fourth item.\n        .type('[down]', () => {\n          assert.isNotOk(isActiveItem(dropdownItems[2]));\n          assert.isOk(isActiveItem(dropdownItems[3]));\n          done();\n        });\n    });\n\n    it('selects facet on enter', function (done) {\n      syn\n        .click(input)\n        .type('[down][enter]', () => {\n          assert.equal(input.value, 'user:');\n          done();\n        });\n    });\n\n    it('dropdown stays open when clicking on a part of it that is not one of the suggestions', function (done) {\n      syn\n        .click(input)\n        .click(dropdown.querySelector('div'), () => {\n          assert.isTrue(dropdown.classList.contains('is-open'));\n          done();\n        });\n    });\n\n    it('search options narrow as input changes', function (done) {\n      syn\n        .click(input)\n        .type('g', () => {\n          assert.isTrue(dropdownItems[0].classList.contains('is-hidden'));\n          assert.isFalse(dropdownItems[1].classList.contains('is-hidden'));\n          assert.isTrue(dropdownItems[2].classList.contains('is-hidden'));\n          assert.isFalse(dropdownItems[3].classList.contains('is-hidden'));\n          done();\n        });\n    });\n\n    it('highlights the correct facet from narrowed dropdown items on up and down arrow keys', function (done) {\n      syn\n        .click(input)\n        .type('g[down]', () => {\n          assert.isOk(isActiveItem(dropdownItems[1]));\n        })\n        .type('[up]', () => {\n          assert.isNotOk(isActiveItem(dropdownItems[1]));\n          assert.isOk(isActiveItem(dropdownItems[3]));\n          done();\n        });\n    });\n\n    it('dropdown closes when user types \":\"', function (done) {\n      syn\n        .click(input)\n        .type(':', () => {\n          assert.isFalse(dropdown.classList.contains('is-open'));\n          done();\n        });\n    });\n\n    it('dropdown closes when there are no matches', function (done) {\n      syn\n        .click(input)\n        .type('x', () => {\n          assert.isFalse(dropdown.classList.contains('is-open'));\n          done();\n        });\n    });\n\n    it('does not submit the form when a dropdown element is selected', function (done) {\n      let submitted = false;\n      form.addEventListener('submit', () => {\n        submitted = true;\n      });\n\n      syn\n        .click(input)\n        .type('[down][enter]', () => {\n          assert.isFalse(submitted);\n          done();\n        });\n    });\n\n    it('allows submitting the form when query is empty and no dropdown element is selected', function (done) {\n      var submit = sinon.stub(form, 'submit');\n\n      syn\n        .click(input)\n        .type('[enter]', () => {\n          assert.isTrue(submit.calledOnce);\n          done();\n        });\n    });\n  });\n\n  describe('Lozenges', function () {\n    var testEl;\n    var input;\n    var inputHidden;\n    var ctrl;\n    var TEMPLATE = `\n      <form>\n        <div class=\"search-bar__lozenges\" data-ref=\"searchBarLozenges\">\n        </div>\n        <input data-ref=\"searchBarInput\" class=\"search-bar__input\" />\n        <input data-ref=\"searchBarInputHidden\" class=\"js-search-bar__input-hidden\" name=\"q\" value=\"foo 'bar\" />\n        <div data-ref=\"searchBarDropdown\">\n        </div>\n      </form>\n    `;\n\n    beforeEach(function () {\n      testEl = document.createElement('div');\n      testEl.innerHTML = TEMPLATE;\n      document.body.appendChild(testEl);\n\n      ctrl = new SearchBarController(testEl);\n\n      input = ctrl.refs.searchBarInput;\n      inputHidden = ctrl.refs.searchBarInputHidden;\n    });\n\n    afterEach(function () {\n      document.body.removeChild(testEl);\n    });\n\n    it('should create lozenges for existing query terms in the hidden input on page load', function () {\n      assert.equal(testEl.querySelectorAll('.js-lozenge__content')[0].textContent, 'foo');\n    });\n\n    it('should  not create a lozenge for incomplete query strings in the hidden input on page load', function () {\n      assert.equal(testEl.querySelectorAll('.js-lozenge__content').length, 1);\n      assert.equal(testEl.querySelectorAll('.js-lozenge__content')[0].textContent, 'foo');\n      assert.equal(testEl.querySelector('[data-ref=\"searchBarInput\"]').value, '\\'bar');\n    });\n\n    it('should create a lozenge when the user presses space and there are no incomplete query strings in the input', function (done) {\n      input.value = '';\n      inputHidden.value = '';\n      syn\n        .click(input)\n        .type('gar')\n        .type('[space]', () => {\n          assert.equal(testEl.querySelectorAll('.js-lozenge__content')[1].textContent, 'gar');\n          done();\n        });\n    });\n\n    it('should create a lozenge when the user completes a previously incomplete query string and then presses the space key', function (done) {\n      syn\n        .click(input)\n        .type(' gar\\'')\n        .type('[space]', () => {\n          assert.equal(testEl.querySelectorAll('.js-lozenge__content')[1].textContent, '\\'bar gar\\'');\n          done();\n        });\n    });\n\n    it('should not create a lozenge when the user does not completes a previously incomplete query string and presses the space key', function (done) {\n      syn\n        .click(input)\n        .type('[space]')\n        .type('gar')\n        .type('[space]', () => {\n          var lozenges = testEl.querySelectorAll('.js-lozenge__content');\n          assert.equal(lozenges.length, 1);\n          assert.equal(lozenges[0].textContent, 'foo');\n          assert.equal(input.value, '\\'bar gar ');\n          done();\n        });\n    });\n  });\n});\n"},{"size":1532,"relativepath":"h/static/scripts/tests/controllers/form-select-onfocus-controller-test.js","filename":"form-select-onfocus-controller-test.js","extension":".js","content":"'use strict';\n\nvar FormSelectOnFocusController = require('../../controllers/form-select-onfocus-controller');\n\n// helper to dispatch a native event to an element\nfunction sendEvent(element, eventType) {\n  // createEvent() used instead of Event constructor\n  // for PhantomJS compatibility\n  var event = document.createEvent('Event');\n  event.initEvent(eventType, true /* bubbles */, true /* cancelable */);\n  element.dispatchEvent(event);\n}\n\ndescribe('FormSelectOnFocusController', function() {\n  var root;\n\n  beforeEach(function() {\n    root = document.createElement('div');\n    root.innerHTML = '<form id=\"js-users-delete-form\">' +\n                     '<input type=\"text\" class=\"js-select-onfocus\" value=\"some-test-value\">';\n    document.body.appendChild(root);\n  });\n\n  afterEach(function() {\n    root.parentNode.removeChild(root);\n  });\n\n  it('it selects the element on focus event', function() {\n    new FormSelectOnFocusController(root);\n    var input = root.querySelector('input');\n    sendEvent(input, 'focus');\n    assert.strictEqual(input.selectionStart, 0);\n    assert.strictEqual(input.selectionEnd, input.value.length);\n  });\n\n  it('it selects the element without focus event when it is the active element', function() {\n    // Focus element before instantiating the controller\n    var input = root.querySelector('input');\n    input.focus();\n\n    new FormSelectOnFocusController(document.body);\n    assert.strictEqual(input.selectionStart, 0);\n    assert.strictEqual(input.selectionEnd, input.value.length);\n  });\n});\n"},{"size":758,"relativepath":"h/static/scripts/tests/controllers/signup-form-controller-test.js","filename":"signup-form-controller-test.js","extension":".js","content":"'use strict';\n\nvar SignupFormController = require('../../controllers/signup-form-controller');\n\nvar TEMPLATE = `\n  <form class=\"js-signup-form\">\n    <input type=\"submit\" class=\"js-signup-btn\">\n  </form>\n  `;\n\ndescribe('SignupFormController', function () {\n  var element;\n  var form;\n  var submitBtn;\n\n  beforeEach(function () {\n    element = document.createElement('div');\n    element.innerHTML = TEMPLATE;\n    form = element.querySelector('.js-signup-form');\n    submitBtn = element.querySelector('.js-signup-btn');\n  });\n\n  it('disables the submit button on form submit', function () {\n    new SignupFormController(form);\n    assert.isFalse(submitBtn.disabled);\n    form.dispatchEvent(new Event('submit'));\n    assert.isTrue(submitBtn.disabled);\n  });\n});\n"},{"size":4322,"relativepath":"h/static/scripts/tests/controllers/character-limit-controller-test.js","filename":"character-limit-controller-test.js","extension":".js","content":"'use strict';\n\nvar CharacterLimitController = require('../../controllers/character-limit-controller');\nvar util = require('./util');\n\ndescribe('CharacterLimitController', function () {\n\n  var ctrl;\n\n  afterEach(function () {\n    if (ctrl) {\n      ctrl.element.remove();\n      ctrl = null;\n    }\n  });\n\n  /**\n   * Make a <textarea> with the character limit controller enhancement\n   * applied and return the various parts of the component.\n   */\n  function component(value, maxlength) {\n    maxlength = maxlength || 250;\n\n    var template = '<div class=\"js-character-limit\">';\n    template += '<textarea data-ref=\"characterLimitInput\" data-maxlength=\"' + maxlength + '\">';\n    if (value) {\n      template += value;\n    }\n    template += '</textarea><span data-ref=\"characterLimitCounter\">Foo</span>';\n    template += '</div>';\n\n    ctrl = util.setupComponent(document, template, CharacterLimitController);\n\n    return {\n      counterEl: ctrl.refs.characterLimitCounter,\n      textarea: ctrl.refs.characterLimitInput,\n      ctrl: ctrl,\n    };\n  }\n\n  it('adds the ready class', function () {\n    var counterEl = component().counterEl;\n\n    assert.equal(counterEl.classList.contains('is-ready'), true);\n  });\n\n  it('shows the counter initially even if textarea empty', function () {\n    var counterEl = component().counterEl;\n\n    assert.equal(counterEl.innerHTML, '0/250');\n  });\n\n  it('shows the counter if the element has pre-rendered text', function () {\n    var counterEl = component('pre-rendered').counterEl;\n\n    assert.equal(counterEl.innerHTML, '12/250');\n  });\n\n  it('continues to show the container after text deleted', function() {\n    var parts = component();\n    var counterEl = parts.counterEl;\n    var textarea = parts.textarea;\n\n    // Trigger the counter to be shown.\n    textarea.value = 'Some text';\n    textarea.dispatchEvent(new Event('input'));\n\n    // Delete all the text in the textarea,\n    textarea.value = '';\n    textarea.dispatchEvent(new Event('input'));\n\n    assert.equal(counterEl.innerHTML, '0/250');\n  });\n\n  it('reads the max length from the data-maxlength attribute', function () {\n    var counterEl = component('foo', 500).counterEl;\n\n    assert.equal(counterEl.innerHTML, '3/500');\n  });\n\n  it('updates the counter when text is added on \"input\" events', function () {\n    var parts = component();\n    var textarea = parts.textarea;\n    var counterEl = parts.counterEl;\n\n    textarea.value = 'testing';\n    textarea.dispatchEvent(new Event('input'));\n\n    assert.equal(counterEl.innerHTML, '7/250');\n  });\n\n  it('updates the counter when text is removed on \"input\" events', function () {\n    var parts = component('Testing testing');\n    var textarea = parts.textarea;\n    var counterEl = parts.counterEl;\n\n    // Make the text shorter.\n    textarea.value = 'Testing';\n    textarea.dispatchEvent(new Event('input'));\n\n    assert.equal(counterEl.innerHTML, '7/250');\n  });\n\n  it('does not add error class when no pre-rendered text', function() {\n    var counterEl = component(null, 5).counterEl;\n\n    assert.equal(counterEl.classList.contains('is-too-long'),\n                 false);\n  });\n\n  it('does not add error class when pre-rendered text short enough', function() {\n    var counterEl = component('foo', 5).counterEl;\n\n    assert.equal(counterEl.classList.contains('is-too-long'),\n                 false);\n  });\n\n  it('adds an error class to the counter when pre-rendered value too long', function() {\n    var counterEl = component('Too long', 5).counterEl;\n\n    assert.equal(counterEl.classList.contains('is-too-long'),\n                 true);\n  });\n\n  it('adds an error class to the counter when too much text entered', function() {\n    var parts = component(null, 5);\n    var counterEl = parts.counterEl;\n    var textarea = parts.textarea;\n\n    textarea.value = 'too long';\n    textarea.dispatchEvent(new Event('input'));\n\n    assert.equal(counterEl.classList.contains('is-too-long'),\n                 true);\n  });\n\n  it('removes error class from counter when text reduced', function() {\n    var parts = component('too long', 6);\n    var counterEl = parts.counterEl;\n    var textarea = parts.textarea;\n\n    textarea.value = 'short';\n    textarea.dispatchEvent(new Event('input'));\n\n    assert.equal(counterEl.classList.contains('is-too-long'),\n                 false);\n  });\n});\n"},{"size":1102,"relativepath":"h/static/scripts/tests/controllers/tooltip-controller-test.js","filename":"tooltip-controller-test.js","extension":".js","content":"'use strict';\n\nvar TooltipController = require('../../controllers/tooltip-controller');\n\ndescribe('TooltipController', function () {\n  var targetEl;\n  var template;\n  var testEl;\n  var tooltipEl;\n\n  before(function () {\n    template = '<div class=\"form-input__hint-icon js-tooltip\"' +\n     'aria-label=\"Test\"></div>';\n  });\n\n  beforeEach(function () {\n    testEl = document.createElement('div');\n    testEl.innerHTML = template;\n\n    targetEl = testEl.querySelector('div');\n    new TooltipController(targetEl);\n\n    tooltipEl = testEl.querySelector('.tooltip');\n  });\n\n\n  it('appears when the target is hovered', function () {\n    targetEl.dispatchEvent(new Event('mouseover'));\n    assert.equal(tooltipEl.style.visibility, '');\n  });\n\n  it('sets the label from the target\\'s \"aria-label\" attribute', function () {\n    targetEl.dispatchEvent(new Event('mouseover'));\n    assert.equal(tooltipEl.textContent, 'Test');\n  });\n\n  it('disappears when the target is unhovered', function () {\n    targetEl.dispatchEvent(new Event('mouseout'));\n    assert.equal(tooltipEl.style.visibility, 'hidden');\n  });\n});\n"},{"size":9292,"relativepath":"h/static/scripts/tests/controllers/form-controller-test.js","filename":"form-controller-test.js","extension":".js","content":"'use strict';\n\nvar proxyquire = require('proxyquire');\n\nvar { noCallThru } = require('../util');\nvar upgradeElements = require('../../base/upgrade-elements');\n\n// Simplified version of forms rendered by deform on the server\nvar TEMPLATE = `\n  <form class=\"js-form\">\n    <div data-ref=\"formBackdrop\"></div>\n    <div class=\"js-form-input\">\n      <input id=\"deformField\" data-ref=\"formInput firstInput\" value=\"original value\">\n    </div>\n    <div class=\"js-form-input\">\n      <input id=\"deformField2\" data-ref=\"formInput secondInput\" value=\"original value 2\">\n    </div>\n    <div class=\"js-form-input\">\n      <input id=\"deformField3\" data-ref=\"formInput checkboxInput\" type=\"checkbox\">\n    </div>\n    <div data-ref=\"formActions\">\n      <button data-ref=\"testSaveBtn\">Save</button>\n      <button data-ref=\"cancelBtn\">Cancel</button>\n    </div>\n    <div data-ref=\"formSubmitError\">\n      <div data-ref=\"formSubmitErrorMessage\"></div>\n    </div>\n  </form>\n`;\n\nvar UPDATED_FORM = TEMPLATE.replace('js-form', 'js-form is-updated');\n\ndescribe('FormController', function () {\n  var ctrl;\n  var fakeSubmitForm;\n  var reloadSpy;\n\n  beforeEach(function () {\n    fakeSubmitForm = sinon.stub();\n    var FormController = proxyquire('../../controllers/form-controller', {\n      '../util/submit-form': noCallThru(fakeSubmitForm),\n    });\n\n    var container = document.createElement('div');\n    container.innerHTML = TEMPLATE;\n    upgradeElements(container, {\n      '.js-form': FormController,\n    });\n\n    ctrl = container.querySelector('.js-form').controllers[0];\n\n    // Wrap the original `reload` function passed to the controller so we can\n    // spy on calls to it and update `ctrl` to the new controller instance\n    // when the form is reloaded\n    var reloadFn = ctrl.options.reload;\n    reloadSpy = sinon.spy(html => {\n      var newElement = reloadFn(html);\n      ctrl = newElement.controllers[0];\n      return newElement;\n    });\n    ctrl.options.reload = reloadSpy;\n\n    // Add element to document so that it can be focused\n    document.body.appendChild(ctrl.element);\n  });\n\n  afterEach(function () {\n    ctrl.beforeRemove();\n    ctrl.element.remove();\n  });\n\n  function isEditing() {\n    return ctrl.element.classList.contains('is-editing');\n  }\n\n  function submitForm() {\n    return ctrl.submit();\n  }\n\n  function startEditing() {\n    ctrl.refs.firstInput.focus();\n  }\n\n  function isSaving() {\n    return ctrl.refs.formActions.classList.contains('is-saving');\n  }\n\n  function submitError() {\n    if (!ctrl.refs.formSubmitError.classList.contains('is-visible')) {\n      return '<hidden>';\n    }\n    return ctrl.refs.formSubmitErrorMessage.textContent;\n  }\n\n  it('begins editing when a field is focused', function () {\n    ctrl.refs.firstInput.focus();\n    ctrl.refs.firstInput.dispatchEvent(new Event('focus'));\n    assert.isTrue(isEditing());\n  });\n\n  it('reverts the form when \"Cancel\" is clicked', function () {\n    startEditing();\n    ctrl.refs.firstInput.value = 'new value';\n    ctrl.refs.cancelBtn.click();\n    assert.equal(ctrl.refs.firstInput.value, 'original value');\n  });\n\n  it('reverts the form when \"Escape\" key is pressed', function () {\n    startEditing();\n    var event = new Event('keydown', {bubbles: true});\n    event.key = 'Escape';\n    ctrl.refs.firstInput.dispatchEvent(event);\n    assert.equal(ctrl.refs.firstInput.value, 'original value');\n  });\n\n  it('submits the form when \"Save\" is clicked', function () {\n    fakeSubmitForm.returns(Promise.resolve({status: 200, form: UPDATED_FORM}));\n    ctrl.refs.testSaveBtn.click();\n    assert.calledWith(fakeSubmitForm, ctrl.element);\n\n    // Ensure that test does not complete until `FormController#submit` has\n    // run\n    return Promise.resolve();\n  });\n\n  context('when form is successfully submitted', function () {\n    it('updates form with new rendered version from server', function () {\n      fakeSubmitForm.returns(Promise.resolve({status: 200, form: UPDATED_FORM}));\n      return submitForm().then(function () {\n        assert.isTrue(ctrl.element.classList.contains('is-updated'));\n      });\n    });\n\n    it('stops editing the form', function () {\n      fakeSubmitForm.returns(Promise.resolve({status: 200, form: UPDATED_FORM}));\n      return submitForm().then(function () {\n        assert.isFalse(isEditing());\n      });\n    });\n  });\n\n  context('when validation fails', function () {\n    it('updates form with rendered version from server', function () {\n      startEditing();\n      fakeSubmitForm.returns(Promise.reject({status: 400, form: UPDATED_FORM}));\n      return submitForm().then(function () {\n        assert.isTrue(ctrl.element.classList.contains('is-updated'));\n      });\n    });\n\n    it('marks updated form as dirty', function () {\n      startEditing();\n      fakeSubmitForm.returns(Promise.reject({status: 400, form: UPDATED_FORM}));\n      return submitForm().then(function () {\n        assert.isTrue(ctrl.state.dirty);\n      });\n    });\n\n    it('continues editing current field', function () {\n      startEditing();\n      fakeSubmitForm.returns(Promise.reject({status: 400, form: UPDATED_FORM}));\n      return submitForm().then(function () {\n        assert.isTrue(isEditing());\n      });\n    });\n\n    it('focuses the matching input field in the re-rendered form', function () {\n      startEditing();\n      fakeSubmitForm.returns(Promise.reject({status: 400, form: UPDATED_FORM}));\n\n      // Simulate the user saving the form by clicking the 'Save' button, which\n      // changes the focus from the input field to the button\n      ctrl.refs.testSaveBtn.focus();\n\n      return submitForm().then(function () {\n        // In the re-rendered form, the input field should be focused\n        assert.equal(document.activeElement.id, 'deformField');\n      });\n    });\n  });\n\n  it('enters the \"saving\" state while the form is being submitted', function () {\n    fakeSubmitForm.returns(Promise.resolve({status: 200, form: UPDATED_FORM}));\n    var saved = submitForm();\n    assert.isTrue(isSaving());\n    return saved.then(function () {\n      assert.isFalse(isSaving());\n    });\n  });\n\n  it('displays an error if form submission fails without returning a new form', function () {\n    fakeSubmitForm.returns(Promise.reject({status: 500, reason: 'Internal Server Error'}));\n    return submitForm().then(function () {\n      assert.equal(submitError(), 'Internal Server Error');\n    });\n  });\n\n  it('ignores clicks outside the field being edited', function () {\n    startEditing();\n    var event = new Event('mousedown', {cancelable: true});\n    ctrl.refs.formBackdrop.dispatchEvent(event);\n    assert.isTrue(event.defaultPrevented);\n  });\n\n  it('sets form state to dirty if user modifies active field', function () {\n    startEditing();\n\n    ctrl.refs.firstInput.dispatchEvent(new Event('input', {bubbles: true}));\n\n    assert.isTrue(ctrl.state.dirty);\n  });\n\n  context('when focus moves to another input while editing', function () {\n    it('clears editing state of first input', function () {\n      startEditing();\n      var inputs = ctrl.element.querySelectorAll('.js-form-input');\n\n      // Focus second input. Although the user cannot focus the second input with\n      // the mouse while the first is focused, they can navigate to it with the\n      // tab key\n      ctrl.refs.secondInput.focus();\n\n      assert.isFalse(inputs[0].classList.contains('is-editing'));\n      assert.isTrue(inputs[1].classList.contains('is-editing'));\n    });\n\n    it('keeps focus in previous input if it has unsaved changes', function () {\n      startEditing();\n      ctrl.setState({dirty: true});\n\n      // Simulate user/browser attempting to switch to another field\n      ctrl.refs.secondInput.focus();\n\n      assert.equal(document.activeElement, ctrl.refs.firstInput);\n    });\n  });\n\n  context('when focus moves outside of form', function () {\n    var outsideEl;\n\n    beforeEach(function () {\n      outsideEl = document.createElement('input');\n      document.body.appendChild(outsideEl);\n    });\n\n    afterEach(function () {\n      outsideEl.remove();\n    });\n\n    it('clears editing state if field does not have unsaved changes', function () {\n      startEditing();\n\n      // Simulate user moving focus outside of form (eg. via tab key).\n      outsideEl.focus();\n\n      assert.isFalse(isEditing());\n    });\n\n    it('keeps current field focused if it has unsaved changes', function () {\n      startEditing();\n      ctrl.setState({dirty: true});\n\n      // Simulate user/browser attempting to switch focus to an element outside\n      // the form\n      outsideEl.focus();\n\n      assert.equal(document.activeElement, ctrl.refs.firstInput);\n    });\n  });\n\n  context('when a checkbox is toggled', function () {\n    beforeEach(function () {\n      fakeSubmitForm.returns(Promise.resolve({status: 200, form: UPDATED_FORM}));\n      ctrl.refs.checkboxInput.focus();\n      ctrl.refs.checkboxInput.dispatchEvent(new Event('change', {bubbles: true}));\n    });\n\n    afterEach(function () {\n      // Wait for form submission to complete\n      return Promise.resolve();\n    });\n\n    it('does not show form save buttons', function () {\n      assert.isTrue(ctrl.refs.formActions.classList.contains('is-hidden'));\n    });\n\n    it('automatically submits the form', function () {\n      assert.calledWith(fakeSubmitForm, ctrl.element);\n    });\n  });\n});\n"},{"size":1141,"relativepath":"h/static/scripts/tests/controllers/admin-users-controller-test.js","filename":"admin-users-controller-test.js","extension":".js","content":"'use strict';\n\nvar AdminUsersController = require('../../controllers/admin-users-controller');\n\nfunction submitEvent() {\n  return new Event('submit', {bubbles: true, cancelable: true});\n}\n\ndescribe('AdminUsersController', function () {\n  var root;\n  var form;\n\n  beforeEach(function () {\n    root = document.createElement('div');\n    root.innerHTML = '<form><input type=\"submit\"></form>';\n    form = root.querySelector('form');\n    document.body.appendChild(root);\n  });\n\n  afterEach(function () {\n    root.remove();\n  });\n\n  it('it submits the form when confirm returns true', function () {\n    var event = submitEvent();\n    var fakeWindow = {confirm: sinon.stub().returns(true)};\n    new AdminUsersController(root, {window: fakeWindow});\n\n    form.dispatchEvent(event);\n\n    assert.isFalse(event.defaultPrevented);\n  });\n\n  it('it cancels the form submission when confirm returns false', function () {\n    var event = submitEvent();\n    var fakeWindow = {confirm: sinon.stub().returns(false)};\n    new AdminUsersController(root, {window: fakeWindow});\n\n    form.dispatchEvent(event);\n\n    assert.isTrue(event.defaultPrevented);\n  });\n});\n"},{"size":1837,"relativepath":"h/static/scripts/tests/controllers/create-group-form-controller-test.js","filename":"create-group-form-controller-test.js","extension":".js","content":"'use strict';\n\nvar CreateGroupFormController = require('../../controllers/create-group-form-controller');\n\nfunction isHidden(elt) {\n  return elt.classList.contains('is-hidden');\n}\n\n// helper to dispatch a native event to an element\nfunction sendEvent(element, eventType) {\n  // createEvent() used instead of Event constructor\n  // for PhantomJS compatibility\n  var event = document.createEvent('Event');\n  event.initEvent(eventType, true /* bubbles */, true /* cancelable */);\n  element.dispatchEvent(event);\n}\n\ndescribe('CreateGroupFormController', function () {\n  var element;\n  var template;\n\n  before(function () {\n    template = '<input type=\"text\" class=\"js-group-name-input\">' +\n               '<input type=\"submit\" class=\"js-create-group-create-btn\">' +\n               '<a href=\"\" class=\"js-group-info-link\">Tell me more!</a>' +\n               '<div class=\"js-group-info-text is-hidden\">More!</div>';\n  });\n\n  beforeEach(function () {\n    element = document.createElement('div');\n    element.innerHTML = template;\n  });\n\n  it('should enable submission if form is valid', function () {\n    var controller = new CreateGroupFormController(element);\n    controller._groupNameInput.value = '';\n    sendEvent(controller._groupNameInput, 'input');\n    assert.equal(controller._submitBtn.disabled, true);\n    controller._groupNameInput.value = 'a group name';\n    sendEvent(controller._groupNameInput, 'input');\n    assert.equal(controller._submitBtn.disabled, false);\n  });\n\n  it('should toggle info text when explain link is clicked', function () {\n    var controller = new CreateGroupFormController(element);\n    assert.equal(isHidden(controller._infoText), true);\n    sendEvent(controller._infoLink, 'click');\n    assert.equal(isHidden(controller._infoText), false);\n    assert.equal(isHidden(controller._infoLink), true);\n  });\n});\n"},{"size":950,"relativepath":"h/static/scripts/legacy-site.js","filename":"legacy-site.js","extension":".js","content":"'use strict';\n\nwindow.$ = window.jQuery = require('jquery');\nrequire('bootstrap');\n\nif (window.chrome !== undefined) {\n  var elements = document.getElementsByClassName('unhide-in-chrome');\n  var i;\n  for (i = 0; i < elements.length; i++) {\n    elements[i].classList.remove('hidden');\n  }\n  elements = document.getElementsByClassName('hide-in-chrome');\n  for (i = 0; i < elements.length; i++) {\n    elements[i].classList.add('hidden');\n  }\n}\n\nvar bookmarkletInstaller = document.getElementById('js-bookmarklet-install');\nif (bookmarkletInstaller) {\n  bookmarkletInstaller.addEventListener('click', function (event) {\n    window.alert('Drag me to the bookmarks bar');\n    event.preventDefault();\n  });\n}\n\nvar chromeextInstaller = document.getElementById('js-chrome-extension-install');\nif (chromeextInstaller) {\n  chromeextInstaller.addEventListener('click', function (event) {\n    window.chrome.webstore.install();\n    event.preventDefault();\n  });\n}\n"},{"size":3387,"relativepath":"h/static/scripts/base/environment-flags.js","filename":"environment-flags.js","extension":".js","content":"'use strict';\n\n/**\n * EnvironmentFlags provides a facility to modify the appearance or behavior\n * of components on the page depending on the capabilities of the user agent.\n *\n * It adds `env-${flag}` classes to a top-level element in the document to\n * indicate support for scripting, touch input etc. These classes can then be\n * used to modify other elements in the page via descendent selectors.\n *\n * EnvironmentFlags provides hooks to override the detected set of environment\n * features via query-string or fragment parameters in the URL:\n *\n *  \"__env__\" -  A semi-colon list of environment flags to enable or disable\n *               (if prefixed with \"no-\"). eg. \"__env__=touch\"\n *  \"nojs=1\"  -  Shorthand for \"__env__=no-js-capable\"\n */\nclass EnvironmentFlags {\n  /**\n    * @param {Element} element - DOM element which environment flags will be added\n    *                  to.\n    */\n  constructor(element) {\n    this._element = element;\n  }\n\n  /**\n   * Return the current value of an environment flag.\n   *\n   * @param {string} flag\n   */\n  get(flag) {\n    var flagClass = 'env-' + flag;\n    return this._element.classList.contains(flagClass);\n  }\n\n  /**\n   * Set or clear an environment flag.\n   *\n   * This will add or remove the `env-${flag}` class from the element which\n   * contains environment flags.\n   *\n   * @param {string} flag\n   * @param {boolean} on\n   */\n  set(flag, on) {\n    var flagClass = 'env-' + flag;\n    if (on) {\n      this._element.classList.add(flagClass);\n    } else {\n      this._element.classList.remove(flagClass);\n    }\n  }\n\n  /**\n   * Detect user agent capabilities and set default flags.\n   *\n   * This sets the `js-capable` flag but clears it if `ready()` is not called\n   * within 5000ms. This can be used to hide elements of the page assuming that\n   * they can later be shown via JS but show them again if scripts fail to load.\n   *\n   * @param {string} [url] - Optional value to use as the URL for flag overrides\n   */\n  init(url) {\n    var JS_LOAD_TIMEOUT = 5000;\n\n    // Mark browser as JS capable\n    this.set('js-capable', true);\n\n    // Set a flag to indicate touch support. Useful for browsers that do not\n    // support interaction media queries.\n    // See http://caniuse.com/#feat=css-media-interaction\n    this.set('touch', this._element.ontouchstart);\n\n    // Set an additional flag if scripts fail to load in a reasonable period of\n    // time\n    this._jsLoadTimeout = setTimeout(() => {\n      this.set('js-timeout', true);\n    }, JS_LOAD_TIMEOUT);\n\n    // Process flag overrides specified in URL\n    var flags = envFlagsFromUrl(url || this._element.ownerDocument.location.href);\n    flags.forEach(flag => {\n      if (flag.indexOf('no-') === 0) {\n        this.set(flag.slice(3), false);\n      } else {\n        this.set(flag, true);\n      }\n    });\n  }\n\n  /**\n   * Mark the page load as successful.\n   */\n  ready() {\n    if (this._jsLoadTimeout) {\n      clearTimeout(this._jsLoadTimeout);\n    }\n  }\n}\n\n/**\n * Extract environment flags from `url`.\n *\n * @param {string} url\n * @return {Array<string>} flags\n */\nfunction envFlagsFromUrl(url) {\n  var match = /\\b__env__=([^&]+)/.exec(url);\n  var flags = [];\n  if (match) {\n    flags = match[1].split(';');\n  }\n\n  // Convenience shorthand to disable JS\n  if (url.match(/\\bnojs=1\\b/)) {\n    flags.push('no-js-capable');\n  }\n  return flags;\n}\n\nmodule.exports = EnvironmentFlags;\n"},{"size":2712,"relativepath":"h/static/scripts/base/controller.js","filename":"controller.js","extension":".js","content":"'use strict';\n\nvar { findRefs } = require('../util/dom');\n\n/*\n * @typedef {Object} ControllerOptions\n * @property {Function} [reload] - A function that replaces the content of\n *           the current element with new markup (eg. returned by an XHR request\n *           to the server) and returns the new root Element.\n */\n\n/**\n * Base class for controllers that upgrade elements with additional\n * functionality.\n *\n * - Child elements with `data-ref=\"$name\"` attributes are exposed on the\n *   controller as `this.refs.$name`.\n * - The element passed to the controller is exposed via the `element` property\n * - The controllers attached to an element are accessible via the\n *   `element.controllers` array\n *\n * The controller maintains internal state in `this.state`, which can only be\n * updated by calling (`this.setState(changes)`). Whenever the internal state of\n * the controller changes, `this.update()` is called to sync the DOM with this\n * state.\n */\nclass Controller {\n  /**\n   * Initialize the controller.\n   *\n   * @param {Element} element - The DOM Element to upgrade\n   * @param {ControllerOptions} [options] - Configuration options for the\n   *        controller. Subclasses extend this interface to provide config\n   *        specific to that type of controller.\n   */\n  constructor(element, options = {}) {\n    if (!element.controllers) {\n      element.controllers = [this];\n    } else {\n      element.controllers.push(this);\n    }\n\n    this.state = {};\n    this.element = element;\n    this.options = options;\n    this.refs = findRefs(element);\n  }\n\n  /**\n   * Set the state of the controller.\n   *\n   * This will merge `changes` into the current state and call the `update()`\n   * method provided by the subclass to update the DOM to match the current state.\n   */\n  setState(changes) {\n    var prevState = this.state;\n    this.state = Object.freeze(Object.assign({}, this.state, changes));\n    this.update(this.state, prevState);\n  }\n\n  /**\n   * Calls update() with the current state.\n   *\n   * This is useful for controllers where the state is available in the DOM\n   * itself, so doesn't need to be maintained internally.\n   */\n  forceUpdate() {\n    this.update(this.state, this.state);\n  }\n\n  /**\n   * Listen for events dispatched to the root element passed to the controller.\n   *\n   * This a convenience wrapper around `this.element.addEventListener`.\n   */\n  on(event, listener, useCapture) {\n    this.element.addEventListener(event, listener, useCapture);\n  }\n\n  /**\n   * Handler which is invoked when the controller's element is about to be\n   * removed.\n   *\n   * This can be used to clean up subscriptions, timeouts etc.\n   */\n  beforeRemove() {}\n}\n\nmodule.exports = Controller;\n"},{"size":2543,"relativepath":"h/static/scripts/base/raven.js","filename":"raven.js","extension":".js","content":"'use strict';\n\n/**\n * This module configures Raven for reporting crashes\n * to Sentry.\n *\n * Logging requires the Sentry DSN and Hypothesis\n * version to be provided via the app's settings object.\n */\n\nrequire('core-js/fn/object/assign');\n\nvar Raven = require('raven-js');\n\nfunction init(config) {\n  Raven.config(config.dsn, {\n    release: config.release,\n  }).install();\n  installUnhandledPromiseErrorHandler();\n}\n\nfunction setUserInfo(info) {\n  if (info) {\n    Raven.setUserContext(info);\n  } else {\n    Raven.setUserContext();\n  }\n}\n\n/**\n * Report an error to Sentry.\n *\n * @param {Error} error - An error object describing what went wrong\n * @param {string} when - A string describing the context in which\n *                        the error occurred.\n * @param {Object} [context] - A JSON-serializable object containing additional\n *                             information which may be useful when\n *                             investigating the error.\n */\nfunction report(error, when, context) {\n  if (!(error instanceof Error)) {\n    // If the passed object is not an Error, raven-js\n    // will serialize it using toString() which produces unhelpful results\n    // for objects that do not provide their own toString() implementations.\n    //\n    // If the error is a plain object or non-Error subclass with a message\n    // property, such as errors returned by chrome.extension.lastError,\n    // use that instead.\n    if (typeof error === 'object' && error.message) {\n      error = error.message;\n    }\n  }\n\n  var extra = Object.assign({ when: when }, context);\n  Raven.captureException(error, { extra: extra });\n}\n\n/**\n * Installs a handler to catch unhandled rejected promises.\n *\n * For this to work, the browser or the Promise polyfill must support\n * the unhandled promise rejection event (Chrome >= 49). On other browsers,\n * the rejections will simply go unnoticed. Therefore, app code _should_\n * always provide a .catch() handler on the top-most promise chain.\n *\n * See https://github.com/getsentry/raven-js/issues/424\n * and https://www.chromestatus.com/feature/4805872211460096\n *\n * It is possible that future versions of Raven JS may handle these events\n * automatically, in which case this code can simply be removed.\n */\nfunction installUnhandledPromiseErrorHandler() {\n  window.addEventListener('unhandledrejection', function (event) {\n    if (event.reason) {\n      report(event.reason, 'Unhandled Promise rejection');\n    }\n  });\n}\n\nmodule.exports = {\n  init: init,\n  setUserInfo: setUserInfo,\n  report: report,\n};\n"},{"size":2755,"relativepath":"h/static/scripts/base/upgrade-elements.js","filename":"upgrade-elements.js","extension":".js","content":"'use strict';\n\n/**\n * Mark an element as having been upgraded.\n */\nfunction markReady(element) {\n  var HIDE_CLASS = 'is-hidden-when-loading';\n  var hideOnLoad = Array.from(element.querySelectorAll('.' + HIDE_CLASS));\n  hideOnLoad.forEach(function (el) {\n    el.classList.remove(HIDE_CLASS);\n  });\n  element.classList.remove(HIDE_CLASS);\n}\n\n// List of all elements which have had upgrades applied\nvar upgradedElements = [];\n\n/**\n * Remove all of the controllers for elements under `root`.\n *\n * This clears the `controllers` list for all elements under `root` and notifies\n * the controllers that their root element is about to be removed from the\n * document.\n */\nfunction removeControllers(root) {\n  upgradedElements = upgradedElements.filter(el => {\n    if (root.contains(el)) {\n      el.controllers.forEach(ctrl => ctrl.beforeRemove());\n      el.controllers = [];\n      return false;\n    } else {\n      return true;\n    }\n  });\n}\n\n/**\n * Upgrade elements on the page with additional functionality\n *\n * Controllers attached to upgraded elements are accessible via the `controllers`\n * property on the element.\n *\n * @param {Element} root - The root element to search for matching elements\n * @param {Object} controllers - Object mapping selectors to controller classes.\n *        For each element matching a given selector, an instance of the\n *        controller class will be constructed and passed the element in\n *        order to upgrade it.\n */\nfunction upgradeElements(root, controllers) {\n  // A helper which replaces the content (including the root element) of\n  // an upgraded element with new markup and re-applies element upgrades to\n  // the new root element\n  function reload(element, html) {\n    removeControllers(element);\n\n    if (typeof html !== 'string') {\n      throw new Error('Replacement markup must be a string');\n    }\n    var container = document.createElement('div');\n    container.innerHTML = html;\n    upgradeElements(container, controllers);\n\n    var newElement = container.children[0];\n    element.parentElement.replaceChild(newElement, element);\n    return newElement;\n  }\n\n  Object.keys(controllers).forEach(function (selector) {\n    var elements = Array.from(root.querySelectorAll(selector));\n    elements.forEach(function (el) {\n      var ControllerClass = controllers[selector];\n      try {\n        new ControllerClass(el, {\n          reload: reload.bind(null, el),\n        });\n        upgradedElements.push(el);\n        markReady(el);\n      } catch (err) {\n        console.error('Failed to upgrade element %s with controller', el, ControllerClass, ':', err.toString());\n\n        // Re-raise error so that Raven can capture and report it\n        throw err;\n      }\n    });\n  });\n}\n\nmodule.exports = upgradeElements;\n"},{"size":946,"relativepath":"h/static/scripts/base/settings.js","filename":"settings.js","extension":".js","content":"'use strict';\n\nrequire('core-js/fn/object/assign');\n\n/**\n * Return application configuration information from the host page.\n *\n * Exposes shared application settings, read from script tags with the\n * class `settingsClass` which contain JSON content.\n *\n * If there are multiple such tags, the configuration from each is merged.\n *\n * @param {Document|Element} document - The root element to search for\n *                                      <script> settings tags.\n * @param {string} settingsClass - The class name to match on <script> tags.\n */\nfunction settings(document, settingsClass) {\n  if (!settingsClass) {\n    settingsClass = 'js-hypothesis-settings';\n  }\n  var settingsElements =\n    document.querySelectorAll('script.' + settingsClass);\n\n  var config = {};\n  for (var i=0; i < settingsElements.length; i++) {\n    Object.assign(config, JSON.parse(settingsElements[i].textContent));\n  }\n  return config;\n}\n\nmodule.exports = settings;\n"},{"size":1732,"relativepath":"h/static/scripts/site.js","filename":"site.js","extension":".js","content":"'use strict';\n\n// Configure error reporting\nvar settings = require('./base/settings')(document);\nif (settings.raven) {\n  require('./base/raven').init(settings.raven);\n}\n\nrequire('./polyfills');\n\nvar CharacterLimitController = require('./controllers/character-limit-controller');\nvar CreateGroupFormController = require('./controllers/create-group-form-controller');\nvar DropdownMenuController = require('./controllers/dropdown-menu-controller');\nvar FormController = require('./controllers/form-controller');\nvar FormSelectOnFocusController = require('./controllers/form-select-onfocus-controller');\nvar SearchBarController = require('./controllers/search-bar-controller');\nvar SearchBucketController = require('./controllers/search-bucket-controller');\nvar SignupFormController = require('./controllers/signup-form-controller');\nvar TooltipController = require('./controllers/tooltip-controller');\nvar upgradeElements = require('./base/upgrade-elements');\n\nvar controllers = {\n  '.js-character-limit': CharacterLimitController,\n  '.js-create-group-form': CreateGroupFormController,\n  '.js-dropdown-menu': DropdownMenuController,\n  '.js-form': FormController,\n  '.js-select-onfocus': FormSelectOnFocusController,\n  '.js-search-bar': SearchBarController,\n  '.js-search-bucket': SearchBucketController,\n  '.js-signup-form': SignupFormController,\n  '.js-tooltip': TooltipController,\n};\n\nif (window.envFlags && window.envFlags.get('js-capable')) {\n  upgradeElements(document.body, controllers);\n  window.envFlags.ready();\n} else {\n  // Environment flags not initialized. The header script may have been missed\n  // in the page or may have failed to load.\n  console.warn('EnvironmentFlags not initialized. Skipping element upgrades');\n}\n"},{"size":391,"relativepath":"h/static/scripts/header.js","filename":"header.js","extension":".js","content":"'use strict';\n\n// Header script which is included inline at the top of every page on the site.\n//\n// This should be a small script which does things like setting up flags to\n// indicate that scripting is active, send analytics events etc.\n\nvar EnvironmentFlags = require('./base/environment-flags');\n\nwindow.envFlags = new EnvironmentFlags(document.documentElement);\nwindow.envFlags.init();\n"},{"size":2181,"relativepath":"h/static/scripts/util/submit-form.js","filename":"submit-form.js","extension":".js","content":"'use strict';\n\n/**\n * @typedef SubmitError\n * @property {number} status - HTTP status code. 400 if form submission failed\n *           due to a validation error or a different 4xx or 5xx code if it\n *           failed for other reasons.\n * @property {string} [form] - HTML markup for the form containing validation\n *           error messages if submission failed with a 400 status.\n * @property {string} [reason] - The status message if form submission failed\n *           for reasons other than a validation error.\n */\n\n/**\n * Exception thrown if form submission fails.\n *\n * @property {SubmitError} params - Describes why submission failed. These\n *           properties are exposed on the FormSubmitError instance.\n */\nclass FormSubmitError extends Error {\n  constructor(message, params) {\n    super(message);\n    Object.assign(this, params);\n  }\n}\n\n/**\n * @typedef {Object} SubmitResult\n * @property {number} status - Always 200\n * @property {string} form - The HTML markup for the re-rendered form\n */\n\n/**\n * Submit a form using the Fetch API and return the markup for the re-rendered\n * version of the form.\n *\n * @param {HTMLFormElement} formEl - The `<form>` to submit\n * @return {Promise<SubmitResult>} A promise which resolves when the form\n *         submission completes or rejects with a FormSubmitError if the server\n *         rejects the submission due to a validation error or the network\n *         request fails.\n */\nfunction submitForm(formEl, fetch = window.fetch) {\n  var response;\n  return fetch(formEl.action, {\n    body: new FormData(formEl),\n    credentials: 'same-origin',\n    method: 'POST',\n    headers: {\n      'X-Requested-With': 'XMLHttpRequest',\n    },\n  }).then(response_ => {\n    response = response_;\n    return response.text();\n  }).then(body => {\n    var { status } = response;\n    switch (status) {\n    case 200:\n      return {status, form: body};\n    case 400:\n      throw new FormSubmitError('Form validation failed', {\n        status, form: body,\n      });\n    default:\n      throw new FormSubmitError('Form submission failed', {\n        status,\n        reason: response.statusText,\n      });\n    }\n  });\n}\n\nmodule.exports = submitForm;\n"},{"size":3766,"relativepath":"h/static/scripts/util/search-text-parser.js","filename":"search-text-parser.js","extension":".js","content":"'use strict';\n\n/**\n * Function which determines if it is possible to lozengify a given phrase.\n *\n * @param {String} phrase A potential query term.\n *\n * @returns {Bool} True if the input phrase can be lozengified and false otherwise.\n *\n * @example\n * // returns True\n * canLozengify('foo')\n * @example\n * // returns False\n * canLozengify('foo)\n */\nfunction canLozengify(phrase) {\n  phrase = phrase.trim();\n  // if there is no word\n  if (!phrase) {\n    return false;\n  }\n  // if phrase starts with a double quote, it has to end with one\n  if (phrase.indexOf('\"') === 0 && phrase.indexOf('\"', 1) !== phrase.length - 1) {\n    return false;\n  }\n  // if phrase ends with a double quote it has to start with one\n  if (phrase.indexOf('\"', 1) === phrase.length - 1 && phrase.indexOf('\"') !== 0) {\n    return false;\n  }\n  // if phrase starts with a single quote, it has to end with one\n  if (phrase.indexOf(\"'\") === 0 && phrase.indexOf(\"'\", 1) !== phrase.length - 1) {\n    return false;\n  }\n  // if phrase ends with a single quote it has to start with one\n  if (phrase.indexOf(\"'\", 1) === phrase.length - 1 && phrase.indexOf(\"'\") !== 0) {\n    return false;\n  }\n  return true;\n}\n\n/**\n * Function which determines if a phrase can be lozengified as is or\n * if it needs to be divided into a facet name and value first.\n *\n * @param {String} phrase A potential query term.\n *\n * @returns {Bool} True if the input phrase is ready to be\n * lozengified and false otherwise.\n *\n * @example\n * // returns True\n * shouldLozengify('foo:bar')\n * @example\n * // returns False\n * shouldLozengify('foo:\"bar')\n */\nfunction shouldLozengify(phrase) {\n  var facetName;\n  var facetValue;\n  var i;\n\n  // if the phrase has a facet and value\n  if (phrase.indexOf(':') >= 0) {\n    i = phrase.indexOf(':');\n    facetName = phrase.slice(0, i).trim();\n    facetValue = phrase.slice(i+1, phrase.length).trim();\n\n    if (!canLozengify(facetName)) {\n      return false;\n    }\n    if (facetValue.length > 0 && !canLozengify(facetValue)) {\n      return false;\n    }\n  }\n  else if (!canLozengify(phrase)) {\n    return false;\n  }\n  return true;\n}\n\nfunction getLozengeValuesAndIncompleteSearchTerms(queryString) {\n  var inputTerms = '';\n  var quoted;\n  var queryTerms = [];\n  queryString.split(' ').forEach(function(term) {\n    if (quoted) {\n      inputTerms = inputTerms + ' ' + term;\n      if (shouldLozengify(inputTerms)) {\n        queryTerms.push(inputTerms);\n        inputTerms = '';\n        quoted = false;\n      }\n    } else {\n      if (shouldLozengify(term)) {\n        queryTerms.push(term);\n      } else {\n        inputTerms = term;\n        quoted = true;\n      }\n    }\n  });\n  return {\n    lozengeValues: queryTerms,\n    incompleteInputValue: inputTerms,\n  };\n}\n\n/**\n * Function which returns individual lozenge from a string.\n *\n * @param {String} queryString A string of query terms.\n *\n * @returns {Array} queryTerms An array of individual query terms.\n *\n * @example\n * // returns ['foo', 'key:\"foo bar\"', 'gar']\n * getLozengeValues('foo key:\"foo bar\" gar')\n */\nfunction getLozengeValues(queryString) {\n  return getLozengeValuesAndIncompleteSearchTerms(queryString).lozengeValues;\n}\n\n/**\n * Function which returns an incomplete quoted sentance from a string.\n *\n * @param {String} queryString A string of query terms.\n *\n * @returns {String} inputTerms A string which starts with a quote but\n * doesnt have an end quote.\n *\n * @example\n * // returns ['\"bar gar']\n * getIncompleteInputValue('foo \"bar gar')\n */\nfunction getIncompleteInputValue(queryString) {\n  return getLozengeValuesAndIncompleteSearchTerms(queryString).incompleteInputValue;\n}\n\nmodule.exports = {\n  shouldLozengify: shouldLozengify,\n  getLozengeValues: getLozengeValues,\n  getIncompleteInputValue: getIncompleteInputValue,\n};\n"},{"size":668,"relativepath":"h/static/scripts/util/annotation-ids.js","filename":"annotation-ids.js","extension":".js","content":"'use strict';\n\n/**\n * Extracts a direct-linked annotation ID from the fragment of a URL.\n *\n * @param {string} url - The URL which may contain a '#annotations:<ID>'\n *        fragment.\n * @return {string?} The annotation ID if present\n */\nfunction extractIDFromURL(url) {\n  try {\n    // Annotation IDs are url-safe-base64 identifiers\n    // See https://tools.ietf.org/html/rfc4648#page-7\n    var annotFragmentMatch = url.match(/#annotations:([A-Za-z0-9_-]+)$/);\n    if (annotFragmentMatch) {\n      return annotFragmentMatch[1];\n    } else {\n      return null;\n    }\n  } catch (err) {\n    return null;\n  }\n}\n\nmodule.exports = {\n  extractIDFromURL: extractIDFromURL,\n};\n"},{"size":1431,"relativepath":"h/static/scripts/util/dom.js","filename":"dom.js","extension":".js","content":"'use strict';\n\nvar stringUtil = require('./string');\n\nvar hyphenate = stringUtil.hyphenate;\n\n/**\n * Utility functions for DOM manipulation.\n */\n\n/**\n * Set the state classes (`is-$state`) on an element.\n *\n * @param {Element} el\n * @param {Object} state - A map of state keys to boolean. For each key `k`,\n *                 the class `is-$k` will be added to the element if the value\n *                 is true or removed otherwise.\n */\nfunction setElementState(el, state) {\n  Object.keys(state).forEach(function (key) {\n    var stateClass = 'is-' + hyphenate(key);\n    el.classList.toggle(stateClass, !!state[key]);\n  });\n}\n\n/**\n * Search the DOM tree starting at `el` and return a map of \"data-ref\" attribute\n * values to elements.\n *\n * This provides a way to label parts of a control in markup and get a\n * reference to them subsequently in code.\n */\nfunction findRefs(el) {\n  var map = {};\n\n  var descendantsWithRef = el.querySelectorAll('[data-ref]');\n  for (var i=0; i < descendantsWithRef.length; i++) {\n    // Use `Element#getAttribute` rather than `Element#dataset` to support IE 10\n    // and avoid https://bugs.webkit.org/show_bug.cgi?id=161454\n    var refEl = descendantsWithRef[i];\n    var refs = (refEl.getAttribute('data-ref') || '').split(' ');\n    refs.forEach(function (ref) {\n      map[ref] = refEl;\n    });\n  }\n\n  return map;\n}\n\nmodule.exports = {\n  findRefs: findRefs,\n  setElementState: setElementState,\n};\n"},{"size":574,"relativepath":"h/static/scripts/util/string.js","filename":"string.js","extension":".js","content":"'use strict';\n\n/**\n * Convert a `camelCase` or `CapitalCase` string to `kebab-case`\n */\nfunction hyphenate(name) {\n  var uppercasePattern = /([A-Z])/g;\n  return name.replace(uppercasePattern, '-$1').toLowerCase();\n}\n\n/** Convert a `kebab-case` string to `camelCase` */\nfunction unhyphenate(name) {\n  var idx = name.indexOf('-');\n  if (idx === -1) {\n    return name;\n  } else {\n    var ch = (name[idx+1] || '').toUpperCase();\n    return unhyphenate(name.slice(0,idx) + ch + name.slice(idx+2));\n  }\n}\n\nmodule.exports = {\n  hyphenate: hyphenate,\n  unhyphenate: unhyphenate,\n};\n"},{"size":2212,"relativepath":"h/static/scripts/util/modal-focus.js","filename":"modal-focus.js","extension":".js","content":"'use strict';\n\n// Focus release function returned by most recent call to trap()\nvar currentReleaseFn;\n\n/**\n * Trap focus within a group of elements.\n *\n * Watch focus changes in a document and react to and/or prevent focus moving\n * outside a specified group of elements.\n *\n * @param {Element[]} elements - Array of elements which make up the modal group\n * @param {(Element) => Element|null} callback - Callback which is invoked when\n *        focus tries to move outside the modal group. It is called with the\n *        new element that will be focused. If it returns null, the focus change\n *        will proceed, otherwise if it returns an element within the group,\n *        that element will be focused instead.\n * @return {Function} A function which releases the modal focus, if it has not\n *        been changed by another call to trap() in the meantime.\n */\nfunction trap(elements, callback) {\n  if (currentReleaseFn) {\n    currentReleaseFn();\n  }\n\n  // The most obvious way of detecting an element losing focus and reacting\n  // based on the new focused element is the \"focusout\" event and the\n  // FocusEvent#relatedTarget property.\n  //\n  // However, FocusEvent#relatedTarget is not implemented in all browsers\n  // (Firefox < 48, IE) and is null in some cases even for browsers that do\n  // support it.\n  //\n  // Instead we watch the 'focus' event on the document itself.\n\n  var onFocusChange = event => {\n    if (elements.some(el => el.contains(event.target))) {\n      // Focus remains within modal group\n      return;\n    }\n\n    // Focus is trying to move outside of the modal group, test whether to\n    // allow this\n    var newTarget = callback(event.target);\n    if (newTarget) {\n      event.preventDefault();\n      event.stopPropagation();\n      newTarget.focus();\n    } else if (currentReleaseFn) {\n      currentReleaseFn();\n    }\n  };\n  document.addEventListener('focus', onFocusChange, true /* useCapture */);\n\n  var releaseFn = () => {\n    if (currentReleaseFn === releaseFn) {\n      currentReleaseFn = null;\n      document.removeEventListener('focus', onFocusChange, true /* useCapture */);\n    }\n  };\n  currentReleaseFn = releaseFn;\n  return releaseFn;\n}\n\nmodule.exports = {\n  trap,\n};\n"},{"size":1246,"relativepath":"h/static/scripts/controllers/dropdown-menu-controller.js","filename":"dropdown-menu-controller.js","extension":".js","content":"'use strict';\n\nvar Controller = require('../base/controller');\nvar setElementState = require('../util/dom').setElementState;\n\n/**\n * Controller for dropdown menus.\n */\nclass DropdownMenuController extends Controller {\n  constructor(element) {\n    super(element);\n\n    var toggleEl = this.refs.dropdownMenuToggle;\n\n    var handleClickOutside = event => {\n      if (!this.refs.dropdownMenuContent.contains(event.target)) {\n        // When clicking outside the menu on the toggle element, stop the event\n        // so that it does not re-trigger the menu\n        if (toggleEl.contains(event.target)) {\n          event.stopPropagation();\n          event.preventDefault();\n        }\n\n        this.setState({open: false});\n\n        element.ownerDocument.removeEventListener('click', handleClickOutside,\n          true /* capture */);\n      }\n    };\n\n    toggleEl.addEventListener('click', event => {\n      event.preventDefault();\n      event.stopPropagation();\n\n      this.setState({open: true});\n\n      element.ownerDocument.addEventListener('click', handleClickOutside,\n        true /* capture */);\n    });\n  }\n\n  update(state) {\n    setElementState(this.refs.dropdownMenuContent, {open: state.open});\n  }\n}\n\nmodule.exports = DropdownMenuController;\n"},{"size":10024,"relativepath":"h/static/scripts/controllers/search-bar-controller.js","filename":"search-bar-controller.js","extension":".js","content":"'use strict';\n\nvar Controller = require('../base/controller');\nvar setElementState = require('../util/dom').setElementState;\nvar LozengeController = require('./lozenge-controller');\nvar SearchTextParser = require('../util/search-text-parser');\n\n/**\n * Controller for the search bar.\n */\nclass SearchBarController extends Controller {\n  constructor(element) {\n    super(element);\n\n    this._dropdown = this.refs.searchBarDropdown;\n    this._dropdownItems = Array.from(\n      element.querySelectorAll('[data-ref=\"searchBarDropdownItem\"]'));\n    this._input = this.refs.searchBarInput;\n    this._inputHidden = this.refs.searchBarInputHidden;\n    this._lozengeContainer = this.refs.searchBarLozenges;\n    var getActiveDropdownItem = () => {\n      return element.querySelector('.js-search-bar-dropdown-menu-item--active');\n    };\n\n    var clearActiveDropdownItem = () => {\n      var activeItem = getActiveDropdownItem();\n      if (activeItem) {\n        activeItem.classList.remove('js-search-bar-dropdown-menu-item--active');\n      }\n    };\n\n    var updateActiveDropdownItem = element => {\n      clearActiveDropdownItem();\n      element.classList.add('js-search-bar-dropdown-menu-item--active');\n    };\n\n    var isHidden = element => {\n      return element &&\n        (element.nodeType !== 1 ||\n          !element.classList ||\n          element.classList.contains('is-hidden'));\n    };\n\n    var getPreviousVisibleSiblingElement = element => {\n      if (!element) {\n        return null;\n      }\n\n      do {\n        element = element.previousSibling;\n      } while (isHidden(element));\n      return element;\n    };\n\n    var getNextVisibleSiblingElement = element => {\n      if (!element) {\n        return null;\n      }\n\n      do {\n        element = element.nextSibling;\n      } while (isHidden(element));\n\n      return element;\n    };\n\n    var showAllDropdownItems = () => {\n      this._dropdownItems.forEach(function(dropdownItem) {\n        dropdownItem.classList.remove('is-hidden');\n      });\n    };\n\n    var closeDropdown = () => {\n      if (!this.state.open) { return; }\n      clearActiveDropdownItem();\n      showAllDropdownItems();\n      this.setState({open: false});\n    };\n\n    var openDropdown = () => {\n      if (this.state.open) { return; }\n      clearActiveDropdownItem();\n      this.setState({open: true});\n    };\n\n    var selectFacet = facet => {\n      this._input.value = facet;\n\n      closeDropdown();\n\n      setTimeout(function() {\n        this._input.focus();\n      }.bind(this), 0);\n    };\n\n    var getVisibleDropdownItems = () => {\n      return this._dropdown.querySelectorAll('li:not(.is-hidden)');\n    };\n\n    /** Show items that match the word and hide ones that don't. */\n    var setVisibleDropdownItems = word => {\n      this._dropdownItems.forEach(function(dropdownItem) {\n        var dropdownItemTitle =\n          dropdownItem.querySelector('[data-ref=\"searchBarDropdownItemTitle\"]').\n            innerHTML.trim();\n        if (dropdownItemTitle.indexOf(word) < 0) {\n          dropdownItem.classList.add('is-hidden');\n        } else {\n          dropdownItem.classList.remove('is-hidden');\n        }\n      });\n    };\n\n    var getTrimmedInputValue = () => {\n      return this._input.value.trim();\n    };\n\n    var maybeOpenOrCloseDropdown = () => {\n      var word = getTrimmedInputValue();\n      var shouldOpenDropdown = true;\n\n      // If there are no visible items that match the word close the dropdown\n      if (getVisibleDropdownItems().length < 1) {\n        shouldOpenDropdown = false;\n      }\n\n      // If the word has a ':' don't show dropdown\n      if (word.indexOf(':') > -1) {\n        shouldOpenDropdown = false;\n      }\n\n      if (shouldOpenDropdown) {\n        openDropdown();\n      } else {\n        closeDropdown();\n      }\n    };\n\n    /**\n     * Updates the hidden input field with the consolidated\n     * search terms from the lozenges.\n     */\n    var updateHiddenInputValue = () => {\n      var newValue = '';\n      Array.from(this._lozengeContainer.querySelectorAll('.js-lozenge__content'), function(loz) {\n        newValue = newValue + loz.textContent + ' ';\n      });\n      newValue = newValue + getTrimmedInputValue();\n      this._inputHidden.value = newValue;\n    };\n\n    /**\n     * Creates a lozenge and sets the content string to the\n     * content provided and executes the delete callback when\n     * the lozenge is deleted.\n     *\n     * @param {String} content The search term\n     */\n    var addLozenge = content => {\n      var deleteCallback = () => {\n        updateHiddenInputValue();\n        this._lozengeContainer.querySelectorAll('.js-lozenge').forEach(function(loz) {\n          loz.classList.add('is-disabled');\n        });\n        this.element.querySelector('form').submit();\n      };\n\n      new LozengeController(\n        this._lozengeContainer,\n        {\n          content: content,\n          deleteCallback: deleteCallback,\n        }\n      );\n    };\n\n    /**\n     * Add incomplete search query terms which start with a quote but are missing the end quote\n     * to the input field from the hidden input field on page load.\n     */\n    var addIncompleteSearchTermToInput = () => {\n      this._input.value = SearchTextParser.getIncompleteInputValue(this._inputHidden.value);\n    };\n\n    /**\n     * Create lozenges for the search query terms already in\n     * the hidden input field on page load.\n     */\n    var lozengifyHiddenInput = () => {\n      var queryTerms = SearchTextParser.getLozengeValues(this._inputHidden.value);\n      queryTerms.forEach(function(term) {\n        addLozenge(term);\n      });\n    };\n\n    /**\n     * Setup listener keys with the handlers provided for each\n     * of them.\n     *\n     * @param {Event} The event.\n     * @param {Object} The function to execute when\n     * the event fires for each listener key.\n     */\n    var setupListenerKeys = (event, handlers) => {\n      var handler = handlers[event.keyCode];\n      if (handler) {\n        handler(event);\n      }\n    };\n\n    /**\n     * Setup the space key as the  listener for\n     * creating a lozenge.\n     *\n     * @param {Event} The event to listen for.\n     */\n    var setupLozengeListenerKeys = event => {\n      const SPACE_KEY_CODE = 32;\n\n      var handleSpaceKey = () => {\n        var word = getTrimmedInputValue();\n        if (SearchTextParser.shouldLozengify(word)) {\n          addLozenge(word);\n          // Clear the input after the lozenge is created and\n          // appended to the container element.\n          event.preventDefault();\n          this._input.value = '';\n        }\n      };\n\n      var handlers = {};\n      handlers[SPACE_KEY_CODE] = handleSpaceKey;\n      setupListenerKeys(event, handlers);\n    };\n\n    /**\n     * Setup the keys to  listener for in the search dropdown.\n     *\n     * @param {Event} The event to listen for.\n     */\n    var setupDropdownListenerKeys = event => {\n      const DOWN_ARROW_KEY_CODE = 40;\n      const ENTER_KEY_CODE = 13;\n      const UP_ARROW_KEY_CODE = 38;\n\n      var activeItem = getActiveDropdownItem();\n      var handlers = {};\n\n      var visibleDropdownItems = getVisibleDropdownItems();\n\n      var handleDownArrowKey = () => {\n        updateActiveDropdownItem(getNextVisibleSiblingElement(activeItem) ||\n          visibleDropdownItems[0]);\n      };\n\n      var handleEnterKey = event => {\n        if (activeItem) {\n          event.preventDefault();\n          var facet =\n            activeItem.\n              querySelector('[data-ref=\"searchBarDropdownItemTitle\"]').\n              innerHTML.trim();\n          selectFacet(facet);\n        } else {\n          updateHiddenInputValue();\n          this.element.querySelector('form').submit();\n        }\n      };\n\n      var handleUpArrowKey = () => {\n        updateActiveDropdownItem(getPreviousVisibleSiblingElement(activeItem) ||\n          visibleDropdownItems[visibleDropdownItems.length - 1]);\n      };\n\n      handlers[DOWN_ARROW_KEY_CODE] = handleDownArrowKey;\n      handlers[ENTER_KEY_CODE] = handleEnterKey;\n      handlers[UP_ARROW_KEY_CODE] = handleUpArrowKey;\n\n      setupListenerKeys(event, handlers);\n    };\n\n    var handleClickOnItem = event => {\n      var facet =\n        event.currentTarget.\n          querySelector('[data-ref=\"searchBarDropdownItemTitle\"]').\n          innerHTML.trim();\n      selectFacet(facet);\n    };\n\n    var handleHoverOnItem = event => {\n      updateActiveDropdownItem(event.currentTarget);\n    };\n\n    var handleClickOnDropdown = event => {\n      // prevent clicking on a part of the dropdown menu itself that\n      // isn't one of the suggestions from closing the menu\n      event.preventDefault();\n    };\n\n    var handleFocusOutside = event => {\n      if (!element.contains(event.target) ||\n        !element.contains(event.relatedTarget)) {\n        this.setState({open: false});\n      }\n      closeDropdown();\n      this._input.removeEventListener('keydown', setupDropdownListenerKeys);\n      this._input.removeEventListener('keydown', setupLozengeListenerKeys);\n    };\n\n    var handleFocusinOnInput = () => {\n      this._input.addEventListener('keydown', setupDropdownListenerKeys);\n      maybeOpenOrCloseDropdown();\n    };\n\n    var handleInputOnInput = () => {\n      var word = getTrimmedInputValue();\n      setVisibleDropdownItems(word);\n      maybeOpenOrCloseDropdown();\n      this._input.addEventListener('keydown', setupLozengeListenerKeys);\n    };\n\n    this._dropdownItems.forEach(function(item) {\n      if(item && item.addEventListener) {\n        item.addEventListener('mousemove', handleHoverOnItem);\n        item.addEventListener('mousedown', handleClickOnItem);\n      }\n    });\n\n    this._dropdown.addEventListener('mousedown', handleClickOnDropdown);\n    this._input.addEventListener('blur', handleFocusOutside);\n    this._input.addEventListener('input', handleInputOnInput);\n    this._input.addEventListener('focus', handleFocusinOnInput);\n\n    lozengifyHiddenInput();\n    addIncompleteSearchTermToInput();\n  }\n\n  update(state) {\n    setElementState(this._dropdown, {open: state.open});\n  }\n}\n\nmodule.exports = SearchBarController;\n"},{"size":1396,"relativepath":"h/static/scripts/controllers/search-bucket-controller.js","filename":"search-bucket-controller.js","extension":".js","content":"'use strict';\n\nvar scrollIntoView = require('scroll-into-view');\n\nvar Controller = require('../base/controller');\nvar setElementState = require('../util/dom').setElementState;\n\n/**\n * @typedef Options\n * @property {EnvironmentFlags} [envFlags] - Environment flags. Provided as a\n *           test seam.\n * @property {Function} [scrollTo] - A function that scrolls a given element\n *           into view. Provided as a test seam.\n */\n\n/**\n * Controller for buckets of results in the search result list\n */\nclass SearchBucketController extends Controller {\n  /**\n   * @param {Element} element\n   * @param {Options} options\n   */\n  constructor(element, options) {\n    super(element, options);\n\n    this.scrollTo = this.options.scrollTo || scrollIntoView;\n\n    this.refs.header.addEventListener('click', () => {\n      this.setState({expanded: !this.state.expanded});\n    });\n\n    var envFlags = this.options.envFlags || window.envFlags;\n\n    this.setState({\n      expanded: !!envFlags.get('js-timeout'),\n    });\n  }\n\n  update(state, prevState) {\n    setElementState(this.refs.content, {hidden: !state.expanded});\n    setElementState(this.element, {expanded: state.expanded});\n\n    // Scroll to element when expanded, except on initial load\n    if (typeof prevState.expanded !== 'undefined' && state.expanded) {\n      this.scrollTo(this.element);\n    }\n  }\n}\n\nmodule.exports = SearchBucketController;\n"},{"size":765,"relativepath":"h/static/scripts/controllers/character-limit-controller.js","filename":"character-limit-controller.js","extension":".js","content":"'use strict';\n\nvar Controller = require('../base/controller');\nvar { setElementState } = require('../util/dom');\n\nclass CharacterLimitController extends Controller {\n  constructor(element) {\n    super(element);\n\n    this.refs.characterLimitInput.addEventListener('input', () => {\n      this.forceUpdate();\n    });\n    this.forceUpdate();\n  }\n\n  update() {\n    var input = this.refs.characterLimitInput;\n    var maxlength = parseInt(input.dataset.maxlength);\n    var counter = this.refs.characterLimitCounter;\n    counter.textContent = input.value.length + '/' + maxlength;\n    setElementState(counter, {tooLong: input.value.length > maxlength});\n    setElementState(this.refs.characterLimitCounter, {ready: true});\n  }\n}\n\nmodule.exports = CharacterLimitController;\n"},{"size":457,"relativepath":"h/static/scripts/controllers/form-select-onfocus-controller.js","filename":"form-select-onfocus-controller.js","extension":".js","content":"'use strict';\n\nvar Controller = require('../base/controller');\n\nclass FormSelectOnFocusController extends Controller {\n  constructor(element) {\n    super(element);\n\n    // In case the `focus` event has already been fired, select the element\n    if (element === document.activeElement) {\n      element.select();\n    }\n\n    element.addEventListener('focus', event => {\n      event.target.select();\n    });\n  }\n}\n\nmodule.exports = FormSelectOnFocusController;\n"},{"size":354,"relativepath":"h/static/scripts/controllers/signup-form-controller.js","filename":"signup-form-controller.js","extension":".js","content":"'use strict';\n\nvar Controller = require('../base/controller');\n\nclass SignupFormController extends Controller {\n  constructor(element) {\n    super(element);\n\n    var submitBtn = element.querySelector('.js-signup-btn');\n\n    element.addEventListener('submit', () => {\n      submitBtn.disabled = true;\n    });\n  }\n}\n\nmodule.exports = SignupFormController;\n"},{"size":521,"relativepath":"h/static/scripts/controllers/admin-users-controller.js","filename":"admin-users-controller.js","extension":".js","content":"'use strict';\n\nvar Controller = require('../base/controller');\n\nclass AdminUsersController extends Controller {\n  constructor(element, options) {\n    super(element, options);\n\n    var window_ = options.window || window;\n    function confirmFormSubmit() {\n      return window_.confirm('This will permanently delete all the user\\'s data. Are you sure?');\n    }\n\n    this.on('submit', event => {\n      if (!confirmFormSubmit()) {\n        event.preventDefault();\n      }\n    });\n  }\n}\n\nmodule.exports = AdminUsersController;\n"},{"size":836,"relativepath":"h/static/scripts/controllers/create-group-form-controller.js","filename":"create-group-form-controller.js","extension":".js","content":"'use strict';\n\nfunction CreateGroupFormController(element) {\n  // Create Group form handling\n  var self = this;\n  this._submitBtn = element.querySelector('.js-create-group-create-btn');\n  this._groupNameInput = element.querySelector('.js-group-name-input');\n  this._infoLink = element.querySelector('.js-group-info-link');\n  this._infoText = element.querySelector('.js-group-info-text');\n\n  function groupNameChanged() {\n    self._submitBtn.disabled = self._groupNameInput.value.trim().length === 0;\n  }\n\n  self._groupNameInput.addEventListener('input', groupNameChanged);\n  groupNameChanged();\n\n  this._infoLink.addEventListener('click', function (event) {\n    event.preventDefault();\n    self._infoLink.classList.add('is-hidden');\n    self._infoText.classList.remove('is-hidden');\n  });\n}\n\nmodule.exports = CreateGroupFormController;\n"},{"size":6532,"relativepath":"h/static/scripts/controllers/form-controller.js","filename":"form-controller.js","extension":".js","content":"'use strict';\n\nvar Controller = require('../base/controller');\nvar { findRefs, setElementState } = require('../util/dom');\nvar modalFocus = require('../util/modal-focus');\nvar submitForm = require('../util/submit-form');\n\nfunction shouldAutosubmit(type) {\n  var autosubmitTypes = ['checkbox', 'radio'];\n  return autosubmitTypes.indexOf(type) !== -1;\n}\n\n/**\n * A controller which adds inline editing functionality to forms\n */\nclass FormController extends Controller {\n  constructor(element, options) {\n    super(element, options);\n\n    setElementState(this.refs.cancelBtn, {hidden: false});\n    this.refs.cancelBtn.addEventListener('click', event => {\n      event.preventDefault();\n      this.cancel();\n    });\n\n    // List of groups of controls that constitute each form field\n    this._fields = Array.from(element.querySelectorAll('.js-form-input'))\n      .map(el => {\n        var parts = findRefs(el);\n        return {container: el, input: parts.formInput};\n      });\n\n    this.on('focus', event => {\n      var field = this._fields.find(field => field.input === event.target);\n      if (!field) {\n        return;\n      }\n\n      this.setState({editingField: field});\n    }, true /* capture - focus does not bubble */);\n\n    this.on('change', event => {\n      if (shouldAutosubmit(event.target.type)) {\n        this.submit();\n      }\n    });\n\n    this.on('input', event => {\n      // Some but not all browsers deliver an `input` event for radio/checkbox\n      // inputs. Since we auto-submit when such inputs change, don't mark the\n      // field as dirty.\n      if (shouldAutosubmit(event.target.type)) {\n        return;\n      }\n      this.setState({dirty: true});\n    });\n\n    this.on('keydown', event => {\n      event.stopPropagation();\n      if (event.key === 'Escape') {\n        this.cancel();\n      }\n    });\n\n    // Ignore clicks outside of the active field when editing\n    this.refs.formBackdrop.addEventListener('mousedown', event => {\n      event.preventDefault();\n      event.stopPropagation();\n    });\n\n    // Setup AJAX handling for forms\n    this.on('submit', event => {\n      event.preventDefault();\n      this.submit();\n    });\n\n    this.setState({\n      // True if the user has made changes to the field they are currently\n      // editing\n      dirty: false,\n      // The group of elements (container, input) for the form field currently\n      // being edited\n      editingField: null,\n      // Markup for the original form. Used to revert the form to its original\n      // state when the user cancels editing\n      originalForm: this.element.outerHTML,\n      // Flag that indicates a save is currently in progress\n      saving: false,\n      // Error that occurred while submitting the form\n      submitError: '',\n    });\n  }\n\n  update(state, prevState) {\n    if (prevState.editingField &&\n        state.editingField !== prevState.editingField) {\n      setElementState(prevState.editingField.container, {editing: false});\n    }\n\n    if (state.editingField) {\n      // Display Save/Cancel buttons below the field that we are currently\n      // editing\n      state.editingField.container.parentElement.insertBefore(\n        this.refs.formActions,\n        state.editingField.container.nextSibling\n      );\n      setElementState(state.editingField.container, {editing: true});\n\n      this._trapFocus();\n    }\n\n    var isEditing = !!state.editingField;\n    setElementState(this.element, {editing: isEditing});\n    setElementState(this.refs.formActions, {\n      hidden: !isEditing || shouldAutosubmit(state.editingField.input.type),\n      saving: state.saving,\n    });\n    setElementState(this.refs.formSubmitError, {\n      visible: state.submitError.length > 0,\n    });\n    this.refs.formSubmitErrorMessage.textContent = state.submitError;\n  }\n\n  beforeRemove() {\n    if (this._releaseFocus) {\n      this._releaseFocus();\n    }\n  }\n\n  /**\n   * Perform an AJAX submission of the form and replace it with the rendered\n   * result.\n   */\n  submit() {\n    var originalForm = this.state.originalForm;\n\n    var activeInputId;\n    if (this.state.editingField) {\n      activeInputId = this.state.editingField.input.id;\n    }\n\n    this.setState({saving: true});\n\n    return submitForm(this.element).then(response => {\n      this.options.reload(response.form);\n    }).catch(err => {\n      if (err.form) {\n        // The server processed the request but rejected the submission.\n        // Display the returned form which will contain any validation error\n        // messages.\n        var newFormEl = this.options.reload(err.form);\n        var newFormCtrl = newFormEl.controllers.find(ctrl =>\n          ctrl instanceof FormController);\n\n        // Resume editing the field where validation failed\n        var newInput = document.getElementById(activeInputId);\n        if (newInput) {\n          newInput.focus();\n        }\n\n        newFormCtrl.setState({\n          // Mark the field in the replaced form as dirty since it has unsaved\n          // changes\n          dirty: newInput !== null,\n          // If editing is canceled, revert back to the _original_ version of\n          // the form, not the version with validation errors from the server.\n          originalForm,\n        });\n      } else {\n        // If there was an error processing the request or the server could\n        // not be reached, display a helpful error\n        this.setState({\n          submitError: err.reason,\n          saving: false,\n        });\n      }\n    });\n  }\n\n  /**\n   * Return the set of elements that the user should be able to interact with,\n   * depending upon the field which is currently focused.\n   */\n  _focusGroup() {\n    if (!this.state.editingField) {\n      return null;\n    }\n\n    return [this.refs.formActions, this.state.editingField.container];\n  }\n\n  _trapFocus() {\n    this._releaseFocus = modalFocus.trap(this._focusGroup(), newFocusedElement => {\n      // Keep focus in the current field when it has unsaved changes,\n      // otherwise let the user focus another field in the form or move focus\n      // outside the form entirely.\n      if (this.state.dirty) {\n        return this.state.editingField.input;\n      }\n\n      // If the user tabs out of the form, clear the editing state\n      if (!this.element.contains(newFocusedElement)) {\n        this.setState({editingField: null});\n      }\n\n      return null;\n    });\n  }\n\n  /**\n   * Cancel editing for the currently active field and revert any unsaved\n   * changes.\n   */\n  cancel() {\n    this.options.reload(this.state.originalForm);\n  }\n}\n\nmodule.exports = FormController;\n"},{"size":1848,"relativepath":"h/static/scripts/controllers/tooltip-controller.js","filename":"tooltip-controller.js","extension":".js","content":"'use strict';\n\nvar Controller = require('../base/controller');\n\n/**\n * A custom tooltip similar to the one used in Google Docs which appears\n * instantly when activated on a target element.\n *\n * The tooltip is displayed and hidden by setting its target element.\n *\n *  var tooltip = new Tooltip(document.body);\n *  tooltip.setState({target: aWidget}); // Show tooltip\n *  tooltip.setState({target: null}); // Hide tooltip\n *\n * The tooltip's label is derived from the target element's 'aria-label'\n * attribute.\n */\nclass TooltipController extends Controller {\n  constructor(el) {\n    super(el);\n\n    // With mouse input, show the tooltip on hover. On touch devices we rely on\n    // the browser to synthesize 'mouseover' events to make the tooltip appear\n    // when the host element is tapped and disappear when the host element loses\n    // focus.\n    // See http://www.codediesel.com/javascript/making-mouseover-event-work-on-an-ipad/\n    el.addEventListener('mouseover', () => {\n      this.setState({target: el});\n    });\n\n    el.addEventListener('mouseout', () => {\n      this.setState({target: null});\n    });\n\n    this._tooltipEl = el.ownerDocument.createElement('div');\n    this._tooltipEl.innerHTML = '<span class=\"tooltip-label js-tooltip-label\"></span>';\n    this._tooltipEl.className = 'tooltip';\n    el.appendChild(this._tooltipEl);\n    this._labelEl = this._tooltipEl.querySelector('.js-tooltip-label');\n\n    this.setState({target: null});\n  }\n\n  update(state) {\n    if (!state.target) {\n      this._tooltipEl.style.visibility = 'hidden';\n      return;\n    }\n\n    var target = state.target;\n    var label = target.getAttribute('aria-label');\n    this._labelEl.textContent = label;\n\n    Object.assign(this._tooltipEl.style, {\n      visibility: '',\n      bottom: 'calc(100% + 5px)',\n    });\n  }\n}\n\nmodule.exports = TooltipController;\n"},{"size":1134,"relativepath":"h/static/scripts/controllers/lozenge-controller.js","filename":"lozenge-controller.js","extension":".js","content":"'use strict';\n\nvar Controller = require('../base/controller');\n\n/**\n * Create a lozenge with options.content as its content and append it to containerEl.\n *\n * A lozenge is made of two parts - the lozenge content and\n * the 'x' button which when clicked removes the lozenge\n * from the container and executes the delete callback provided.\n *\n * var lozenge = new Lozenge(containerEl, {\n *   content: content,\n *   deleteCallback: deleteCallback,\n * });\n */\nclass LozengeController extends Controller {\n  constructor(containerEl, options) {\n    super(containerEl, options);\n    var lozengeEl = document.createElement('div');\n    lozengeEl.innerHTML =\n      '<div class=\"js-lozenge__content lozenge__content\">'+\n      options.content+\n      '</div>' +\n      '<div class=\"js-lozenge__close lozenge__close\">x</div>';\n    lozengeEl.classList.add('lozenge');\n    lozengeEl.classList.add('js-lozenge');\n    containerEl.appendChild(lozengeEl);\n\n    lozengeEl.querySelector('.js-lozenge__close').addEventListener('mousedown', () => {\n      lozengeEl.remove();\n      options.deleteCallback();\n    });\n  }\n}\n\nmodule.exports = LozengeController;\n"},{"size":531,"relativepath":"h/static/scripts/polyfills.js","filename":"polyfills.js","extension":".js","content":"'use strict';\n\n// ES2015 polyfills\nrequire('core-js/es6/promise');\nrequire('core-js/fn/array/find');\nrequire('core-js/fn/array/find-index');\nrequire('core-js/fn/array/from');\nrequire('core-js/fn/object/assign');\nrequire('core-js/fn/string/starts-with');\n\n// URL constructor, required by IE 10/11,\n// early versions of Microsoft Edge.\ntry {\n  new window.URL('https://hypothes.is');\n} catch (err) {\n  require('js-polyfills/url');\n}\n\n// Fetch API\n// https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API\nrequire('whatwg-fetch');\n"},{"size":493,"relativepath":"h/static/scripts/admin-site.js","filename":"admin-site.js","extension":".js","content":"'use strict';\n\n// configure error reporting\nvar settings = require('./base/settings')(document);\nif (settings.raven) {\n  require('./base/raven').init(settings.raven);\n}\n\nwindow.$ = window.jQuery = require('jquery');\nrequire('bootstrap');\n\nvar AdminUsersController = require('./controllers/admin-users-controller');\nvar upgradeElements = require('./base/upgrade-elements');\n\nvar controllers = {\n  '.js-users-delete-form': AdminUsersController,\n};\n\nupgradeElements(document.body, controllers);\n\n"},{"size":51,"relativepath":"h/static/robots.txt","filename":"robots.txt","extension":".txt","content":"User-agent: *\nDisallow: /groups\nAllow: /groups/new\n"},{"size":473,"relativepath":"h/resources.py","filename":"resources.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom pyramid.security import Allow\nfrom pyramid.security import ALL_PERMISSIONS\nfrom pyramid.security import DENY_ALL\n\nfrom h.auth import role\n\n\nclass Root(object):\n    __acl__ = [\n        (Allow, role.Staff, 'admin_index'),\n        (Allow, role.Staff, 'admin_groups'),\n        (Allow, role.Staff, 'admin_users'),\n        (Allow, role.Admin, ALL_PERMISSIONS),\n        DENY_ALL\n    ]\n\n    def __init__(self, request):\n        self.request = request\n"},{"size":2604,"relativepath":"h/jinja_extensions.py","filename":"jinja_extensions.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport datetime\nfrom functools import partial\nimport json\nimport re\n\ntry:\n    from xml.etree import cElementTree as ElementTree\nexcept ImportError:\n    from xml.etree import ElementTree\n\nfrom jinja2 import Markup\nfrom jinja2.ext import Extension\n\nSVG_NAMESPACE_URI = 'http://www.w3.org/2000/svg'\n\n\nclass Filters(Extension):\n\n    \"\"\"\n    Set up filters for Jinja2.\n    \"\"\"\n\n    def __init__(self, environment):\n        super(Filters, self).__init__(environment)\n\n        environment.filters['to_json'] = to_json\n        environment.filters['human_timestamp'] = human_timestamp\n\n\ndef human_timestamp(timestamp, now=datetime.datetime.utcnow):\n    \"\"\"Turn a :py:class:`datetime.datetime` into a human-friendly string.\"\"\"\n    fmt = '%d %B at %H:%M'\n    if timestamp.year < now().year:\n        fmt = '%d %B %Y at %H:%M'\n    return timestamp.strftime(fmt)\n\n\ndef to_json(value):\n    \"\"\"Convert a dict into a JSON string\"\"\"\n    return Markup(json.dumps(value))\n\n\nclass SvgIcon(Extension):\n\n    \"\"\"\n    Setup helpers for rendering icons.\n    \"\"\"\n\n    def __init__(self, environment):\n        super(SvgIcon, self).__init__(environment)\n\n        def read_icon(name):\n            return open('build/images/icons/{}.svg'.format(name)).read()\n\n        environment.globals['svg_icon'] = partial(svg_icon, read_icon)\n\n\ndef svg_icon(loader, name, css_class=''):\n    \"\"\"\n    Return inline SVG markup for an icon.\n\n    This is a helper for generating inline SVGs for rendering icons in HTML\n    that can be customized via CSS.\n    See https://github.com/blog/2112-delivering-octicons-with-svg\n\n    :param loader: Callable accepting an icon name and returning XML markup for\n                   the SVG.\n    :param name: The name of the SVG file to render\n    :param css_class: CSS class attribute for the returned `<svg>` element\n    \"\"\"\n\n    # Register SVG as the default namespace. This avoids a problem where\n    # ElementTree otherwise serializes SVG elements with an 'ns0' namespace (eg.\n    # '<ns0:svg>...') and browsers will not render the result as SVG.\n    # See http://stackoverflow.com/questions/8983041\n    ElementTree.register_namespace('', SVG_NAMESPACE_URI)\n    root = ElementTree.fromstring(loader(name))\n\n    if css_class:\n        root.set('class', css_class)\n\n    # If the SVG has its own title, ignore it in favor of the title attribute\n    # of the <svg> or its containing element, which is usually a link.\n    title_el = root.find('{{{}}}title'.format(SVG_NAMESPACE_URI))\n    if title_el is not None:\n        root.remove(title_el)\n\n    return Markup(ElementTree.tostring(root))\n"},{"size":1598,"relativepath":"h/security.py","filename":"security.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport base64\nimport os\n\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives.kdf.hkdf import HKDF\nfrom cryptography.hazmat.backends import default_backend\nfrom passlib.context import CryptContext\n\nDEFAULT_ENTROPY = 32\n\nbackend = default_backend()\n\n# We use a passlib CryptContext to define acceptable hashing algorithms for\n# passwords. This allows us to easily\n#\n# - migrate to new hashing algorithms\n# - update the number of rounds used when hashing passwords\n#\n# simply by using the verify_and_update method of the CryptContext object. See\n# the passlib documentation on hash migration for more details:\n#\n#   https://pythonhosted.org/passlib/lib/passlib.context-tutorial.html#context-migration-example\n#\npassword_context = CryptContext(schemes=['bcrypt'],\n                                bcrypt__ident='2b',\n                                bcrypt__min_rounds=12)\n\n\ndef derive_key(key_material, info, algorithm=None, length=None):\n    if algorithm is None:\n        algorithm = hashes.SHA512()\n    if length is None:\n        length = algorithm.digest_size\n    hkdf = HKDF(algorithm, length, b'h.security', info, backend)\n    return hkdf.derive(key_material)\n\n\n# Implementation modeled on `secrets.token_urlsafe`, new in Python 3.6.\ndef token_urlsafe(nbytes=None):\n    \"\"\"Return a random URL-safe string composed of *nbytes* random bytes.\"\"\"\n    if nbytes is None:\n        nbytes = DEFAULT_ENTROPY\n    tok = os.urandom(nbytes)\n    return base64.urlsafe_b64encode(tok).rstrip(b'=').decode('ascii')\n"},{"size":4115,"relativepath":"h/config.py","filename":"config.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"Configuration for the h application.\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport logging\nimport os\n\nfrom pyramid.config import Configurator\nfrom pyramid.settings import asbool\n\nfrom h.security import derive_key\nfrom h.settings import DockerSetting\nfrom h.settings import EnvSetting\nfrom h.settings import SettingError\nfrom h.settings import database_url\nfrom h.settings import mandrill_settings\n\n__all__ = ('configure',)\n\nlog = logging.getLogger(__name__)\n\n# The list of all settings read from the system environment. These are in\n# reverse-priority order, meaning that later settings trump earlier settings.\n# In general, automatic setup (such as Docker links) is overridden by explicit\n# settings.\nSETTINGS = [\n    # Automatic configuration of remote services via Docker links\n    DockerSetting('es.host', 'elasticsearch',\n                  pattern='http://{port_9200_tcp_addr}:{port_9200_tcp_port}'),\n    DockerSetting('mail.host', 'mail',\n                  pattern='{port_25_tcp_addr}'),\n    DockerSetting('mail.port', 'mail', pattern='{port_25_tcp_port}'),\n    DockerSetting('statsd.host', 'statsd', pattern='{port_8125_udp_addr}'),\n    DockerSetting('statsd.port', 'statsd', pattern='{port_8125_udp_port}'),\n\n    # Mailer configuration for Mandrill\n    mandrill_settings,\n\n    # Configuration for external components\n    EnvSetting('broker_url', 'BROKER_URL'),\n    EnvSetting('es.client_poolsize', 'ELASTICSEARCH_CLIENT_POOLSIZE',\n               type=int),\n    EnvSetting('es.client_timeout', 'ELASTICSEARCH_CLIENT_TIMEOUT', type=int),\n    EnvSetting('es.host', 'ELASTICSEARCH_HOST'),\n    EnvSetting('es.index', 'ELASTICSEARCH_INDEX'),\n    EnvSetting('mail.default_sender', 'MAIL_DEFAULT_SENDER'),\n    EnvSetting('mail.host', 'MAIL_HOST'),\n    EnvSetting('mail.port', 'MAIL_PORT', type=int),\n    EnvSetting('origins', 'ALLOWED_ORIGINS'),\n    EnvSetting('sqlalchemy.url', 'DATABASE_URL', type=database_url),\n    EnvSetting('statsd.host', 'STATSD_HOST'),\n    EnvSetting('statsd.port', 'STATSD_PORT', type=int),\n\n    # Configuration for Pyramid\n    EnvSetting('secret_key', 'SECRET_KEY', type=bytes),\n\n    # Configuration for h\n    EnvSetting('csp.enabled', 'CSP_ENABLED', type=asbool),\n    EnvSetting('csp.report_uri', 'CSP_REPORT_URI'),\n    EnvSetting('csp.report_only', 'CSP_REPORT_ONLY'),\n    EnvSetting('ga_tracking_id', 'GOOGLE_ANALYTICS_TRACKING_ID'),\n    EnvSetting('h.app_url', 'APP_URL'),\n    EnvSetting('h.auth_domain', 'AUTH_DOMAIN'),\n    EnvSetting('h.bouncer_url', 'BOUNCER_URL'),\n    EnvSetting('h.client_id', 'CLIENT_ID'),\n    EnvSetting('h.client_secret', 'CLIENT_SECRET'),\n    EnvSetting('h.db.should_create_all', 'MODEL_CREATE_ALL', type=asbool),\n    EnvSetting('h.db.should_drop_all', 'MODEL_DROP_ALL', type=asbool),\n    EnvSetting('h.proxy_auth', 'PROXY_AUTH', type=asbool),\n    EnvSetting('h.search.autoconfig', 'SEARCH_AUTOCONFIG', type=asbool),\n    EnvSetting('h.websocket_url', 'WEBSOCKET_URL'),\n    # The client Sentry DSN should be of the public kind, lacking the password\n    # component in the DSN URI.\n    EnvSetting('h.client.sentry_dsn', 'SENTRY_DSN_CLIENT'),\n\n    # Debug/development settings\n    EnvSetting('debug_query', 'DEBUG_QUERY'),\n]\n\n\ndef configure(environ=None, settings=None):\n    if environ is None:\n        environ = os.environ\n    if settings is None:\n        settings = {}\n\n    for s in SETTINGS:\n        try:\n            result = s(environ)\n        except SettingError as e:\n            log.warn(e)\n\n        if result is not None:\n            settings.update(result)\n\n    if 'secret_key' not in settings:\n        log.warn('No secret key provided: using transient key. Please '\n                 'configure the secret_key setting or the SECRET_KEY '\n                 'environment variable!')\n        settings['secret_key'] = os.urandom(64)\n\n    # Set up SQLAlchemy debug logging\n    if 'debug_query' in settings:\n        level = logging.INFO\n        if settings['debug_query'] == 'trace':\n            level = logging.DEBUG\n        logging.getLogger('sqlalchemy.engine').setLevel(level)\n\n    return Configurator(settings=settings)\n"},{"size":1225,"relativepath":"h/exceptions.py","filename":"exceptions.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"Exceptions raised by the h application.\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom h.i18n import TranslationString as _\n\n\n# N.B. This class **only** covers exceptions thrown by API code provided by\n# the h package. memex code has its own base APIError class.\nclass APIError(Exception):\n\n    \"\"\"Base exception for problems handling API requests.\"\"\"\n\n    def __init__(self, message, status_code=500):\n        self.status_code = status_code\n        super(APIError, self).__init__(message)\n\n\nclass ClientUnauthorized(APIError):\n\n    \"\"\"\n    Exception raised if the client credentials provided for an API request\n    were missing or invalid.\n    \"\"\"\n\n    def __init__(self):\n        message = _('Client credentials are invalid.')\n        super(ClientUnauthorized, self).__init__(message, status_code=403)\n\n\nclass OAuthTokenError(APIError):\n\n    \"\"\"\n    Exception raised when an OAuth token request failed.\n\n    This specifically handles OAuth errors which have a type (``message``) and\n    a description (``description``).\n    \"\"\"\n\n    def __init__(self, message, type_, status_code=400):\n        self.type = type_\n        super(OAuthTokenError, self).__init__(message, status_code=status_code)\n"},{"size":471,"relativepath":"h/features/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom h.features.client import Client\n\n__all__ = ('Client',)\n\n\ndef includeme(config):\n    config.add_request_method(Client, name='feature', reify=True)\n\n    config.add_subscriber('h.features.subscribers.remove_old_flags',\n                          'pyramid.events.ApplicationCreated')\n    config.add_subscriber('h.features.subscribers.preload_flags',\n                          'pyramid.events.NewRequest')\n"},{"size":987,"relativepath":"h/features/subscribers.py","filename":"subscribers.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport os\n\nfrom h import db\nfrom h.models import Feature\n\n\ndef remove_old_flags(event):\n    \"\"\"Remove old feature flags from the database.\"\"\"\n    # Skip this if we're in a script, not actual app startup. See the comment\n    # in h.cli:main for an explanation.\n    if 'H_SCRIPT' in os.environ:\n        return\n\n    engine = db.make_engine(event.app.registry.settings)\n    session = db.Session(bind=engine)\n    Feature.remove_old_flags(session)\n    session.commit()\n    session.close()\n    engine.dispose()\n\n\ndef preload_flags(event):\n    \"\"\"Load all feature flags from the database for this request.\"\"\"\n    if event.request.path.startswith(('/assets/', '/_debug_toolbar/')):\n        return\n    # This prevents sqlalchemy DetachedInstanceErrors that can occur if the\n    # feature flags client tries to load the feature flags later on and the\n    # database session has already been closed.\n    event.request.feature.load()\n"},{"size":2972,"relativepath":"h/features/client.py","filename":"client.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom h import models\nfrom h.auth import role\n\n\nclass UnknownFeatureError(Exception):\n    pass\n\n\nclass Client(object):\n    \"\"\"\n    Determine if the named feature is enabled for the current request.\n    If the feature has no override in the database, it will default to\n    False. Features must be documented, and an UnknownFeatureError will be\n    thrown if an undocumented feature is interrogated.\n    \"\"\"\n\n    def __init__(self, request, fetcher=models.Feature.all):\n        self.request = request\n        self._fetcher = fetcher\n        self._cache = None\n\n    def __call__(self, name):\n        return self.enabled(name)\n\n    def enabled(self, name):\n        \"\"\"\n        Determine if the named feature is enabled for the current request.\n\n        If the feature has no override in the database, it will default to\n        False. Features must be documented, and an UnknownFeatureError will be\n        thrown if an undocumented feature is interrogated.\n\n        When the internal cache is empty, it will automatically load the\n        feature flags from the database first.\n        \"\"\"\n        if self._cache is None:\n            self.load()\n\n        if name not in self._cache:\n            raise UnknownFeatureError(\n                '{0} is not a valid feature name'.format(name))\n\n        return self._cache[name]\n\n    def all(self):\n        \"\"\"\n        Returns a dict mapping feature flag names to enabled states\n        for the user associated with a given request.\n\n        When the internal cache is empty, it will automatically load the\n        feature flags from the database first.\n        \"\"\"\n        if self._cache is None:\n            self.load()\n\n        return self._cache\n\n    def clear(self):\n        self._cache = None\n\n    def load(self):\n        \"\"\"Load the feature flag states into the internal cache.\"\"\"\n        features = self._fetcher(self.request.db)\n        self._cache = {f.name: self._state(f) for f in features}\n\n    def _state(self, feature):\n        # If \"__feature__[<featurename>]\" is in the query string, then the\n        # feature is on. This allows testing feature flags for logged-out\n        # users.\n        if '__feature__[{}]'.format(feature.name) in self.request.GET:\n            return True\n        # Features that are on for everyone are on.\n        if feature.everyone:\n            return True\n        # Features that are on for admin are on if the current user is an\n        # admin.\n        if feature.admins and role.Admin in self.request.effective_principals:\n            return True\n        # Features that are on for staff are on if the current user is a staff\n        # member.\n        if feature.staff and role.Staff in self.request.effective_principals:\n            return True\n        if self.request.authenticated_user and \\\n           set(feature.cohorts) & set(self.request.authenticated_user.cohorts):\n            return True\n        return False\n"},{"size":2217,"relativepath":"h/session.py","filename":"session.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom pyramid.session import SignedCookieSessionFactory\n\nfrom h.security import derive_key\n\n\ndef model(request):\n    session = {}\n    session['csrf'] = request.session.get_csrf_token()\n    session['userid'] = request.authenticated_userid\n    session['groups'] = _current_groups(request)\n    session['features'] = request.feature.all()\n    session['preferences'] = {}\n    user = request.authenticated_user\n    if user and not user.sidebar_tutorial_dismissed:\n        session['preferences']['show_sidebar_tutorial'] = True\n    return session\n\n\ndef pop_flash(request):\n    return {k: request.session.pop_flash(k)\n            for k in ['error', 'info', 'warning', 'success']}\n\n\ndef _group_sort_key(group):\n    \"\"\"Sort private groups for the session model list\"\"\"\n\n    # groups are sorted first by name but also by ID\n    # so that multiple groups with the same name are displayed\n    # in a consistent order in clients\n    return (group.name.lower(), group.pubid)\n\n\ndef _current_groups(request):\n    \"\"\"Return a list of the groups the current user is a member of.\n\n    This list is meant to be returned to the client in the \"session\" model.\n\n    \"\"\"\n    groups = [\n        {'name': 'Public', 'id': '__world__', 'public': True},\n    ]\n    userid = request.authenticated_userid\n    if userid is None:\n        return groups\n    user = request.authenticated_user\n    if user is None:\n        return groups\n    for group in sorted(user.groups, key=_group_sort_key):\n        groups.append({\n            'name': group.name,\n            'id': group.pubid,\n            'url': request.route_url('group_read',\n                                     pubid=group.pubid,\n                                     slug=group.slug),\n        })\n    return groups\n\n\ndef includeme(config):\n    settings = config.registry.settings\n\n    # By default, derive_key generates a 64-byte (512 bit) secret, which is the\n    # correct length for SHA512-based HMAC as specified by the `hashalg`.\n    factory = SignedCookieSessionFactory(\n        secret=derive_key(settings['secret_key'], b'h.session.cookie_secret'),\n        hashalg='sha512',\n        httponly=True,\n        timeout=3600,\n    )\n    config.set_session_factory(factory)\n"},{"size":6879,"relativepath":"h/websocket.py","filename":"websocket.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"\nThe websocket server for Hypothesis.\n\nThis file contains a worker class for Gunicorn (:py:class:`h.websocket.Worker`)\nand a stripped-down Pyramid application which exposes a single endpoint for\nserving the \"streamer\" over the websocket.\n\nMost of the code in this file: specifically the WebSocketWSGIHandler,\nGEventWebSocketPool, and WSGIServer classes, are essentially lifted straight\nfrom the ws4py codebase. We've made a number of modifications to fix bugs in\nthe (apparently unmaintained) ws4py code, and these are documented below:\n\n1. Override WebSocketWSGIHandler.run_application due to the websocket server\n   crashing with EBADF. A change in gevent (1.1) causes all sockets to be\n   closed when a WSGI handler returns. ws4py starts a new greenlet for each\n   new websocket connection used to return from the WSGI handler. The fix is\n   taken from [1] and waits for the greenlet to finish before returning from\n   the WSGI handler.\n\n   [1]: https://github.com/Lawouach/WebSocket-for-Python/pull/180\n\n   More information at:\n\n   - https://github.com/Lawouach/WebSocket-for-Python/issues/170\n   - https://github.com/gevent/gevent/issues/633\n\n2. Fix GEventWebSocketPool so that if the set of greenlets changes while it is\n   being closed it doesn't throw a \"Set changed size during iteration\"\n   RuntimeError. See:\n\n   - https://github.com/Lawouach/WebSocket-for-Python/issues/132\n\nN.B. Portions of the ws4py code are used here under the terms of the MIT\nlicense distributed with the ws4py project. Such code remains copyright (c)\n2011-2015, Sylvain Hellegouarch.\n\"\"\"\n\nimport logging\n\nfrom gevent.pool import Pool\nfrom gunicorn.workers.ggevent import (GeventPyWSGIWorker, PyWSGIHandler,\n                                      PyWSGIServer)\nfrom ws4py import format_addresses\n\nfrom h import features\nfrom h.config import configure\n\nlog = logging.getLogger(__name__)\n\n\nclass WebSocketWSGIHandler(PyWSGIHandler):\n\n    \"\"\"\n    A WSGI handler that will perform the :rfc:`6455` upgrade and handshake\n    before calling the WSGI application.\n\n    If the incoming request doesn't have a `'Upgrade'` header, the handler will\n    simply fallback to the gevent builtin's handler and process it as per\n    usual.\n    \"\"\"\n\n    def finalize_headers(self):\n        if self.environ.get('HTTP_UPGRADE', '').lower() == 'websocket':\n            # Middleware, like Raven, may yield from the empty upgrade\n            # response, confusing this method into sending \"Transfer-Encoding:\n            # chunked\" and, in turn, this confuses some strict WebSocket\n            # clients.\n            if not hasattr(self.result, '__len__'):\n                self.result = list(self.result)\n\n            # ws4py 0.3.4 will try to pop the websocket from the environ\n            # even if it doesn't exist, causing a key error.\n            self.environ.setdefault('ws4py.websocket', None)\n\n        super(WebSocketWSGIHandler, self).finalize_headers()\n\n    def run_application(self):\n        upgrade_header = self.environ.get('HTTP_UPGRADE', '').lower()\n        if upgrade_header:\n            # Build and start the HTTP response\n            self.environ['ws4py.socket'] = self.socket or self.environ['wsgi.input'].rfile._sock\n            self.result = self.application(self.environ, self.start_response) or []\n            self.process_result()\n            del self.environ['ws4py.socket']\n            self.socket = None\n            self.rfile.close()\n\n            ws = self.environ.pop('ws4py.websocket', None)\n            if ws:\n                ws_greenlet = self.server.pool.track(ws)\n                ws_greenlet.join()\n        else:\n            super(WebSocketWSGIHandler, self).run_application()\n\n\nclass GEventWebSocketPool(Pool):\n\n    \"\"\"\n    Simple pool of bound websockets.\n\n    Internally it uses a gevent group to track the websockets. The server\n    should call the ``clear`` method to initiate the closing handshake when the\n    server is shutdown.\n    \"\"\"\n\n    def track(self, websocket):\n        log.debug(\"managing websocket %s\" % format_addresses(websocket))\n        return self.spawn(websocket.run)\n\n    def clear(self):\n        log.info(\"terminating server and all connected websockets\")\n        for greenlet in list(self):\n            try:\n                websocket = greenlet._run.im_self\n                if websocket:\n                    websocket.close(1001, 'Server is shutting down')\n            except:\n                pass\n            finally:\n                self.discard(greenlet)\n\n\nclass WSGIServer(PyWSGIServer):\n    \"\"\"\n    WSGI server that simply tracks websockets and send them a proper closing\n    handshake when the server terminates.\n\n    Other than that, the server is the same as its\n    :class:`gunicorn.workers.ggevent.PyWSGIServer` base.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super(WSGIServer, self).__init__(*args, **kwargs)\n        self.pool = GEventWebSocketPool()\n\n    def stop(self, *args, **kwargs):\n        self.pool.clear()\n        super(WSGIServer, self).stop(*args, **kwargs)\n\n\nclass Worker(GeventPyWSGIWorker):\n    server_class = WSGIServer\n    wsgi_handler = WebSocketWSGIHandler\n\n    # Used by our gunicorn config to selectively monkeypatch psycopg2\n    use_psycogreen = True\n\n\ndef create_app(global_config, **settings):\n    config = configure(settings=settings)\n\n    config.add_request_method(features.Client, name='feature', reify=True)\n\n    config.include('pyramid_services')\n\n    config.include('h.auth')\n    # Override the default authentication policy.\n    config.set_authentication_policy('h.auth.WEBSOCKET_POLICY')\n\n    config.include('h.authz')\n    config.include('h.session')\n    config.include('h.sentry')\n    config.include('h.stats')\n\n    # We have to include models and db to set up sqlalchemy metadata.\n    config.include('h.models')\n    config.include('h.db')\n\n    # We have to include parts of the `memex` package in order to provide,\n    # among other things:\n    #\n    #   - the links service\n    #   - the default presenters (and their link registrations)\n    #   - the `request.es` property\n    config.include('memex.links')\n    config.include('memex.presenters')\n    config.include('memex.search')\n\n    # accounts provides the UserService\n    config.include('h.accounts')\n\n    # We include links in order to set up the alternative link registrations\n    # for annotations.\n    config.include('h.links')\n\n    # We have to include nipsa to provide the NIPSA service\n    config.include('h.nipsa')\n\n    # And finally we add routes. Static routes are not resolvable by HTTP\n    # clients, but can be used for URL generation within the websocket server.\n    config.add_route('ws', '/ws')\n    config.add_route('annotation', '/a/{id}', static=True)\n    config.add_route('api.annotation', '/api/annotations/{id}', static=True)\n\n    config.include('h.streamer')\n\n    return config.make_wsgi_app()\n\n"},{"size":4447,"relativepath":"h/app.py","filename":"app.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"The main h application.\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport logging\n\nimport transaction\nfrom pyramid.settings import asbool\nfrom pyramid.tweens import EXCVIEW\n\nfrom h.config import configure\n\nlog = logging.getLogger(__name__)\n\n\ndef configure_jinja2_assets(config):\n    jinja2_env = config.get_jinja2_environment()\n    jinja2_env.globals['asset_urls'] = config.registry['assets_env'].urls\n\n\ndef in_debug_mode(request):\n    return asbool(request.registry.settings.get('pyramid.debug_all'))\n\n\ndef create_app(global_config, **settings):\n    \"\"\"\n    Create the h WSGI application.\n\n    This function serves as a paste app factory.\n    \"\"\"\n    config = configure(settings=settings)\n    config.include(__name__)\n    return config.make_wsgi_app()\n\n\ndef includeme(config):\n    config.set_root_factory('h.resources:Root')\n\n    config.add_subscriber('h.subscribers.add_renderer_globals',\n                          'pyramid.events.BeforeRender')\n    config.add_subscriber('h.subscribers.publish_annotation_event',\n                          'memex.events.AnnotationEvent')\n    config.add_subscriber('h.subscribers.send_reply_notifications',\n                          'memex.events.AnnotationEvent')\n\n    config.add_tween('h.tweens.conditional_http_tween_factory', under=EXCVIEW)\n    config.add_tween('h.tweens.redirect_tween_factory')\n    config.add_tween('h.tweens.csrf_tween_factory')\n    config.add_tween('h.tweens.auth_token')\n    config.add_tween('h.tweens.content_security_policy_tween_factory')\n\n    config.add_renderer('csv', 'h.renderers.CSV')\n    config.add_request_method(in_debug_mode, 'debug', reify=True)\n\n    config.include('pyramid_jinja2')\n    config.add_jinja2_extension('h.jinja_extensions.Filters')\n    config.add_jinja2_extension('h.jinja_extensions.SvgIcon')\n    # Register a deferred action to setup the assets environment\n    # when the configuration is committed.\n    config.action(None, configure_jinja2_assets, args=(config,))\n\n    # Pyramid layouts: provides support for reusable components ('panels')\n    # that are used across multiple pages\n    config.include('pyramid_layout')\n\n    config.registry.settings.setdefault('mail.default_sender',\n                                        '\"Annotation Daemon\" <no-reply@localhost>')\n    config.include('pyramid_mailer')\n\n    # Pyramid service layer: provides infrastructure for registering and\n    # retrieving services bound to the request.\n    config.include('pyramid_services')\n\n    # Configure the transaction manager to support retrying retryable\n    # exceptions, and generate a new transaction manager for each request.\n    config.add_settings({\n        \"tm.attempts\": 3,\n        \"tm.manager_hook\": lambda request: transaction.TransactionManager(),\n        \"tm.annotate_user\": False,\n    })\n    config.include('pyramid_tm')\n\n    # Enable a Content Security Policy\n    # This is initially copied from:\n    # https://github.com/pypa/warehouse/blob/e1cf03faf9bbaa15d67d0de2c70f9a9f732596aa/warehouse/config.py#L327\n    config.add_settings({\n        \"csp\": {\n            \"font-src\": [\"'self'\", \"fonts.gstatic.com\"],\n            \"report-uri\": [config.registry.settings.get(\"csp.report_uri\")],\n            \"script-src\": [\"'self'\"],\n            \"style-src\": [\"'self'\", \"fonts.googleapis.com\"],\n        },\n    })\n\n    # API module\n    #\n    # We include this first so that:\n    # - configuration directives provided by modules in `memex` are available\n    #   to the rest of the application at startup.\n    # - we can override behaviour from `memex` if necessary.\n    config.include('memex', route_prefix='/api')\n\n    # Core site modules\n    config.include('h.assets')\n    config.include('h.auth')\n    config.include('h.authz')\n    config.include('h.db')\n    config.include('h.features')\n    config.include('h.form')\n    config.include('h.indexer')\n    config.include('h.models')\n    config.include('h.realtime')\n    config.include('h.routes')\n    config.include('h.sentry')\n    config.include('h.session')\n    config.include('h.stats')\n    config.include('h.views')\n\n    # Site modules\n    config.include('h.accounts')\n    config.include('h.admin')\n    config.include('h.groups')\n    config.include('h.links')\n    config.include('h.nipsa')\n    config.include('h.notification')\n\n    # Debugging assistance\n    if asbool(config.registry.settings.get('h.debug')):\n        config.include('pyramid_debugtoolbar')\n        config.include('h.debug')\n"},{"size":117,"relativepath":"h/emails/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom h.emails import reply_notification, signup\n\n__all__ = ('reply_notification', 'signup')\n"},{"size":1154,"relativepath":"h/emails/signup.py","filename":"signup.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom pyramid.renderers import render\n\nfrom h.i18n import TranslationString as _\n\n\ndef generate(request, id, email, activation_code):\n    \"\"\"\n    Generate an email for a user signup.\n\n    :param request: the current request\n    :type request: pyramid.request.Request\n    :param id: the new user's primary key ID\n    :type id: int\n    :param email: the new user's email address\n    :type email: text\n    :param activation_code: the activation code\n    :type activation_code: text\n\n    :returns: a 4-element tuple containing: recipients, subject, text, html\n    \"\"\"\n    context = {\n        'activate_link': request.route_url('activate',\n                                           id=id,\n                                           code=activation_code),\n    }\n\n    subject = _('Please activate your account')\n\n    text = render('h:templates/emails/signup.txt.jinja2',\n                  context,\n                  request=request)\n    html = render('h:templates/emails/signup.html.jinja2',\n                  context,\n                  request=request)\n\n    return [email], subject, text, html\n"},{"size":2270,"relativepath":"h/emails/reply_notification.py","filename":"reply_notification.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom h import links\n\nfrom pyramid.renderers import render\n\n\ndef generate(request, notification):\n    \"\"\"\n    Generate an email for a reply notification.\n\n    :param request: the current request\n    :type request: pyramid.request.Request\n    :param notification: the reply notification data structure\n    :type notification: h.notifications.reply.Notification\n\n    :returns: a 4-element tuple containing: recipients, subject, text, html\n    \"\"\"\n    document_title = notification.document.title\n    if not document_title:\n        document_title = notification.parent.target_uri\n\n    parent_user_url = request.route_url('stream.user_query',\n                                        user=notification.parent_user.username)\n\n    reply_url = links.incontext_link(request, notification.reply)\n    if not reply_url:\n        reply_url = request.route_url('annotation', id=notification.reply.id)\n\n    reply_user_url = request.route_url('stream.user_query',\n                                       user=notification.reply_user.username)\n\n    unsubscribe_token = _unsubscribe_token(request, notification.parent_user)\n    unsubscribe_url = request.route_url('unsubscribe', token=unsubscribe_token)\n\n    context = {\n        'document_title': document_title,\n        'document_url': notification.parent.target_uri,\n        'parent': notification.parent,\n        'parent_user': notification.parent_user,\n        'parent_user_url': parent_user_url,\n        'reply': notification.reply,\n        'reply_url': reply_url,\n        'reply_user': notification.reply_user,\n        'reply_user_url': reply_user_url,\n        'unsubscribe_url': unsubscribe_url,\n    }\n\n    subject = '{user} has replied to your annotation'.format(\n        user=notification.reply_user.username)\n    text = render('h:templates/emails/reply_notification.txt.jinja2',\n                  context,\n                  request=request)\n    html = render('h:templates/emails/reply_notification.html.jinja2',\n                  context,\n                  request=request)\n\n    return [notification.parent_user.email], subject, text, html\n\n\ndef _unsubscribe_token(request, user):\n    serializer = request.registry.notification_serializer\n    return serializer.dumps({'type': 'reply', 'uri': user.userid})\n"},{"size":116,"relativepath":"h/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom h._version import get_version\n\n__all__ = ('__version__',)\n__version__ = get_version()\n"},{"size":6504,"relativepath":"h/views/groups.py","filename":"groups.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport deform\nfrom pyramid import security\nfrom pyramid.httpexceptions import (HTTPMovedPermanently, HTTPNoContent,\n                                    HTTPSeeOther)\nfrom pyramid.view import view_config, view_defaults\n\nfrom h import form\nfrom h import i18n\nfrom h import presenters\nfrom h.groups import schemas\n\n_ = i18n.TranslationString\n\n\n@view_defaults(route_name='group_create',\n               renderer='h:templates/groups/create.html.jinja2',\n               effective_principals=security.Authenticated)\nclass GroupCreateController(object):\n    def __init__(self, request):\n        self.request = request\n\n        if request.feature('activity_pages'):\n            self.schema = schemas.GroupSchema().bind(request=self.request)\n        else:\n            self.schema = schemas.LegacyGroupSchema().bind(request=self.request)\n\n        submit = deform.Button(title=_('Create a new group'),\n                               css_class='primary-action-btn '\n                                         'group-form__submit-btn '\n                                         'js-create-group-create-btn')\n        self.form = request.create_form(self.schema,\n                                        css_class='group-form__form',\n                                        buttons=(submit,))\n\n    @view_config(request_method='GET')\n    def get(self):\n        \"\"\"Render the form for creating a new group.\"\"\"\n        return self._template_data()\n\n    @view_config(request_method='POST')\n    def post(self):\n        \"\"\"Respond to a submission of the create group form.\"\"\"\n        def on_success(appstruct):\n            groups_service = self.request.find_service(name='groups')\n            group = groups_service.create(\n                name=appstruct['name'],\n                description=appstruct.get('description'),\n                userid=self.request.authenticated_userid)\n\n            url = self.request.route_path('group_read',\n                                          pubid=group.pubid,\n                                          slug=group.slug)\n            return HTTPSeeOther(url)\n\n        return form.handle_form_submission(\n            self.request,\n            self.form,\n            on_success=on_success,\n            on_failure=self._template_data)\n\n    def _template_data(self):\n        \"\"\"Return the data needed to render this controller's page.\"\"\"\n        return {'form': self.form.render()}\n\n\n@view_defaults(route_name='group_edit',\n               renderer='h:templates/groups/edit.html.jinja2',\n               permission='admin')\nclass GroupEditController(object):\n    def __init__(self, group, request):\n        self.group = group\n        self.request = request\n        self.schema = schemas.GroupSchema().bind(request=self.request)\n        self.form = request.create_form(self.schema,\n                                        buttons=(_('Save'),),\n                                        use_inline_editing=True)\n\n    @view_config(request_method='GET')\n    def get(self):\n        self.form.set_appstruct({\n            'name': self.group.name or '',\n            'description': self.group.description or '',\n        })\n\n        return self._template_data()\n\n    @view_config(request_method='POST')\n    def post(self):\n        return form.handle_form_submission(\n                self.request,\n                self.form,\n                on_success=self._update_group,\n                on_failure=self._template_data)\n\n    def _template_data(self):\n        return {\n            'form': self.form.render(),\n            'group_path': self.request.route_path('group_read',\n                                                  pubid=self.group.pubid,\n                                                  slug=self.group.slug)\n        }\n\n    def _update_group(self, appstruct):\n        self.group.name = appstruct['name']\n        self.group.description = appstruct['description']\n\n\n@view_config(route_name='group_read',\n             request_method='GET',\n             renderer='h:templates/groups/share.html.jinja2',\n             effective_principals=security.Authenticated)\ndef read(group, request):\n    \"\"\"Group view for logged-in users.\"\"\"\n    _check_slug(group, request)\n\n    # If the current user is not a member of the group, they will not have the\n    # 'read' permission on the group. In this case, we show them the join\n    # page.\n    if not request.has_permission('read'):\n        request.override_renderer = 'h:templates/groups/join.html.jinja2'\n        return {'group': group}\n\n    return {'group': group,\n            'document_links': [presenters.DocumentHTMLPresenter(d).link\n                               for d in group.documents()],\n            'meta_attrs': [\n                # Ask browsers not to send the page's URL (which can be used to\n                # join the group) to other websites in the Referer header.\n                {'name': 'referrer', 'content': 'origin'},\n                          ],\n            }\n\n\n@view_config(route_name='group_read',\n             request_method='GET',\n             renderer='h:templates/groups/join.html.jinja2')\ndef read_unauthenticated(group, request):\n    \"\"\"Group view for logged-out users, allowing them to join the group.\"\"\"\n    _check_slug(group, request)\n    return {'group': group}\n\n\n@view_config(route_name='group_read_noslug', request_method='GET')\ndef read_noslug(group, request):\n    _check_slug(group, request)\n\n\n@view_config(route_name='group_read',\n             request_method='POST',\n             effective_principals=security.Authenticated)\ndef join(group, request):\n    groups_service = request.find_service(name='groups')\n    groups_service.member_join(group, request.authenticated_userid)\n\n    url = request.route_path('group_read', pubid=group.pubid, slug=group.slug)\n    return HTTPSeeOther(url)\n\n\n@view_config(route_name='group_leave',\n             request_method='POST',\n             effective_principals=security.Authenticated)\ndef leave(group, request):\n    groups_service = request.find_service(name='groups')\n    groups_service.member_leave(group, request.authenticated_userid)\n\n    return HTTPNoContent()\n\n\ndef _check_slug(group, request):\n    \"\"\"Redirect if the request slug does not match that of the group.\"\"\"\n    slug = request.matchdict.get('slug')\n    if slug is None or slug != group.slug:\n        raise HTTPMovedPermanently(request.route_path('group_read',\n                                                      pubid=group.pubid,\n                                                      slug=group.slug))\n"},{"size":26145,"relativepath":"h/views/accounts.py","filename":"accounts.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport datetime\nimport itertools\n\nimport colander\nimport deform\nimport jinja2\nfrom pyramid import httpexceptions\nfrom pyramid import security\nfrom pyramid.exceptions import BadCSRFToken\nfrom pyramid.view import view_config, view_defaults\n\nfrom h import accounts\nfrom h import form\nfrom h import i18n\nfrom h import mailer\nfrom h import models\nfrom h import session\nfrom h.accounts import schemas\nfrom h.accounts.events import ActivationEvent\nfrom h.accounts.events import PasswordResetEvent\nfrom h.accounts.events import LogoutEvent\nfrom h.accounts.events import LoginEvent\nfrom h.util.view import json_view\nfrom h._compat import urlparse\n\n_ = i18n.TranslationString\n\n\n# A little helper to ensure that session data is returned in every ajax\n# response payload.\ndef ajax_payload(request, data):\n    payload = {'flash': session.pop_flash(request),\n               'model': session.model(request)}\n    payload.update(data)\n    return payload\n\n\n@view_config(context=BadCSRFToken,\n             accept='text/html',\n             renderer='h:templates/accounts/session_invalid.html.jinja2')\ndef bad_csrf_token_html(context, request):\n    request.response.status_code = 403\n\n    next_path = '/'\n    referer = urlparse.urlparse(request.referer or '')\n    if referer.hostname == request.domain:\n        next_path = referer.path\n\n    login_path = request.route_path('login', _query={'next': next_path})\n    return {'login_path': login_path}\n\n\n@json_view(context=BadCSRFToken)\ndef bad_csrf_token_json(context, request):\n    request.response.status_code = 403\n    reason = _('Session is invalid. Please try again.')\n    return {\n        'status': 'failure',\n        'reason': reason,\n        'model': session.model(request),\n    }\n\n\n@json_view(context=accounts.JSONError)\ndef error_json(error, request):\n    request.response.status_code = 400\n    return {\n        'status': 'failure',\n        'reason': error.message\n    }\n\n\n@json_view(context=deform.ValidationFailure)\ndef error_validation(error, request):\n    request.response.status_code = 400\n    return ajax_payload(\n        request,\n        {'status': 'failure', 'errors': error.error.asdict()})\n\n\n@view_defaults(route_name='login',\n               renderer='h:templates/accounts/login.html.jinja2')\nclass AuthController(object):\n\n    def __init__(self, request):\n        form_footer = '<a class=\"link\" href=\"{href}\">{text}</a>'.format(\n            href=request.route_path('forgot_password'),\n            text=_('Forgot your password?'))\n\n        self.request = request\n        self.schema = schemas.LoginSchema().bind(request=self.request)\n        self.form = request.create_form(self.schema,\n                                        buttons=(_('Log in'),),\n                                        footer=form_footer)\n\n        self.login_redirect = self.request.params.get(\n            'next',\n            self.request.route_url('stream'))\n        self.logout_redirect = self.request.route_url('index')\n\n    @view_config(request_method='GET')\n    def get(self):\n        \"\"\"Render the login page, including the login form.\"\"\"\n        self._redirect_if_logged_in()\n\n        return {'form': self.form.render()}\n\n    @view_config(request_method='POST')\n    def post(self):\n        \"\"\"Log the user in and redirect them.\"\"\"\n        self._redirect_if_logged_in()\n\n        try:\n            appstruct = self.form.validate(self.request.POST.items())\n        except deform.ValidationFailure:\n            return {'form': self.form.render()}\n\n        user = appstruct['user']\n        headers = self._login(user)\n        return httpexceptions.HTTPFound(location=self.login_redirect,\n                                        headers=headers)\n\n    @view_config(route_name='logout',\n                 renderer=None,\n                 request_method='GET')\n    def logout(self):\n        \"\"\"Log the user out.\"\"\"\n        headers = self._logout()\n        return httpexceptions.HTTPFound(location=self.logout_redirect,\n                                        headers=headers)\n\n    def _redirect_if_logged_in(self):\n        if self.request.authenticated_userid is not None:\n            raise httpexceptions.HTTPFound(location=self.login_redirect)\n\n    def _login(self, user):\n        user.last_login_date = datetime.datetime.utcnow()\n        self.request.registry.notify(LoginEvent(self.request, user))\n        headers = security.remember(self.request, user.userid)\n        return headers\n\n    def _logout(self):\n        if self.request.authenticated_userid is not None:\n            self.request.registry.notify(LogoutEvent(self.request))\n            self.request.session.invalidate()\n        headers = security.forget(self.request)\n        return headers\n\n\n@view_defaults(route_name='session',\n               accept='application/json',\n               renderer='json')\nclass AjaxAuthController(AuthController):\n\n    def __init__(self, request):\n        self.request = request\n        self.schema = schemas.LoginSchema().bind(request=self.request)\n        self.form = request.create_form(self.schema)\n\n    @view_config(request_param='__formid__=login')\n    def login(self):\n        try:\n            json_body = self.request.json_body\n        except ValueError as exc:\n            raise accounts.JSONError(\n                _('Could not parse request body as JSON: {message}'.format(\n                    message=exc.message)))\n\n        if not isinstance(json_body, dict):\n            raise accounts.JSONError(\n                _('Request JSON body must have a top-level object'))\n\n        # Transform non-string usernames and password into strings.\n        # Deform crashes otherwise.\n        json_body['username'] = unicode(json_body.get('username') or '')\n        json_body['password'] = unicode(json_body.get('password') or '')\n\n        appstruct = self.form.validate(json_body.items())\n\n        user = appstruct['user']\n        headers = self._login(user)\n        self.request.response.headers.extend(headers)\n\n        return ajax_payload(self.request, {'status': 'okay'})\n\n    @view_config(request_param='__formid__=logout')\n    def logout(self):\n        headers = self._logout()\n        self.request.response.headers.extend(headers)\n        return ajax_payload(self.request, {'status': 'okay'})\n\n\n@view_defaults(route_name='forgot_password',\n               renderer='h:templates/accounts/forgot_password.html.jinja2')\nclass ForgotPasswordController(object):\n\n    \"\"\"Controller for handling forgotten password forms.\"\"\"\n\n    def __init__(self, request):\n        self.request = request\n        self.schema = schemas.ForgotPasswordSchema().bind(request=self.request)\n        self.form = request.create_form(self.schema, buttons=(_('Reset'),))\n\n    @view_config(request_method='GET')\n    def get(self):\n        \"\"\"Render the forgot password page, including the form.\"\"\"\n        self._redirect_if_logged_in()\n\n        return {'form': self.form.render()}\n\n    @view_config(request_method='POST')\n    def post(self):\n        \"\"\"\n        Handle submission of the forgot password form.\n\n        Validates that the email is one we know about, and then generates a new\n        activation for the associated user, and dispatches a \"reset your\n        password\" email which contains a token and/or link to the reset\n        password form.\n        \"\"\"\n        self._redirect_if_logged_in()\n\n        try:\n            appstruct = self.form.validate(self.request.POST.items())\n        except deform.ValidationFailure:\n            return {'form': self.form.render()}\n\n        user = appstruct['user']\n        self._send_forgot_password_email(user)\n\n        return httpexceptions.HTTPFound(\n            self.request.route_path('account_reset'))\n\n    def _redirect_if_logged_in(self):\n        if self.request.authenticated_userid is not None:\n            raise httpexceptions.HTTPFound(self.request.route_path('index'))\n\n    def _send_forgot_password_email(self, user):\n        serializer = self.request.registry.password_reset_serializer\n        code = serializer.dumps(user.username)\n\n        link = account_reset_link(self.request, code)\n        message = account_reset_email(user, code, link)\n        mailer.send.delay(**message)\n\n\n@view_defaults(route_name='account_reset',\n               renderer='h:templates/accounts/reset.html.jinja2')\nclass ResetController(object):\n\n    \"\"\"Controller for handling password reset forms.\"\"\"\n\n    def __init__(self, request):\n        self.request = request\n        self.schema = schemas.ResetPasswordSchema().bind(request=self.request)\n        self.form = request.create_form(\n            schema=self.schema,\n            action=self.request.route_path('account_reset'),\n            buttons=(_('Save'),))\n\n    @view_config(request_method='GET')\n    def get(self):\n        \"\"\"Render the reset password form.\"\"\"\n        return {'form': self.form.render(), 'has_code': False}\n\n    @view_config(route_name='account_reset_with_code',\n                 request_method='GET')\n    def get_with_prefilled_code(self):\n        \"\"\"Render the reset password form with a prefilled code.\"\"\"\n        code = self.request.matchdict['code']\n\n        # If valid, we inject the supplied it into the form as a hidden field.\n        # Otherwise, we 404.\n        try:\n            user = schemas.ResetCode().deserialize(self.schema, code)\n        except colander.Invalid:\n            raise httpexceptions.HTTPNotFound()\n        else:\n            # N.B. the form field for the reset code is called 'user'. See the\n            # comment in `schemas.ResetPasswordSchema` for details.\n            self.form.set_appstruct({'user': user})\n            self.form.set_widgets({'user': deform.widget.HiddenWidget()})\n\n        return {'form': self.form.render(), 'has_code': True}\n\n    @view_config(request_method='POST')\n    def post(self):\n        \"\"\"\n        Handle submission of the reset password form.\n\n        This function checks that the activation code (i.e. reset token)\n        provided by the form is valid, retrieves the user associated with the\n        activation code, and resets their password.\n        \"\"\"\n        try:\n            appstruct = self.form.validate(self.request.POST.items())\n        except deform.ValidationFailure:\n            # If the code is valid, hide the field.\n            if not self.form['user'].error:\n                self.form.set_widgets({'user': deform.widget.HiddenWidget()})\n            return {'form': self.form.render()}\n\n        self._reset_password(appstruct['user'], appstruct['password'])\n\n        return httpexceptions.HTTPFound(\n            location=self.request.route_path('index'))\n\n    def _redirect_if_logged_in(self):\n        if self.request.authenticated_userid is not None:\n            raise httpexceptions.HTTPFound(self.request.route_path('index'))\n\n    def _reset_password(self, user, password):\n        user.password = password\n\n        self.request.session.flash(jinja2.Markup(_(\n            'Your password has been reset. '\n            'You can now <a href=\"{url}\">login</a> with your new '\n            'password.').format(url=self.request.route_url('login'))),\n            'success')\n        self.request.registry.notify(PasswordResetEvent(self.request, user))\n\n\n@view_defaults(route_name='signup',\n               renderer='h:templates/accounts/signup.html.jinja2')\nclass SignupController(object):\n\n    def __init__(self, request):\n        tos_link = ('<a class=\"link\" href=\"/terms-of-service\">' +\n                    _('Terms of Service') +\n                    '</a>')\n        cg_link = ('<a class=\"link\" href=\"/community-guidelines\">' +\n                   _('Community Guidelines') +\n                   '</a>')\n        form_footer = _(\n            'You are agreeing to our {tos_link} and '\n            '{cg_link}.').format(tos_link=tos_link, cg_link=cg_link)\n\n        self.request = request\n        self.schema = schemas.RegisterSchema().bind(request=self.request)\n        self.form = request.create_form(self.schema,\n                                        buttons=(deform.Button(title=_('Sign up'),\n                                                               css_class='js-signup-btn'),),\n                                        css_class='js-signup-form',\n                                        footer=form_footer)\n\n    @view_config(request_method='GET')\n    def get(self):\n        \"\"\"Render the empty registration form.\"\"\"\n        self._redirect_if_logged_in()\n\n        return {'form': self.form.render()}\n\n    @view_config(request_method='POST')\n    def post(self):\n        \"\"\"\n        Handle submission of the new user registration form.\n\n        Validates the form data, creates a new activation for the user, sends\n        the activation mail, and then redirects the user to the index.\n        \"\"\"\n        self._redirect_if_logged_in()\n\n        try:\n            appstruct = self.form.validate(self.request.POST.items())\n        except deform.ValidationFailure:\n            return {'form': self.form.render()}\n\n        signup_service = self.request.find_service(name='user_signup')\n        signup_service.signup(username=appstruct['username'],\n                              email=appstruct['email'],\n                              password=appstruct['password'])\n\n        self.request.session.flash(jinja2.Markup(_(\n            \"Please check your email and open the link to activate your \"\n            \"account.\")), 'success')\n\n        return httpexceptions.HTTPFound(\n            location=self.request.route_url('index'))\n\n    def _redirect_if_logged_in(self):\n        if self.request.authenticated_userid is not None:\n            raise httpexceptions.HTTPFound(self.request.route_url('stream'))\n\n\n@view_defaults(route_name='activate')\nclass ActivateController(object):\n\n    def __init__(self, request):\n        self.request = request\n\n    @view_config(request_method='GET')\n    def get_when_not_logged_in(self):\n        \"\"\"\n        Handle a request for a user activation link.\n\n        Checks if the activation code passed is valid, and (as a safety check)\n        that it is an activation for the passed user id. If all is well,\n        activate the user and redirect them to the stream.\n        \"\"\"\n        code = self.request.matchdict.get('code')\n        id_ = self.request.matchdict.get('id')\n\n        try:\n            id_ = int(id_)\n        except ValueError:\n            raise httpexceptions.HTTPNotFound()\n\n        activation = models.Activation.get_by_code(self.request.db, code)\n        if activation is None:\n            self.request.session.flash(jinja2.Markup(_(\n                \"We didn't recognize that activation link. \"\n                \"Have you already activated your account? \"\n                'If so, try <a href=\"{url}\">logging in</a> using the username '\n                'and password that you provided.').format(\n                    url=self.request.route_url('login'))),\n                'error')\n            return httpexceptions.HTTPFound(\n                location=self.request.route_url('index'))\n\n        user = models.User.get_by_activation(self.request.db, activation)\n        if user is None or user.id != id_:\n            raise httpexceptions.HTTPNotFound()\n\n        user.activate()\n\n        self.request.session.flash(jinja2.Markup(_(\n            'Your account has been activated! '\n            'You can now <a href=\"{url}\">log in</a> using the password you '\n            'provided.').format(url=self.request.route_url('login'))),\n            'success')\n\n        self.request.registry.notify(ActivationEvent(self.request, user))\n\n        return httpexceptions.HTTPFound(\n            location=self.request.route_url('index'))\n\n    @view_config(request_method='GET',\n                 effective_principals=security.Authenticated)\n    def get_when_logged_in(self):\n        \"\"\"Handle an activation link request while already logged in.\"\"\"\n        id_ = self.request.matchdict.get('id')\n\n        try:\n            id_ = int(id_)\n        except ValueError:\n            raise httpexceptions.HTTPNotFound()\n\n        if id_ == self.request.authenticated_user.id:\n            # The user is already logged in to the account (so the account\n            # must already be activated).\n            self.request.session.flash(jinja2.Markup(_(\n                \"Your account has been activated and you're logged in.\")),\n                'success')\n        else:\n            self.request.session.flash(jinja2.Markup(_(\n                \"You're already logged in to a different account. \"\n                '<a href=\"{url}\">Log out</a> and open the activation link '\n                'again.').format(\n                    url=self.request.route_url('logout'))),\n                'error')\n\n        return httpexceptions.HTTPFound(\n            location=self.request.route_url('index'))\n\n\n@view_defaults(route_name='account',\n               renderer='h:templates/accounts/account.html.jinja2',\n               effective_principals=security.Authenticated)\nclass AccountController(object):\n\n    def __init__(self, request):\n        self.request = request\n\n        if request.feature('activity_pages'):\n            email_schema = schemas.EmailChangeSchema().bind(request=request)\n        else:\n            email_schema = schemas.LegacyEmailChangeSchema().bind(request=request)\n\n        password_schema = schemas.PasswordChangeSchema().bind(request=request)\n\n        # Ensure deform generates unique field IDs for each field in this\n        # multiple-form page.\n        counter = itertools.count()\n\n        self.forms = {\n            'email': request.create_form(email_schema,\n                                         buttons=(_('Change email address'),),\n                                         formid='email',\n                                         counter=counter),\n            'password': request.create_form(password_schema,\n                                            buttons=(_('Change password'),),\n                                            formid='password',\n                                            counter=counter),\n        }\n\n    @view_config(request_method='GET')\n    def get(self):\n        \"\"\"Show the user's account.\"\"\"\n        return self._template_data()\n\n    @view_config(request_method='POST',\n                 request_param='__formid__=email')\n    def post_email_form(self):\n        \"\"\"Called by Pyramid when the change email form is submitted.\"\"\"\n        return form.handle_form_submission(\n            self.request,\n            self.forms['email'],\n            on_success=self.update_email_address,\n            on_failure=self._template_data)\n\n    @view_config(request_method='POST',\n                 request_param='__formid__=password')\n    def post_password_form(self):\n        \"\"\"Called by Pyramid when the change password form is submitted.\"\"\"\n        return form.handle_form_submission(\n            self.request,\n            self.forms['password'],\n            on_success=self.update_password,\n            on_failure=self._template_data)\n\n    def update_email_address(self, appstruct):\n        self.request.authenticated_user.email = appstruct['email']\n\n    def update_password(self, appstruct):\n        self.request.authenticated_user.password = appstruct['new_password']\n\n    def _template_data(self):\n        \"\"\"Return the data needed to render accounts.html.jinja2.\"\"\"\n        email = self.request.authenticated_user.email\n        password_form = self.forms['password'].render()\n\n        if self.request.feature('activity_pages'):\n            email_form = self.forms['email'].render({'email': email})\n        else:\n            email_form = self.forms['email'].render()\n\n        return {'email': email,\n                'email_form': email_form,\n                'password_form': password_form}\n\n\n@view_defaults(route_name='account_profile',\n               renderer='h:templates/accounts/profile.html.jinja2',\n               effective_principals=security.Authenticated)\nclass EditProfileController(object):\n\n    def __init__(self, request):\n        self.request = request\n        self.schema = schemas.EditProfileSchema().bind(request=self.request)\n        self.form = request.create_form(self.schema,\n                                        buttons=(_('Save'),),\n                                        use_inline_editing=True)\n\n    @view_config(request_method='GET')\n    def get(self):\n        \"\"\"Render the 'Edit Profile' form\"\"\"\n        user = self.request.authenticated_user\n        self.form.set_appstruct({\n            'display_name': user.display_name or '',\n            'description': user.description or '',\n            'location': user.location or '',\n            'link': user.uri or '',\n            'orcid': user.orcid or '',\n        })\n        return self._template_data()\n\n    @view_config(request_method='POST')\n    def post(self):\n        return form.handle_form_submission(\n            self.request,\n            self.form,\n            on_success=self._update_user,\n            on_failure=self._template_data)\n\n    def _template_data(self):\n        return {'form': self.form.render()}\n\n    def _update_user(self, appstruct):\n        user = self.request.authenticated_user\n        user.display_name = appstruct['display_name']\n        user.description = appstruct['description']\n        user.location = appstruct['location']\n        user.uri = appstruct['link']\n        user.orcid = appstruct['orcid']\n\n\n@view_defaults(route_name='account_notifications',\n               renderer='h:templates/accounts/notifications.html.jinja2',\n               effective_principals=security.Authenticated)\nclass NotificationsController(object):\n\n    def __init__(self, request):\n        self.request = request\n        self.schema = schemas.NotificationsSchema().bind(request=self.request)\n        self.form = request.create_form(self.schema,\n                                        buttons=(_('Save'),),\n                                        use_inline_editing=True)\n\n    @view_config(request_method='GET')\n    def get(self):\n        \"\"\"Render the notifications form.\"\"\"\n        self.form.set_appstruct({\n            'notifications': set(n.type\n                                 for n in self._user_notifications()\n                                 if n.active)\n        })\n        return self._template_data()\n\n    @view_config(request_method='POST')\n    def post(self):\n        \"\"\"Process notifications POST data.\"\"\"\n        return form.handle_form_submission(\n            self.request,\n            self.form,\n            on_success=self._update_notifications,\n            on_failure=self._template_data)\n\n    def _update_notifications(self, appstruct):\n        for n in self._user_notifications():\n            n.active = n.type in appstruct['notifications']\n\n    def _template_data(self):\n        return {'form': self.form.render()}\n\n    def _user_notifications(self):\n        \"\"\"Fetch the notifications/subscriptions for the logged-in user.\"\"\"\n        return models.Subscriptions.get_subscriptions_for_uri(\n            self.request.db,\n            self.request.authenticated_userid)\n\n\n@view_defaults(route_name='account_developer',\n               renderer='h:templates/accounts/developer.html.jinja2',\n               effective_principals=security.Authenticated)\nclass DeveloperController(object):\n\n    def __init__(self, request):\n        self.request = request\n\n    @view_config(request_method='GET')\n    def get(self):\n        \"\"\"Render the developer page, including the form.\"\"\"\n        token = models.Token.get_dev_token_by_userid(\n            self.request.db,\n            self.request.authenticated_userid\n        )\n        if token:\n            return {'token': token.value}\n        else:\n            return {}\n\n    @view_config(request_method='POST')\n    def post(self):\n        \"\"\"(Re-)generate the user's API token.\"\"\"\n        token = models.Token.get_dev_token_by_userid(\n            self.request.db,\n            self.request.authenticated_userid\n        )\n\n        if token:\n            # The user already has an API token, regenerate it.\n            token.regenerate()\n        else:\n            # The user doesn't have an API token yet, generate one for them.\n            token = models.Token(userid=self.request.authenticated_userid)\n            self.request.db.add(token)\n\n        return {'token': token.value}\n\n\ndef account_reset_email(user, reset_code, reset_link):\n    \"\"\"Return the data for a 'reset your password' email for the given user.\n\n    :rtype: dict\n\n    \"\"\"\n    emailtext = (\"Hello, {username}!\\n\\n\"\n                 \"Someone has requested to reset your password. If it was \"\n                 \"you, reset your password by using this reset code:\\n\\n\"\n                 \"{code}\\n\\n\"\n                 \"Alternatively, you can reset your password by \"\n                 \"clicking on this link:\\n\\n\"\n                 \"{link}\\n\\n\"\n                 \"Regards,\\n\"\n                 \"The Hypothesis Team\\n\")\n    body = emailtext.format(code=reset_code,\n                            link=reset_link,\n                            username=user.username)\n    return {\n        \"recipients\": [user.email],\n        \"subject\": _(\"Reset your password\"),\n        \"body\": body\n    }\n\n\ndef account_reset_link(request, reset_code):\n    \"\"\"Transform an activation code into an account reset link.\"\"\"\n    return request.route_url('account_reset_with_code', code=reset_code)\n\n\n# TODO: This can be removed after October 2016, which will be >1 year from the\n#       date that the last account claim emails were sent out. At this point,\n#       if we have not done so already, we should remove all unclaimed\n#       usernames from the accounts tables.\n@view_config(route_name='claim_account_legacy',\n             request_method='GET',\n             renderer='h:templates/accounts/claim_account_legacy.html.jinja2')\ndef claim_account_legacy(request):\n    \"\"\"Render a page explaining that claim links are no longer valid.\"\"\"\n    return {}\n\n\n@view_config(route_name='dismiss_sidebar_tutorial',\n             request_method='POST',\n             renderer='json')\ndef dismiss_sidebar_tutorial(request):\n    if request.authenticated_userid is None:\n        raise accounts.JSONError()\n    else:\n        request.authenticated_user.sidebar_tutorial_dismissed = True\n        return ajax_payload(request, {'status': 'okay'})\n"},{"size":1753,"relativepath":"h/views/api_exceptions.py","filename":"api_exceptions.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"\nAPI exception views.\n\nViews rendered by the web application in response to exceptions thrown within\nAPI views.\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom pyramid.view import forbidden_view_config\nfrom pyramid.view import notfound_view_config\n\nfrom h.i18n import TranslationString as _\nfrom h.exceptions import APIError\nfrom h.util.view import handle_exception, json_view\n\n\n# Within the API, render a JSON 403/404 message.\n@forbidden_view_config(path_info='/api/', renderer='json')\n@notfound_view_config(path_info='/api/', renderer='json')\ndef api_notfound(request):\n    \"\"\"Handle a request for an unknown/forbidden resource within the API.\"\"\"\n    request.response.status_code = 404\n    message = _(\"Either the resource you requested doesn't exist, or you are \"\n                \"not currently authorized to see it.\")\n    return {'status': 'failure', 'reason': message}\n\n\n@json_view(context=APIError)\ndef api_error(context, request):\n    \"\"\"Handle an expected/deliberately thrown API exception.\"\"\"\n    request.response.status_code = context.status_code\n    return {'status': 'failure', 'reason': context.message}\n\n\n@json_view(context=Exception)\ndef json_error(request):\n    \"\"\"Handle an unexpected exception where the request asked for JSON.\"\"\"\n    handle_exception(request)\n    message = _(\"Uh-oh, something went wrong! We're very sorry, our \"\n                \"application wasn't able to load this page. The team has \"\n                \"been notified and we'll fix it shortly. If the problem \"\n                \"persists or you'd like more information please email \"\n                \"support@hypothes.is with the subject 'Internal Server \"\n                \"Error'.\")\n    return {'status': 'failure', 'reason': message}\n"},{"size":930,"relativepath":"h/views/exceptions.py","filename":"exceptions.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"\nApplication exception views.\n\nViews rendered by the web application in response to exceptions thrown within\nviews.\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom pyramid.view import forbidden_view_config\nfrom pyramid.view import notfound_view_config\nfrom pyramid.view import view_config\n\nfrom h.util.view import handle_exception\n\n\n@forbidden_view_config(renderer='h:templates/notfound.html.jinja2')\n@notfound_view_config(renderer='h:templates/notfound.html.jinja2',\n                      append_slash=True)\ndef notfound(request):\n    \"\"\"Handle a request for an unknown/forbidden resource.\"\"\"\n    request.response.status_int = 404\n    return {}\n\n\n@view_config(context=Exception,\n             accept='text/html',\n             renderer='h:templates/5xx.html.jinja2')\ndef error(request):\n    \"\"\"Handle a request for which the handler threw an exception.\"\"\"\n    handle_exception(request)\n    return {}\n"},{"size":875,"relativepath":"h/views/badge.py","filename":"badge.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom pyramid import httpexceptions\n\nfrom h import models\nfrom h.util.view import json_view\nfrom memex import search\n\n\n@json_view(route_name='badge')\ndef badge(request):\n    \"\"\"Return the number of public annotations on a given page.\n\n    This is for the number that's displayed on the Chrome extension's badge.\n\n    Certain pages are blocklisted so that the badge never shows a number on\n    those pages. The Chrome extension is oblivious to this, we just tell it\n    that there are 0 annotations.\n\n    \"\"\"\n    uri = request.params.get('uri')\n\n    if not uri:\n        raise httpexceptions.HTTPBadRequest()\n\n    if models.Blocklist.is_blocked(request.db, uri):\n        return {'total': 0}\n\n    query = {'uri': uri, 'limit': 0}\n    result = search.Search(request).run(query)\n\n    return {'total': result.total}\n"},{"size":75,"relativepath":"h/views/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\ndef includeme(config):\n    config.scan(__name__)\n"},{"size":1023,"relativepath":"h/views/help.py","filename":"help.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"Help and documentation views.\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport binascii\nimport os\n\nfrom pyramid import httpexceptions as exc\nfrom pyramid.view import view_config\n\n\n@view_config(renderer='h:templates/help.html.jinja2', route_name='custom_onboarding')\ndef custom_onboarding_page(context, request):\n    return {\n        'embed_js_url': request.route_path('embed'),\n        'is_help': False,\n        'is_onboarding': True,\n    }\n\n\n@view_config(renderer='h:templates/help.html.jinja2', route_name='onboarding')\ndef onboarding_page(context, request):\n    return exc.HTTPFound(request.route_url('custom_onboarding',\n                                           slug=_random_word()))\n\n\n@view_config(renderer='h:templates/help.html.jinja2', route_name='help')\ndef help_page(context, request):\n    return {\n        'embed_js_url': request.route_path('embed'),\n        'is_help': True,\n        'is_onboarding': False,\n    }\n\n\ndef _random_word():\n    return binascii.hexlify(os.urandom(8))\n"},{"size":2560,"relativepath":"h/views/main.py","filename":"main.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"\nCore application views.\n\nImportant views which don't form part of any other major feature package.\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport logging\n\nfrom pyramid import httpexceptions\nfrom pyramid import response\nfrom pyramid.view import view_config\n\nfrom h.views.client import render_app\n\nlog = logging.getLogger(__name__)\n\n\n@view_config(route_name='annotation', permission='read')\ndef annotation_page(annotation, request):\n    document = annotation.document\n    if document and document.title:\n        title = 'Annotation by {user} on {title}'.format(\n            user=annotation.userid.replace('acct:', ''),\n            title=document.title)\n    else:\n        title = 'Annotation by {user}'.format(\n            user=annotation.userid.replace('acct:', ''))\n\n    alternate = request.route_url('api.annotation', id=annotation.id)\n\n    return render_app(request, {\n        'meta_attrs': (\n            {'property': 'og:title', 'content': title},\n            {'property': 'og:description', 'content': ''},\n            {'property': 'og:image', 'content': '/assets/images/logo.png'},\n            {'property': 'og:site_name', 'content': 'Hypothes.is'},\n            {'property': 'og:url', 'content': request.url},\n        ),\n        'link_attrs': (\n            {'rel': 'alternate', 'href': alternate,\n                'type': 'application/json'},\n        ),\n    })\n\n\n@view_config(route_name='robots', http_cache=(86400, {'public': True}))\ndef robots(context, request):\n    return response.FileResponse('h/static/robots.txt',\n                                 request=request,\n                                 content_type=b'text/plain')\n\n\n@view_config(route_name='stream')\ndef stream(context, request):\n    atom = request.route_url('stream_atom')\n    rss = request.route_url('stream_rss')\n    return render_app(request, {\n        'link_tags': [\n            {'rel': 'alternate', 'href': atom, 'type': 'application/atom+xml'},\n            {'rel': 'alternate', 'href': rss, 'type': 'application/rss+xml'},\n        ]\n    })\n\n\n@view_config(route_name='stream.tag_query')\ndef stream_tag_redirect(request):\n    query = {'q': 'tag:{}'.format(request.matchdict['tag'])}\n    location = request.route_url('stream', _query=query)\n    raise httpexceptions.HTTPFound(location=location)\n\n\n@view_config(route_name='stream.user_query')\ndef stream_user_redirect(request):\n    query = {'q': 'user:{}'.format(request.matchdict['user'])}\n    location = request.route_url('stream', _query=query)\n    raise httpexceptions.HTTPFound(location=location)\n"},{"size":1160,"relativepath":"h/views/home.py","filename":"home.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"Views serving the homepage and related endpoints.\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom pyramid import httpexceptions\nfrom pyramid.view import view_config\n\n\n@view_config(route_name='via_redirect', request_method='GET')\ndef via_redirect(context, request):\n    url = request.params.get('url')\n\n    if url is None:\n        raise httpexceptions.HTTPBadRequest('\"url\" parameter missing')\n\n    via_link = 'https://via.hypothes.is/{}'.format(url)\n    raise httpexceptions.HTTPFound(location=via_link)\n\n\n@view_config(route_name='index',\n             request_method='GET',\n             renderer='h:templates/home.html.jinja2')\ndef index(context, request):\n    context = {\n        \"chrome_extension_link\": (\"https://chrome.google.com/webstore/detail/\"\n                                  \"bjfhmglciegochdpefhhlphglcehbmek\")\n    }\n\n    if request.authenticated_user:\n        username = request.authenticated_user.username\n        context['username'] = username\n        context['user_account_link'] = (\n            request.route_url(\"stream\") +\n            \"?q=user:{username}\".format(username=username)\n        )\n\n    return context\n"},{"size":2830,"relativepath":"h/views/client.py","filename":"client.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"\nApplication client views.\n\nViews which exist either to serve or support the JavaScript annotation client.\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom pyramid import exceptions\nfrom pyramid import httpexceptions\nfrom pyramid import session\nfrom pyramid.view import view_config\n\nfrom h import client\nfrom h import session as h_session\nfrom h.auth.tokens import generate_jwt\nfrom h.util.view import json_view\n\n\ndef render_app(request, extra=None):\n    \"\"\"Render a page that serves a preconfigured annotation client.\"\"\"\n    client_sentry_dsn = request.registry.settings.get('h.client.sentry_dsn')\n    html = client.render_app_html(\n        assets_env=request.registry['assets_client_env'],\n        # FIXME: The '' here is to ensure this has a trailing slash. This seems\n        # rather messy, and is inconsistent with the rest of the application's\n        # URLs.\n        api_url=request.route_url('api.index'),\n        service_url=request.route_url('index'),\n        ga_tracking_id=request.registry.settings.get('ga_tracking_id'),\n        sentry_public_dsn=client_sentry_dsn,\n        websocket_url=request.registry.settings.get('h.websocket_url'),\n        extra=extra)\n    request.response.text = html\n    return request.response\n\n\n# This view requires credentials (a cookie) so is not currently accessible\n# off-origin, unlike the rest of the API. Given that this method of\n# authenticating to the API is not intended to remain, this seems like a\n# limitation we do not need to lift any time soon.\n@view_config(route_name='token', renderer='string', request_method='GET')\ndef annotator_token(request):\n    \"\"\"\n    Return a JWT access token for the given request.\n\n    The token can be used in the Authorization header in subsequent requests to\n    the API to authenticate the user identified by the\n    request.authenticated_userid of the _current_ request.\n    \"\"\"\n    try:\n        # The client must supply the CSRF token in the X-CSRF-Token request\n        # header.\n        session.check_csrf_token(request)\n    except exceptions.BadCSRFToken:\n        raise httpexceptions.HTTPUnauthorized()\n\n    return generate_jwt(request, 3600)\n\n\n@view_config(route_name='embed')\ndef embed(context, request):\n    request.response.content_type = b'text/javascript'\n    request.response.text = client.render_embed_js(\n        assets_env=request.registry['assets_client_env'],\n        app_html_url=request.route_url('widget'),\n        base_url=request.route_url('index'))\n    return request.response\n\n\n@json_view(route_name='session', http_cache=0)\ndef session_view(request):\n    flash = h_session.pop_flash(request)\n    model = h_session.model(request)\n    return dict(status='okay', flash=flash, model=model)\n\n\n@view_config(route_name='widget')\ndef widget(context, request):\n    return render_app(request)\n"},{"size":1352,"relativepath":"h/views/activity.py","filename":"activity.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"\nActivity pages views.\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom pyramid import httpexceptions\nfrom pyramid.view import view_config\n\nfrom h.activity import query\nfrom h.paginator import paginate\n\nPAGE_SIZE = 200\n\n\n@view_config(route_name='activity.search',\n             request_method='GET',\n             renderer='h:templates/activity/search.html.jinja2')\n@view_config(route_name='activity.group_search',\n             request_method='GET',\n             renderer='h:templates/activity/search.html.jinja2')\n@view_config(route_name='activity.user_search',\n             request_method='GET',\n             renderer='h:templates/activity/search.html.jinja2')\ndef search(request):\n    if not request.feature('search_page'):\n        raise httpexceptions.HTTPNotFound()\n\n    q = query.extract(request)\n\n    # Check whether a redirect is required\n    query.check_url(request, q)\n\n    page_size = request.params.get('page_size', PAGE_SIZE)\n    try:\n        page_size = int(page_size)\n    except ValueError:\n        page_size = PAGE_SIZE\n\n    # Fetch results\n    result = query.execute(request, q, page_size=page_size)\n\n    return {\n        'total': result.total,\n        'aggregations': result.aggregations,\n        'timeframes': result.timeframes,\n        'page': paginate(request, result.total, page_size=page_size),\n    }\n"},{"size":1912,"relativepath":"h/views/api_users.py","filename":"api_users.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport hmac\n\nimport sqlalchemy as sa\n\nfrom h.auth.util import basic_auth_creds\nfrom h.exceptions import ClientUnauthorized\nfrom h.models import AuthClient\nfrom h.util.view import json_view\n\n\n@json_view(route_name='api.users', request_method='POST')\ndef create(request):\n    \"\"\"\n    Create a user.\n\n    This API endpoint allows authorised clients (those able to provide a valid\n    Client ID and Client Secret) to create users in their authority. These\n    users are created pre-activated, and are unable to log in to the web\n    service directly.\n    \"\"\"\n    client = _request_client(request)\n    payload = request.json_body\n\n    user_props = {\n        'authority': client.authority,\n        'username': payload['username'],\n        'email': payload['email'],\n    }\n\n    user_signup_service = request.find_service(name='user_signup')\n    user = user_signup_service.signup(require_activation=False, **user_props)\n\n    return {\n        'authority': user.authority,\n        'email': user.email,\n        'userid': user.userid,\n        'username': user.username,\n    }\n\n\ndef _request_client(request):\n    creds = basic_auth_creds(request)\n    if creds is None:\n        raise ClientUnauthorized()\n\n    # We fetch the client by its ID and then do a constant-time comparison of\n    # the secret with that provided in the request.\n    #\n    # It is important not to include the secret as part of the SQL query\n    # because the resulting code may be subject to a timing attack.\n    client_id, client_secret = creds\n    try:\n        client = request.db.query(AuthClient).get(client_id)\n    except sa.exc.StatementError:  # client_id is malformed\n        raise ClientUnauthorized()\n    if client is None:\n        raise ClientUnauthorized()\n\n    if not hmac.compare_digest(client.secret, client_secret):\n        raise ClientUnauthorized()\n\n    return client\n"},{"size":1962,"relativepath":"h/views/panels.py","filename":"panels.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"Shared components used across multiple pages on the site.\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom pyramid_layout.panel import panel_config\n\nfrom h import i18n\n\n_ = i18n.TranslationString\n\n\n@panel_config(name='navbar', renderer='h:templates/panels/navbar.html.jinja2')\ndef navbar(context, request):\n    \"\"\"\n    The navigation bar displayed at the top of the page.\n    \"\"\"\n\n    groups_menu_items = []\n    stream_url = None\n    username = None\n\n    if request.authenticated_user:\n        for group in request.authenticated_user.groups:\n            groups_menu_items.append({\n                'title': group.name,\n                'link': request.route_url('group_read', pubid=group.pubid, slug=group.slug)\n                })\n        stream_url = (request.route_url('activity.search') +\n            \"?q=user:{}\".format(request.authenticated_user.username))\n        username = request.authenticated_user.username\n\n    if request.matched_route.name in ['activity.group_search', 'activity.user_search']:\n        search_url = request.current_route_url()\n    else:\n        search_url = request.route_url('activity.search')\n\n    return {\n        'settings_menu_items': [\n            {'title': _('Account details'), 'link': request.route_url('account')},\n            {'title': _('Edit profile'), 'link': request.route_url('account_profile')},\n            {'title': _('Notifications'), 'link': request.route_url('account_notifications')},\n            {'title': _('Developer'), 'link': request.route_url('account_developer')},\n        ],\n        'signout_item': {'title': _('Sign out'), 'link': request.route_url('logout')},\n        'groups_menu_items': groups_menu_items,\n        'create_group_item':\n            {'title': _('Create new group'), 'link': request.route_url('group_create')},\n        'username': username,\n        'username_url': stream_url,\n        'search_url': search_url,\n        'q': request.params.get('q', ''),\n    }\n"},{"size":1429,"relativepath":"h/views/feeds.py","filename":"feeds.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom pyramid.view import view_config\nfrom pyramid import i18n\n\nfrom memex import search\nfrom memex.storage import fetch_ordered_annotations\nfrom h.feeds import render_atom, render_rss\n\n\n_ = i18n.TranslationStringFactory(__package__)\n\n\ndef _annotations(request):\n    \"\"\"Return the annotations from the search API.\"\"\"\n    result = search.Search(request).run(request.params)\n    return fetch_ordered_annotations(request.db, result.annotation_ids)\n\n\n@view_config(route_name='stream_atom')\ndef stream_atom(request):\n    \"\"\"An Atom feed of the /stream page.\"\"\"\n    return render_atom(\n        request=request, annotations=_annotations(request),\n        atom_url=request.route_url(\"stream_atom\"),\n        html_url=request.route_url(\"stream\"),\n        title=request.registry.settings.get(\"h.feed.title\"),\n        subtitle=request.registry.settings.get(\"h.feed.subtitle\"))\n\n\n@view_config(route_name='stream_rss')\ndef stream_rss(request):\n    \"\"\"An RSS feed of the /stream page.\"\"\"\n    return render_rss(\n        request=request, annotations=_annotations(request),\n        rss_url=request.route_url(\"stream_rss\"),\n        html_url=request.route_url(\"stream\"),\n        title=request.registry.settings.get(\"h.feed.title\") or _(\n            \"Hypothesis Stream\"),\n        description=request.registry.settings.get(\"h.feed.description\") or _(\n            \"The Web. Annotated\"))\n"},{"size":707,"relativepath":"h/views/notification.py","filename":"notification.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom pyramid.httpexceptions import HTTPNotFound\nfrom pyramid.view import view_config\n\nfrom h.models import Subscriptions\n\n\n@view_config(route_name='unsubscribe',\n             renderer='h:templates/unsubscribe.html.jinja2')\ndef unsubscribe(request):\n    token = request.matchdict['token']\n    try:\n        payload = request.registry.notification_serializer.loads(token)\n    except ValueError:\n        raise HTTPNotFound()\n\n    subscriptions = request.db.query(Subscriptions).filter_by(type=payload['type'],\n                                                              uri=payload['uri'])\n\n    for s in subscriptions:\n        if s.active:\n            s.active = False\n\n    return {}\n"},{"size":1529,"relativepath":"h/debug.py","filename":"debug.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"\nA module that configures the application for debugging.\n\nThis module should *only* be included in the application in development\nenvironments.\n\"\"\"\nfrom __future__ import print_function\n\nimport sys\nimport textwrap\n\nfrom pyramid_mailer.interfaces import IMailer\n\nCONSOLE_WIDTH = 70\n\n\nclass DebugMailer(object):\n    \"\"\"\n    Debug mailer for use in development.\n    \"\"\"\n\n    def _send(self, message, fail_silently=False):\n        if not message.sender:\n            message.sender = 'Default sender'\n\n        mail_message = message.to_message()\n\n        _print(\"=\" * CONSOLE_WIDTH)\n        _print(\"DEBUG: sending email...\\n\")\n\n        for key, val in sorted(mail_message.items()):\n            _print(\"    %s: %s\" % (key, val))\n        _print(\"\")\n\n        for part in mail_message.walk():\n            if part.get_content_type() != 'text/plain':\n                continue\n            content = part.get_payload(decode=True)\n            _print('\\n'.join(textwrap.wrap(content,\n                                           width=CONSOLE_WIDTH,\n                                           initial_indent='    ',\n                                           subsequent_indent='    ')))\n\n        _print(\"=\" * CONSOLE_WIDTH)\n\n    send = _send\n    send_immediately = _send\n    send_to_queue = _send\n    send_sendmail = _send\n    send_immediately_sendmail = _send\n\n\ndef _print(text):\n    print(text, file=sys.stderr)\n\n\ndef includeme(config):\n    mailer = DebugMailer()\n    config.registry.registerUtility(mailer, IMailer)\n"},{"size":775,"relativepath":"h/assets_client.ini","filename":"assets_client.ini","extension":".ini","content":"[bundles]\n# The H client application\napp_js =\n  scripts/raven.bundle.js\n  scripts/angular.bundle.js\n  scripts/katex.bundle.js\n  scripts/showdown.bundle.js\n  scripts/polyfills.bundle.js\n  scripts/unorm.bundle.js\n  scripts/app.bundle.js\n\napp_css =\n  styles/angular-csp.css\n  styles/angular-toastr.css\n  styles/icomoon.css\n  styles/katex.min.css\n  styles/app.css\n\n\n# The inject bundle is intended to be loaded into pages for bootstrapping the\n# application. It sets up RPC channels for cross-domain communication between\n# frames participating in annotation by using the annotator bridge plugin.\ninject_js =\n  scripts/polyfills.bundle.js\n  scripts/jquery.bundle.js\n  scripts/injector.bundle.js\n\ninject_css =\n  styles/icomoon.css\n  styles/inject.css\n  styles/pdfjs-overrides.css\n"},{"size":859,"relativepath":"h/feeds/util.py","filename":"util.py","extension":".py","content":"\"\"\"Utility functions for feed-generating code.\"\"\"\nfrom h._compat import urlparse\n\n# See RFC4151 for details of the use and format of the tag date:\n#\n#   https://tools.ietf.org/html/rfc4151#section-2.1\nFEED_TAG_DATE='2015-09'\n\n\ndef tag_uri_for_annotation(annotation, annotation_url):\n    \"\"\"Return a tag URI (unique identifier) for the given annotation.\n\n    Suitable for use as the value of the <id> element of an <entry> in an\n    Atom feed, or the <guid> element of an <item> in an RSS feed.\n\n    :returns: A tag URI (RFC 4151) for use as the ID for the Atom entry.\n    :rtype: string\n\n    \"\"\"\n    domain = urlparse.urlparse(annotation_url(annotation)).hostname\n    return u\"tag:{domain},{date}:{id_}\".format(domain=domain,\n                                               date=FEED_TAG_DATE,\n                                               id_=annotation.id)\n"},{"size":255,"relativepath":"h/feeds/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"Code for generating feeds (e.g. Atom and RSS feeds).\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom h.feeds.render import render_atom\nfrom h.feeds.render import render_rss\n\n__all__ = (\n    'render_atom',\n    'render_rss',\n)\n"},{"size":2442,"relativepath":"h/feeds/rss.py","filename":"rss.py","extension":".py","content":"\"\"\"Functions for generating RSS feeds.\"\"\"\nfrom pyramid import i18n\n\nfrom h import presenters\nfrom h import util\nimport h.feeds.util\n\n\n_ = i18n.TranslationStringFactory(__package__)\n\n\ndef _pubDate_string_from_annotation(annotation):\n    \"\"\"Return a correctly-formatted pubDate string for the given annotation.\n\n    Return a pubDate string like 'Tue, 03 Jun 2003 09:39:21 GMT' from a\n    Hypothesis API 'created' datetime string like\n    '2015-03-11T10:43:54.537626+00:00'.\n\n    Suitable for use as the contents of a <pubDate> element in an <item>\n    element of an RSS feed.\n\n    \"\"\"\n    return annotation.created.strftime('%a, %d %b %Y %H:%M:%S +0000')\n\n\ndef _feed_item_from_annotation(annotation, annotation_url):\n    \"\"\"Return an RSS feed item for the given annotation.\n\n    :returns: A logical representation of the RSS feed item as a dict,\n        containing all of the data that a template would need to render the\n        feed item to XML.\n    :rtype: dict\n\n    \"\"\"\n    try:\n        name = util.user.split_user(annotation.userid)[\"username\"]\n    except ValueError:\n        name = annotation.userid\n    return {\n        \"author\": {\"name\": name},\n        \"title\": annotation.title,\n        \"description\": annotation.description,\n        \"pubDate\": _pubDate_string_from_annotation(annotation),\n        \"guid\": h.feeds.util.tag_uri_for_annotation(annotation, annotation_url),\n        \"link\": annotation_url(annotation)\n    }\n\n\ndef feed_from_annotations(annotations, annotation_url, rss_url, html_url,\n                          title, description):\n    \"\"\"Return an RSS feed for the given list of annotations.\n\n    :returns: A logical representation of an RSS feed as a Python dict\n        containing all of the data that a template would need to render the\n        feed to XML (including a list of dicts for the feed's items).\n    :rtype: dict\n\n    \"\"\"\n    annotations = [presenters.AnnotationHTMLPresenter(a) for a in annotations]\n\n    feed = {\n        'title': title,\n        'rss_url': rss_url,\n        'html_url': html_url,\n        'description': description,\n        # This is called entries not items so as not to clash with the dict's\n        # standard .items() method.\n        'entries': [\n            _feed_item_from_annotation(annotation, annotation_url)\n            for annotation in annotations]\n    }\n\n    if annotations:\n        feed['pubDate'] = annotations[0].updated.strftime('%a, %d %b %Y %H:%M:%S UTC')\n\n    return feed\n"},{"size":2672,"relativepath":"h/feeds/atom.py","filename":"atom.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"Functions for generating Atom feeds.\"\"\"\nfrom pyramid import i18n\n\nfrom h import presenters\nfrom h import util\nimport h.feeds.util\n\n_ = i18n.TranslationStringFactory(__package__)\n\n\ndef _feed_entry_from_annotation(\n        annotation, annotation_url, annotation_api_url=None):\n    \"\"\"Return an Atom feed entry for the given annotation.\n\n    :returns: A logical representation of the Atom feed entry as a dict,\n        containing all of the data that a template would need to render the\n        feed item to XML.\n    :rtype: dict\n\n    \"\"\"\n    try:\n        name = util.user.split_user(annotation.userid)[\"username\"]\n    except ValueError:\n        name = annotation.userid\n\n    entry = {\n        \"id\": h.feeds.util.tag_uri_for_annotation(\n            annotation.annotation, annotation_url),\n        \"author\": {\"name\": name},\n        \"title\": annotation.title,\n        \"updated\": _utc_iso8601_string(annotation.updated),\n        \"published\": _utc_iso8601_string(annotation.created),\n        \"content\": annotation.description,\n        \"links\": [\n            {\"rel\": \"alternate\", \"type\": \"text/html\",\n             \"href\": annotation_url(annotation.annotation)},\n        ]\n    }\n    if annotation_api_url:\n        entry[\"links\"].append(\n            {\"rel\": \"alternate\", \"type\": \"application/json\",\n             \"href\": annotation_api_url(annotation.annotation)}\n        )\n\n    return entry\n\n\ndef _utc_iso8601_string(timestamp):\n    return timestamp.strftime('%Y-%m-%dT%H:%M:%S.%f+00:00')\n\n\ndef feed_from_annotations(\n        annotations, atom_url, annotation_url, annotation_api_url=None,\n        html_url=None, title=None, subtitle=None):\n    \"\"\"Return an Atom feed for the given list of annotations.\n\n    :returns: A logical representation of an Atom feed as a Python dict\n        containing all of the data that a template would need to render the\n        feed to XML (including a list of dicts for the feed's entries).\n    :rtype: dict\n\n    \"\"\"\n    annotations = [presenters.AnnotationHTMLPresenter(a) for a in annotations]\n\n    links = [{\"rel\": \"self\", \"type\": \"application/atom+xml\", \"href\": atom_url}]\n\n    if html_url:\n        links.append(\n            {\"rel\": \"alternate\", \"type\": \"text/html\", \"href\": html_url})\n\n    entries = [\n        _feed_entry_from_annotation(a, annotation_url, annotation_api_url)\n        for a in annotations]\n\n    feed = {\n        \"id\": atom_url,\n        \"title\": title or _(\"Hypothesis Stream\"),\n        \"subtitle\": subtitle or _(\"The Web. Annotated\"),\n        \"entries\": entries,\n        \"links\": links\n    }\n\n    if annotations:\n        feed[\"updated\"] = _utc_iso8601_string(annotations[0].updated)\n\n    return feed\n"},{"size":2685,"relativepath":"h/feeds/render.py","filename":"render.py","extension":".py","content":"from pyramid import renderers\n\nfrom h.feeds import atom\nfrom h.feeds import rss\n\n\ndef render_atom(request, annotations, atom_url, html_url, title, subtitle):\n    \"\"\"Return a rendered Atom feed of the given annotations.\n\n    :param annotations: The list of annotations to render as the feed's entries\n    :type annotations: list of dicts\n\n    :param atom_url: The URL that this Atom feed will be served at\n    :type atom_url: string\n\n    :param html_url: The URL of the HTML page that this Atom feed is a feed of\n    :type html_url: string\n\n    :param title: The title of this Atom feed\n    :type title: unicode\n\n    :param subtitle: The subtitle of this Atom feed\n    :type subtitle: unicode\n\n    :rtype: pyramid.response.Response\n\n    \"\"\"\n    request.response.content_type = \"application/atom+xml\"\n\n    def annotation_url(annotation):\n        \"\"\"Return the HTML permalink URL for the given annotation.\"\"\"\n        return request.route_url('annotation', id=annotation.id)\n\n    def annotation_api_url(annotation):\n        \"\"\"Return the JSON API URL for the given annotation.\"\"\"\n        return request.route_url('api.annotation', id=annotation.id)\n\n    feed = atom.feed_from_annotations(\n        annotations=annotations, atom_url=atom_url,\n        annotation_url=annotation_url, annotation_api_url=annotation_api_url,\n        html_url=html_url, title=title, subtitle=subtitle)\n\n    return renderers.render_to_response(\n        'h:templates/atom.xml.jinja2', {\"feed\": feed}, request=request)\n\n\ndef render_rss(request, annotations, rss_url, html_url, title, description):\n    \"\"\"Return a rendered RSS feed of the given annotations.\n\n    :param annotations: The list of annotations to render as the feed's items\n    :type annotations: list of dicts\n\n    :param rss_url: The URL that this RSS feed will be served at\n    :type rss_url: string\n\n    :param html_url: The URL of the HTML page that this RSS feed is a feed of\n    :type html_url: string\n\n    :param title: The title of this RSS feed\n    :type title: unicode\n\n    :param description: The description of this RSS feed\n    :type description: unicode\n\n    :rtype: pyramid.response.Response\n\n    \"\"\"\n    request.response.content_type = \"application/rss+xml\"\n\n    def annotation_url(annotation):\n        \"\"\"Return the HTML permalink URL for the given annotation.\"\"\"\n        return request.route_url('annotation', id=annotation.id)\n\n    feed = rss.feed_from_annotations(\n        annotations=annotations, annotation_url=annotation_url,\n        rss_url=rss_url, html_url=html_url, title=title,\n        description=description)\n\n    return renderers.render_to_response(\n        'h:templates/rss.xml.jinja2', {\"feed\": feed}, request=request)\n"},{"size":1849,"relativepath":"h/models/feature_cohort.py","filename":"feature_cohort.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport sqlalchemy as sa\n\nfrom h.db import Base\nfrom h.db import mixins\n\n\nclass FeatureCohort(Base, mixins.Timestamps):\n    __tablename__ = 'featurecohort'\n\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n    name = sa.Column(sa.UnicodeText(), nullable=False, index=True)\n\n    # Cohort membership\n    members = sa.orm.relationship('User',\n                                  secondary='featurecohort_user',\n                                  backref='cohorts')\n\n    features = sa.orm.relationship('Feature',\n                                   secondary='featurecohort_feature',\n                                   backref='cohorts')\n\n    def __init__(self, name):\n        self.name = name\n\n\nFEATURECOHORT_USER_TABLE = sa.Table(\n    'featurecohort_user', Base.metadata,\n    sa.Column('id',\n              sa.Integer,\n              nullable=False,\n              autoincrement=True,\n              primary_key=True),\n    sa.Column('cohort_id',\n              sa.Integer,\n              sa.ForeignKey('featurecohort.id'),\n              nullable=False),\n    sa.Column('user_id',\n              sa.Integer,\n              sa.ForeignKey('user.id'),\n              nullable=False),\n    sa.UniqueConstraint('cohort_id', 'user_id'),\n)\n\nFEATURECOHORT_FEATURE_TABLE = sa.Table(\n    'featurecohort_feature', Base.metadata,\n    sa.Column('id',\n              sa.Integer(),\n              nullable=False,\n              autoincrement=True,\n              primary_key=True),\n    sa.Column('cohort_id',\n              sa.Integer(),\n              sa.ForeignKey('featurecohort.id'),\n              nullable=False),\n    sa.Column('feature_id',\n              sa.Integer(),\n              sa.ForeignKey('feature.id'),\n              nullable=False),\n    sa.UniqueConstraint('cohort_id', 'feature_id'),\n)\n"},{"size":3844,"relativepath":"h/models/feature.py","filename":"feature.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport logging\n\nimport sqlalchemy as sa\n\nfrom h.db import Base\n\nlog = logging.getLogger(__name__)\n\nFEATURES = {\n    'activity_pages': \"Show the new activity pages?\",\n    'defer_realtime_updates': (\"Require a user action before applying real-time\"\n                               \" updates to annotations in the client?\"),\n    'orphans_tab': \"Show the orphans tab to separate anchored and unanchored annotations?\",\n    'search_page': \"Show the activity pages search skeleton page?\",\n}\n\n# Once a feature has been fully deployed, we remove the flag from the codebase.\n# We can't do this in one step, because removing it entirely will cause stage\n# to remove the flag data from the database on boot, which will in turn disable\n# the feature in prod.\n#\n# Instead, the procedure for removing a feature is as follows:\n#\n# 1. Remove all feature lookups for the named feature throughout the code.\n#\n# 2. Move the feature to FEATURES_PENDING_REMOVAL. This ensures that the\n#    feature won't show up in the admin panel, and any uses of the feature will\n#    provoke UnknownFeatureErrors (server-side) or console warnings\n#    (client-side).\n#\n# 3. Deploy these changes all the way out to production.\n#\n# 4. Finally, remove the feature from FEATURES_PENDING_REMOVAL.\n#\nFEATURES_PENDING_REMOVAL = {}\n\n\nclass Feature(Base):\n\n    \"\"\"A feature flag for the application.\"\"\"\n\n    __tablename__ = 'feature'\n\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n    name = sa.Column(sa.Text(), nullable=False, unique=True)\n\n    # Is the feature enabled for everyone?\n    everyone = sa.Column(sa.Boolean,\n                         nullable=False,\n                         default=False,\n                         server_default=sa.sql.expression.false())\n\n    # Is the feature enabled for admins?\n    admins = sa.Column(sa.Boolean,\n                       nullable=False,\n                       default=False,\n                       server_default=sa.sql.expression.false())\n\n    # Is the feature enabled for all staff?\n    staff = sa.Column(sa.Boolean,\n                      nullable=False,\n                      default=False,\n                      server_default=sa.sql.expression.false())\n\n    @property\n    def description(self):\n        return FEATURES[self.name]\n\n    @classmethod\n    def all(cls, session):\n        \"\"\"Fetch (or, if necessary, create) rows for all defined features.\"\"\"\n        features = {f.name: f\n                    for f in session.query(cls)\n                    if f.name in FEATURES}\n\n        # Add missing features\n        missing = [cls(name=n)\n                   for n in FEATURES\n                   if n not in features]\n        session.add_all(missing)\n\n        return list(features.values()) + missing\n\n    @classmethod\n    def remove_old_flags(cls, session):\n        \"\"\"\n        Remove old/unknown data from the feature table.\n\n        When a feature flag is removed from the codebase, it will remain in the\n        database. This could potentially cause very surprising issues in the\n        event that a feature flag with the same name (but a different meaning)\n        is added at some point in the future.\n\n        This function removes unknown feature flags from the database.\n        \"\"\"\n        # N.B. We remove only those features we know absolutely nothing about,\n        # which means that FEATURES_PENDING_REMOVAL are left alone.\n        known = set(FEATURES) | set(FEATURES_PENDING_REMOVAL)\n        unknown_flags = session.query(cls).filter(sa.not_(cls.name.in_(known)))\n        count = unknown_flags.delete(synchronize_session=False)\n        if count > 0:\n            log.info('removed %d old/unknown feature flags from database', count)\n\n    def __repr__(self):\n        return '<Feature {f.name} everyone={f.everyone}>'.format(f=self)\n"},{"size":4051,"relativepath":"h/models/group.py","filename":"group.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport sqlalchemy as sa\nfrom pyramid import security\nfrom sqlalchemy.orm import exc\nimport slugify\n\nfrom memex import models\nfrom h.db import Base\nfrom h.db import mixins\nfrom h import pubid\n\n\nGROUP_NAME_MIN_LENGTH = 4\nGROUP_NAME_MAX_LENGTH = 25\nGROUP_DESCRIPTION_MAX_LENGTH = 250\n\n\nclass GroupFactory(object):\n    def __init__(self, request):\n        self.request = request\n\n    def __getitem__(self, pubid):\n        try:\n            return self.request.db.query(Group).filter_by(pubid=pubid).one()\n        except exc.NoResultFound:\n            raise KeyError()\n\n\nclass Group(Base, mixins.Timestamps):\n    __tablename__ = 'group'\n\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n    # We don't expose the integer PK to the world, so we generate a short\n    # random string to use as the publicly visible ID.\n    pubid = sa.Column(sa.Text(),\n                      default=pubid.generate,\n                      unique=True,\n                      nullable=False)\n    name = sa.Column(sa.UnicodeText(), nullable=False, index=True)\n\n    # We store information about who created the group -- we don't use this\n    # currently, but it seems careless to lose this information when in the\n    # future these people may be the first admins of their groups.\n    creator_id = sa.Column(\n        sa.Integer, sa.ForeignKey('user.id'), nullable=False)\n    creator = sa.orm.relationship('User')\n\n    description = sa.Column(sa.UnicodeText())\n\n    # Group membership\n    members = sa.orm.relationship(\n        'User', secondary='user_group', backref=sa.orm.backref(\n            'groups', order_by='Group.name'))\n\n    def __init__(self, name, creator, description=None):\n        self.name = name\n        self.description = description\n        self.creator = creator\n        self.members.append(creator)\n\n    @sa.orm.validates('name')\n    def validate_name(self, key, name):\n        if not GROUP_NAME_MIN_LENGTH <= len(name) <= GROUP_NAME_MAX_LENGTH:\n            raise ValueError('name must be between {min} and {max} characters '\n                             'long'.format(min=GROUP_NAME_MIN_LENGTH,\n                                           max=GROUP_NAME_MAX_LENGTH))\n        return name\n\n    @property\n    def slug(self):\n        \"\"\"A version of this group's name suitable for use in a URL.\"\"\"\n        return slugify.slugify(self.name)\n\n    def documents(self, limit=25):\n        \"\"\"\n        Return this group's most recently annotated documents.\n\n        Only returns documents that have shared annotations in this group,\n        not documents that only have private annotations in the group.\n\n        \"\"\"\n        documents = []\n        annotations = (\n            sa.orm.object_session(self).query(models.Annotation)\n            .filter_by(groupid=self.pubid, shared=True)\n            .order_by(models.Annotation.updated.desc())\n            .limit(1000))\n        for annotation in annotations:\n            if annotation.document and annotation.document not in documents:\n                documents.append(annotation.document)\n                if len(documents) >= limit:\n                    break\n\n        return documents\n\n    def __acl__(self):\n        return [\n            (security.Allow, 'group:{}'.format(self.pubid), 'read'),\n            (security.Allow, self.creator.userid, 'admin'),\n            security.DENY_ALL,\n        ]\n\n    def __repr__(self):\n        return '<Group: %s>' % self.slug\n\n    @classmethod\n    def created_by(cls, session, user):\n        \"\"\"Return a query object filtering groups by creator.\"\"\"\n        return session.query(cls).filter(Group.creator == user)\n\n\nUSER_GROUP_TABLE = sa.Table(\n    'user_group', Base.metadata,\n    sa.Column('id', sa.Integer, autoincrement=True, primary_key=True),\n    sa.Column('user_id',\n              sa.Integer,\n              sa.ForeignKey('user.id'),\n              nullable=False),\n    sa.Column('group_id',\n              sa.Integer,\n              sa.ForeignKey('group.id'),\n              nullable=False),\n    sa.UniqueConstraint('user_id', 'group_id'),\n)\n"},{"size":1738,"relativepath":"h/models/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"\nA module into which all ORM classes are imported.\n\nTo avoid circular imports almost all code should import ORM classes from this\nmodule rather than importing them directly,\n``from h import models`` rather than ``from h.foo import models``\n\nThis is a convenience - you can just import this one module and all of the\nORM classes will be defined, instead of having to import every models module\nindividually.\n\nFor example when testing ORM classes the test module for ``h.foo.models.Bar``\ncan't just import ``h.foo.models``, it would also need to import the models\nmodule for each database table that ``Bar`` has a (direct or indirect) foreign\nkey to. So for convenience the test module can instead just do\n``from h import models`` and have all ORM classes be defined.\n\n\"\"\"\n\nfrom memex.models.annotation import Annotation\nfrom memex.models.document import Document, DocumentMeta, DocumentURI\n\nfrom h.models.activation import Activation\nfrom h.models.auth_client import AuthClient\nfrom h.models.auth_ticket import AuthTicket\nfrom h.models.blocklist import Blocklist\nfrom h.models.feature import Feature\nfrom h.models.feature_cohort import FeatureCohort\nfrom h.models.group import Group\nfrom h.models.subscriptions import Subscriptions\nfrom h.models.token import Token\nfrom h.models.user import User\n\n__all__ = (\n    'Activation',\n    'Annotation',\n    'AuthClient',\n    'AuthTicket',\n    'Blocklist',\n    'Document',\n    'DocumentMeta',\n    'DocumentURI',\n    'Feature',\n    'FeatureCohort',\n    'Group',\n    'Subscriptions',\n    'Token',\n    'User',\n)\n\n\ndef includeme(_):\n    # This module is included for side-effects only. SQLAlchemy models register\n    # with the global metadata object when imported.\n    pass\n"},{"size":1360,"relativepath":"h/models/auth_client.py","filename":"auth_client.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects import postgresql\n\nfrom h.db import Base\nfrom h.db.mixins import Timestamps\nfrom h.security import token_urlsafe\n\n\nclass AuthClient(Base, Timestamps):\n    \"\"\"\n    An OAuth client.\n\n    An AuthClient represents an OAuth client, an entity which can access\n    protected resources (such as annotations) on behalf of a user.\n\n    The first type of OAuth client we have is a very special one, which can\n    access protected resources for *any* user within its *authority*. These\n    are \"publisher\" accounts, which can create users in our database, and\n    subsequently issue grant authorization tokens for any of those users.\n    \"\"\"\n\n    __tablename__ = 'authclient'\n\n    #: Public client identifier\n    id = sa.Column(postgresql.UUID,\n                   server_default=sa.func.uuid_generate_v1mc(),\n                   primary_key=True)\n\n    #: Human-readable name for reference.\n    name = sa.Column(sa.UnicodeText, nullable=True)\n\n    #: Client secret\n    secret = sa.Column(sa.UnicodeText, default=token_urlsafe, nullable=False)\n\n    #: Authority for which this client is allowed to authorize users.\n    authority = sa.Column(sa.UnicodeText, nullable=False)\n\n    def __repr__(self):\n        return 'AuthClient(id={self.id!r})'.format(self=self)\n"},{"size":1270,"relativepath":"h/models/auth_ticket.py","filename":"auth_ticket.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport sqlalchemy as sa\n\nfrom h.db import Base\nfrom h.db.mixins import Timestamps\n\n\nclass AuthTicket(Base, Timestamps):\n    \"\"\"\n    An auth ticket.\n\n    An auth ticket represents an open authentication session for a logged-in\n    user. The ``id`` is typically stored in an ``auth`` cookie, provided by\n    :py:class:`pyramid_authsanity.sources.CookieAuthSource`.\n    \"\"\"\n\n    __tablename__ = 'authticket'\n\n    #: The id that is typically stored in the cookie, it should be a\n    #: cryptographically random string with an appropriate amount of entropy.\n    id = sa.Column(sa.UnicodeText(), primary_key=True)\n\n    #: The datetime when this ticket expires\n    expires = sa.Column(sa.DateTime, nullable=False)\n\n    user_id = sa.Column(sa.Integer,\n                        sa.ForeignKey('user.id', ondelete='cascade'),\n                        nullable=False)\n\n    #: The user whose auth ticket it is\n    user = sa.orm.relationship('User')\n\n    #: The user's userid, denormalised onto this table to avoid the need to do\n    #: a SELECT against the user table just to find the authenticated_userid\n    #: associated with the request.\n    user_userid = sa.Column('user_userid', sa.UnicodeText(), nullable=False)\n"},{"size":1150,"relativepath":"h/models/activation.py","filename":"activation.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport hashlib\nimport random\nimport string\n\nimport sqlalchemy as sa\n\nfrom h._compat import text_type\nfrom h.db import Base\n\n\ndef _generate_random_string(length=12):\n    \"\"\"Generate a random ascii string of the requested length.\"\"\"\n    msg = hashlib.sha256()\n    word = ''\n    for _ in range(length):\n        word += random.choice(string.ascii_letters)\n    msg.update(word.encode('ascii'))\n    return text_type(msg.hexdigest()[:length])\n\n\nclass Activation(Base):\n\n    \"\"\"\n    Handles activations for users.\n\n    The code should be a random hash that is valid only once.\n    After the hash is used to access the site, it'll be removed.\n    \"\"\"\n\n    __tablename__ = 'activation'\n\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n\n    # A random hash that is valid only once.\n    code = sa.Column(sa.UnicodeText(),\n                     nullable=False,\n                     unique=True,\n                     default=_generate_random_string)\n\n    @classmethod\n    def get_by_code(cls, session, code):\n        \"\"\"Fetch an activation by code.\"\"\"\n        return session.query(cls).filter(cls.code == code).first()\n"},{"size":784,"relativepath":"h/models/blocklist.py","filename":"blocklist.py","extension":".py","content":"# -*- coding: utf-8 -*-\nimport sqlalchemy as sa\nfrom sqlalchemy.sql import expression\n\nfrom h.db import Base\n\n\nclass Blocklist(Base):\n\n    \"\"\"A list of URIs for which the badge API will always return 0.\n\n    This means that the Chrome extension will never show a number of\n    annotations on its badge for these URIs.\n\n    \"\"\"\n\n    __tablename__ = 'blocklist'\n\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n    uri = sa.Column(sa.UnicodeText(), nullable=False, unique=True)\n\n    def __repr__(self):\n        return self.uri\n\n    @classmethod\n    def is_blocked(cls, session, uri):\n        \"\"\"Return True if the given URI is blocked.\"\"\"\n        uri_matches = expression.literal(uri).like(cls.uri)\n        return session.query(cls).filter(uri_matches).count() > 0\n"},{"size":894,"relativepath":"h/models/subscriptions.py","filename":"subscriptions.py","extension":".py","content":"# -*- coding: utf-8 -*-\nimport sqlalchemy as sa\nfrom sqlalchemy import func\n\nfrom h.db import Base\n\n\nclass Subscriptions(Base):\n    __tablename__ = 'subscriptions'\n    __table_args__ = sa.Index('subs_uri_idx_subscriptions', 'uri'),\n\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n    uri = sa.Column(sa.UnicodeText(), nullable=False)\n    type = sa.Column(sa.VARCHAR(64), nullable=False)\n    active = sa.Column(sa.Boolean, default=True, nullable=False)\n\n    @classmethod\n    def get_subscriptions_for_uri(cls, session, uri):\n        return session.query(cls).filter(\n            func.lower(cls.uri) == func.lower(uri)\n        ).all()\n\n    def __repr__(self):\n        return '<Subscription uri=%s type=%s active=%s>' % (self.uri,\n                                                            self.type,\n                                                            self.active)\n"},{"size":9631,"relativepath":"h/models/user.py","filename":"user.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport datetime\nimport re\n\nimport sqlalchemy as sa\nfrom sqlalchemy.ext.hybrid import Comparator, hybrid_property\n\nfrom h._compat import text_type\nfrom h.db import Base\nfrom h.security import password_context\nfrom h.util.user import split_user\n\nUSERNAME_MIN_LENGTH = 3\nUSERNAME_MAX_LENGTH = 30\nUSERNAME_PATTERN = '(?i)^[A-Z0-9._]+$'\nEMAIL_MAX_LENGTH = 100\nPASSWORD_MIN_LENGTH = 2\n\n\nclass UserIDComparator(Comparator):\n    \"\"\"\n    Custom comparator for the User.userid property.\n\n    This is a comparator conforming to the\n    :py:class:`sqlalchemy.orm.interfaces.PropComparator` interface, which\n    makes it possible to find users by userid without doing ugly SQL\n    concatenation that prevents the use of indices.\n    \"\"\"\n    def __init__(self, username, authority):\n        self.username = username\n        self.authority = authority\n\n    def __eq__(self, other):\n        try:\n            val = split_user(other)\n        except ValueError:\n            # The value being compared isn't a valid userid\n            return False\n        return sa.and_(val['username'] == self.username,\n                       val['domain'] == self.authority)\n\n\nclass User(Base):\n    __tablename__ = 'user'\n    __table_args__ = (\n        sa.UniqueConstraint('email', 'authority'),\n        sa.UniqueConstraint('uid', 'authority'),\n        sa.UniqueConstraint('username', 'authority'),\n    )\n\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n\n    #: Normalised user identifier\n    uid = sa.Column(sa.UnicodeText(), nullable=False)\n    #: Username as chosen by the user on registration\n    _username = sa.Column('username', sa.UnicodeText(), nullable=False)\n\n    #: The \"authority\" for this user. This represents the \"namespace\" in which\n    #: this user lives. By default, all users are created in the namespace\n    #: corresponding to `request.domain`, but this can be overridden with the\n    #: `AUTH_DOMAIN` environment variable.\n    authority = sa.Column('authority',\n                          sa.UnicodeText(),\n                          index=True,\n                          nullable=False)\n\n    #: The display name which will be used when rendering an annotation.\n    display_name = sa.Column(sa.UnicodeText())\n\n    #: A short user description/bio\n    description = sa.Column(sa.UnicodeText())\n\n    #: A free-form column to allow the user to say where they are\n    location = sa.Column(sa.UnicodeText())\n\n    #: The user's URI/link on the web\n    uri = sa.Column(sa.UnicodeText())\n\n    #: The user's ORCID ID\n    orcid = sa.Column(sa.UnicodeText())\n\n    #: Is this user an admin member?\n    admin = sa.Column(sa.Boolean,\n                      default=False,\n                      nullable=False,\n                      server_default=sa.sql.expression.false())\n\n    #: Is this user a staff member?\n    staff = sa.Column(sa.Boolean,\n                      nullable=False,\n                      default=False,\n                      server_default=sa.sql.expression.false())\n\n    #: Is this user flagged as \"Not (Suitable) In Public Site Areas\" (AKA\n    #: NIPSA). This flag is used to shadow-ban a user so their annotations\n    #: don't appear to anyone but themselves.\n    nipsa = sa.Column(sa.Boolean,\n                      nullable=False,\n                      default=False,\n                      server_default=sa.sql.expression.false())\n\n    sidebar_tutorial_dismissed = sa.Column(sa.Boolean,\n                                           default=False,\n                                           server_default=(\n                                                sa.sql.expression.false()))\n\n    @hybrid_property\n    def username(self):\n        return self._username\n\n    @username.setter\n    def username(self, value):\n        self._username = value\n        self.uid = _username_to_uid(value)\n\n    @hybrid_property\n    def userid(self):\n        return u'acct:{username}@{authority}'.format(username=self.username,\n                                                     authority=self.authority)\n\n    @userid.comparator\n    def userid(cls):\n        # Rather than using the default generated by hybrid_property, which\n        # would generate SQL like the following:\n        #\n        #     ... WHERE 'acct:' || username || '@' || authority = ...\n        #\n        # we use a custom comparator so that we can take advantage of indices\n        # on the username and authority columns.\n        return UserIDComparator(cls.username, cls.authority)\n\n    email = sa.Column(sa.UnicodeText(), nullable=False)\n\n    last_login_date = sa.Column(sa.TIMESTAMP(timezone=False),\n                                default=datetime.datetime.utcnow,\n                                server_default=sa.func.now(),\n                                nullable=False)\n    registered_date = sa.Column(sa.TIMESTAMP(timezone=False),\n                                default=datetime.datetime.utcnow,\n                                server_default=sa.func.now(),\n                                nullable=False)\n\n    # Activation foreign key\n    activation_id = sa.Column(sa.Integer, sa.ForeignKey('activation.id'))\n    activation = sa.orm.relationship('Activation', backref='user')\n\n    @property\n    def is_activated(self):\n        if self.activation_id is None:\n            return True\n\n        return False\n\n    def activate(self):\n        \"\"\"Activate the user by deleting any activation they have.\"\"\"\n        session = sa.orm.object_session(self)\n        session.delete(self.activation)\n\n    #: Hashed password\n    _password = sa.Column('password', sa.UnicodeText(), nullable=True)\n    #: Last password update\n    password_updated = sa.Column(sa.DateTime(), nullable=True)\n\n    #: Password salt\n    #:\n    #: N.B. This field is DEPRECATED. The password context we use already\n    #: manages the generation of a random salt when hashing a password and we\n    #: don't need a separate salt column. This remains for \"legacy\" passwords\n    #: which were, sadly, double-salted. As users log in, we are slowly\n    #: upgrading their passwords and setting this column to None.\n    salt = sa.Column(sa.UnicodeText(), nullable=True)\n\n    @hybrid_property\n    def password(self):\n        return self._password\n\n    @password.setter\n    def password(self, secret):\n        if len(secret) < PASSWORD_MIN_LENGTH:\n            raise ValueError('password must be more than {min} characters '\n                             'long'.format(min=PASSWORD_MIN_LENGTH))\n        # Remove any existing explicit salt (the password context salts the\n        # password automatically).\n        self.salt = None\n        self._password = text_type(password_context.encrypt(secret))\n        self.password_updated = datetime.datetime.utcnow()\n\n    def check_password(self, secret):\n        \"\"\"Check the passed password for this user.\"\"\"\n        if not self.password:\n            return False\n\n        # Old-style separate salt.\n        #\n        # TODO: remove this deprecated code path when a suitable proportion of\n        # users have updated their password by logging-in. (Check how many\n        # users still have a non-null salt in the database.)\n        if self.salt is not None:\n            verified = password_context.verify(secret + self.salt,\n                                               self.password)\n\n            # If the password is correct, take this opportunity to upgrade the\n            # password and remove the salt.\n            if verified:\n                self.password = secret\n\n            return verified\n\n        verified, new_hash = password_context.verify_and_update(secret,\n                                                                self.password)\n        if not verified:\n            return False\n\n        if new_hash is not None:\n            self._password = text_type(new_hash)\n\n        return verified\n\n    @sa.orm.validates('email')\n    def validate_email(self, key, email):\n        if len(email) > EMAIL_MAX_LENGTH:\n            raise ValueError('email must be less than {max} characters '\n                             'long'.format(max=EMAIL_MAX_LENGTH))\n        return email\n\n    @sa.orm.validates('_username')\n    def validate_username(self, key, username):\n        if not USERNAME_MIN_LENGTH <= len(username) <= USERNAME_MAX_LENGTH:\n            raise ValueError('username must be between {min} and {max} '\n                             'characters long'.format(\n                                 min=USERNAME_MIN_LENGTH,\n                                 max=USERNAME_MAX_LENGTH))\n\n        if not re.match(USERNAME_PATTERN, username):\n            raise ValueError('username must have only letters, numbers, '\n                             'periods, and underscores.')\n\n        return username\n\n    @classmethod\n    def get_by_email(cls, session, email):\n        \"\"\"Fetch a user by email address.\"\"\"\n        return session.query(cls).filter(\n            sa.func.lower(cls.email) == email.lower()\n        ).first()\n\n    @classmethod\n    def get_by_activation(cls, session, activation):\n        \"\"\"Fetch a user by activation instance.\"\"\"\n        user = session.query(cls).filter(\n            cls.activation_id == activation.id\n        ).first()\n\n        return user\n\n    @classmethod\n    def get_by_username(cls, session, username):\n        \"\"\"Fetch a user by username.\"\"\"\n        uid = _username_to_uid(username)\n        return session.query(cls).filter(cls.uid == uid).first()\n\n    def __repr__(self):\n        return '<User: %s>' % self.username\n\n\ndef _username_to_uid(username):\n    # We normalize usernames by dots and case in order to discourage attempts\n    # at impersonation.\n    return username.replace('.', '').lower()\n"},{"size":2142,"relativepath":"h/models/token.py","filename":"token.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport binascii\nimport datetime\nimport os\n\nimport sqlalchemy\nfrom sqlalchemy.dialects import postgresql\n\nfrom h.auth.interfaces import IAuthenticationToken\nfrom h.db import Base\nfrom h.db import mixins\n\n\nclass Token(Base, mixins.Timestamps):\n\n    \"\"\"A long-lived API token for a user.\"\"\"\n\n    __tablename__ = 'token'\n\n    #: A prefix that identifies a token as a long-lived API token (as opposed\n    #: to, for example, one of the short-lived JWTs that the client uses).\n    prefix = u'6879-'\n\n    id = sqlalchemy.Column(sqlalchemy.Integer,\n                           autoincrement=True,\n                           primary_key=True)\n\n    userid = sqlalchemy.Column(sqlalchemy.UnicodeText(),\n                               nullable=False)\n\n    value = sqlalchemy.Column(sqlalchemy.UnicodeText(),\n                              nullable=False,\n                              unique=True)\n\n    #: A timestamp after which this token will no longer be considered valid.\n    #: A NULL value in this column indicates a token that does not expire.\n    expires = sqlalchemy.Column(sqlalchemy.DateTime, nullable=True)\n\n    _authclient_id = sqlalchemy.Column('authclient_id',\n                                       postgresql.UUID(),\n                                       sqlalchemy.ForeignKey('authclient.id', ondelete='cascade'),\n                                       nullable=True)\n\n    #: The authclient which created the token.\n    #: A NULL value means it is a developer token.\n    authclient = sqlalchemy.orm.relationship('AuthClient')\n\n    def __init__(self, **kwargs):\n        super(Token, self).__init__(**kwargs)\n        self.regenerate()\n\n    @classmethod\n    def get_dev_token_by_userid(cls, session, userid):\n        return (session.query(cls)\n                .filter_by(userid=userid, authclient=None)\n                .order_by(cls.created.desc())\n                .first())\n\n    def regenerate(self):\n        self.value = self.prefix + _token()\n\n\ndef _token():\n    \"\"\"Return a random string suitable for use in an API token.\"\"\"\n    return binascii.hexlify(os.urandom(16))\n"},{"size":87,"relativepath":"h/__main__.py","filename":"__main__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom h.cli import main\n\nif __name__ == '__main__':\n    main()\n"},{"size":2133,"relativepath":"h/subscribers.py","filename":"subscribers.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\nfrom h import __version__\nfrom h import emails\nfrom h import mailer\nfrom memex import storage\nfrom h.notification import reply\n\n\ndef add_renderer_globals(event):\n    request = event['request']\n\n    event['h_version'] = __version__\n    event['base_url'] = request.route_url('index')\n    event['feature'] = request.feature\n\n    # Add Google Analytics\n    ga_tracking_id = request.registry.settings.get('ga_tracking_id')\n    if ga_tracking_id is not None:\n        event['ga_tracking_id'] = ga_tracking_id\n        if 'localhost' in request.host:\n            event['ga_cookie_domain'] = \"none\"\n        else:\n            event['ga_cookie_domain'] = \"auto\"\n\n\ndef publish_annotation_event(event):\n    \"\"\"Publish an annotation event to the message queue.\"\"\"\n    data = {\n        'action': event.action,\n        'annotation_id': event.annotation_id,\n        'src_client_id': event.request.headers.get('X-Client-Id'),\n    }\n    if event.annotation_dict:\n        data['annotation_dict'] = event.annotation_dict\n\n    event.request.realtime.publish_annotation(data)\n\n\ndef send_reply_notifications(event,\n                             get_notification=reply.get_notification,\n                             generate_mail=emails.reply_notification.generate,\n                             send=mailer.send.delay):\n    \"\"\"Queue any reply notification emails triggered by an annotation event.\"\"\"\n    request = event.request\n    annotation = storage.fetch_annotation(event.request.db, event.annotation_id)\n    action = event.action\n    try:\n        notification = get_notification(request, annotation, action)\n        if notification is None:\n            return\n        send_params = generate_mail(request, notification)\n        send(*send_params)\n    # We don't want any exceptions thrown by this code to cause the annotation\n    # CRUD action to fail, but we do want to collect the error in Sentry, so we\n    # explicitly wrap this here.\n    #\n    # FIXME: Fix the underlying bugs and remove this try/except.\n    except Exception:\n        event.request.sentry.captureException()\n        if event.request.debug:\n            raise\n"},{"size":2561,"relativepath":"h/settings.py","filename":"settings.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"Helpers for parsing settings from the environment.\"\"\"\n\nimport string\n\n\nclass SettingError(Exception):\n    pass\n\n\nclass EnvSetting(object):\n\n    \"\"\"An (optionally typed) setting read from an environment variable.\"\"\"\n\n    def __init__(self, setting, varname, type=None):\n        self.setting = setting\n        self.varname = varname\n        if type is not None:\n            self.type = type\n        else:\n            self.type = str\n\n    def __call__(self, environ):\n        if self.varname in environ:\n            try:\n                value = self.type(environ[self.varname])\n            except ValueError:\n                raise SettingError('error parsing environment variable '\n                                   '{varname}={value!r} as {typename}'.format(\n                                       varname=self.varname,\n                                       typename=self.type.__name__,\n                                       value=environ[self.varname]))\n            return {self.setting: value}\n\n\nclass DockerSetting(object):\n\n    \"\"\"A setting read from Docker link environment variables.\"\"\"\n\n    def __init__(self, setting, link, pattern):\n        self.setting = setting\n        self.link = link.upper()\n        self.pattern = pattern\n\n        # Determine the settings that need to be present\n        formatter = string.Formatter()\n        self.placeholders = [field\n                             for _, field, _, _ in formatter.parse(pattern)\n                             if field is not None]\n\n    def __call__(self, environ):\n        try:\n            values = {x: environ['{}_{}'.format(self.link, x.upper())]\n                      for x in self.placeholders}\n        except KeyError:\n            pass\n        else:\n            return {self.setting: self.pattern.format(**values)}\n\n\ndef database_url(url):\n    \"\"\"Parse a string as a Heroku-style database URL.\"\"\"\n    # Heroku database URLs start with postgres://, which is an old and\n    # deprecated dialect as far as sqlalchemy is concerned. We upgrade this\n    # to postgresql+psycopg2 by default.\n    if url.startswith('postgres://'):\n        url = 'postgresql+psycopg2://' + url[len('postgres://'):]\n    return url\n\n\ndef mandrill_settings(environ):\n    if 'MANDRILL_USERNAME' in environ and 'MANDRILL_APIKEY' in environ:\n        return {\n            'mail.username': environ['MANDRILL_USERNAME'],\n            'mail.password': environ['MANDRILL_APIKEY'],\n            'mail.host': 'smtp.mandrillapp.com',\n            'mail.port': 587,\n            'mail.tls': True,\n        }\n"},{"size":2133,"relativepath":"h/sentry.py","filename":"sentry.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"\nProvide a Sentry client at `request.sentry`.\n\nThis module provides a Sentry client, preconfigured with appropriate request\ncontext, as a request property, `request.sentry`. This allows us to more easily\nlog exceptions from within the application with a useful complement of\ndiagnostic data.\n\"\"\"\n\nimport raven\nfrom raven.transport import GeventedHTTPTransport\nfrom raven.utils.wsgi import get_environ\n\nfrom h import __version__\n\nPROCESSORS = (\n    'raven.processors.SanitizePasswordsProcessor',\n    'raven.processors.RemovePostDataProcessor',\n)\n\n\ndef http_context_data(request):\n    return {\n        'url': request.url,\n        'method': request.method,\n        'data': request.body,\n        'query_string': request.query_string,\n        'cookies': dict(request.cookies),\n        'headers': dict(request.headers),\n        'env': dict(get_environ(request.environ)),\n    }\n\n\ndef user_context_data(request):\n    return {\n        'id': request.authenticated_userid,\n        'ip_address': request.client_addr,\n    }\n\n\ndef get_client(settings):\n    \"\"\"\n    Get a Sentry client configured with context data for the current request.\n    \"\"\"\n    # If the `raven.transport` setting is set to 'gevent', then we use the\n    # raven-supplied gevent compatible transport.\n    transport_name = settings.get('raven.transport')\n    transport = GeventedHTTPTransport if transport_name == 'gevent' else None\n\n    return raven.Client(release=__version__,\n                        transport=transport,\n                        processors=PROCESSORS)\n\n\ndef _get_request_client(request):\n    client = request.registry['sentry.client']\n    client.http_context(http_context_data(request))\n    client.user_context(user_context_data(request))\n    request.add_finished_callback(lambda _: client.context.clear())\n    return client\n\n\ndef includeme(config):\n    # Create a sentry client and store it in the registry\n    config.registry['sentry.client'] = get_client(config.registry.settings)\n\n    # Allow retrieval of the client within a request as `request.sentry`\n    config.add_request_method(_get_request_client, 'sentry', reify=True)\n"},{"size":1427,"relativepath":"h/pubid.py","filename":"pubid.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"\nGenerate random strings for use as identifiers in URLs (and other places).\n\nThe random strings are generated using an alphabet of ASCII digits and letters\nwith the following removed:\n\n  - 0, O, I, 1: easily mistaken for one another when reading a URL.\n  - C, c, F, f, H, h, S, s, U, u, T, t: avoid making curse words accidentally.\n\nWith a default length of n characters, the size of the space of possible\nstrings is:\n\n    N = len(ALPHABET) ** n\n\nThe chance of a collision when generating k random ids of length n is\napproximately:\n\n   k**2\n   ----\n    2N\n\n(for sufficiently large k and N). This means that with a default length of 8,\nas here, we have a 99.97% chance of generating 100,000 strings in a row without\ncollisions, so we hopefully won't need to worry about that any time soon.\n\nReference: http://preshing.com/20110504/hash-collision-probabilities/\n\"\"\"\n\nimport random\n\nALPHABET = '123456789ABDEGJKLMNPQRVWXYZabdegijkmnopqrvwxyz'\nDEFAULT_LENGTH = 8\n\n\ndef generate(length=DEFAULT_LENGTH):\n    \"\"\"\n    Generate a random string of the specified length.\n\n    The returned string is composed of an alphabet that shouldn't include any\n    characters that are easily mistakeable for one another (I, 1, O, 0), and\n    hopefully won't accidentally contain any English-language curse words.\n    \"\"\"\n    return ''.join(random.SystemRandom().choice(ALPHABET)\n                   for _ in range(length))\n"},{"size":3960,"relativepath":"h/client.py","filename":"client.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"\nProvides functions for building the assets for the Hypothesis client\napplication.\n\"\"\"\nimport json\nfrom h._compat import urlparse\n\nfrom jinja2 import Environment, PackageLoader\nfrom h import __version__\n\njinja_env = Environment(loader=PackageLoader(__package__, 'templates'))\n\ndef url_with_path(url):\n    if urlparse.urlparse(url).path == '':\n        return '{}/'.format(url)\n    else:\n        return url\n\n\ndef _app_html_context(assets_env, api_url, service_url, ga_tracking_id,\n                      sentry_public_dsn, websocket_url):\n    \"\"\"\n    Returns a dict of asset URLs and contents used by the sidebar app\n    HTML tempate.\n    \"\"\"\n\n    if urlparse.urlparse(service_url).hostname == 'localhost':\n        ga_cookie_domain = 'none'\n    else:\n        ga_cookie_domain = 'auto'\n\n    # the serviceUrl parameter must contain a path element\n    service_url = url_with_path(service_url)\n\n    app_config = {\n        'apiUrl': api_url,\n        'serviceUrl': service_url,\n        'release': __version__\n    }\n\n    if websocket_url:\n        app_config.update({\n            'websocketUrl': websocket_url,\n        })\n\n    if sentry_public_dsn:\n        app_config.update({\n            'raven': {\n                'dsn': sentry_public_dsn,\n                'release': __version__\n            }\n        })\n\n    return {\n        'app_config': json.dumps(app_config),\n        'app_css_urls': assets_env.urls('app_css'),\n        'app_js_urls': assets_env.urls('app_js'),\n        'ga_tracking_id': ga_tracking_id,\n        'ga_cookie_domain': ga_cookie_domain,\n    }\n\n\ndef render_app_html(assets_env,\n                    service_url,\n                    api_url,\n                    sentry_public_dsn,\n                    ga_tracking_id=None,\n                    websocket_url=None,\n                    extra=None):\n    \"\"\"\n    Return the HTML for the Hypothesis app page,\n    used by the sidebar, stream and single-annotation page.\n\n    :param assets_env: The assets environment\n    :param service_url: The base URL of the Hypothesis service\n                     (eg. https://hypothes.is/)\n    :param api_url: The root URL for the Hypothesis service API\n    :param websocket_url: The WebSocket URL which the client should connect to\n    :param sentry_public_dsn: The _public_ Sentry DSN for client-side\n                              crash reporting\n    :param ga_tracking_id: The Google Analytics tracking ID\n    :param extra: A dict of optional properties specifying link tags and\n                  meta attributes to be included on the page, passed through to\n                  app.html.jinja2\n    \"\"\"\n    template = jinja_env.get_template('app.html.jinja2')\n    context = _app_html_context(api_url=api_url,\n                                service_url=service_url,\n                                ga_tracking_id=ga_tracking_id,\n                                sentry_public_dsn=sentry_public_dsn,\n                                assets_env=assets_env,\n                                websocket_url=websocket_url).copy()\n    if extra is not None:\n        context.update(extra)\n    return template.render(context)\n\n\ndef render_embed_js(assets_env, app_html_url, base_url=None):\n    \"\"\"\n    Return the code for the script which is injected into a page in order\n    to load the Hypothesis annotation client into it.\n\n    :param assets_env: The assets environment\n    :param app_html_url: The URL of the app.html page for the sidebar\n    :param base_url: The absolute base URL of the web service\n    \"\"\"\n\n    def absolute_asset_urls(bundle_name):\n        return [urlparse.urljoin(base_url, url)\n                for url in assets_env.urls(bundle_name)]\n\n    template = jinja_env.get_template('embed.js.jinja2')\n    template_args = {\n        'app_html_url': app_html_url,\n        'inject_resource_urls': absolute_asset_urls('inject_js') +\n                                absolute_asset_urls('inject_css')\n    }\n    return template.render(template_args)\n"},{"size":2351,"relativepath":"h/_version.py","filename":"_version.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport datetime\nimport subprocess\n\ntry:\n    from subprocess import DEVNULL  # Python 3\nexcept ImportError:\n    import os\n    DEVNULL = open(os.devnull, 'wb')\n\n__all__ = ('get_version',)\n\n# git-archive substitution markers. When this file is written out by a `git\n# archive` command, these will be replaced by the short commit hash and the\n# commit date, respectively.\nVERSION_GIT_REF = '$Format:%h$'\nVERSION_GIT_DATE = '$Format:%ct$'\n\n# Fallback version in case we cannot derive the version.\nVERSION_UNKNOWN = '0+unknown'\n\ndef fetch_git_ref():\n    return subprocess.check_output(['git', 'rev-parse', '--short', 'HEAD'],\n                                   stderr=DEVNULL).strip()\n\n\ndef fetch_git_date(ref):\n    ts = subprocess.check_output(['git', 'show', '-s', '--format=%ct', ref])\n    return datetime.datetime.fromtimestamp(int(ts))\n\n\ndef fetch_git_dirty():\n    dirty_tree = subprocess.call(['git', 'diff-files', '--quiet']) != 0\n    dirty_index = subprocess.call(['git', 'diff-index', '--quiet',\n                                   '--cached', 'HEAD']) != 0\n    return dirty_tree or dirty_index\n\n\ndef git_version():\n    ref = fetch_git_ref()\n    date = fetch_git_date(ref)\n    dirty = fetch_git_dirty()\n    return pep440_version(date, ref, dirty)\n\n\ndef git_archive_version():\n    ref = VERSION_GIT_REF\n    date = datetime.datetime.fromtimestamp(int(VERSION_GIT_DATE))\n    return pep440_version(date, ref)\n\n\ndef pep440_version(date, ref, dirty=False):\n    \"\"\"Build a PEP440-compliant version number from the passed information.\"\"\"\n    return '{date}+g{ref}{dirty}'.format(date=date.strftime('%Y%m%d'),\n                                         ref=ref,\n                                         dirty='.dirty' if dirty else '')\n\n\ndef get_version():\n    \"\"\"Fetch the current application version.\"\"\"\n    # First we try to retrieve the current application version from git.\n    try:\n        return git_version()\n    except subprocess.CalledProcessError:\n        pass\n\n    # We are not in a git checkout or extracting the version from git failed,\n    # so we attempt to read a version written into the header of this file by\n    # `git archive`.\n    if not VERSION_GIT_REF.startswith('$'):\n        return git_archive_version()\n\n    # If neither of these strategies work, we fall back to VERSION_UNKNOWN.\n    return VERSION_UNKNOWN\n"},{"size":2241,"relativepath":"h/accounts/util.py","filename":"util.py","extension":".py","content":"\"\"\"\nHelpers for account forms\n\"\"\"\n\nimport re\n\nfrom h._compat import urlparse\n\ndef validate_url(url):\n    \"\"\"\n    Validate an HTTP(S) URL as a link for a user's profile.\n\n    Helper for use with Colander that validates a URL provided by a user as a\n    link for their profile.\n\n    Returns the normalized URL if successfully parsed or raises a ValueError\n    otherwise.\n    \"\"\"\n\n    # Minimal URL validation with urlparse. This is extremely lenient, we might\n    # want to use something like https://github.com/kvesteri/validators instead.\n    parsed_url = urlparse.urlparse(url)\n\n    if not parsed_url.scheme:\n        parsed_url = urlparse.urlparse('http://' + url)\n\n    if not re.match('https?', parsed_url.scheme):\n        raise ValueError('Links must have an \"http\" or \"https\" prefix')\n\n    if not parsed_url.netloc:\n        raise ValueError('Links must include a domain name')\n\n    return parsed_url.geturl()\n\n\ndef validate_orcid(orcid):\n    \"\"\"\n    Validate an ORCID identifier.\n\n    Verify that an ORCID identifier conforms to the structure described at\n    http://support.orcid.org/knowledgebase/articles/116780-structure-of-the-orcid-identifier\n\n    Returns the normalized ORCID if successfully parsed or raises a ValueError\n    otherwise.\n    \"\"\"\n    ORCID_REGEX = '\\A[0-9]{4}-[0-9]{4}-[0-9]{4}-[0-9]{3}[0-9X]\\Z'\n\n    if not re.match(ORCID_REGEX, orcid):\n        raise ValueError('The format of this ORCID is incorrect'.format(orcid))\n\n    if _orcid_checksum_digit(orcid[:-1]) != orcid[-1:]:\n        raise ValueError('{} is not a valid ORCID'.format(orcid))\n\n    return True\n\n\ndef _orcid_checksum_digit(orcid):\n    \"\"\"\n    Return the checksum digit for an ORCID identifier.\n\n    Translated from the example ISO 7064 checksum implementation at\n    http://support.orcid.org/knowledgebase/articles/116780-structure-of-the-orcid-identifier\n\n    :param orcid: ORCID ID consisting of hyphens and digits, assumed to be in\n                  the correct format.\n    \"\"\"\n    total = 0\n    digits = [int(ch) for ch in orcid.replace('-', '')]\n    for digit in digits:\n        total = (total + digit) * 2\n    remainder = total % 11\n    result = (12 - remainder) % 11\n\n    if result == 10:\n        return 'X'\n    else:\n        return str(result)\n"},{"size":1855,"relativepath":"h/accounts/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\nfrom itsdangerous import URLSafeTimedSerializer\n\nfrom h.security import derive_key\n\n\nclass Error(Exception):\n\n    \"\"\"Base class for this package's custom exception classes.\"\"\"\n\n    pass\n\n\nclass JSONError(Error):\n\n    \"\"\"Exception raised when there's a problem with a request's JSON body.\n\n    This is for pre-validation problems such as no JSON body, body cannot\n    be parsed as JSON, or top-level keys missing from the JSON.\n\n    \"\"\"\n\n    pass\n\n\ndef authenticated_user(request):\n    \"\"\"Return the authenticated user or None.\n\n    :rtype: h.models.User or None\n\n    \"\"\"\n    if request.authenticated_userid is None:\n        return None\n\n    user_service = request.find_service(name='user')\n    user = user_service.fetch(request.authenticated_userid)\n\n    return user\n\n\ndef includeme(config):\n    \"\"\"A local identity provider.\"\"\"\n\n    # Add a `request.authenticated_user` property.\n    #\n    # N.B. we use `property=True` and not `reify=True` here because it is\n    # important that responsibility for caching user lookups is left to the\n    # UserService and not duplicated here.\n    #\n    # This prevents retried requests (those that raise\n    # `transaction.interfaces.TransientError`) gaining access to a stale\n    # `User` instance.\n    config.add_request_method(authenticated_user, property=True)\n\n    config.register_service_factory('.services.user_service_factory',\n                                    name='user')\n    config.register_service_factory('.services.user_signup_service_factory',\n                                    name='user_signup')\n\n    config.include('.schemas')\n    config.include('.subscribers')\n\n    secret = config.registry.settings['secret_key']\n    derived = derive_key(secret, b'h.accounts')\n    serializer = URLSafeTimedSerializer(derived)\n    config.registry.password_reset_serializer = serializer\n"},{"size":627,"relativepath":"h/accounts/subscribers.py","filename":"subscribers.py","extension":".py","content":"# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom pyramid.events import subscriber\n\nfrom h.accounts import events\n\n\n@subscriber(events.LoginEvent)\ndef login(event):\n    event.request.stats.incr('auth.local.login')\n\n\n@subscriber(events.LogoutEvent)\ndef logout(event):\n    event.request.stats.incr('auth.local.logout')\n\n\n@subscriber(events.PasswordResetEvent)\ndef password_reset(event):\n    event.request.stats.incr('auth.local.reset_password')\n\n\n@subscriber(events.ActivationEvent)\ndef activation(event):\n    event.request.stats.incr('auth.local.activate')\n\n\ndef includeme(config):\n    config.scan(__name__)\n"},{"size":497,"relativepath":"h/accounts/events.py","filename":"events.py","extension":".py","content":"# -*- coding: utf-8 -*-\nclass ActivationEvent(object):\n    def __init__(self, request, user):\n        self.request = request\n        self.user = user\n\n\nclass LoginEvent(object):\n    def __init__(self, request, user):\n        self.request = request\n        self.user = user\n\n\nclass LogoutEvent(object):\n    def __init__(self, request):\n        self.request = request\n\n\nclass PasswordResetEvent(object):\n    def __init__(self, request, user):\n        self.request = request\n        self.user = user\n"},{"size":5898,"relativepath":"h/accounts/services.py","filename":"services.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom functools import partial\n\nimport sqlalchemy\n\nfrom h import mailer\nfrom h._compat import text_type\nfrom h.emails import signup\nfrom h.models import Activation, Subscriptions, User\n\n\nclass LoginError(Exception):\n    pass\n\n\nclass UserNotActivated(LoginError):\n    \"\"\"Tried to log in to an unactivated user account.\"\"\"\n\n\nclass UserNotKnown(LoginError):\n    \"\"\"User not found while attempting to log in.\"\"\"\n\n\nclass UserService(object):\n\n    \"\"\"A service for retrieving and performing common operations on users.\"\"\"\n\n    def __init__(self, default_authority, session):\n        \"\"\"\n        Create a new user service.\n\n        :param default_authority: the default authority for users\n        :param session: the SQLAlchemy session object\n        \"\"\"\n        self.default_authority = default_authority\n        self.session = session\n\n        # Local cache of fetched users.\n        self._cache = {}\n\n        # But don't allow the cache to persist after the session is closed.\n        @sqlalchemy.event.listens_for(session, 'after_commit')\n        @sqlalchemy.event.listens_for(session, 'after_rollback')\n        def flush_cache(session):\n            self._cache = {}\n\n    def fetch(self, userid):\n        \"\"\"\n        Fetch a user by userid, e.g. 'acct:foo@example.com'\n\n        :returns: a user instance, if found\n        :rtype: h.models.User or None\n        \"\"\"\n        if userid not in self._cache:\n            self._cache[userid] = (self.session.query(User)\n                                   .filter_by(userid=userid)\n                                   .one_or_none())\n\n        return self._cache[userid]\n\n    def login(self, username_or_email, password):\n        \"\"\"\n        Attempt to login using *username_or_email* and *password*.\n\n        :returns: A user object if login succeeded, None otherwise.\n        :rtype: h.models.User or NoneType\n        :raises UserNotActivated: When the user is not activated.\n        :raises UserNotKnown: When the user cannot be found in the default\n            authority.\n        \"\"\"\n        filters = {'authority': self.default_authority}\n        if '@' in username_or_email:\n            filters['email'] = username_or_email\n        else:\n            filters['username'] = username_or_email\n\n        user = (self.session.query(User)\n                .filter_by(**filters)\n                .one_or_none())\n\n        if user is None:\n            raise UserNotKnown()\n\n        if not user.is_activated:\n            raise UserNotActivated()\n\n        if user.check_password(password):\n            return user\n\n        return None\n\n\nclass UserSignupService(object):\n\n    \"\"\"A service for registering users.\"\"\"\n\n    def __init__(self,\n                 default_authority,\n                 mailer,\n                 session,\n                 signup_email,\n                 stats=None):\n        \"\"\"\n        Create a new user signup service.\n\n        :param default_authority: the default authority for new users\n        :param mailer: a mailer (such as :py:mod:`h.mailer`)\n        :param session: the SQLAlchemy session object\n        :param signup_email: a function for generating a signup email\n        :param stats: the stats service\n        \"\"\"\n        self.default_authority = default_authority\n        self.mailer = mailer\n        self.session = session\n        self.signup_email = signup_email\n        self.stats = stats\n\n    def signup(self, require_activation=True, **kwargs):\n        \"\"\"\n        Create a new user.\n\n        If *require_activation* is ``True``, the user will be flagged as\n        requiring activation and an activation email will be sent.\n\n        :param require_activation: The name to use.\n        :type require_activation: bool.\n\n        Remaining keyword arguments are passed to the\n        :py:class:`h.models.User` constructor.\n\n        :returns: the newly-created user object.\n        :rtype: h.models.User\n        \"\"\"\n        kwargs.setdefault('authority', self.default_authority)\n        user = User(**kwargs)\n        self.session.add(user)\n\n        # Create a new activation for the user\n        if require_activation:\n            self._require_activation(user)\n\n        # FIXME: this is horrible, but is needed until the\n        # notification/subscription system is made opt-out rather than opt-in\n        # (at least from the perspective of the database).\n        sub = Subscriptions(uri=user.userid, type='reply', active=True)\n        self.session.add(sub)\n\n        # Record a registration with the stats service\n        if self.stats is not None:\n            self.stats.incr('auth.local.register')\n\n        return user\n\n    def _require_activation(self, user):\n        activation = Activation()\n        self.session.add(activation)\n        user.activation = activation\n\n        # Flush the session to ensure that the user can be created and the\n        # activation is successfully wired up.\n        self.session.flush()\n\n        # Send the activation email\n        mail_params = self.signup_email(id=user.id,\n                                        email=user.email,\n                                        activation_code=user.activation.code)\n        self.mailer.send.delay(*mail_params)\n\n\ndef user_service_factory(context, request):\n    \"\"\"Return a UserService instance for the passed context and request.\"\"\"\n    return UserService(default_authority=text_type(request.auth_domain),\n                       session=request.db)\n\n\ndef user_signup_service_factory(context, request):\n    \"\"\"Return a UserSignupService instance for the passed context and request.\"\"\"\n    return UserSignupService(default_authority=text_type(request.auth_domain),\n                             mailer=mailer,\n                             session=request.db,\n                             signup_email=partial(signup.generate, request),\n                             stats=request.stats)\n"},{"size":2590,"relativepath":"h/accounts/blacklist","filename":"blacklist","extension":"","content":"-\nabout\naccess\naccount\naccounts\nactivity\nadd\naddress\nadm\nadmin\nadministration\nadministrator\nadult\nadvertising\naffiliate\naffiliates\najax\nall\nanalytics\nandroid\nannotatorjs\nannouncements\nanonymous\nanywhere\napi\napi_rules\napi_terms\napirules\napiterms\napp\napps\narchive\naside\nauth\nauthentication\nauthor\navatar\naward\nawards\nbackup\nbadges\nbanner\nbanners\nbilling\nbin\nbins\nblog\nblogs\nboard\nbookmark\nbookmarks\nbots\nbugs\nbusiness\ncache\ncalendar\ncampaign\ncareer\ncareers\ncgi\nchat\nclient\nclone\ncode\ncollection\ncollections\ncommercial\nconfig\nconnect\ncontact\ncontacts\ncontest\ncopyright\ncreate\ncss\ndashboard\ndata\ndb\ndelete\ndemo\ndesign\ndesigner\ndevel\ndevelopers\ndevices\ndir\ndirect\ndirectory\ndiscover\ndiscovery\ndocs\ndomain\ndonate\ndonor\ndonors\ndownloads\necommerce\nedit\neditor\nemail\nembed\nfacebook\nfaq\nfavorite\nfavorites\nfavourite\nfavourites\nfavs\nfeed\nfeedback\nfile\nfiles\nfinadmin\nfind\nfind_sources\nfind_users\nfollow\nfollowers\nfollowing\nfont\nfonts\nforum\nforums\nfree\nfriend\nfriend_request\nfriendrequest\nfriends\nftp\nfund\nget\ngist\ngoodies\ngoogle\ngpl\ngraph\ngraphs\ngreetings\ngroup\ngroups\nhead\nhelp\nhistory\nhome\nhomepage\nhooks\nhost\nhosting\nhostname\nhtml\nhttp\nhttpd\nhttps\nimage\nimages\nimap\nimg\ninbox\nindex\nindices\ninfo\ninformation\nintranet\ninvitation\ninvitations\ninvite\nipad\niphone\nirc\nissues\njob\njobs\njoin\njs\nkickstarter\nknowledgebase\nlast\nlegal\nlicense\nlink\nlinkedin\nlinks\nlist\nlists\nlog\nlogin\nlogout\nlogs\nmail\nmailchimp\nmailer\nmailing\nmake\nmanager\nmarketing\nmarks\nmaster\nme\nmedia\nmessage\nmessages\nmessenger\nmine\nmob\nmobile\nmsn\nmx\nmy\nname\nnamed\nnet\nnetwork\nnew\nnews\nnewsletter\nnickname\nnotes\nnotifications\nnudge\noauth\nold\nonline\nopen\noperator\noptions\norder\norders\nowner\npage\npager\npages\npanel\npartner\npartners\npassword\npayrollreports\npersonal\nphotos\npic\npics\nplugin\nplugins\npop\npop3\npositions\npost\npostfix\npostmaster\nposts\npress\nprivacy\nprivate\npro\nprocessor\nproduct\nprofile\nproject\nprojects\npromo\npub\npublic\nput\nreg\nregister\nregistration\nrelay\nreplies\nreply\nroot\nrss\nrules\nrunner\nsale\nsales\nsample\nsamples\nsave\nscript\nscripts\nsearch\nsecure\nsecurity\nsend\nsent\nservice\nsetting\nsettings\nsetup\nshare\nshop\nshow\nsignin\nsignup\nsimilar\nsite\nsitemap\nsites\nsmtp\nsources\nspam\nsql\nssh\nstage\nstaging\nstart\nstat\nstatistics\nstats\nstatus\nstore\nstores\nsubdomain\nsubscribe\nsupport\nsystem\ntalk\ntask\ntasks\nteam\ntech\ntelnet\nterms\ntest\ntests\ntheme\nthemes\ntmp\ntodo\ntools\ntos\ntranslate\ntrends\ntutorials\ntwitter\nunarchive\nupdate\nupgrade\nupload\nurl\nurls\nusage\nusername\nusers\nverify\nvideo\nvideos\nvisitor\nwatch\nweb\nwebmail\nwebmaster\nwebsite\nwebsites\nwelcome\nwho\nwhois\nwidget\nwidgets\nworkshop\nwww\nwwww\nyou\nyourdomain\nyourname\nyoursite\nyourusername\n"},{"size":13438,"relativepath":"h/accounts/schemas.py","filename":"schemas.py","extension":".py","content":"# -*- coding: utf-8 -*-\nfrom codecs import open\nimport logging\n\nimport colander\nimport deform\nfrom pyramid.session import check_csrf_token\nfrom itsdangerous import BadData, SignatureExpired\n\nfrom h import i18n, models, validators\nfrom h.accounts import util\nfrom h.accounts.services import UserNotActivated, UserNotKnown\nfrom h.models.user import (\n    EMAIL_MAX_LENGTH,\n    PASSWORD_MIN_LENGTH,\n    USERNAME_MAX_LENGTH,\n    USERNAME_MIN_LENGTH,\n    USERNAME_PATTERN,\n)\n\n_ = i18n.TranslationString\nlog = logging.getLogger(__name__)\n\nUSERNAME_BLACKLIST = None\n\n\n@colander.deferred\ndef deferred_csrf_token(node, kw):\n    request = kw.get('request')\n    return request.session.get_csrf_token()\n\n\ndef get_blacklist():\n    global USERNAME_BLACKLIST\n    if USERNAME_BLACKLIST is None:\n        # Try to load the blacklist file from disk. If, for whatever reason, we\n        # can't load the file, then don't crash out, just log a warning about\n        # the problem.\n        try:\n            with open('h/accounts/blacklist', encoding='utf-8') as fp:\n                blacklist = fp.readlines()\n        except (IOError, ValueError):\n            log.exception('unable to load blacklist')\n            blacklist = []\n        USERNAME_BLACKLIST = set(l.strip().lower() for l in blacklist)\n    return USERNAME_BLACKLIST\n\n\ndef unique_email(node, value):\n    '''Colander validator that ensures no user with this email exists.'''\n    request = node.bindings['request']\n    user = models.User.get_by_email(request.db, value)\n    if user and user.userid != request.authenticated_userid:\n        msg = _(\"Sorry, an account with this email address already exists.\")\n        raise colander.Invalid(node, msg)\n\n\ndef unique_username(node, value):\n    '''Colander validator that ensures the username does not exist.'''\n    request = node.bindings['request']\n    user = models.User.get_by_username(request.db, value)\n    if user:\n        msg = _(\"This username is already taken.\")\n        raise colander.Invalid(node, msg)\n\n\ndef email_node(**kwargs):\n    \"\"\"Return a Colander schema node for a new user email.\"\"\"\n    return colander.SchemaNode(\n        colander.String(),\n        validator=colander.All(\n            validators.Length(max=EMAIL_MAX_LENGTH),\n            validators.Email(),\n            unique_email,\n        ),\n        widget=deform.widget.TextInputWidget(template='emailinput'),\n        **kwargs)\n\n\ndef unblacklisted_username(node, value, blacklist=None):\n    '''Colander validator that ensures the username is not blacklisted.'''\n    if blacklist is None:\n        blacklist = get_blacklist()\n    if value.lower() in blacklist:\n        # We raise a generic \"user with this name already exists\" error so as\n        # not to make explicit the presence of a blacklist.\n        msg = _(\"Sorry, an account with this username already exists. \"\n                \"Please enter another one.\")\n        raise colander.Invalid(node, msg)\n\n\ndef password_node(**kwargs):\n    \"\"\"Return a Colander schema node for an existing user password.\"\"\"\n    kwargs.setdefault('widget', deform.widget.PasswordWidget())\n    return colander.SchemaNode(\n        colander.String(),\n        **kwargs)\n\n\ndef new_password_node(**kwargs):\n    \"\"\"Return a Colander schema node for a new user password.\"\"\"\n    kwargs.setdefault('widget', deform.widget.PasswordWidget())\n    return colander.SchemaNode(\n        colander.String(),\n        validator=validators.Length(min=PASSWORD_MIN_LENGTH),\n        **kwargs)\n\n\nclass CSRFSchema(colander.Schema):\n    \"\"\"\n    A CSRFSchema backward-compatible with the one from the hem module.\n\n    Unlike hem, this doesn't require that the csrf_token appear in the\n    serialized appstruct.\n    \"\"\"\n\n    csrf_token = colander.SchemaNode(colander.String(),\n                                     widget=deform.widget.HiddenWidget(),\n                                     default=deferred_csrf_token,\n                                     missing=None)\n\n    def validator(self, form, value):\n        request = form.bindings['request']\n        check_csrf_token(request)\n\n\nclass LoginSchema(CSRFSchema):\n    username = colander.SchemaNode(\n        colander.String(),\n        title=_('Username / email'),\n        widget=deform.widget.TextInputWidget(autofocus=True),\n    )\n    password = colander.SchemaNode(\n        colander.String(),\n        title=_('Password'),\n        widget=deform.widget.PasswordWidget()\n    )\n\n    def validator(self, node, value):\n        super(LoginSchema, self).validator(node, value)\n\n        request = node.bindings['request']\n        username = value.get('username')\n        password = value.get('password')\n\n        user_service = request.find_service(name='user')\n\n        try:\n            user = user_service.login(username_or_email=username,\n                                      password=password)\n        except UserNotKnown:\n            err = colander.Invalid(node)\n            err['username'] = _('User does not exist.')\n            raise err\n        except UserNotActivated:\n            err = colander.Invalid(node)\n            err['username'] = _(\"Please check your email and open the link \"\n                                \"to activate your account.\")\n            raise err\n\n        if user is None:\n            err = colander.Invalid(node)\n            err['password'] = _('Wrong password.')\n            raise err\n\n        value['user'] = user\n\n\nclass ForgotPasswordSchema(CSRFSchema):\n    email = colander.SchemaNode(\n        colander.String(),\n        validator=colander.All(validators.Email()),\n        title=_('Email address'),\n        widget=deform.widget.TextInputWidget(template='emailinput',\n                                             autofocus=True),\n    )\n\n    def validator(self, node, value):\n        super(ForgotPasswordSchema, self).validator(node, value)\n\n        request = node.bindings['request']\n        email = value.get('email')\n        user = models.User.get_by_email(request.db, email)\n\n        if user is None:\n            err = colander.Invalid(node)\n            err['email'] = _('Unknown email address.')\n            raise err\n\n        value['user'] = user\n\n\nclass RegisterSchema(CSRFSchema):\n    username = colander.SchemaNode(\n        colander.String(),\n        validator=colander.All(\n            validators.Length(min=USERNAME_MIN_LENGTH,\n                              max=USERNAME_MAX_LENGTH),\n            colander.Regex(\n                USERNAME_PATTERN,\n                msg=_(\"Must have only letters, numbers, periods, and \"\n                      \"underscores.\")),\n            unique_username,\n            unblacklisted_username,\n        ),\n        title=_('Username'),\n        hint=_('Must be between {min} and {max} characters, containing only '\n               'letters, numbers, periods, and underscores.').format(\n            min=USERNAME_MIN_LENGTH,\n            max=USERNAME_MAX_LENGTH\n        ),\n        widget=deform.widget.TextInputWidget(autofocus=True),\n    )\n    email = email_node(title=_('Email address'))\n    password = new_password_node(title=_('Password'))\n\n\nclass ResetCode(colander.SchemaType):\n\n    \"\"\"Schema type transforming a reset code to a user and back.\"\"\"\n\n    def serialize(self, node, appstruct):\n        if appstruct is colander.null:\n            return colander.null\n        if not isinstance(appstruct, models.User):\n            raise colander.Invalid(node, '%r is not a User' % appstruct)\n        request = node.bindings['request']\n        serializer = request.registry.password_reset_serializer\n        return serializer.dumps(appstruct.username)\n\n    def deserialize(self, node, cstruct):\n        if cstruct is colander.null:\n            return colander.null\n\n        request = node.bindings['request']\n        serializer = request.registry.password_reset_serializer\n\n        try:\n            (username, timestamp) = serializer.loads(cstruct,\n                                                     max_age=72*3600,\n                                                     return_timestamp=True)\n        except SignatureExpired:\n            raise colander.Invalid(node, _('Reset code has expired. Please reset your password again'))\n        except BadData:\n            raise colander.Invalid(node, _('Wrong reset code.'))\n\n        user = models.User.get_by_username(request.db, username)\n        if user is None:\n            raise colander.Invalid(node, _('Your reset code is not valid'))\n        if user.password_updated is not None and timestamp < user.password_updated:\n            raise colander.Invalid(node,\n                                   _('This reset code has already been used.'))\n        return user\n\n\nclass ResetPasswordSchema(CSRFSchema):\n    # N.B. this is the field into which the user puts their reset code, but we\n    # call it `user` because when validated, it will return a `User` object.\n    user = colander.SchemaNode(\n        ResetCode(),\n        title=_('Reset code'),\n        hint=_('This will be emailed to you.'),\n        widget=deform.widget.TextInputWidget(disable_autocomplete=True))\n    password = new_password_node(\n        title=_('New password'),\n        widget=deform.widget.PasswordWidget(disable_autocomplete=True))\n\n\nclass LegacyEmailChangeSchema(CSRFSchema):\n    email = email_node(title=_('New email address'))\n    # No validators: all validation is done on the email field and we merely\n    # assert that the confirmation field is the same.\n    email_confirm = colander.SchemaNode(\n        colander.String(),\n        title=_('Confirm new email address'),\n        widget=deform.widget.TextInputWidget(template='emailinput'))\n    password = new_password_node(title=_('Current password'))\n\n    def validator(self, node, value):\n        super(LegacyEmailChangeSchema, self).validator(node, value)\n        exc = colander.Invalid(node)\n        request = node.bindings['request']\n        user = request.authenticated_user\n\n        if value.get('email') != value.get('email_confirm'):\n            exc['email_confirm'] = _('The emails must match')\n\n        if not user.check_password(value.get('password')):\n            exc['password'] = _('Wrong password.')\n\n        if exc.children:\n            raise exc\n\n\nclass EmailChangeSchema(CSRFSchema):\n    email = email_node(title=_('Email address'))\n    # No validators: all validation is done on the email field\n    password = password_node(title=_('Confirm password'))\n\n    def validator(self, node, value):\n        super(EmailChangeSchema, self).validator(node, value)\n        exc = colander.Invalid(node)\n        request = node.bindings['request']\n        user = request.authenticated_user\n\n        if not user.check_password(value.get('password')):\n            exc['password'] = _('Wrong password.')\n\n        if exc.children:\n            raise exc\n\n\nclass PasswordChangeSchema(CSRFSchema):\n    password = password_node(title=_('Current password'))\n    new_password = password_node(title=_('New password'))\n    # No validators: all validation is done on the new_password field and we\n    # merely assert that the confirmation field is the same.\n    new_password_confirm = colander.SchemaNode(\n        colander.String(),\n        title=_('Confirm new password'),\n        widget=deform.widget.PasswordWidget())\n\n    def validator(self, node, value):\n        super(PasswordChangeSchema, self).validator(node, value)\n        exc = colander.Invalid(node)\n        request = node.bindings['request']\n        user = request.authenticated_user\n\n        if value.get('new_password') != value.get('new_password_confirm'):\n            exc['new_password_confirm'] = _('The passwords must match')\n\n        if not user.check_password(value.get('password')):\n            exc['password'] = _('Wrong password.')\n\n        if exc.children:\n            raise exc\n\n\ndef validate_url(node, cstruct):\n    try:\n        util.validate_url(cstruct)\n    except ValueError as exc:\n        raise colander.Invalid(node, str(exc))\n\n\ndef validate_orcid(node, cstruct):\n    try:\n        util.validate_orcid(cstruct)\n    except ValueError as exc:\n        raise colander.Invalid(node, str(exc))\n\n\nclass EditProfileSchema(CSRFSchema):\n    display_name = colander.SchemaNode(\n        colander.String(),\n        missing=None,\n        validator=validators.Length(max=30),\n        title=_('Display name'))\n\n    description = colander.SchemaNode(\n        colander.String(),\n        missing=None,\n        validator=validators.Length(max=250),\n        widget=deform.widget.TextAreaWidget(\n            max_length=250,\n            rows=4,\n        ),\n        title=_('Description'))\n\n    location = colander.SchemaNode(\n        colander.String(),\n        missing=None,\n        validator=validators.Length(max=100),\n        title=_('Location'))\n\n    link = colander.SchemaNode(\n        colander.String(),\n        missing=None,\n        validator=colander.All(\n            validators.Length(max=250),\n            validate_url),\n        title=_('Link'))\n\n    orcid = colander.SchemaNode(\n        colander.String(),\n        missing=None,\n        validator=validate_orcid,\n        title=_('ORCID'),\n        hint=_('ORCID provides a persistent identifier for researchers (see orcid.org).'))\n\n\nclass NotificationsSchema(CSRFSchema):\n    types = (('reply', _('Email me when someone replies to one of my annotations.'),),)\n\n    notifications = colander.SchemaNode(\n        colander.Set(),\n        widget=deform.widget.CheckboxChoiceWidget(\n            omit_label=True,\n            values=types),\n    )\n\n\ndef includeme(config):\n    pass\n"},{"size":1644,"relativepath":"h/links.py","filename":"links.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"\nProvides links to different representations of annotations.\n\"\"\"\n\n\nfrom h._compat import urlparse\n\n\ndef html_link(request, annotation):\n    \"\"\"Generate a link to an HTML representation of an annotation.\"\"\"\n    return request.route_url('annotation', id=annotation.id)\n\n\ndef incontext_link(request, annotation):\n    \"\"\"Generate a link to an annotation on the page where it was made.\"\"\"\n    bouncer_url = request.registry.settings.get('h.bouncer_url')\n    if not bouncer_url:\n        return None\n\n    link = urlparse.urljoin(bouncer_url, annotation.thread_root_id)\n    uri = annotation.target_uri\n    if uri.startswith(('http://', 'https://')):\n        # We can't use urljoin here, because if it detects the second argument\n        # is a URL it will discard the base URL, breaking the link entirely.\n        link += '/' + uri[uri.index('://')+3:]\n    elif uri.startswith('urn:x-pdf:') and annotation.document:\n        for docuri in annotation.document.document_uris:\n            uri = docuri.uri\n            if uri.startswith(('http://', 'https://')):\n                link += '/' + uri[uri.index('://')+3:]\n                break\n\n    return link\n\n\ndef includeme(config):\n    # Add an annotation link generator for the `annotation` view -- this adds a\n    # named link called \"html\" to API rendered views of annotations. See\n    # :py:mod:`memex.presenters` for details.\n    config.add_annotation_link_generator('html', html_link)\n\n    # Add an annotation link generator for viewing annotations in context on\n    # the page on which they were made.\n    config.add_annotation_link_generator('incontext', incontext_link)\n"},{"size":340,"relativepath":"h/notification/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\nfrom webob.cookies import SignedSerializer\n\nfrom ..security import derive_key\n\n\ndef includeme(config):\n    config.include('.reply')\n\n    secret = config.registry.settings['secret_key']\n    derived = derive_key(secret, b'h.notification')\n\n    config.registry.notification_serializer = SignedSerializer(derived, None)\n"},{"size":3665,"relativepath":"h/notification/reply.py","filename":"reply.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom collections import namedtuple\nimport logging\n\nfrom memex import storage\nfrom h.models import Subscriptions\n\nlog = logging.getLogger(__name__)\n\n\nclass Notification(namedtuple('Notification', [\n    'reply',\n    'reply_user',\n    'parent',\n    'parent_user',\n    'document',\n])):\n    \"\"\"\n    A data structure representing a notification of a reply to an annotation.\n\n    :param reply: the reply annotation\n    :type reply: h.models.Annotation (or memex.models.elastic.Annotation)\n    :param reply_user: the user who made the reply annotation\n    :type reply_user: h.models.User\n    :param parent: the annotation being replied to\n    :type parent: h.models.Annotation (or memex.models.elastic.Annotation)\n    :param parent_user: the user being replied to\n    :type parent_user: h.models.User\n    :param document: the document for the page on which the reply happened\n    :type document: h.models.Document (or memex.models.elastic.Document)\n    \"\"\"\n\n\ndef get_notification(request, annotation, action):\n    \"\"\"\n    Check if the passed annotation and action pair should send a notification.\n\n    Checks to see if the annotation event represented by the passed annotation\n    and action should trigger a notification. If it should, this function\n    returns the relevant :py:class:`~h.notification.reply.Notification` object.\n    Otherwise, it returns None.\n\n    :param request: the current request object\n    :type request: pyramid.request.Request\n    :param annotation: the reply annotation\n    :type annotation: memex.models.elastic.Annotation or h.models.Annotation\n    :param action: the event action\n    :type action: str\n\n    :returns: a :py:class:`~h.notification.reply.Notification`, or None\n    \"\"\"\n    # Only send notifications when new annotations are created\n    if action != 'create':\n        return\n\n    # If the annotation doesn't have a parent, or we can't find its parent,\n    # then we can't send a notification email.\n    parent_id = annotation.parent_id\n    if parent_id is None:\n        return\n\n    # Now we know we're dealing with a reply\n    reply = annotation\n\n    parent = storage.fetch_annotation(request.db, parent_id)\n    if parent is None:\n        return\n\n    user_service = request.find_service(name='user')\n\n    # If the parent user doesn't exist (anymore), we can't send an email.\n    parent_user = user_service.fetch(parent.userid)\n    if parent_user is None:\n        return\n\n    # If the reply user doesn't exist (anymore), we can't send an email, but\n    # this would be super weird, so log a warning.\n    reply_user = user_service.fetch(reply.userid)\n    if reply_user is None:\n        log.warn('user who just replied no longer exists: %s', reply.userid)\n        return\n\n    # Do not notify users about their own replies\n    if parent_user == reply_user:\n        return\n\n    # Don't send reply notifications to the author of the parent annotation if\n    # the reply was private.\n    if not reply.shared:\n        return\n\n    # FIXME: we should be retrieving the document from the root annotation, not\n    # the reply, and dealing with the possibility that we have no document\n    # metadata.\n    if reply.document is None:\n        return\n\n    # Bail if there is no active 'reply' subscription for the user being\n    # replied to.\n    sub = request.db.query(Subscriptions).filter_by(active=True,\n                                                    type='reply',\n                                                    uri=parent.userid).first()\n    if sub is None:\n        return\n\n    return Notification(reply, reply_user, parent, parent_user, reply.document)\n\n\ndef includeme(config):\n    config.scan(__name__)\n"},{"size":2281,"relativepath":"h/cli/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\nfrom __future__ import print_function\n\nimport functools\nimport logging\nimport os\n\nimport click\nfrom pyramid import paster\nfrom pyramid import path\nfrom pyramid.request import Request\n\nfrom h import __version__\n\nlog = logging.getLogger('h')\n\nSUBCOMMANDS = (\n    'h.cli.commands.celery.celery',\n    'h.cli.commands.devserver.devserver',\n    'h.cli.commands.initdb.initdb',\n    'h.cli.commands.migrate.migrate',\n    'h.cli.commands.move_uri.move_uri',\n    'h.cli.commands.normalize_uris.normalize_uris',\n    'h.cli.commands.reindex.reindex',\n    'h.cli.commands.shell.shell',\n    'h.cli.commands.user.user',\n)\n\n\ndef bootstrap(app_url, dev=False):\n    \"\"\"\n    Bootstrap the application from the given arguments.\n\n    Returns a bootstrapped request object.\n    \"\"\"\n    # Set a flag in the environment that other code can use to detect if it's\n    # running in a script rather than a full web application.\n    #\n    # FIXME: This is a nasty hack and should go when we no longer need to spin\n    # up an entire application to build the extensions.\n    os.environ['H_SCRIPT'] = 'true'\n\n    # In development, we will happily provide a default APP_URL, but it must be\n    # set in production mode.\n    if not app_url:\n        if dev:\n            app_url = 'http://localhost:5000'\n        else:\n            raise click.ClickException('the app URL must be set in production mode!')\n\n    config = 'conf/development-app.ini' if dev else 'conf/app.ini'\n\n    paster.setup_logging(config)\n    request = Request.blank('/', base_url=app_url)\n    env = paster.bootstrap(config, request=request)\n    request.root = env['root']\n    return request\n\n\n@click.group()\n@click.option('--app-url',\n              help=\"The base URL for the application\",\n              envvar='APP_URL',\n              metavar='URL')\n@click.option('--dev',\n              help=\"Use defaults suitable for development?\",\n              default=False,\n              is_flag=True)\n@click.version_option(version=__version__)\n@click.pass_context\ndef cli(ctx, app_url, dev):\n    ctx.obj['bootstrap'] = functools.partial(bootstrap, app_url, dev)\n\n\ndef main():\n    resolver = path.DottedNameResolver()\n    for cmd in SUBCOMMANDS:\n        cli.add_command(resolver.resolve(cmd))\n    cli(prog_name='hypothesis', obj={})\n"},{"size":1706,"relativepath":"h/cli/commands/migrate.py","filename":"migrate.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport argparse\n\nimport click\nfrom alembic.config import CommandLine as _CommandLine\nfrom alembic.config import Config\n\n\nclass CommandLine(_CommandLine):\n\n    \"\"\"\n    A modified version of the default Alembic CommandLine.\n\n    This class suppresses the -c/--config option from the help, and defaults it\n    to a specified config file.\n    \"\"\"\n\n    def __init__(self, file_, prog=None):\n        self.file_ = file_\n\n        super(CommandLine, self).__init__(prog=prog)\n\n        # This is super sneaky. Grab the config option and suppress its help.\n        conf = None\n        for a in self.parser._actions:\n            if '--config' in a.option_strings:\n                conf = a\n                break\n        if conf:\n            conf.help = argparse.SUPPRESS\n\n    def main(self, argv=None):\n        options = self.parser.parse_args(argv)\n        if not hasattr(options, \"cmd\"):\n            # see http://bugs.python.org/issue9253, argparse\n            # behavior changed incompatibly in py3.3\n            self.parser.error(\"too few arguments\")\n        else:\n            cfg = Config(file_=self.file_,\n                         ini_section=options.name, cmd_opts=options)\n            self.run_cmd(cfg, options)\n\n\n@click.command(add_help_option=False,  # --help is passed through to Alembic\n               context_settings={'allow_extra_args': True,\n                                 'ignore_unknown_options': True})\n@click.pass_context\ndef migrate(ctx):\n    \"\"\"\n    Run Alembic (database migration) commands.\n\n    This command gives preconfigured access to the full Alembic CLI.\n    \"\"\"\n    cli = CommandLine(file_='conf/alembic.ini', prog=ctx.command_path)\n    cli.main(argv=ctx.args)\n"},{"size":318,"relativepath":"h/cli/commands/reindex.py","filename":"reindex.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport click\n\nfrom memex.search import index\n\n\n@click.command()\n@click.pass_context\ndef reindex(ctx):\n    \"\"\"\n    Reindex all annotations from the PostgreSQL database to the Elasticsearch index.\n    \"\"\"\n\n    request = ctx.obj['bootstrap']()\n\n    index.reindex(request.db, request.es, request)\n"},{"size":4355,"relativepath":"h/cli/commands/normalize_uris.py","filename":"normalize_uris.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom collections import namedtuple\nimport click\n\nfrom memex import models\nfrom memex import uri\nfrom memex.search import index\n\n\nclass Window(namedtuple('Window', ['start', 'end'])):\n    pass\n\n\n@click.command('normalize-uris')\n@click.pass_context\ndef normalize_uris(ctx):\n    \"\"\"\n    Normalize all URIs in the database and reindex the changed annotations.\n    \"\"\"\n\n    request = ctx.obj['bootstrap']()\n\n    normalize_document_uris(request)\n    normalize_document_meta(request)\n    normalize_annotations(request)\n\n\ndef normalize_document_uris(request):\n    windows = _fetch_windows(request.db, models.DocumentURI.updated)\n    request.tm.commit()\n\n    for window in windows:\n        request.tm.begin()\n        _normalize_document_uris_window(request.db, window)\n        request.tm.commit()\n\n\ndef normalize_document_meta(request):\n    windows = _fetch_windows(request.db, models.DocumentMeta.updated)\n    request.tm.commit()\n\n    for window in windows:\n        request.tm.begin()\n        _normalize_document_meta_window(request.db, window)\n        request.tm.commit()\n\n\ndef normalize_annotations(request):\n    windows = _fetch_windows(request.db, models.Annotation.updated)\n    request.tm.commit()\n\n    for window in windows:\n        request.tm.begin()\n        ids = _normalize_annotations_window(request.db, window)\n        request.tm.commit()\n\n        request.tm.begin()\n        _reindex_annotations(request, ids)\n        request.tm.commit()\n\n\ndef _normalize_document_uris_window(session, window):\n    query = session.query(models.DocumentURI) \\\n        .filter(models.DocumentURI.updated.between(window.start, window.end)) \\\n        .order_by(models.DocumentURI.updated.asc())\n\n    for docuri in query:\n        documents = models.Document.find_by_uris(session, [docuri.uri])\n        if documents.count() > 1:\n            models.merge_documents(session, documents)\n\n        existing = session.query(models.DocumentURI).filter(\n            models.DocumentURI.id != docuri.id,\n            models.DocumentURI.document_id == docuri.document_id,\n            models.DocumentURI.claimant_normalized == uri.normalize(docuri.claimant),\n            models.DocumentURI.uri_normalized == uri.normalize(docuri.uri),\n            models.DocumentURI.type == docuri.type,\n            models.DocumentURI.content_type == docuri.content_type)\n\n        if existing.count() > 0:\n            session.delete(docuri)\n        else:\n            docuri._claimant_normalized = uri.normalize(docuri.claimant)\n            docuri._uri_normalized = uri.normalize(docuri.uri)\n\n        session.flush()\n\n\ndef _normalize_document_meta_window(session, window):\n    query = session.query(models.DocumentMeta) \\\n        .filter(models.DocumentMeta.updated.between(window.start, window.end)) \\\n        .order_by(models.DocumentMeta.updated.asc())\n\n    for docmeta in query:\n        existing = session.query(models.DocumentMeta).filter(\n            models.DocumentMeta.id != docmeta.id,\n            models.DocumentMeta.claimant_normalized == uri.normalize(docmeta.claimant),\n            models.DocumentMeta.type == docmeta.type)\n\n        if existing.count() > 0:\n            session.delete(docmeta)\n        else:\n            docmeta._claimant_normalized = uri.normalize(docmeta.claimant)\n\n        session.flush()\n\n\ndef _normalize_annotations_window(session, window):\n    query = session.query(models.Annotation) \\\n        .filter(models.Annotation.updated.between(window.start, window.end)) \\\n        .order_by(models.Annotation.updated.asc())\n\n    ids = set()\n    for a in query:\n        normalized = uri.normalize(a.target_uri)\n        if normalized != a.target_uri_normalized:\n            a._target_uri_normalized = normalized\n            ids.add(a.id)\n\n    return ids\n\n\ndef _reindex_annotations(request, ids):\n    indexer = index.BatchIndexer(request.db, request.es, request)\n\n    for _ in range(2):\n        ids = indexer.index(ids)\n        if not ids:\n            break\n\n\ndef _fetch_windows(session, column, chunksize=100):\n    updated = session.query(column). \\\n        execution_options(stream_results=True). \\\n        order_by(column.desc()).all()\n\n    count = len(updated)\n    windows = [Window(start=updated[min(x+chunksize, count)-1].updated,\n                      end=updated[x].updated)\n               for x in xrange(0, count, chunksize)]\n\n    return windows\n"},{"size":393,"relativepath":"h/cli/commands/initdb.py","filename":"initdb.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport os\n\nimport click\n\n\n@click.command()\n@click.pass_context\ndef initdb(ctx):\n    \"\"\"Create database tables and elasticsearch indices.\"\"\"\n    # Settings to autocreate database tables and indices\n    os.environ['MODEL_CREATE_ALL'] = 'true'\n    os.environ['SEARCH_AUTOCONFIG'] = 'true'\n\n    # Start the application\n    bootstrap = ctx.obj['bootstrap']\n    bootstrap()\n"},{"size":547,"relativepath":"h/cli/commands/celery.py","filename":"celery.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport click\n\nfrom h.celery import start\n\n\n@click.command(add_help_option=False,  # --help is passed through to Celery\n               context_settings={'allow_extra_args': True,\n                                 'ignore_unknown_options': True})\n@click.pass_context\ndef celery(ctx):\n    \"\"\"\n    Run Celery commands.\n\n    This command delegates to the celery-worker command, giving access to the\n    full Celery CLI.\n    \"\"\"\n    argv = [ctx.command_path] + list(ctx.args)\n    start(argv=argv, bootstrap=ctx.obj['bootstrap'])\n"},{"size":1752,"relativepath":"h/cli/commands/shell.py","filename":"shell.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"Command to run an interactive shell with application context.\"\"\"\n\nimport click\n\nBANNER = \"\"\"Environment:\n  m, models    The `h.models` module.\n  registry     Active Pyramid registry.\n  request      Active request object.\n  session      Active database session.\n\"\"\"\n\n\ndef autodetect():\n    try:\n        import bpython  # noqa\n        return \"bpython\"\n    except ImportError:\n        try:\n            import IPython  # noqa\n            return \"ipython\"\n        except ImportError:\n            pass\n\n    return \"plain\"\n\n\ndef bpython(**locals_):\n    import bpython\n    bpython.embed(locals_, banner=BANNER)\n\n\ndef ipython(**locals_):\n    from IPython import start_ipython\n    from traitlets.config import get_config\n    c = get_config()\n    c.TerminalInteractiveShell.banner2 = BANNER\n    start_ipython(argv=[], config=c, user_ns=locals_)\n\n\ndef plain(**locals_):\n    import code\n    code.interact(banner=BANNER, local=locals_)\n\n\n@click.command('shell')\n@click.option(\n    \"--type\", \"type_\",\n    type=click.Choice([\"bpython\", \"ipython\", \"plain\"]),\n    help=\"What type of shell to use, default will autodetect.\"\n)\n@click.pass_obj\ndef shell(config, type_):\n    \"\"\"Open a shell with the h application environment preconfigured.\"\"\"\n    if type_ is None:\n        type_ = autodetect()\n\n    runner = {\"bpython\": bpython, \"ipython\": ipython, \"plain\": plain}[type_]\n\n    from h import models\n\n    request = config['bootstrap']()\n    locals_ = {\n        'm': models,\n        'models': models,\n        'registry': request.registry,\n        'request': request,\n        'session': request.db,\n    }\n\n    try:\n        runner(**locals_)\n    except ImportError:\n        raise click.ClickException(\"The {!r} shell is not available.\".format(type_))\n"},{"size":3268,"relativepath":"h/cli/commands/devserver.py","filename":"devserver.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport os\nimport sys\n\nimport click\n\n\n@click.command()\n@click.option('--https',\n              envvar='USE_HTTPS',\n              default=False,\n              is_flag=True,\n              help='Serve HTTPS rather than plain HTTP.')\n@click.option('--web/--no-web',\n              default=True,\n              help=\"Whether or not to run the Pyramid app process \"\n                   \"(default: --web).\")\n@click.option('--ws/--no-ws',\n              default=True,\n              help=\"Whether or not to run the WebSocket process \"\n                   \"(default: --ws).\")\n@click.option('--worker/--no-worker',\n              default=True,\n              help=\"Whether or not to run the Celery worker process \"\n                   \"(default: --worker).\")\n@click.option('--assets/--no-assets',\n              default=True,\n              help=\"Whether or not to run the gulp watch process \"\n                   \"(default: --assets).\")\n@click.option('--beat/--no-beat',\n              default=True,\n              help=\"Wheter or not to run the celery beat process \"\n                   \"(default: --beat).\")\ndef devserver(https, web, ws, worker, assets, beat):\n    \"\"\"\n    Run a development server.\n\n    This command will start a development instance of h, consisting of a web\n    application, Celery worker, and websocket server. It will also start a\n    process which will watch and build the frontend assets.\n\n    By default, the webserver will be accessible at:\n\n        http://localhost:5000\n\n    You can also pass the `--https` flag, which will look for a TLS certificate\n    and key in PEM format in the current directory, in files called:\n\n        .tlscert.pem\n        .tlskey.pem\n\n    If you use this flag, the webserver will be accessible at:\n\n        https://localhost:5000\n\n    If you wish this to be the default behaviour, you can set the\n    USE_HTTPS environment variable.\n    \"\"\"\n    try:\n        from honcho.manager import Manager\n    except ImportError:\n        raise click.ClickException('cannot import honcho: did you run `pip install -r requirements-dev.in` yet?')\n\n    os.environ['PYTHONUNBUFFERED'] = 'true'\n    if https:\n        gunicorn_args = '--certfile=.tlscert.pem --keyfile=.tlskey.pem'\n        os.environ['APP_URL'] = 'https://localhost:5000'\n        os.environ['WEBSOCKET_URL'] = 'wss://localhost:5001/ws'\n        os.environ['ALLOWED_ORIGINS'] = ' '.join(\n            ['https://localhost:5000', os.environ.get('ALLOWED_ORIGINS', '')])\n    else:\n        gunicorn_args = ''\n        os.environ['APP_URL'] = 'http://localhost:5000'\n        os.environ['WEBSOCKET_URL'] = 'ws://localhost:5001/ws'\n\n    m = Manager()\n    if web:\n        m.add_process('web',\n                      'MODEL_CREATE_ALL=true '\n                      'SEARCH_AUTOCONFIG=true '\n                      'gunicorn --reload --paste conf/development-app.ini %s' % gunicorn_args)\n\n    if ws:\n        m.add_process('ws', 'gunicorn --reload --paste conf/development-websocket.ini %s' % gunicorn_args)\n\n    if worker:\n        m.add_process('worker', 'hypothesis --dev celery worker --autoreload')\n\n    if beat:\n        m.add_process('beat', 'hypothesis --dev celery beat')\n\n    if assets:\n        m.add_process('assets', 'gulp watch')\n\n    m.loop()\n\n    sys.exit(m.returncode)\n"},{"size":1768,"relativepath":"h/cli/commands/user.py","filename":"user.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport click\nimport sqlalchemy\n\nfrom h import models\n\n\n@click.group()\ndef user():\n    \"\"\"Manage users.\"\"\"\n\n\n@user.command()\n@click.option('--username', prompt=True)\n@click.option('--email', prompt=True)\n@click.password_option()\n@click.pass_context\ndef add(ctx, username, email, password):\n    \"\"\"Create a new user.\"\"\"\n    request = ctx.obj['bootstrap']()\n\n    signup_service = request.find_service(name='user_signup')\n\n    user = signup_service.signup(username=username,\n                                 email=email,\n                                 password=password)\n    user.activate()\n\n    try:\n        request.tm.commit()\n    except sqlalchemy.exc.IntegrityError as err:\n        upstream_error = '\\n'.join('    ' + line\n                                   for line in err.message.split('\\n'))\n        message = ('could not create user due to integrity constraint.\\n\\n{}'\n                   .format(upstream_error))\n        raise click.ClickException(message)\n\n    click.echo(\"{username} created\".format(username=username), err=True)\n\n\n@user.command()\n@click.argument('username')\n@click.option('--on/--off', default=True)\n@click.pass_context\ndef admin(ctx, username, on):\n    \"\"\"\n    Make a user an admin.\n\n    You must specify the username of a user which you wish to give\n    administrative privileges.\n    \"\"\"\n    request = ctx.obj['bootstrap']()\n    user = models.User.get_by_username(request.db, username)\n    if user is None:\n        raise click.ClickException('no user with username \"{}\"'.format(username))\n\n    user.admin = on\n    request.tm.commit()\n\n    click.echo(\"{username} is now {status}an administrator\"\n               .format(username=username,\n                       status='' if on else 'NOT '),\n               err=True)\n"},{"size":2952,"relativepath":"h/cli/commands/move_uri.py","filename":"move_uri.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport click\n\nfrom h import models\nfrom memex import uri\nfrom memex.search.index import BatchIndexer\nfrom memex.models import merge_documents\n\n\n@click.command('move-uri')\n@click.option('--old', required=True,\n              help='Old URI with annotations and documents.')\n@click.option('--new', required=True, confirmation_prompt=True,\n              help='New URI for matching annotations and documents.')\n@click.pass_context\ndef move_uri(ctx, old, new):\n    \"\"\"\n    Move annotations and document equivalence data from one URL to another.\n\n    This will **replace** the annotation's ``target_uri`` and all the\n    document uri's ``claimant``, plus the matching ``uri`` for self-claim and\n    canonical uris.\n    \"\"\"\n\n    request = ctx.obj['bootstrap']()\n\n    annotations = _fetch_annotations(request.db, old)\n    docuris_claimant = _fetch_document_uri_claimants(request.db, old)\n    docuris_uri = _fetch_document_uri_canonical_self_claim(request.db, old)\n\n    prompt = ('Changing all annotations and document data matching:\\n' +\n              '\"{old}\"\\nto:\\n\"{new}\"\\n' +\n              'This will affect {ann_count} annotations, {doc_claimant} ' +\n              'document uri claimants, and {doc_uri} document uri self-claims ' +\n              'or canonical uris.\\n' +\n              'Are you sure? [y/N]').format(old=old, new=new,\n                                            ann_count=len(annotations),\n                                            doc_claimant=len(docuris_claimant),\n                                            doc_uri=len(docuris_uri))\n    c = click.prompt(prompt, default='n', show_default=False)\n\n    if c != 'y':\n        print('Aborted')\n        return\n\n    for annotation in annotations:\n        annotation.target_uri = new\n\n    for docuri in docuris_claimant:\n        docuri.claimant = new\n\n    for docuri in docuris_uri:\n        docuri.uri = new\n\n    if annotations:\n        indexer = BatchIndexer(request.db, request.es, request)\n        ids = [a.id for a in annotations]\n        indexer.index(ids)\n\n    request.db.flush()\n\n    documents = models.Document.find_by_uris(request.db, [new])\n    if documents.count() > 1:\n        merge_documents(request.db, documents)\n\n    request.tm.commit()\n\n\ndef _fetch_annotations(session, uri_):\n    return session.query(models.Annotation).filter(\n        models.Annotation.target_uri_normalized == uri.normalize(uri_)).all()\n\n\ndef _fetch_document_uri_claimants(session, uri_):\n    return session.query(models.DocumentURI).filter(\n        models.DocumentURI.claimant_normalized == uri.normalize(uri_)).all()\n\n\ndef _fetch_document_uri_canonical_self_claim(session, uri_):\n    return session.query(models.DocumentURI).filter(\n        models.DocumentURI.uri_normalized == uri.normalize(uri_),\n        models.DocumentURI.type.in_([u'self-claim', u'rel-canonical'])).all()\n\n\ndef _fetch_documents(session, uri_):\n    return models.Document.find_by_uris(session, [uri_]).all()\n"},{"size":1081,"relativepath":"h/_compat.py","filename":"_compat.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"Helpers for the Python 2 to Python 3 transition.\"\"\"\n\nimport sys\n\n__all__ = (\n    'PY2',\n\n    'text_type',\n    'string_types',\n\n    'configparser',\n\n    'urlparse',\n    'url_quote',\n    'url_quote_plus',\n    'url_unquote',\n    'url_unquote_plus',\n\n    'StringIO',\n)\n\nPY2 = sys.version_info[0] == 2\n\nif not PY2:\n    text_type = str\n    string_types = (str,)\n    xrange = xrange\nelse:\n    text_type = unicode  # noqa\n    string_types = (str, unicode)  # noqa\n    xrange = range\n\ntry:\n    import ConfigParser as configparser\nexcept ImportError:\n    import configparser\n\ntry:\n    from urllib import parse as urlparse\n    url_quote = urlparse.quote\n    url_quote_plus = urlparse.quote_plus\n    url_unquote = urlparse.unquote\n    url_unquote_plus = urlparse.unquote_plus\nexcept ImportError:\n    import urllib\n    import urlparse\n    url_quote = urllib.quote\n    url_quote_plus = urllib.quote_plus\n    url_unquote = urllib.unquote\n    url_unquote_plus = urllib.unquote_plus\n\ntry:\n    from StringIO import StringIO\nexcept ImportError:\n    from io import StringIO\n"},{"size":1074,"relativepath":"h/renderers.py","filename":"renderers.py","extension":".py","content":"# -*- coding: utf-8 -*-\n# Taken from:\n# https://pyramid-cookbook.readthedocs.io/en/latest/templates/customrenderers.html\n# with minor modifications\nimport unicodecsv as csv\nfrom h._compat import StringIO\n\n\nclass CSV(object):\n    def __init__(self, info):\n        pass\n\n    def __call__(self, value, system):\n        \"\"\" Returns a plain CSV-encoded string with content-type\n        ``text/csv``. The content-type may be overridden by\n        setting ``request.response.content_type``.\"\"\"\n\n        request = system.get('request')\n        if request is not None:\n            response = request.response\n            ct = response.content_type\n            if ct == response.default_content_type:\n                response.content_type = 'text/csv'\n\n        fout = StringIO()\n        writer = csv.writer(fout,\n                            delimiter=',',\n                            quotechar=',',\n                            quoting=csv.QUOTE_MINIMAL)\n\n        writer.writerow(value.get('header', []))\n        writer.writerows(value.get('rows', []))\n\n        return fout.getvalue()\n"},{"size":5161,"relativepath":"h/realtime.py","filename":"realtime.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport base64\nimport random\nimport struct\nfrom datetime import datetime\n\nimport kombu\nfrom kombu.mixins import ConsumerMixin\nfrom kombu.pools import producers as producer_pool\n\n\nclass Consumer(ConsumerMixin):\n    \"\"\"\n    A realtime consumer that listens to the configured routing key and calls\n    the wrapped handler function on receiving a matching message.\n\n    Conforms to the :py:class:`kombu.mixins.ConsumerMixin` interface.\n\n    :param connection: a `kombe.Connection`\n    :param routing_key: listen to messages with this routing key\n    :param handler: the function which gets called when a messages arrives\n    :param sentry_client: an optional Sentry client for error reporting\n    \"\"\"\n\n    def __init__(self,\n                 connection,\n                 routing_key,\n                 handler,\n                 sentry_client=None,\n                 statsd_client=None):\n        self.connection = connection\n        self.routing_key = routing_key\n        self.handler = handler\n        self.exchange = get_exchange()\n        self.sentry_client = sentry_client\n        self.statsd_client = statsd_client\n\n    def get_consumers(self, consumer_factory, channel):\n        name = self.generate_queue_name()\n        queue = kombu.Queue(name, self.exchange,\n                            durable=False,\n                            routing_key=self.routing_key,\n                            auto_delete=True)\n        return [consumer_factory(queues=[queue], callbacks=[self.handle_message])]\n\n    def generate_queue_name(self):\n        return 'realtime-{}-{}'.format(self.routing_key, self._random_id())\n\n    def handle_message(self, body, message):\n        \"\"\"\n        Handles a realtime message by acknowledging it and then calling the\n        wrapped handler.\n        \"\"\"\n        if self.statsd_client:\n            self._record_time_in_queue(message)\n        message.ack()\n        self.handler(body)\n\n    def on_connection_error(self, exc, interval):\n        if self.sentry_client:\n            extra = {'exchange': self.exchange.name}\n            self.sentry_client.captureException(extra=extra)\n\n        super(Consumer, self).on_connection_error(exc, interval)\n\n    def on_decode_error(self, message, exc):\n        if self.sentry_client:\n            extra = {'exchange': self.exchange.name,\n                     'message_headers': message.headers,\n                     'message_properties': message.properties}\n            self.sentry_client.captureException(extra=extra)\n\n        super(Consumer, self).on_decode_error(message, exc)\n\n    def _random_id(self):\n        \"\"\"Generate a short random string\"\"\"\n        data = struct.pack('Q', random.getrandbits(64))\n        return base64.urlsafe_b64encode(data).strip(b'=')\n\n    def _record_time_in_queue(self, message):\n        \"\"\"Send a very rough estimate of time-in-queue to the stats client.\"\"\"\n        # N.B. This gives only a *rough approximation* of the time spent in the\n        # message queue. Using wall clocks like this is NOT going to be very\n        # accurate.\n        if 'timestamp' not in message.headers:\n            return\n\n        timestamp = datetime.strptime(message.headers['timestamp'],\n                                      '%Y-%m-%dT%H:%M:%S.%fZ')\n        delta = datetime.utcnow() - timestamp\n        delta_millis = int(delta.total_seconds() * 1000)\n\n        self.statsd_client.timing('streamer.msg.queueing', delta_millis)\n\n\nclass Publisher(object):\n    \"\"\"\n    A realtime publisher for publishing messages to all subscribers.\n\n    An instance of this publisher is available on Pyramid requests\n    with `request.realtime`.\n\n    :param request: a `pyramid.request.Request`\n    \"\"\"\n    def __init__(self, request):\n        self.connection = get_connection(request.registry.settings)\n        self.exchange = get_exchange()\n\n    def publish_annotation(self, payload):\n        \"\"\"Publish an annotation message with the routing key 'annotation'.\"\"\"\n        self._publish('annotation', payload)\n\n    def publish_user(self, payload):\n        \"\"\"Publish a user message with the routing key 'user'.\"\"\"\n        self._publish('user', payload)\n\n    def _publish(self, routing_key, payload):\n        headers = {'timestamp': datetime.utcnow().isoformat() + 'Z'}\n\n        with producer_pool[self.connection].acquire(block=True) as producer:\n            producer.publish(payload,\n                             exchange=self.exchange,\n                             declare=[self.exchange],\n                             routing_key=routing_key,\n                             headers=headers)\n\n\ndef get_exchange():\n    \"\"\"Returns a configures `kombu.Exchange` to use for realtime messages.\"\"\"\n\n    return kombu.Exchange('realtime',\n                          type='direct',\n                          durable=False,\n                          delivery_mode='transient')\n\n\ndef get_connection(settings):\n    \"\"\"Returns a `kombu.Connection` based on the application's settings.\"\"\"\n\n    conn = settings.get('broker_url', 'amqp://guest:guest@localhost:5672//')\n    return kombu.Connection(conn)\n\n\ndef includeme(config):\n    config.add_request_method(Publisher, name='realtime', reify=True)\n"},{"size":1239,"relativepath":"h/mailer.py","filename":"mailer.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"\nA module for sending email.\n\nThis module defines a Celery task for sending emails in a worker process.\n\"\"\"\n\nimport smtplib\n\nimport pyramid_mailer\nimport pyramid_mailer.message\n\nfrom h.celery import celery\n\n__all__ = ('send',)\n\n\n@celery.task(bind=True, max_retries=3)\ndef send(self, recipients, subject, body, html=None):\n    \"\"\"\n    Send an email.\n\n    :param recipients: the list of email addresses to send the email to\n    :type recipients: list of unicode strings\n\n    :param subject: the subject of the email\n    :type subject: unicode\n\n    :param body: the body of the email\n    :type body: unicode\n    \"\"\"\n    email = pyramid_mailer.message.Message(subject=subject,\n                                           recipients=recipients,\n                                           body=body,\n                                           html=html)\n    mailer = pyramid_mailer.get_mailer(celery.request)\n    try:\n        mailer.send_immediately(email)\n    except (smtplib.socket.error, smtplib.SMTPException) as exc:\n        # Exponential backoff in case the SMTP service is having problems.\n        countdown = self.default_retry_delay * 2 ** self.request.retries\n        self.retry(exc=exc, countdown=countdown)\n"},{"size":2902,"relativepath":"h/auth/util.py","filename":"util.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport base64\n\nfrom pyramid import security\n\nfrom h.auth import role\n\n\ndef basic_auth_creds(request):\n    \"\"\"\n    Extract any HTTP Basic authentication credentials for the request.\n\n    Returns a tuple with the HTTP Basic access authentication credentials\n    ``(username, password)`` if provided, otherwise ``None``.\n\n    :param request: the request object\n    :type request: pyramid.request.Request\n\n    :returns: a tuple of (username, password) or None\n    :rtype: tuple or NoneType\n    \"\"\"\n    try:\n        authtype, value = request.authorization\n    except TypeError:  # no authorization header\n        return None\n    if authtype.lower() != 'basic':\n        return None\n    try:\n        user_pass_bytes = base64.standard_b64decode(value)\n    except TypeError:  # failed to decode\n        return None\n    try:\n        # See the lengthy comment in the tests about why we assume UTF-8\n        # encoding here.\n        user_pass = user_pass_bytes.decode('utf-8')\n    except UnicodeError:  # not UTF-8\n        return None\n    try:\n        username, password = user_pass.split(':', 1)\n    except ValueError:  # not enough values to unpack\n        return None\n    return (username, password)\n\n\ndef groupfinder(userid, request):\n    \"\"\"\n    Return the list of additional principals for a userid, or None.\n\n    This loads the user and then calls ``principals_for_user``.\n\n    If `userid` identifies a valid user in the system, this function will\n    return the list of additional principals for that user. If `userid` is not\n    recognised as a valid user in the system, the function will return None.\n\n    :param userid: the userid claimed by the request.\n    :type userid: str\n    :param request: the request object\n    :type request: pyramid.request.Request\n\n    :returns: additional principals for the user (possibly empty) or None\n    :rtype: list or None\n    \"\"\"\n    user_service = request.find_service(name='user')\n    user = user_service.fetch(userid)\n\n    return principals_for_user(user)\n\n\ndef principals_for_user(user):\n    \"\"\"Return the list of additional principals for a user, or None.\"\"\"\n    if user is None:\n        return None\n\n    principals = set()\n    if user.admin:\n        principals.add(role.Admin)\n    if user.staff:\n        principals.add(role.Staff)\n    for group in user.groups:\n        principals.add('group:{group.pubid}'.format(group=group))\n\n    return list(principals)\n\n\ndef translate_annotation_principals(principals):\n    \"\"\"\n    Translate a list of annotation principals to a list of pyramid principals.\n    \"\"\"\n    result = set([])\n    for principal in principals:\n        # Ignore suspicious principals from annotations\n        if principal.startswith('system.'):\n            continue\n        if principal == 'group:__world__':\n            result.add(security.Everyone)\n        else:\n            result.add(principal)\n    return list(result)\n\n"},{"size":3090,"relativepath":"h/auth/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"Authentication configuration.\"\"\"\n\nimport logging\n\nfrom pyramid.authentication import RemoteUserAuthenticationPolicy\nimport pyramid_authsanity\nfrom pyramid_multiauth import MultiAuthenticationPolicy\n\nfrom h.auth.policy import AuthenticationPolicy, TokenAuthenticationPolicy\nfrom h.auth.util import groupfinder\nfrom h.security import derive_key\n\n__all__ = (\n    'DEFAULT_POLICY',\n    'WEBSOCKET_POLICY',\n)\n\nlog = logging.getLogger(__name__)\n\nPROXY_POLICY = RemoteUserAuthenticationPolicy(environ_key='HTTP_X_FORWARDED_USER',\n                                              callback=groupfinder)\nTICKET_POLICY = pyramid_authsanity.AuthServicePolicy()\nTOKEN_POLICY = TokenAuthenticationPolicy(callback=groupfinder)\n\nDEFAULT_POLICY = AuthenticationPolicy(api_policy=TOKEN_POLICY,\n                                      fallback_policy=TICKET_POLICY)\nWEBSOCKET_POLICY = MultiAuthenticationPolicy([TOKEN_POLICY, TICKET_POLICY])\n\n\ndef auth_domain(request):\n    \"\"\"Return the value of the h.auth_domain config settings.\n\n    Falls back on returning request.domain if h.auth_domain isn't set.\n\n    \"\"\"\n    return request.registry.settings.get('h.auth_domain', request.domain)\n\n\ndef includeme(config):\n    global DEFAULT_POLICY\n    global WEBSOCKET_POLICY\n\n    # Set up authsanity\n    config.register_service_factory('.services.auth_ticket_service_factory',\n                                    iface='pyramid_authsanity.interfaces.IAuthService')\n    settings = config.registry.settings\n    settings['authsanity.source'] = 'cookie'\n    settings['authsanity.cookie.max_age'] = 2592000\n    settings['authsanity.cookie.httponly'] = True\n    settings['authsanity.secret'] = derive_key(settings['secret_key'],\n                                               b'h.auth.cookie_secret')\n    config.include('pyramid_authsanity')\n\n    if config.registry.settings.get('h.proxy_auth'):\n        log.warn('Enabling proxy authentication mode: you MUST ensure that '\n                 'the X-Forwarded-User request header can ONLY be set by '\n                 'trusted downstream reverse proxies! Failure to heed this '\n                 'warning will result in ALL DATA stored by this service '\n                 'being available to ANYONE!')\n\n        DEFAULT_POLICY = AuthenticationPolicy(api_policy=TOKEN_POLICY,\n                                              fallback_policy=PROXY_POLICY)\n        WEBSOCKET_POLICY = MultiAuthenticationPolicy([TOKEN_POLICY,\n                                                      PROXY_POLICY])\n\n    config.register_service_factory('.services.oauth_service_factory',\n                                    name='oauth')\n\n    # Set the default authentication policy. This can be overridden by modules\n    # that include this one.\n    config.set_authentication_policy(DEFAULT_POLICY)\n\n    # Allow retrieval of the auth_domain from the request object.\n    config.add_request_method(auth_domain, name='auth_domain', reify=True)\n\n    # Allow retrieval of the auth token (if present) from the request object.\n    config.add_request_method('.tokens.auth_token', reify=True)\n"},{"size":4238,"relativepath":"h/auth/tokens.py","filename":"tokens.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport datetime\n\nimport jwt\nfrom zope.interface import implementer\n\nfrom h._compat import text_type\nfrom h import models\nfrom h.auth.interfaces import IAuthenticationToken\n\n\n@implementer(IAuthenticationToken)\nclass Token(object):\n    \"\"\"\n    A long-lived API token for a user.\n\n    This is a wrapper class that wraps an ``h.models.Token`` and provides an\n    implementation of the ``IAuthenticationToken`` interface.\n\n    Unlike ``models.Token`` this class is not a sqlalchemy ORM class so it can\n    be used after the request's db session has been committed or invalidated\n    without getting ``DetachedInstanceError``s from sqlalchemy.\n\n    \"\"\"\n\n    def __init__(self, token_model):\n        self.expires = token_model.expires\n        self.userid = token_model.userid\n\n    def is_valid(self):\n        \"\"\"Return ``True`` if this token is not expired, ``False`` if it is.\"\"\"\n        if self.expires is None:\n            return True\n        now = datetime.datetime.utcnow()\n        return now < self.expires\n\n\n@implementer(IAuthenticationToken)\nclass LegacyClientJWT(object):\n\n    \"\"\"\n    A wrapper around JWT issued to the Hypothesis client.\n\n    Exposes the standard \"auth token\" interface on top of legacy tokens.\n    \"\"\"\n\n    def __init__(self, body, key, audience=None, leeway=240):\n        self.payload = jwt.decode(body,\n                                  key=key,\n                                  audience=audience,\n                                  leeway=leeway,\n                                  algorithms=['HS256'])\n\n    def is_valid(self):\n        \"\"\"Check if the token is valid. Always true for JWTs.\"\"\"\n        # JWT validity checks happen at construction time. If an instance is\n        # successfully constructed, it is by definition valid.\n        return True\n\n    @property\n    def userid(self):\n        return self.payload.get('sub')\n\n\ndef generate_jwt(request, expires_in):\n    \"\"\"Return a signed JSON Web Token for the given request.\n\n    The token can be used in the Authorization header in subsequent requests to\n    the API to authenticate the user identified by the\n    request.authenticated_userid of the _current_ request.\n\n    :param request: the HTTP request to return a token for, the token will\n        authenticate the userid given by this request's authenticated_userid\n        property\n    :type request: pyramid.request.Request\n\n    :param expires_in: when the returned token should expire, in seconds from\n        the current time\n    :type expires_in: int\n\n    :returns: a signed JSON Web Token\n    :rtype: string\n\n    \"\"\"\n    now = datetime.datetime.utcnow().replace(microsecond=0)\n\n    claims = {\n        'iss': request.registry.settings['h.client_id'],\n        'aud': request.host_url,\n        'sub': request.authenticated_userid,\n        'exp': now + datetime.timedelta(seconds=expires_in),\n        'iat': now,\n    }\n\n    return jwt.encode(claims,\n                      request.registry.settings['h.client_secret'],\n                      algorithm='HS256')\n\n\ndef auth_token(request):\n    \"\"\"\n    Fetch the token (if any) associated with a request.\n\n    :param request: the request object\n    :type request: pyramid.request.Request\n\n    :returns: the auth token carried by the request, or None\n    :rtype: h.models.Token or None\n    \"\"\"\n    try:\n        header = request.headers['Authorization']\n    except KeyError:\n        return None\n\n    if not header.startswith('Bearer '):\n        return None\n\n    token = text_type(header[len('Bearer '):]).strip()\n    # If the token is empty at this point, it is clearly invalid and we\n    # should reject it.\n    if not token:\n        return None\n\n    token_model = (request.db.query(models.Token)\n                   .filter_by(value=token)\n                   .one_or_none())\n    if token_model is not None:\n        return Token(token_model)\n\n    # If we've got this far it's possible the token is a legacy client JWT.\n    return _maybe_jwt(token, request)\n\n\ndef _maybe_jwt(token, request):\n    try:\n        return LegacyClientJWT(token,\n                               key=request.registry.settings['h.client_secret'],\n                               audience=request.host_url)\n    except jwt.InvalidTokenError:\n        return None\n"},{"size":209,"relativepath":"h/auth/role.py","filename":"role.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n#: Administrators. These users have super cow powers.\nAdmin = 'group:__admin__'\n\n#: Hypothesis staff. These users have limited access to admin functionality.\nStaff = 'group:__staff__'\n"},{"size":8249,"relativepath":"h/auth/services.py","filename":"services.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport datetime\n\nimport jwt\nfrom pyramid_authsanity import interfaces\nimport sqlalchemy as sa\nfrom zope import interface\n\nfrom h import models\nfrom h.exceptions import OAuthTokenError\nfrom h.auth.util import principals_for_user\nfrom h._compat import text_type\n\nTICKET_TTL = datetime.timedelta(days=7)\n\n# We only want to update the `expires` column when the tickets `expires` is at\n# least one minute smaller than the potential new value. This prevents that we\n# update the `expires` column on every single request.\nTICKET_REFRESH_INTERVAL = datetime.timedelta(minutes=1)\n\n# TTL of an OAuth token\nTOKEN_TTL = datetime.timedelta(hours=1)\n\n\nclass AuthTicketNotLoadedError(Exception):\n    pass\n\n\n@interface.implementer(interfaces.IAuthService)\nclass AuthTicketService(object):\n    def __init__(self, session, user_service):\n        self.session = session\n        self.usersvc = user_service\n\n        self._userid = None\n\n    def userid(self):\n        \"\"\"\n        Return current userid, or None.\n\n        Raises ``AuthTicketNotLoadedError`` when auth ticket has not been\n        loaded yet, which signals the auth policy to call ``verify_ticket``.\n        \"\"\"\n\n        if self._userid is None:\n            raise AuthTicketNotLoadedError('auth ticket is not loaded yet')\n\n        return self._userid\n\n    def groups(self):\n        \"\"\"Returns security principals of the logged-in user.\"\"\"\n\n        if self._userid is None:\n            raise AuthTicketNotLoadedError('auth ticket is not loaded yet')\n\n        user = self.usersvc.fetch(self._userid)\n        return principals_for_user(user)\n\n    def verify_ticket(self, principal, ticket_id):\n        \"\"\"\n        Verifies an authentication claim (usually extracted from a cookie)\n        against the stored tickets.\n\n        This will only successfully verify a ticket when it is found in the\n        database, the principal is the same, and it hasn't expired yet.\n        \"\"\"\n\n        if ticket_id is None:\n            return False\n\n        ticket = self.session.query(models.AuthTicket) \\\n            .filter(models.AuthTicket.id == ticket_id,\n                    models.AuthTicket.user_userid == principal,\n                    models.AuthTicket.expires > sa.func.now()) \\\n            .one_or_none()\n\n        if ticket is None:\n            return False\n\n        self._userid = ticket.user_userid\n\n        # We don't want to update the `expires` column of an auth ticket on\n        # every single request, but only when the ticket hasn't been touched\n        # within a the defined `TICKET_REFRESH_INTERVAL`.\n        if (utcnow() - ticket.updated) > TICKET_REFRESH_INTERVAL:\n            ticket.expires = utcnow() + TICKET_TTL\n\n        return True\n\n    def add_ticket(self, principal, ticket_id):\n        \"\"\"Store a new ticket with the given id and principal in the database.\"\"\"\n\n        user = self.usersvc.fetch(principal)\n        if user is None:\n            raise ValueError('Cannot find user with userid %s' % principal)\n\n        ticket = models.AuthTicket(id=ticket_id,\n                                   user=user,\n                                   user_userid=user.userid,\n                                   expires=(utcnow() + TICKET_TTL))\n        self.session.add(ticket)\n        # We cache the new userid, this will allow us to migrate the old\n        # session policy to this new ticket policy.\n        self._userid = user.userid\n\n    def remove_ticket(self, ticket_id):\n        \"\"\"Delete a ticket by id from the database.\"\"\"\n\n        if ticket_id:\n            self.session.query(models.AuthTicket).filter_by(id=ticket_id).delete()\n        self._userid = None\n\n\nclass OAuthService(object):\n    def __init__(self, session, user_service, domain):\n        self.session = session\n        self.usersvc = user_service\n        self.domain = domain\n\n    def verify_jwt_bearer(self, assertion, grant_type):\n        \"\"\"\n        Verifies a JWT bearer grant token and returns the matched user.\n\n        This adheres to RFC7523 [1] (\"JSON Web Token (JWT) Profile for\n        OAuth 2.0 Client Authentication and Authorization Grants\").\n\n        [1]: https://tools.ietf.org/html/rfc7523\n\n        :param assertion: the assertion param (typically from ``request.POST``).\n        :type assertion: text_type\n\n        :param grant_type: the grant type (typically from ``request.POST``).\n        :type grant_type: text_type\n\n        :raises h.exceptions.OAuthTokenError: if the given request and/or JWT claims are invalid\n\n        :returns: a tuple with the user and authclient\n        :rtype: tuple\n        \"\"\"\n        if grant_type != 'urn:ietf:params:oauth:grant-type:jwt-bearer':\n            raise OAuthTokenError('specified grant type is not supported',\n                                  'unsupported_grant_type')\n\n        if not assertion or type(assertion) != text_type:\n            raise OAuthTokenError('required assertion parameter is missing',\n                                  'invalid_request')\n        token = assertion\n\n        unverified_claims = self._decode(token, verify=False)\n\n        client_id = unverified_claims.get('iss', None)\n        if not client_id:\n            raise OAuthTokenError('grant token issuer is missing', 'invalid_grant')\n        authclient = self.session.query(models.AuthClient).get(client_id)\n        if not authclient:\n            raise OAuthTokenError('given JWT issuer is invalid', 'invalid_grant')\n\n        claims = self._decode(token,\n                              algorithms=['HS256'],\n                              audience=self.domain,\n                              key=authclient.secret,\n                              leeway=10)\n\n        userid = claims.get('sub')\n        if not userid:\n            raise OAuthTokenError('JWT subject is missing', 'invalid_grant')\n\n        user = self.usersvc.fetch(userid)\n        if user is None:\n            raise OAuthTokenError('user with userid described in subject could not be found',\n                                  'invalid_grant')\n\n        return (user, authclient)\n\n    def create_token(self, user, authclient):\n        \"\"\"\n        Creates a token for the passed-in user without any additional\n        verification.\n\n        It is the caller's responsibility to verify the token request, e.g. with\n        ``verify_jwt_bearer``.\n\n        :param assertion: the user for whom the token should be created.\n        :type assertion: h.models.User\n\n        :rtype: h.models.Token\n        \"\"\"\n        token = models.Token(userid=user.userid,\n                             expires=(utcnow() + TOKEN_TTL),\n                             authclient=authclient)\n        self.session.add(token)\n\n        return token\n\n    def _decode(self, token, **kwargs):\n        try:\n            claims = jwt.decode(token, **kwargs)\n            return claims\n        except jwt.DecodeError:\n            raise OAuthTokenError('invalid JWT signature', 'invalid_grant')\n        except jwt.exceptions.InvalidAlgorithmError:\n            raise OAuthTokenError('invalid JWT signature algorithm', 'invalid_grant')\n        except jwt.MissingRequiredClaimError as exc:\n            raise OAuthTokenError('JWT is missing claim %s' % exc.claim, 'invalid_grant')\n        except jwt.InvalidAudienceError:\n            raise OAuthTokenError('invalid JWT audience', 'invalid_grant')\n        except jwt.ImmatureSignatureError:\n            raise OAuthTokenError('JWT not before is in the future', 'invalid_grant')\n        except jwt.ExpiredSignatureError:\n            raise OAuthTokenError('JWT token is expired', 'invalid_grant')\n        except jwt.InvalidIssuedAtError:\n            raise OAuthTokenError('JWT issued at is in the future', 'invalid_grant')\n\n\ndef auth_ticket_service_factory(context, request):\n    \"\"\"Return a AuthTicketService instance for the passed context and request.\"\"\"\n    user_service = request.find_service(name='user')\n    return AuthTicketService(request.db, user_service)\n\n\ndef oauth_service_factory(context, request):\n    \"\"\"Return a OAuthService instance for the passed context and request.\"\"\"\n    user_service = request.find_service(name='user')\n    return OAuthService(request.db, user_service, request.domain)\n\n\ndef utcnow():\n    return datetime.datetime.utcnow()\n"},{"size":359,"relativepath":"h/auth/interfaces.py","filename":"interfaces.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom zope.interface import Attribute, Interface\n\n\nclass IAuthenticationToken(Interface):\n    \"\"\"Represents an authentication token.\"\"\"\n\n    userid = Attribute(\"\"\"The userid to which this token was issued.\"\"\")\n\n    def is_valid(self):\n        \"\"\"Checks token validity (such as expiry date).\"\"\"\n"},{"size":3192,"relativepath":"h/auth/policy.py","filename":"policy.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom pyramid import interfaces\nfrom pyramid.authentication import CallbackAuthenticationPolicy\nfrom zope import interface\n\n\n@interface.implementer(interfaces.IAuthenticationPolicy)\nclass AuthenticationPolicy(object):\n    def __init__(self, api_policy, fallback_policy):\n        self.api_policy = api_policy\n        self.fallback_policy = fallback_policy\n\n    def authenticated_userid(self, request):\n        if _is_api_request(request):\n            return self.api_policy.authenticated_userid(request)\n\n        return self.fallback_policy.authenticated_userid(request)\n\n    def unauthenticated_userid(self, request):\n        if _is_api_request(request):\n            return self.api_policy.unauthenticated_userid(request)\n        return self.fallback_policy.unauthenticated_userid(request)\n\n    def effective_principals(self, request):\n        if _is_api_request(request):\n            return self.api_policy.effective_principals(request)\n        return self.fallback_policy.effective_principals(request)\n\n    def remember(self, request, userid, **kw):\n        if _is_api_request(request):\n            return self.api_policy.remember(request, userid, **kw)\n        return self.fallback_policy.remember(request, userid, **kw)\n\n    def forget(self, request):\n        if _is_api_request(request):\n            return self.api_policy.forget(request)\n        return self.fallback_policy.forget(request)\n\n\n@interface.implementer(interfaces.IAuthenticationPolicy)\nclass TokenAuthenticationPolicy(CallbackAuthenticationPolicy):\n\n    \"\"\"\n    A bearer token authentication policy.\n\n    This is a Pyramid authentication policy in which the user's identity is\n    provided by and authenticated by the presence of a valid authentication\n    token associated with the request. The token is retrieved from the\n    ``request.auth_token`` property, which is provided by the\n    :py:func:`h.auth.token.auth_token` function.\n\n    It uses Pyramid's CallbackAuthenticationPolicy to divide responsibility\n    between this component (which is responsible only for establishing\n    identity), and a callback function, which is responsible for providing\n    additional principals for the authenticated user.\n    \"\"\"\n\n    def __init__(self, callback=None, debug=False):\n        self.callback = callback\n        self.debug = debug\n\n    def remember(self, request, userid, **kw):\n        \"\"\"Not implemented for token auth policy.\"\"\"\n        return []\n\n    def forget(self, request):\n        \"\"\"Not implemented for token auth policy.\"\"\"\n        return []\n\n    def unauthenticated_userid(self, request):\n        \"\"\"\n        Return the userid implied by the token in the passed request, if any.\n\n        :param request: a request object\n        :type request: pyramid.request.Request\n\n        :returns: the userid authenticated for the passed request or None\n        :rtype: unicode or None\n        \"\"\"\n        token = getattr(request, 'auth_token', None)\n        if token is None or not token.is_valid():\n            return None\n\n        return token.userid\n\n\ndef _is_api_request(request):\n    return (request.path.startswith('/api') and\n            request.path not in ['/api/token', '/api/badge'])\n"},{"size":565,"relativepath":"h/auth/worker.py","filename":"worker.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom datetime import datetime\n\nfrom h import models\nfrom h.celery import celery\nfrom h.celery import get_task_logger\n\n\nlog = get_task_logger(__name__)\n\n\n@celery.task\ndef delete_expired_auth_tickets():\n    celery.request.db.query(models.AuthTicket) \\\n        .filter(models.AuthTicket.expires < datetime.utcnow()) \\\n        .delete()\n\n\n@celery.task\ndef delete_expired_tokens():\n    celery.request.db.query(models.Token) \\\n        .filter(models.Token.expires < datetime.utcnow()) \\\n        .delete()\n"},{"size":664,"relativepath":"h/validators.py","filename":"validators.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"Custom Colander validators.\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport colander\n\n\nclass Email(colander.Email):\n    def __init__(self, *args, **kwargs):\n        if 'msg' not in kwargs:\n            kwargs['msg'] = \"Invalid email address.\"\n        super(Email, self).__init__(*args, **kwargs)\n\n\nclass Length(colander.Length):\n    def __init__(self, *args, **kwargs):\n        if 'min_err' not in kwargs:\n            kwargs['min_err'] = \"Must be ${min} characters or more.\"\n        if 'max_err' not in kwargs:\n            kwargs['max_err'] = \"Must be ${max} characters or less.\"\n        super(Length, self).__init__(*args, **kwargs)\n"},{"size":4570,"relativepath":"h/db/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"\nConfigure and expose the application database session.\n\nThis module is responsible for setting up the database session and engine, and\nmaking that accessible to other parts of the application.\n\nModels should inherit from `h.db.Base` in order to have their metadata bound at\napplication startup (and if `h.db.should_create_all` is set, their tables will\nbe automatically created).\n\nMost application code should access the database session using the request\nproperty `request.db` which is provided by this module.\n\"\"\"\n\nimport logging\n\nimport sqlalchemy\nimport zope.sqlalchemy\nimport zope.sqlalchemy.datamanager\nfrom pyramid.settings import asbool\nfrom sqlalchemy import event\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\nfrom memex import db as api_db\n\n__all__ = (\n    'Base',\n    'Session',\n    'init',\n    'make_engine',\n)\n\nlog = logging.getLogger(__name__)\n\n# Create a default metadata object with naming conventions for indexes and\n# constraints. This makes changing such constraints and indexes with alembic\n# after creation much easier. See:\n#\n#   http://docs.sqlalchemy.org/en/latest/core/constraints.html#configuring-constraint-naming-conventions\n#\n# N.B. This must be kept in sync with the naming conventions in\n# :py:mod:`memex.db`.\n#\nmetadata = sqlalchemy.MetaData(naming_convention={\n    \"ix\": \"ix__%(column_0_label)s\",\n    \"uq\": \"uq__%(table_name)s__%(column_0_name)s\",\n    \"ck\": \"ck__%(table_name)s__%(constraint_name)s\",\n    \"fk\": \"fk__%(table_name)s__%(column_0_name)s__%(referred_table_name)s\",\n    \"pk\": \"pk__%(table_name)s\"\n})\n\nBase = declarative_base(metadata=metadata)\n\nSession = sessionmaker()\n\n\ndef init(engine, base=Base, should_create=False, should_drop=False):\n    \"\"\"Initialise the database tables managed by `h.db`.\"\"\"\n    if should_drop:\n        base.metadata.reflect(engine)\n        base.metadata.drop_all(engine)\n    if should_create:\n        # In order to be able to generate UUIDs, we load the uuid-ossp\n        # extension.\n        engine.execute('CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";')\n        base.metadata.create_all(engine)\n    api_db.init(engine, should_create=should_create, should_drop=should_drop)\n\n\ndef make_engine(settings):\n    \"\"\"Construct a sqlalchemy engine from the passed ``settings``.\"\"\"\n    return sqlalchemy.create_engine(settings['sqlalchemy.url'])\n\n\ndef _session(request):\n    engine = request.registry['sqlalchemy.engine']\n    session = Session(bind=engine)\n\n    # If the request has a transaction manager, associate the session with it.\n    try:\n        tm = request.tm\n    except AttributeError:\n        pass\n    else:\n        zope.sqlalchemy.register(session, transaction_manager=tm)\n\n    # pyramid_tm doesn't always close the database session for us.\n    #\n    # For example if an exception view accesses the session and causes a new\n    # transaction to be opened, pyramid_tm won't close this connection because\n    # pyramid_tm's transaction has already ended before exception views are\n    # executed.\n    # Connections opened by NewResponse and finished callbacks aren't closed by\n    # pyramid_tm either.\n    #\n    # So add our own callback here to make sure db sessions are always closed.\n    #\n    # See: https://github.com/Pylons/pyramid_tm/issues/40\n    @request.add_finished_callback\n    def close_the_sqlalchemy_session(request):\n        if session.dirty:\n            request.sentry.captureMessage('closing a dirty session', stack=True, extra={\n                'dirty': session.dirty,\n            })\n        session.close()\n\n    return session\n\n\ndef includeme(config):\n    settings = config.registry.settings\n    should_create = asbool(settings.get('h.db.should_create_all', False))\n    should_drop = asbool(settings.get('h.db.should_drop_all', False))\n\n    # Create the SQLAlchemy engine and save a reference in the app registry.\n    engine = make_engine(settings)\n    config.registry['sqlalchemy.engine'] = engine\n\n    # Add a property to all requests for easy access to the session. This means\n    # that view functions need only refer to `request.db` in order to retrieve\n    # the current database session.\n    config.add_request_method(_session, name='db', reify=True)\n\n    # Register a deferred action to bind the engine when the configuration is\n    # committed. Deferring the action means that this module can be included\n    # before model modules without ill effect.\n    config.action(None, init, (engine,), {\n        'should_create': should_create,\n        'should_drop': should_drop\n    }, order=10)\n"},{"size":630,"relativepath":"h/db/mixins.py","filename":"mixins.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"Reusable mixins for SQLAlchemy declarative models.\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport datetime\n\nimport sqlalchemy as sa\n\n\nclass Timestamps(object):\n    created = sa.Column(sa.DateTime,\n                        default=datetime.datetime.utcnow,\n                        server_default=sa.func.now(),\n                        nullable=False)\n    updated = sa.Column(sa.DateTime,\n                        server_default=sa.func.now(),\n                        default=datetime.datetime.utcnow,\n                        onupdate=datetime.datetime.utcnow,\n                        nullable=False)\n"},{"size":66,"relativepath":"h/templates/deform/emailinput.jinja2","filename":"emailinput.jinja2","extension":".jinja2","content":"<input type=\"email\"\n{% include \"includes/common_attrs.jinja2\" %}>\n"},{"size":335,"relativepath":"h/templates/deform/textarea.jinja2","filename":"textarea.jinja2","extension":".jinja2","content":"<textarea {% if field.widget.rows -%}rows=\"{{ field.widget.rows }}\"{% endif %}\n{% include \"includes/common_attrs.jinja2\" %}>{{ cstruct }}</textarea>\n{% if field.widget.max_length %}\n  <span class=\"form-input__character-counter\" data-ref=\"characterLimitCounter\">\n    Up to {{ field.widget.max_length }} characters\n  </span>\n{% endif %}\n"},{"size":1521,"relativepath":"h/templates/deform/checkbox_choice.jinja2","filename":"checkbox_choice.jinja2","extension":".jinja2","content":"<input type=\"hidden\" name=\"__start__\" value=\"{{ field.name }}:sequence\">\n<div class=\"form-checkbox-list\">\n  {% for value, title in field.widget.values %}\n  {% if feature('activity_pages') %}\n  <div class=\"form-checkbox\">\n    <label for=\"{{ field.oid }}-{{ loop.index0 }}\"\n           class=\"form-checkbox__label\">\n      <input type=\"checkbox\"\n             name=\"checkbox\"\n             data-ref=\"formInput\"\n             value=\"{{ value }}\"\n             id=\"{{ field.oid }}-{{ loop.index0 }}\"\n             class=\"form-checkbox__input\n             {%- if field.widget.css_class %} {{ field.widget.css_class }}{% endif -%}\"\n             {%- if field.error -%}\n             aria-invalid=\"true\"\n             {% endif -%}\n             {% if value in cstruct %}\n             checked=\"True\"\n             {% endif %}>\n      {{ title }}\n    </label>\n  </div>\n  {% else %}\n  <div class=\"form-checkbox-item\">\n    <input type=\"checkbox\"\n           name=\"checkbox\"\n           value=\"{{ value }}\"\n           id=\"{{ field.oid }}-{{ loop.index0 }}\"\n           {% if field.widget.css_class -%}\n           class=\"{{ field.widget.css_class }}\"\n           {% endif -%}\n           {%- if field.error -%}\n           aria-invalid=\"true\"\n           {% endif -%}\n           {% if value in cstruct %}\n           checked=\"True\"\n           {% endif %}>\n    <label for=\"{{ field.oid }}-{{ loop.index0 }}\">\n      {{ title }}\n    </label>\n  </div>\n  {% endif %}\n  {% endfor %}\n</div>\n<input type=\"hidden\" name=\"__end__\" value=\"{{ field.name }}:sequence\">\n"},{"size":1193,"relativepath":"h/templates/deform/includes/common_attrs.jinja2","filename":"common_attrs.jinja2","extension":".jinja2","content":"{% if feature('activity_pages') %}\n{% set field_css_class = 'form-input__input' %}\n{% else %}\n{% set field_css_class = 'form-input' %}\n{% endif %}\n\n{% if field.widget.template in ('textinput', 'textarea') and field.widget.max_length %}\n{% set ref = 'characterLimitInput' %}\n{% endif %}\n\nname=\"{{ field.name }}\"\nvalue=\"{{ cstruct }}\"\nid=\"{{ field.oid }}\"\ndata-ref=\"{{ ref }} formInput\"\nclass=\"{{field_css_class}}\n      {% if field.widget.css_class %} {{ field.widget.css_class }} {% endif %}\n      {% if field.widget.autofocus %} js-select-onfocus{% endif %}\n      {% if field.schema.hint %} has-hint {% endif %}\"\n{%- if field.widget.size -%}\nsize=\"{{ field.widget.size }}\"\n{% endif -%}\n{%- if field.schema.hint -%}\naria-describedby=\"hint-{{ field.oid }}\"\n{% endif -%}\n{%- if field.error %}\naria-invalid=\"true\"\n{% endif -%}\n{%- if field.widget.autofocus -%}\nautofocus\n{% endif -%}\n{%- if field.widget.disable_autocomplete -%}\nautocomplete=\"off\"\n{% endif -%}\n{%- if field.widget.max_length -%}\ndata-maxlength=\"{{ field.widget.max_length }}\"\n{% endif -%}\n{%- if field.widget.placeholder -%}\nplaceholder=\"{{ field.widget.placeholder }}\"\n{% endif -%}\n{%- if field.required -%}\nrequired\n{% endif %}\n"},{"size":69,"relativepath":"h/templates/deform/password.jinja2","filename":"password.jinja2","extension":".jinja2","content":"<input type=\"password\"\n{% include \"includes/common_attrs.jinja2\" %}>\n"},{"size":277,"relativepath":"h/templates/deform/textinput.jinja2","filename":"textinput.jinja2","extension":".jinja2","content":"<input type=\"text\"\n{% include \"includes/common_attrs.jinja2\" %}>\n{%- if field.widget.max_length and feature('activity_pages') -%}\n<span class=\"form-input__character-counter\" data-ref=\"characterLimitCounter\">\n  Up to {{ field.widget.max_length }} characters\n</span>\n{% endif %}\n"},{"size":2837,"relativepath":"h/templates/deform/mapping_item.jinja2","filename":"mapping_item.jinja2","extension":".jinja2","content":"{% if feature('activity_pages') %}\n{% set field_class = 'form-input' %}\n{% set field_error_state_class = 'is-error' %}\n{% set field_label_class = 'form-input__label' %}\n{% set field_error_list_class = 'form-input__error-list' %}\n{% set field_error_item_class = 'form-input__error-item' %}\n{% set show_char_counter = field.widget.template in ('textinput', 'textarea') and\n                           field.widget.max_length %}\n{% else %}\n{% set field_class = 'form-group form-field' %}\n{% set field_error_state_class = 'form-field-error' %}\n{% set field_label_class = 'form-label' %}\n{% set field_error_list_class = 'form-error-list' %}\n{% set field_error_item_class = 'form-error' %}\n{% set show_char_counter = False %}\n{% endif %}\n\n{%- if not field.widget.hidden -%}\n<div class=\"{{ field_class }}\n            js-form-input\n            {% if field.error %}{{ field_error_state_class }}{% endif %}\n            {% if show_char_counter %} js-character-limit {%- endif %}\"\n     {%- if field.description -%}\n     title=\"{{ _(field.description) }}\"\n     {% endif %}\n     id=\"item-{{ field.oid }}\">\n{% endif -%}\n\n{%- if not (field.widget.hidden or field.widget.omit_label or field.widget.category == 'structural') -%}\n  <label class=\"{{ field_label_class }} {% if field.widget.label_css_class %} {{ field.widget.label_css_class }}{% endif %}\n                {%- if field.schema.hint and feature('activity_pages') -%}js-tooltip{% endif %}\"\n         {%- if field.schema.hint %}aria-label=\"{{ field.schema.hint }}\"{% endif %}\n         {%- if field.description -%}\n         title=\"{{ _(field.description) }}\"\n         {% endif %}\n         for=\"{{ field.oid }}\">\n           {{ _(field.title) }}\n    {%- if field.required and field.widget.show_required and feature('activity_pages') -%}\n      <span class=\"form-input__required\">*</span>\n    {% endif -%}\n    {%- if field.schema.hint and feature('activity_pages') -%}\n      <i class=\"form-input__hint-icon\">\n        {{ svg_icon('info_icon') }}\n      </i>\n    {% endif -%}\n    {%- if field.schema.hint and not feature('activity_pages') %}\n      <span class=\"form-hint\" id=\"hint-{{ field.oid }}\">({{ field.schema.hint }})</span>\n    {% endif -%}\n  </label>\n{% endif -%}\n\n{{ field.serialize(cstruct) }}\n\n{%- if field.error and not field.widget.hidden -%}\n  <ul class=\"{{ field_error_list_class }}\">\n  {% for msg in field.error.messages() -%}\n    {%- set errstr = 'error-%s' % field.oid -%}\n    {%- set pid = (loop.index0==0 and errstr) or ('%s-%s' % (errstr, loop.index0)) -%}\n    <li class=\"{{ field_error_item_class }}\" id=\"{{ pid }}\">{{ _(msg) }}</li>\n  {% endfor -%}\n  </ul>\n{% endif -%}\n\n{%- if not field.widget.hidden -%}\n</div>\n\n{% if field.schema.hint and feature('activity_pages') %}\n<div class=\"form-input__hint\" id=\"hint-{{ field.oid }}\">{{ field.schema.hint }}</div>\n{% endif %}\n\n{% endif -%}\n"},{"size":2386,"relativepath":"h/templates/deform/form.jinja2","filename":"form.jinja2","extension":".jinja2","content":"{% if feature('activity_pages') %}\n{% set form_buttons_class = 'form-actions__buttons' %}\n{% set form_message_class = 'form-actions__message' %}\n{% else %}\n{% set form_buttons_class = 'form-actions-buttons' %}\n{% set form_message_class = 'form-actions-message' %}\n{% endif %}\n<form id=\"{{ field.formid }}\"\n      action=\"{{ field.action }}\"\n      method=\"{{ field.method }}\"\n      enctype=\"multipart/form-data\"\n      accept-charset=\"utf-8\"\n      class=\"form {{ field.css_class or '' }}\n             {%- if field.use_inline_editing %} js-form {% endif %}\">\n  <input type=\"hidden\" name=\"__formid__\" value=\"{{ field.formid }}\" />\n\n  <div class=\"form__backdrop\" data-ref=\"formBackdrop\"></div>\n\n  {%- for f in field.children -%}\n    {{ field.renderer(field.widget.item_template, field=f, cstruct=cstruct.get(f.name, null)) }}\n  {% endfor -%}\n\n  <div class=\"form-actions {% if field.use_inline_editing %} is-hidden-when-loading {% endif %}\"\n       data-ref=\"formActions\">\n    {% if feature('activity_pages') %}\n    <div class=\"form__submit-error\" data-ref=\"formSubmitError\">\n      <span>{% trans %}Unable to save changes: {% endtrans %}</span>\n      <span data-ref=\"formSubmitErrorMessage\"></span>\n    </div>\n    {% endif %}\n    <div class=\"{{ form_message_class }}\">\n      {%- if field.footer %}{{ field.footer | safe }}{% endif -%}\n    </div>\n    {% if feature('activity_pages') %}\n    <div class=\"u-stretch\"></div>\n    {% endif %}\n    <div class=\"{{ form_buttons_class }}\">\n      {%- for button in field.buttons -%}\n        <button id=\"{{ field.formid + button.name }}\"\n                name=\"{{ button.name }}\"\n                type=\"{{ button.type }}\"\n                class=\"form-actions__btn btn{% if button.css_class %} {{ button.css_class }}{% endif %}\"\n                value=\"{{ _(button.value) }}\"\n                {%- if button.disabled -%}\n                disabled=\"disabled\"\n                {% endif -%}\n                >\n        {{ _(button.title) }}\n        </button>\n        {% if feature('activity_pages') %}\n        <button class=\"btn btn--cancel is-hidden\" data-ref=\"cancelBtn\">Cancel</button>\n        {% endif %}\n      {% endfor -%}\n    </div>\n  </div>\n\n  {#\n    The default deform templates are ajax capable. I've removed that code here\n    for the sake of clarity. If we need to put it back it can be found in\n    deform_jinja2:bootstrap_templates/form.jinja2.\n  #}\n</form>\n"},{"size":595,"relativepath":"h/templates/unsubscribe.html.jinja2","filename":"unsubscribe.html.jinja2","extension":".jinja2","content":"{% extends \"layouts/base.html.jinja2\" %}\n\n{% set style_bundle = 'legacy_site_css' %}\n\n{% block title %}Unsubscribed{% endblock %}\n\n{% block content %}\n  <main class=\"content paper styled-text page\">\n    <h1>Your unsubscribe request has been processed.</h1>\n    <p>You should no longer receive further notifications of this type.</p>\n    <p>\n      If you have made a mistake and wish to resubscribe, please see your\n      <a href=\"{{request.route_path('login', _query={'next': request.route_path('account_notifications')})}}\"\n        >notification settings</a>.\n    </p>\n  </main>\n{% endblock %}\n"},{"size":143,"relativepath":"h/templates/emails/signup.html.jinja2","filename":"signup.html.jinja2","extension":".jinja2","content":"<p>Please validate your email and activate your account by visiting:</p>\n\n<p>&nbsp;&nbsp;<a href=\"{{activate_link}}\">{{activate_link}}</a></p>\n"},{"size":87,"relativepath":"h/templates/emails/signup.txt.jinja2","filename":"signup.txt.jinja2","extension":".jinja2","content":"Please validate your email and activate your account by visiting:\n\n  {{activate_link}}\n"},{"size":774,"relativepath":"h/templates/emails/reply_notification.html.jinja2","filename":"reply_notification.html.jinja2","extension":".jinja2","content":"<p>\n  <a href=\"{{ reply_user_url }}\">{{ reply_user.username }}</a>\n  has\n  <a href=\"{{ reply_url }}\">replied to your annotation</a>\n  on\n  <a href=\"{{ document_url }}\">&ldquo;{{ document_title }}&rdquo;</a>:\n</p>\n\n<p>\n  On\n  {{ parent.created | human_timestamp }}\n  <a href=\"{{ parent_user_url }}\">{{ parent_user.username }}</a>\n  commented:\n</p>\n\n<blockquote>{{ parent.text or \"\" }}</blockquote>\n\n<p>\n  On\n  {{ reply.created | human_timestamp }}\n  <a href=\"{{ reply_user_url }}\">{{ reply_user.username }}</a>\n  replied:\n</p>\n\n<blockquote>{{ reply.text or \"\" }}</blockquote>\n\n<p><a href=\"{{ reply_url }}\">View the thread and respond</a>.</p>\n\n<p><small>If you'd rather not receive these notifications you can\n<a href=\"{{ unsubscribe_url }}\">unsubscribe now</a>.</small></p>\n"},{"size":433,"relativepath":"h/templates/emails/reply_notification.txt.jinja2","filename":"reply_notification.txt.jinja2","extension":".jinja2","content":"{{ reply_user.username }} has replied to your annotation on \"{{ document_title }}\":\n\nOn {{ parent.created | human_timestamp }} {{ parent_user.username }} commented:\n\n> {{ parent.text or \"\" }}\n\nOn {{ reply.created | human_timestamp }} {{ reply_user.username }} replied:\n\n> {{ reply.text or \"\" }}\n\nView the thread and respond: {{ reply_url }}\n\nIf you'd rather not receive these notifications you can unsubscribe: {{ unsubscribe_url }}\n"},{"size":1103,"relativepath":"h/templates/rss.xml.jinja2","filename":"rss.xml.jinja2","extension":".jinja2","content":"{# Generic template for rendering an RSS feed given a feed dict.\n\nThe feed dict should be a logical representation of an RSS feed as a Python\ndict, including a list of dicts for the feed's items. This template will\nrender the feed to RSS XML.\n\n-#}\n<?xml version=\"1.0\"?>\n<rss version=\"2.0\"\n     xmlns:atom=\"http://www.w3.org/2005/Atom\"\n     xmlns:dc=\"http://purl.org/dc/elements/1.1/\">\n  <channel>\n    <title>{{ feed.title }}</title>\n    <link>{{ feed.html_url }}</link>\n    <atom:link href=\"{{ feed.rss_url }}\" rel=\"self\" type=\"application/rss+xml\" />\n    <description>{{ feed.description }}</description>\n    <pubDate>{{ feed.pubDate }}</pubDate>\n    <docs>http://blogs.law.harvard.edu/tech/rss</docs>\n\n    {% for item in feed.entries %}\n    <item>\n       <title>{{ item.title }}</title>\n       <description>{{ item.description|safe }}</description>\n       <pubDate>{{ item.pubDate }}</pubDate>\n       <guid isPermaLink=\"true\">{{ item.guid }}</guid>\n       <link>{{ item.link }}</link>\n       <dc:creator><![CDATA[{{ item.author.name }}]]></dc:creator>\n    </item>\n    {% endfor %}\n  </channel>\n</rss>\n"},{"size":1092,"relativepath":"h/templates/bookmarklet.js.jinja2","filename":"bookmarklet.js.jinja2","extension":".jinja2","content":"(function (window, document, location) {\n  var embedUrl = '{{request.route_url(\"embed\")}}';\n  var isHTTPS = location.protocol.indexOf('https') === 0;\n  var isEmbedHTTPS = embedUrl.indexOf('https') === 0;\n  var isLocal = location.protocol === 'file:';\n  var isPDF = location.pathname.toLowerCase().indexOf('.pdf') > 0;\n  var hasPDFjs = typeof window.PDFJS !== 'undefined';\n  var embed;\n\n  if (isLocal && !isPDF) {\n    window.alert('Sorry, Hypothesis doesn\\'t work on this type of file. Only PDF\\'s can be annotated locally.');\n    return;\n  }\n  if (isPDF && !hasPDFjs) {\n    window.alert('Sorry, this bookmarklet doesn\\'t work with PDF documents. Please use one of our browser extensions or the Firefox browser.');\n    return;\n  }\n  if (isHTTPS && !isEmbedHTTPS) {\n    window.alert('Sorry, but this bookmarklet is unavailable on pages served with HTTPS at this time. Please contact support for further assistance.');\n    return;\n  }\n\n  embed = document.createElement('script');\n  embed.setAttribute('src', embedUrl);\n  document.body.appendChild(embed);\n})(this, this.document, this.location);\n"},{"size":1708,"relativepath":"h/templates/app.html.jinja2","filename":"app.html.jinja2","extension":".jinja2","content":"<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset=\"UTF-8\" />\n    <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n    <title>Hypothesis</title>\n    {# the <base> tag is required by Angular JS when HTML 5 history is\n     enabled. We shouldn't really need this because a given instance of the app\n     only ever displays a single route.\n     #}\n    <base target=\"_top\" href=\"/\" />\n  {% for url in app_css_urls %}\n    <link rel=\"stylesheet\" href=\"{{ url }}\">\n    {% endfor %}\n    {% for attrs in meta_attrs -%}\n      <meta {% for key, value in attrs.items() %}{{ key }}=\"{{ value }}\" {% endfor %}/>\n    {% endfor -%}\n    {% if link_tags %}\n      {% for link in link_tags %}\n        <link rel=\"{{ link.rel }}\" type=\"{{ link.type }}\"\n              href=\"{{ link.href }}\"/>\n      {% endfor %}\n    {% endif %}\n  </head>\n  <body>\n    <hypothesis-app></hypothesis-app>\n\n    <!-- App Configuration !-->\n    <script class=\"js-hypothesis-settings\" type=\"application/json\">\n      {{ app_config | safe }}\n    </script>\n\n    <!-- Scripts !-->\n    {% for url in app_js_urls %}\n    <script src=\"{{ url }}\"></script>\n    {% endfor %}\n\n    <!-- Analytics !-->\n    {% if ga_tracking_id %}\n      <!-- Google Analytics -->\n      <script async src='//www.google-analytics.com/analytics.js'></script>\n      <script>\n       window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;\n       ga('create', 'UA-{{ga_tracking_id}}', '{{ga_cookie_domain}}');\n\n       {# No pageview event is sent here because that is handled by the\n          Angular GA integration in the client app after it boots.\n        #}\n      </script>\n      <!-- End Google Analytics -->\n    {% endif %}\n  </body>\n</html>\n"},{"size":718,"relativepath":"h/templates/layouts/group.html.jinja2","filename":"group.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/base.html.jinja2\" %}\n\n{% if not feature('activity_pages') %}\n{% set style_bundle = 'site_css' %}\n{% endif %}\n\n{% block page_title %}{{ page_title }}{% endblock %}\n\n{% block content %}\n  {% if feature('activity_pages') %}\n    {% include \"h:templates/includes/logo-header.html.jinja2\" %}\n  {%- endif %}\n\n  <div class=\"content paper\">\n    <div class=\"form-container\">\n      {% if request.session.peek_flash('success') -%}\n        <div class=\"form-flash\">\n          {% for message in request.session.pop_flash('success') %}\n            <p>{{ message }}</p>\n          {%- endfor %}\n        </div>\n      {%- endif %}\n      {{ self.page_content() }}\n    </div>\n  </div>\n{% endblock content %}\n"},{"size":2168,"relativepath":"h/templates/layouts/account.html.jinja2","filename":"account.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/base.html.jinja2\" %}\n\n{% if not feature('activity_pages') %}\n{% set style_bundle = 'legacy_site_css' %}\n{% endif %}\n\n{% if feature('activity_pages') %}\n{%- set nav_pages = [\n    ('account', 'Account'),\n    ('account_profile', 'Edit profile'),\n    ('account_notifications', 'Notifications'),\n    ('account_developer', 'Developer'),\n] -%}\n{% else %}\n{%- set nav_pages = [\n    ('account', 'Account'),\n    ('account_notifications', 'Notifications'),\n    ('account_developer', 'Developer'),\n] -%}\n{% endif %}\n\n{% block page_title %}{{ page_title }}{% endblock %}\n\n{% block content %}\n  {% if feature('activity_pages') %}\n  {{ panel('navbar') }}\n  {% endif %}\n  <div class=\"content paper\">\n    {% if feature('activity_pages') %}\n      <div class=\"form-container\">\n        <nav class=\"tabs\">\n          <ul>\n            {% for route, title in nav_pages %}\n              <li class=\"tabs__item\">\n                  <a href=\"{{ request.route_url(route) }}\"\n                     class=\"tabs__link{% if route == page_route %} is-active{% endif %}\">\n                    {{ title }}\n                  </a>\n              </li>\n            {% endfor %}\n          </ul>\n        </nav>\n        {% if request.session.peek_flash('success') -%}\n          <div class=\"form-flash\">\n            {% for message in request.session.pop_flash('success') %}\n              <p>{{ message }}</p>\n            {%- endfor %}\n          </div>\n        {%- endif %}\n        {{ self.page_content() }}\n      </div>\n    {% else %}\n      {% include \"h:templates/includes/logo-header.html.jinja2\" %}\n      <ul class=\"nav nav-tabs\">\n        {% for route, title in nav_pages %}\n          <li{% if route == page_route %} class=\"active\"{% endif %}>\n              <a href=\"{{ request.route_url(route) }}\">{{ title }}</a>\n          </li>\n        {% endfor %}\n      </ul>\n      {% if request.session.peek_flash('success') -%}\n      <div class=\"form-flash\">\n        {% for message in request.session.pop_flash('success') %}\n          <p>{{ message }}</p>\n        {%- endfor %}\n      </div>\n      {%- endif %}\n      {{ self.page_content() }}\n    {% endif %}\n  </div>\n{% endblock content %}\n"},{"size":3630,"relativepath":"h/templates/layouts/admin.html.jinja2","filename":"admin.html.jinja2","extension":".jinja2","content":"{%- set nav_pages = [\n    ('index', 'admin_index', 'Home', []),\n    ('features', 'admin_features', 'Feature flags', [\n      ('features', 'admin_features', 'Manage feature flags'),\n      ('cohorts', 'admin_cohorts', 'Manage feature cohorts'),\n    ]),\n    ('nipsa', 'admin_nipsa', 'NIPSA', []),\n    ('admins', 'admin_admins', 'Administrators', []),\n    ('staff', 'admin_staff', 'Staff', []),\n    ('users', 'admin_users', 'Users', []),\n    ('groups', 'admin_groups', 'Groups', []),\n    ('badge', 'admin_badge', 'Badge', []),\n] -%}\n\n{%- set page_id = page_id|default('home') -%}\n{%- set page_title = page_title|default('Administration pages') -%}\n\n<!DOCTYPE html>\n<html>\n  <head>\n    <meta charset=\"UTF-8\" />\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\"/>\n    <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n\n    <title>\n      Hypothesis: {{ page_title }}\n    </title>\n\n  {% for url in asset_urls(\"admin_css\") %}\n<link rel=\"stylesheet\" href=\"{{ url }}\">\n{% endfor %}\n\n    {% if request.sentry.get_public_dsn() %}\n      <script class=\"js-hypothesis-settings\" type=\"application/json\">\n        {\n          \"raven\": {\n            \"dsn\": \"{{ request.sentry.get_public_dsn('https') }}\",\n            \"release\": \"{{ h_version }}\"\n          }\n        }\n      </script>\n    {% endif %}\n  </head>\n  <body>\n    <nav class=\"navbar navbar-inverse navbar-fixed-top\">\n      <div class=\"container\">\n        <div class=\"navbar-header\">\n          <button type=\"button\" class=\"navbar-toggle collapsed\" data-toggle=\"collapse\" data-target=\"#navbar\" aria-expanded=\"false\" aria-controls=\"navbar\">\n            <span class=\"sr-only\">Toggle navigation</span>\n            <span class=\"icon-bar\"></span>\n            <span class=\"icon-bar\"></span>\n            <span class=\"icon-bar\"></span>\n          </button>\n          <a class=\"navbar-brand\" href=\"{{ request.route_url('admin_index') }}\">\n            Hypothesis Admin\n          </a>\n        </div>\n        <div id=\"navbar\" class=\"navbar-collapse collapse\">\n          <ul class=\"nav navbar-nav\">\n            {% for id, permission, title, children in nav_pages %}\n              {% if request.has_permission(permission) %}\n                {% if not children %}\n                  <li{% if id == page_id %} class=\"active\"{% endif %}>\n                    <a href=\"{{ request.route_url(permission) }}\">{{ title }}</a>\n                  </li>\n                {% else %}\n                  <li class=\"dropdown{% if id in page_id %} active{% endif %}\">\n                      <a href=\"#\" class=\"dropdown-toggle\" data-toggle=\"dropdown\" role=\"button\" aria-haspopup=\"true\" aria-expanded=\"false\">\n                      {{ title }}\n                      <span class=\"caret\"></span>\n                      </a>\n                      <ul class=\"dropdown-menu\">\n                        {% for id, url, title in children %}\n                          <li><a href=\"{{ request.route_url(url) }}\">{{ title }}</a></li>\n                        {% endfor %}\n                      </ul>\n                  </li>\n                {% endif %}\n              {% endif %}\n            {% endfor %}\n          </ul>\n        </div>\n      </div>\n    </nav>\n\n    <div class=\"container\">\n      <div class=\"row\">\n        <div class=\"col-md-12 main\">\n          {% include \"h:templates/includes/flashbar.html.jinja2\" %}\n          <h1 class=\"page-header\">{{ page_title }}</h1>\n          {% block content %}{% endblock %}\n        </div>\n      </div>\n    </div>\n\n    {% for url in asset_urls(\"admin_js\") %}\n    <script src=\"{{ url }}\"></script>\n    {% endfor %}\n    {% block scripts %}{% endblock %}\n  </body>\n</html>\n"},{"size":2993,"relativepath":"h/templates/layouts/base.html.jinja2","filename":"base.html.jinja2","extension":".jinja2","content":"{#- Controls the name of the default style bundle included on the page. -#}\n{%- set style_bundle = style_bundle|default('site_v2_css') -%}\n<!DOCTYPE html>\n<html lang=\"en\" prefix=\"og: http://ogp.me/ns#\">\n  <head>\n    {% block meta %}\n      <meta charset=\"UTF-8\" />\n      <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n      {% for attrs in meta_attrs -%}\n        <meta {% for key, value in attrs.items() %}{{ key }}=\"{{ value }}\" {% endfor %}/>\n      {% endfor -%}\n    {% endblock %}\n\n    <title>\n      {%- block title -%}\n        {%- if self.page_title %}{{self.page_title()}} | {% endif -%}\n        Hypothesis\n      {%- endblock -%}\n    </title>\n\n    {% if link_tags %}\n      {% for link in link_tags %}\n        <link rel=\"{{ link.rel }}\" type=\"{{ link.type }}\"\n              href=\"{{ link.href }}\"/>\n      {% endfor %}\n    {% endif %}\n\n    {% for attrs in link_attrs -%}\n      <link {% for key, value in attrs.items() %}{{ key }}=\"{{ value }}\" {% endfor %}/>\n    {% endfor -%}\n\n    {% block styles %}\n      {% for url in asset_urls(style_bundle) %}\n      <link rel=\"stylesheet\" href=\"{{ url }}\">\n      {% endfor %}\n    {% endblock %}\n\n    <link rel=\"apple-touch-icon\" sizes=\"152x152\"\n          href=\"{{ base_url }}assets/images/apple-touch-icon-152x152.png\">\n    <link rel=\"icon\" type=\"image/png\" sizes=\"16x16\"\n          href=\"{{ base_url }}assets/images/favicons/favicon-16x16.png\">\n    <link rel=\"icon\" type=\"image/png\" sizes=\"32x32\"\n          href=\"{{ base_url }}assets/images/favicons/favicon-32x32.png\">\n    <link rel=\"icon\" type=\"image/png\" sizes=\"96x96\"\n          href=\"{{ base_url }}assets/images/favicons/favicon-96x96.png\">\n    <link rel=\"icon\" type=\"image/png\" sizes=\"192x192\"\n          href=\"{{ base_url }}assets/images/favicons/android-chrome-192x192.png\">\n    <link rel=\"shortcut icon\"\n          href=\"{{ base_url }}assets/images/favicons/favicon.ico\">\n\n    {% if ga_tracking_id %}\n      <!-- Google Analytics -->\n      <script async src='//www.google-analytics.com/analytics.js'></script>\n      <script>\n       window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;\n       ga('create', 'UA-{{ga_tracking_id}}', '{{ga_cookie_domain}}');\n       {% block ga_pageview %}\n       ga('send', 'pageview');\n       {% endblock %}\n      </script>\n      <!-- End Google Analytics -->\n    {% endif %}\n\n    {% if request.sentry.get_public_dsn() %}\n      <script class=\"js-hypothesis-settings\" type=\"application/json\">\n        {\n          \"raven\": {\n            \"dsn\": \"{{ request.sentry.get_public_dsn('https') }}\",\n            \"release\": \"{{ h_version }}\"\n          }\n        }\n      </script>\n    {% endif %}\n\n    {% for url in asset_urls(\"header_js\") %}\n    <script src=\"{{ url }}\"></script>\n    {% endfor %}\n  </head>\n  <body class=\"body\">\n    {% block content %}{% endblock %}\n    {% block scripts %}\n    {% for url in asset_urls(\"site_js\") %}\n    <script src=\"{{ url }}\"></script>\n    {% endfor %}\n    {% endblock %}\n  </body>\n</html>\n"},{"size":1192,"relativepath":"h/templates/accounts/forgot_password.html.jinja2","filename":"forgot_password.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/base.html.jinja2\" %}\n\n{% if not feature('activity_pages') %}\n{% set style_bundle = 'legacy_site_css' %}\n{% endif %}\n\n{% block page_title %}\n{% if feature('activity_pages') %}\nReset your password\n{% else %}\nPassword reset\n{% endif %}\n{% endblock %}\n\n{% block content %}\n{%if feature('activity_pages') %}\n  {% include \"h:templates/includes/logo-header.html.jinja2\" %}\n  <div class=\"form-container content\">\n    <h1 class=\"form-header\">Reset your password</h1>\n    {{ form }}\n    <footer class=\"form-footer\">\n      Already know your password?\n      <a class=\"link\" href=\"{{ request.route_path('login') }}\">Log in</a>\n    </footer>\n  </div>\n{% else %}\n  <div class=\"content paper\">\n    {% include \"h:templates/includes/logo-header.html.jinja2\" %}\n    <div class=\"form-vertical\">\n      <ul class=\"nav nav-tabs\">\n        <li><a href=\"{{ request.route_path('login') }}\">Log in</a></li>{#\n        #}<li><a href=\"{{ request.route_path('signup') }}\">Create an account</a></li>{#\n        #}<li class=\"active\"><a href=\"{{ request.route_path('forgot_password') }}\">Password reset</a></li>\n      </ul>\n      {{ form }}\n    </div>\n  </div>\n{% endif %}\n{% endblock content %}\n"},{"size":203,"relativepath":"h/templates/accounts/profile.html.jinja2","filename":"profile.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/account.html.jinja2\" %}\n\n{% set page_route = 'account_profile' %}\n{% set page_title = 'Edit profile' %}\n\n{% block page_content %}\n  {{ form }}\n{% endblock page_content %}\n"},{"size":1546,"relativepath":"h/templates/accounts/account.html.jinja2","filename":"account.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/account.html.jinja2\" %}\n\n{% set page_route = 'account' %}\n{% set page_title = 'Account' %}\n\n{% block page_content %}\n  <div class=\"form-vertical\">\n    {% if not feature('activity_pages') -%}\n    <h2 class=\"form-heading\">\n      <span>{% trans %}Change your email address{% endtrans %}</span>\n    </h2>\n    <legend>\n      {% trans %}Your current email address is:{% endtrans %}\n      <strong>{{ email }}</strong>.\n    </legend>\n    {%- endif %}\n    {{ email_form }}\n\n    <h2 class=\"form-heading\">\n    {% if not feature('activity_pages') -%}\n      <span>{% trans %}Change your password{% endtrans %}</span>\n    {%- endif %}\n    </h2>\n    {{ password_form }}\n\n    {% if not feature('activity_pages') -%}\n    <h2 class=\"form-heading\">\n      <span>{% trans %}Delete account{% endtrans %}</span>\n    </h2>\n    {%- endif %}\n    {% if feature('activity_pages') -%}\n    <footer class=\"form-footer\">\n      {% trans %}\n        If you would like to delete your account, please email us at\n        <a class=\"link\" href=\"mailto:support@hypothes.is\">support@hypothes.is</a> from your\n        registered email address, and we'll take it from there.\n      {% endtrans %}\n    </footer>\n    {% else %}\n    <legend>\n      {% trans %}\n        If you would like to delete your account, please email us at\n        <a href=\"mailto:support@hypothes.is\">support@hypothes.is</a> from your\n        registered email address, and we'll take it from there.\n      {% endtrans %}\n    </legend>\n    {%- endif %}\n  </div>\n{% endblock page_content %}\n"},{"size":1125,"relativepath":"h/templates/accounts/signup.html.jinja2","filename":"signup.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/base.html.jinja2\" %}\n\n{% if not feature('activity_pages') %}\n{% set style_bundle = 'legacy_site_css' %}\n{% endif %}\n\n{% block page_title %}\n{% if feature('activity_pages') %}\nSign up for Hypothesis\n{% else %}\nCreate account\n{% endif %}\n{% endblock %}\n\n{% block content %}\n  {%if feature('activity_pages') %}\n    {% include \"h:templates/includes/logo-header.html.jinja2\" %}\n    <div class=\"form-container content\">\n      <h1 class=\"form-header\">Sign up for Hypothesis</h1>\n      {{ form }}\n      <footer class=\"form-footer\">\n        Already have an account?\n        <a class=\"link\" href=\"{{ request.route_path('login') }}\">Log in</a>\n      </footer>\n    </div>\n  {% else %}\n  <div class=\"content paper\">\n    {% include \"h:templates/includes/logo-header.html.jinja2\" %}\n    <div class=\"form-vertical\">\n      <ul class=\"nav nav-tabs\">\n        <li><a href=\"{{ request.route_path('login') }}\">Log in</a></li>{#\n        #}<li class=\"active\"><a href=\"{{ request.route_path('signup') }}\">Create an account</a></li>\n      </ul>\n      {{ form }}\n    </div>\n  </div>\n  {% endif %}\n{% endblock content %}\n"},{"size":248,"relativepath":"h/templates/accounts/session_invalid.html.jinja2","filename":"session_invalid.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/base.html.jinja2\" %}\n\n{% block page_title %}Invalid Session{% endblock %}\n\n{% block content %}\nSorry, but your session has expired.\nPlease <a href=\"{{ login_path }}\">go back</a> and try again.\n{% endblock content %}\n"},{"size":555,"relativepath":"h/templates/accounts/claim_account_legacy.html.jinja2","filename":"claim_account_legacy.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/base.html.jinja2\" %}\n\n{% set style_bundle = 'legacy_site_css' %}\n\n{% block page_title %}Claim account{% endblock page_title %}\n\n{% block content %}\n  <div id=\"claim\" class=\"content paper\">\n    {% include \"h:templates/includes/logo-header.html.jinja2\" %}\n    <p>\n      Sorry, your claim link has expired. If you still wish to claim a username\n      you reserved, please contact us at\n      <a href=\"mailto:support@hypothes.is?Subject=Claim%20my%20username\">\n        support@hypothes.is</a>.\n  </div>\n{% endblock content %}\n\n"},{"size":3097,"relativepath":"h/templates/accounts/developer.html.jinja2","filename":"developer.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/account.html.jinja2\" %}\n\n{% set page_route = 'account_developer' %}\n{% set page_title = 'Developer' %}\n\n{% block page_content %}\n  <div class=\"form-vertical\">\n    {% if not feature('activity_pages') -%}\n    <h2 class=\"form-heading\">\n      <span>{% trans %}Generate your API token{% endtrans %}</span>\n    </h2>\n    {% endif %}\n\n    {% if token %}\n      {% if feature('activity_pages') %}\n        <p class=\"form-help-text\">\n        <label for=\"token\">{% trans %}Your API token is:{% endtrans %}</label>\n        </p>\n        <input id=\"token\"\n               type=\"text\"\n               value=\"{{ token }}\"\n               readonly=\"readonly\"\n               class=\"api-token\">\n        <p class=\"form-help-text\">\n          Please keep your API token safe as it can be used to access your account.\n        </p>\n      {% else %}\n      <label for=\"token\">{% trans %}Your API token is:{% endtrans %}</label>\n      <input id=\"token\" type=\"text\" value=\"{{ token }}\" readonly=\"readonly\"\n             class=\"api-token-input\">\n      <span class=\"help-block\">\n        Please keep your API token safe as it can be used to access your\n        account.\n      </span>\n      {% endif %}\n    {% else %}\n      {% if not feature('activity_pages') -%}\n      <legend>\n        {% trans %}You haven't generated an API token yet.{% endtrans %}\n      </legend>\n      {%- endif %}\n    {% endif %}\n\n      <form method=\"POST\">\n        {% if feature('activity_pages') %}\n          {% if token %}\n            <button type=\"submit\" class=\"btn\"\n                    title=\"{% trans %}Delete your API token and generate a new one{% endtrans%}\">\n              Regenerate your API token\n            </button>\n          {% else %}\n            <button type=\"submit\" class=\"btn btn-primary\">\n              {% trans %}Generate your API token{% endtrans %}\n            </button>\n          {% endif %}\n        {% else %}\n        <div class=\"form-actions\">\n          <div class=\"form-actions-buttons\">\n\n    {% if token %}\n            <button type=\"submit\" class=\"btn btn-danger\"\n                    title=\"{% trans %}Delete your API token and generate a new one{% endtrans%}\">\n              Regenerate your API token\n            </button>\n    {% else %}\n            <button type=\"submit\" class=\"btn btn-primary\">\n              {% trans %}Generate your API token{% endtrans %}\n            </button>\n    {% endif %}\n          </div>\n        </div>\n        {% endif %}\n      </form>\n      {% if feature('activity_pages') -%}\n      <footer class=\"form-footer\">\n        You can learn more about the Hypothesis API at\n        <a class=\"link\" href=\"https://h.readthedocs.io/en/latest/api.html\">h.readthedocs.io/en/latest/api.html</a>\n      </footer>\n      {% else %}\n      <h2 class=\"form-heading\">\n        <span>{% trans %}API documentation{% endtrans %}</span>\n      </h2>\n      <legend>\n        You can learn more about the Hypothesis API at\n        <a href=\"https://h.readthedocs.io/en/latest/api.html\">h.readthedocs.io/en/latest/api.html</a>.\n      </legend>\n      {%- endif %}\n  </div>\n{% endblock page_content %}\n"},{"size":555,"relativepath":"h/templates/accounts/notifications.html.jinja2","filename":"notifications.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/account.html.jinja2\" %}\n\n{% if not feature('activity_pages') %}\n{% set style_bundle = 'legacy_site_css' %}\n{% endif %}\n\n{% set page_route = 'account_notifications' %}\n{% set page_title = 'Notifications' %}\n\n{% block page_content %}\n  {% if feature('activity_pages') %}\n    {{ form }}\n  {% else %}\n    <div class=\"form-vertical\">\n      <h2 class=\"form-heading\">\n        <span>{% trans %}Update your notification settings{% endtrans %}</span>\n      </h2>\n      {{ form }}\n    </div>\n  {% endif %}\n{% endblock page_content %}\n"},{"size":1048,"relativepath":"h/templates/accounts/login.html.jinja2","filename":"login.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/base.html.jinja2\" %}\n\n{% if not feature('activity_pages') %}\n{% set style_bundle = 'legacy_site_css' %}\n{% endif %}\n\n{% block page_title %}Log in{% endblock %}\n\n{% block content %}\n  {%if feature('activity_pages') %}\n    {% include \"h:templates/includes/logo-header.html.jinja2\" %}\n    <div class=\"form-container content\">\n      <h1 class=\"form-header\">Log in</h1>\n      {{ form }}\n      <footer class=\"form-footer\">\n        Don't have a Hypothesis account?\n        <a class=\"link\" href=\"{{ request.route_path('signup') }}\">Sign up</a>\n      </footer>\n    </div>\n  {% else %}\n    <div class=\"content paper\">\n      {% include \"h:templates/includes/logo-header.html.jinja2\" %}\n      <div class=\"form-vertical\">\n        <ul class=\"nav nav-tabs\">\n          <li class=\"active\"><a href=\"{{ request.route_path('login') }}\">Log in</a></li>{#\n          #}<li><a href=\"{{ request.route_path('signup') }}\">Create an account</a></li>\n        </ul>\n        {{ form }}\n      </div>\n    </div>\n  {% endif %}\n{% endblock content %}\n"},{"size":1728,"relativepath":"h/templates/accounts/reset.html.jinja2","filename":"reset.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/base.html.jinja2\" %}\n\n{% if not feature('activity_pages') %}\n{% set style_bundle = 'legacy_site_css' %}\n{% endif %}\n\n{% block page_title %}\n{% if feature('activity_pages') %}\nReset your password\n{% else %}\nPassword reset\n{% endif %}\n{% endblock %}\n\n{% block content %}\n  {% if feature('activity_pages') %}\n  {% include \"h:templates/includes/logo-header.html.jinja2\" %}\n  <div class=\"form-container content\">\n    <h1 class=\"form-header\">New password</h1>\n    {% if not has_code %}\n    <div class=\"form-description\">\n    {% trans %}\n    Please check your email. We've sent you a reset code that you must enter\n    below in order to set your new password.\n    {% endtrans %}\n    </div>\n    {% endif %}\n    {{ form }}\n    <footer class=\"form-footer\">\n      Already know your password?\n      <a class=\"link\" href=\"{{ request.route_path('login') }}\">Log in</a>\n    </footer>\n  </div>\n  {% else %}\n  <div class=\"content paper\">\n    {% include \"h:templates/includes/logo-header.html.jinja2\" %}\n    <div class=\"form-vertical\">\n      <ul class=\"nav nav-tabs\">\n        <li><a href=\"{{ request.route_path('login') }}\">Log in</a></li>{#\n        #}<li><a href=\"{{ request.route_path('signup') }}\">Create an account</a></li>{#\n        #}<li class=\"active\"><a href=\"\">New password</a></li>\n      </ul>\n      {% if not has_code %}\n      <legend>\n        {% trans %}\n        When you reset your password, we will send you an email containing a\n        code you can use to complete the process. Please check your email and\n        retrieve the code in order to set your new password.\n        {% endtrans %}\n      </legend>\n      {% endif %}\n      {{ form }}\n    </div>\n  </div>\n  {% endif %}\n{% endblock content %}\n"},{"size":1960,"relativepath":"h/templates/5xx.html.jinja2","filename":"5xx.html.jinja2","extension":".jinja2","content":"<!DOCTYPE html>\n<html>\n  <head>\n      <meta charset=\"UTF-8\" />\n      <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\"/>\n      <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n      <title>Server Error</title>\n      <style>\n        body {\n          font-family: \"Helvetica Neue\",Helvetica,Arial,\"Lucida Grande\",sans-serif;\n          font-weight: 300;\n          color: #585858;\n          background: #fff url(/assets/images/noise_1.png);\n        }\n\n        h1 {\n          font-size: 1.991em;\n          padding: 0.5em 0 0;\n          font-weight: 400;\n          text-align: center;\n        }\n\n        p {\n          line-height: 1.5;\n          margin: .618em 0;\n          text-align: center;\n        }\n\n        a {\n          text-decoration: underline;\n          color: #bd5862;\n          text-decoration: none;\n        }\n\n        main {\n          margin-left: auto;\n          margin-right: auto;\n          background: #fff;\n          border: 1px solid #d3d3d3;\n          border-radius: 2px;\n          padding: 2em 2em 3em;\n        }\n\n        @media only screen and (max-width: 1024px) and (min-width: 767px) {\n          main {\n            padding: 2em 4em 3em;\n            margin: auto;\n            max-width: 768px;\n          }\n        }\n\n        #graphic {\n          display: block;\n          width: 200px;\n          margin: auto;\n        }\n      </style>\n  </head>\n  <body>\n  <main class=\"content paper styled-text page\">\n    <img id=\"graphic\" src=\"/assets/images/sad-annotation.svg\" />\n    <h1>Uh-oh, something went wrong!</h1>\n    <p>We&rsquo;re very sorry, our application wasn&rsquo;t able to load this page. The\n       team has been notified and we&rsquo;ll&nbsp;fix&nbsp;it&nbsp;shortly.</p>\n    <p>If the problem persists or you'd like more information please contact&nbsp;<a href=\"mailto:support@hypothes.is?subject=Internal%20Server%20Error%20on%20Hypothes.is\">support@hypothes.is</a>.</p>\n  </main>\n  </body>\n</html>\n"},{"size":810,"relativepath":"h/templates/notfound.html.jinja2","filename":"notfound.html.jinja2","extension":".jinja2","content":"{% extends \"layouts/base.html.jinja2\" %}\n\n{% set style_bundle = 'legacy_site_css' %}\n\n{% block title %}Page Not Found{% endblock %}\n\n{% block content %}\n  <main class=\"content paper styled-text page\">\n    <h1>There&rsquo;s nothing here!</h1>\n    <p>Either this page doesn&rsquo;t exist, or you don&rsquo;t have the permissions required for viewing it.</p>\n    <form class=\"form\" action=\"/stream\" method=\"get\">\n      <div class=\"form-field\">\n        <label class=\"form-label\" for=\"search\">Search annotations:</label>\n        <input class=\"form-input\" name=\"q\" type=\"text\" />\n        <div class=\"form-actions\">\n          <div class=\"form-actions-buttons\">\n            <button class=\"btn btn-primary\" type=\"submit\">Search</button>\n          </div>\n        </div>\n      </div>\n    </form>\n  </main>\n{% endblock %}\n"},{"size":359,"relativepath":"h/templates/includes/logo-header.html.jinja2","filename":"logo-header.html.jinja2","extension":".jinja2","content":"<header class=\"masthead\">\n  {% if feature('activity_pages') %}\n  <a href=\"/\" title=\"Hypothesis homepage\"><!--\n    !--><img alt=\"Hypothesis logo\" class=\"masthead-logo\" src=\"/assets/images/logo.svg\"></a>\n  {% else %}\n  <hgroup>\n\t<a href=\"https://hypothes.is\" class=\"masthead-heading\">Hypothes<span class=\"red\">.</span>is</a>\n  </hgroup>\n  {% endif %}\n</header>\n"},{"size":1650,"relativepath":"h/templates/includes/paginator.html.jinja2","filename":"paginator.html.jinja2","extension":".jinja2","content":"<nav>\n  <ul class=\"pager\">\n    {% if page.prev is none %}\n      <li>\n        <span class=\"pager__item pager__item--begin is-disabled\" aria-hidden=\"true\">\n          {{ svg_icon('pagination-left') }}\n        </span>\n      </li>\n    {% else %}\n      <li>\n        <a class=\"pager__item pager__item--begin pager__item--link\"\n          href=\"{{ page.url_for(page.prev) }}\"\n          aria-label=\"{% trans %}Go to previous page{% endtrans %}\">\n          {{ svg_icon('pagination-left') }}\n        </a>\n      </li>\n    {% endif %}\n    {% for n in page.numbers %}\n      {% if n == page.cur %}\n        <li>\n          <span class=\"pager__item is-highlighted\"\n            aria-label=\"Page {{ n }}\">\n            {{ n }}\n          </span>\n        </li>\n      {% elif n == '...' %}\n        <li>\n          <span class=\"pager__item pager__item--more is-disabled\">\n            &#133;\n          </span>\n        </li>\n      {% else %}\n        <li>\n          <a class=\"pager__item pager__item--link\"\n            href=\"{{ page.url_for(n) }}\"\n            aria-label=\"Go to page {{ n }}\">\n            {{ n }}\n          </a>\n        </li>\n      {% endif %}\n    {% endfor %}\n    {% if page.next is none %}\n      <li>\n        <span class=\"pager__item pager__item--end is-disabled\" aria-hidden=\"true\">\n          {{ svg_icon('pagination-right') }}\n        </span>\n      </li>\n    {% else %}\n      <li>\n        <a class=\"pager__item pager__item--end pager__item--link\"\n          href=\"{{ page.url_for(page.next) }}\"\n          aria-label=\"{% trans %}Go to next page{% endtrans %}\">\n          {{ svg_icon('pagination-right') }}\n        </a>\n      </li>\n    {% endif %}\n  </ul>\n</nav>\n"},{"size":528,"relativepath":"h/templates/includes/flashbar.html.jinja2","filename":"flashbar.html.jinja2","extension":".jinja2","content":"{%- set flash_types = [\n  ('error', 'danger'),\n  ('info', 'info'),\n  ('warning', 'warning'),\n  ('success', 'success'),\n] -%}\n<div class=\"flashbar\">\n  {% for flashkey, classname in flash_types %}\n    {% for message in request.session.pop_flash(flashkey) %}\n      <div class=\"alert alert-{{ classname }} alert-dismissable\" role=\"alert\">\n\t<button type=\"button\" class=\"close\" data-dismiss=\"alert\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></button>\n\t{{ message }}\n      </div>\n    {% endfor %}\n  {% endfor %}\n</div>\n"},{"size":1193,"relativepath":"h/templates/includes/dropdown_menu.html.jinja2","filename":"dropdown_menu.html.jinja2","extension":".jinja2","content":"{#\n  Dropdown menu component.\n\n  Render a dropdown menu and the link that opens and closes it.\n\n  Usage:\n    {% call dropdown_menu(items, title='Menu') %}\n      <a href=\"/link-used-if-JS-is-inactive\">Menu</a>\n    {% endcall %}\n\n  :param items: List of items to include in the menu\n  :param title: Title to display at the top of the menu\n  :param footer_item: Optional item to display at the bottom of the menu,\n                      visually separated from the rest of the menu items\n#}\n{% macro dropdown_menu(items, title='', footer_item=None) -%}\n<div class=\"dropdown-menu js-dropdown-menu\">\n  <span data-ref=\"dropdownMenuToggle\">\n    {{ caller() }}\n  </span>\n  <div class=\"dropdown-menu__menu\" data-ref=\"dropdownMenuContent\">\n    <h2 class=\"dropdown-menu__title\">{{ title }}</h2>\n    <ul>\n      {% for item in items %}\n      <li>\n        <a class=\"dropdown-menu__item\" href=\"{{ item.link }}\">{{ item.title }}</a>\n      </li>\n      {% endfor %}\n      {% if footer_item %}\n      <li>\n        <a class=\"dropdown-menu__item dropdown-menu__item--footer\"\n           href=\"{{ footer_item.link }}\">{{ footer_item.title }}</a>\n      </li>\n      {% endif %}\n    </ul>\n  </div>\n</div>\n{%- endmacro %}\n"},{"size":281,"relativepath":"h/templates/includes/bookmarklet.html.jinja2","filename":"bookmarklet.html.jinja2","extension":".jinja2","content":"  <a class=\"bookmarklet\"\n   title=\"Drag this to your bookmarks\"\n   onclick=\"alert('Drag this to your bookmarks bar first');return false\"\n   href=\"javascript:{% filter urlencode %}{% include \"../bookmarklet.js.jinja2\" %}{% endfilter %}\"><i class=\"h-icon-bookmark\"></i> Annotate</a>\n"},{"size":724,"relativepath":"h/templates/includes/annotation_card.html.jinja2","filename":"annotation_card.html.jinja2","extension":".jinja2","content":"{% macro annotation_card(annotation, request) -%}\n\n<li class=\"annotation-card\">\n  <header class=\"annotation-card__header\">\n    <a href=\"{{ request.route_url('stream') }}?q=user:{{ annotation.username }}\"\n      class=\"annotation-card__username\">\n      {{ annotation.username }}\n    </a>\n    <a href=\"{{ request.route_url('annotation', id=annotation.id) }}\"\n      class=\"annotation-card__timestamp\">\n      {{ annotation.updated.strftime('%d %b %Y') }}\n    </a>\n  </header>\n  {% if annotation.quote %}\n    <section class=\"annotation-card__quote\">\n      {{ annotation.quote|safe }}\n    </section>\n  {% endif %}\n  <section class=\"annotation-card__text\">\n    {{ annotation.text_rendered|safe }}\n  </section>\n</li>\n{%- endmacro %}\n"},{"size":1270,"relativepath":"h/templates/atom.xml.jinja2","filename":"atom.xml.jinja2","extension":".jinja2","content":"{# Generic template for rendering an Atom feed given a feed dict.\n\nThe feed dict should be a logical representation of an Atom feed as a Python\ndict, including a list of dicts for the feed's entries. This template will\nrender the feed to Atom XML.\n\n-#}\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\n  <id>{{ feed.id }}</id>\n  <title>{{ feed.title }}</title>\n  <subtitle>{{ feed.subtitle }}</subtitle>\n  <updated>{{ feed.updated }}</updated>\n\n  {% for link in feed.links %}\n  <link rel=\"{{ link.rel }}\"{% if link.type %} type=\"{{ link.type }}\"{% endif %} href=\"{{ link.href }}\" />\n  {% endfor %}\n\n  {% for entry in feed.entries %}\n  <entry>\n    <id>{{ entry.id }}</id>\n    <title>{{ entry.title }}</title>\n    <updated>{{ entry.updated }}</updated>\n    <published>{{ entry.published }}</published>\n    <author>\n      <name>{{ entry.author.name }}</name>\n    </author>\n    {% for link in entry.links %}\n    <link rel=\"{{ link.rel }}\"{% if link.type %} type=\"{{ link.type }}\"{% endif %} href=\"{{ link.href }}\" />\n    {% endfor %}\n    <content type=\"html\">\n        {# This is already HTML-escaped in Python, so we don't escape it again\n           here. #}\n        {{ entry.content|safe }}\n    </content>\n  </entry>\n  {% endfor %}\n</feed>\n"},{"size":6568,"relativepath":"h/templates/help.html.jinja2","filename":"help.html.jinja2","extension":".jinja2","content":"{% extends \"layouts/base.html.jinja2\" %}\n\n{% set style_bundle = 'help_page_css' %}\n\n{% block meta %}\n  <link href='//fonts.googleapis.com/css?family=Lato:400,300' rel='stylesheet' type='text/css'>\n  {{ super() }}\n  <script type=\"application/json\" class=\"js-hypothesis-config\">\n    {\n      \"firstRun\": true, {# TODO: remove after 2016-09-01, by which time old clients will be gone. #}\n      \"openSidebar\": true,\n      \"openLoginForm\": true\n    }\n  </script>\n  {% if not is_onboarding %}\n    <script async defer src=\"{{ embed_js_url }}\"></script>\n  {% endif %}\n{% endblock %}\n\n{% block content %}\n  <div class=\"help-page\">\n    <div class=\"help-page-content masthead-small\">\n      {% include \"includes/logo-header.html.jinja2\" %}\n    </div>\n    <article class=\"help-page-content\">\n      {% if is_help %}\n        <section class=\"help-page-section\">\n          <h2 id=\"installation\" class=\"help-page-heading\">Installation</h2>\n          <p class=\"help-page-lede\">There are a couple of installations of Hypothesis to choose from:</p>\n          <div class=\"numbered-list grid\">\n            <div class=\"column-desktop-1-2\"><div class=\"numbered-list-item\">If you want to annotate and comment on documents then install our <a href=\"https://chrome.google.com/webstore/detail/hypothesis-web-pdf-annota/bjfhmglciegochdpefhhlphglcehbmek\">browser extension</a>.</div></div>\n            <div class=\"column-desktop-1-2\"><div class=\"numbered-list-item\">If you wish to install Hypothesis on your own site then head over to GitHub.</div></div>\n          </div>\n        </section>\n      {% endif %}\n      {% if is_onboarding %}\n        <section class=\"help-page-section\">\n          <h2 id=\"getting-started\" class=\"help-page-heading\">Getting started</h2>\n          <p class=\"help-page-lede\">Now you have the extension up and running. It's time to\n            start annotating some documents.</p>\n          <div class=\"numbered-list grid\">\n            <div class=\"column-desktop-1-2\"><div class=\"numbered-list-item\">Create an account using the sidebar on the right of the screen.</div></div>\n            <div class=\"column-desktop-1-2\"><div class=\"numbered-list-item\">Go forth and annotate! Enable the sidebar via the button in the location bar.</div></div>\n          </div>\n        </section>\n      {% endif %}\n      <section class=\"help-page-section\">\n        <h2 id=\"key-features\" class=\"help-page-heading\">Annotation Types</h2>\n        <p class=\"help-page-lede\">There are a few types of annotations that can be created\n          with the application:</p>\n        <div class=\"feature-content\">\n          <section class=\"feature\">\n            <h3 class=\"feature-heading\"><i class=\"feature-icon h-icon-insert-comment\"></i> Notes</h3>\n            <div class=\"feature-content styled-text\">\n              <p>Create a <em>note</em> by selecting some text and clicking the <i class=\"help-icon h-icon-insert-comment\"></i> button</p>\n            </div>\n          </section>\n          <section class=\"feature\">\n            <h3 class=\"feature-heading\"><i class=\"feature-icon h-icon-border-color\"></i> Highlights</h3>\n            <div class=\"feature-content\">\n              <p><em>Highlights</em> can be created by clicking the <i class=\"help-icon h-icon-border-color\"></i> button.\n              Try it on this sentence.</p>\n            </div>\n          </section>\n          <section class=\"feature\">\n            <h3 class=\"feature-heading\"><i class=\"feature-icon h-icon-reply\"></i> Replies</h3>\n            <div class=\"feature-content\">\n              <p>You can  <em>reply</em> to any annotation by using the <i class=\"help-icon h-icon-reply\"></i> reply action\n                on every card.</p>\n            </div>\n          </section>\n        </div>\n      </section>\n      <section class=\"help-page-section\">\n        <h2 id=\"key-features\" class=\"help-page-heading\">Privacy</h2>\n        <p class=\"help-page-lede\">Annotations are either public and visible to everyone\n          or private and visible only to you.</p>\n        <div class=\"grid feature-content\">\n          <section class=\"feature column-desktop-1-2\">\n            <h3 class=\"feature-heading\"><i class=\"feature-icon h-icon-public\"></i> Public</h3>\n            <div class=\"feature-content styled-text\">\n              <p>These annotations are visible to everyone both in the\n                document itself and our <a\n                href=\"{{request.route_url('stream')}}\">public stream</a>.</p>\n            </div>\n          </section>\n          <section class=\"feature column-desktop-1-2\">\n            <h3 class=\"feature-heading\"><i class=\"feature-icon h-icon-lock\"></i> Private</h3>\n            <div class=\"feature-content\">\n              <p>Private annotations are visible only to you when logged in.</p>\n            </div>\n          </section>\n        </div>\n      </section>\n      <section class=\"help-page-section\">\n        <section class=\"feature\">\n          <h3 class=\"feature-heading\"><i class=\"feature-icon h-icon-visibility\"></i>Show/Hide Highlights</h3>\n          <p class=\"feature-content\">Use the <i class=\"help-icon h-icon-visibility\"></i> button to toggle highlight visibility on a page.</p>\n        </section>\n        <section class=\"feature\">\n          <h3 class=\"feature-heading\"><i class=\"feature-icon h-icon-share\"></i>Sharing a page</h3>\n          <div class=\"feature-content\">\n            <p>Use the <i class=\"help-icon h-icon-share\"></i> button to get a sharable link to the page with annotations.</p>\n          </div>\n        </section>\n      </section>\n      <section class=\"help-page-section\">\n        <h2 class=\"help-page-heading\">Resources</h2>\n        <div class=\"styled-text\">\n          <ul>\n            <li>View the <a href=\"https://hypothes.is/roadmap/\">product roadmap</a> to check out what we're working on.</li>\n            <li>Request features, report bugs and meet other users in our <a href=\"https://groups.google.com/forum/#!forum/hypothesis-forum\">discussion forums</a>.</li>\n            <li>If you need help please don't hesitate to <a href=\"mailto:support@hypothes.is\">get in touch</a>.</li>\n            <li>Visit <a href=\"https://hypothes.is/about/\">our website</a> to learn more about the project.</li>\n            <li>Check out the code on <a href=\"https://github.com/hypothesis/h\">GitHub</a>.</li>\n          </ul>\n        </div>\n      </section>\n    </article>\n    <div class=\"help-page-sidebar\">\n      <div id=\"help-1\">\n        <p>Show and hide the sidebar using the <i class=\"h-icon-chevron-left\"></i> button</p>\n      </div>\n      <div id=\"help-2\"></div>\n    </div>\n  </div>\n{% endblock %}\n"},{"size":2984,"relativepath":"h/templates/activity/search.html.jinja2","filename":"search.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/base.html.jinja2\" %}\n\n{% from '../includes/annotation_card.html.jinja2' import annotation_card %}\n\n{# Card displaying statistics about a bucket of annotations. #}\n{% macro search_bucket_stats(bucket) %}\n<div class=\"search-bucket-stats\">\n  {% if bucket.uri %}\n    <div class=\"search-bucket-stats__key\">\n        Address\n    </div>\n    <div class=\"search-bucket-stats__val search-bucket-stats__address\">\n        {{ bucket.uri }}\n    </div>\n  {% endif %}\n  {% if bucket.tags %}\n    <div class=\"search-bucket-stats__key\">\n      Tags\n    </div>\n    <ul class=\"search-bucket-stats__val\">\n      {% for tag in bucket.tags %}\n        <li>{{ tag }}</li>\n      {% endfor %}\n    </ul>\n  {% endif %}\n  <div class=\"search-bucket-stats__key\">\n    Annotators\n  </div>\n  <ul class=\"search-bucket-stats__val\">\n    {% for user in bucket.users %}\n      <li class=\"search-bucket-stats__username\">\n        {{ user.split(':')[1].split('@')[0] }}\n      </li>\n    {% endfor %}\n  </ul>\n</div>\n{% endmacro %}\n\n{#\n  A collapsible bucket/group of annotations\n#}\n{% macro search_result_bucket(bucket) %}\n<div class=\"search-result-bucket js-search-bucket\">\n\n  {# The header is the clickable area that expands/collapses the bucket when\n     clicked #}\n  <div class=\"search-result-bucket__header\" data-ref=\"header\">\n    <div class=\"search-result-bucket__domain\">\n      {{ bucket.domain }}\n    </div>\n    <div class=\"search-result-bucket__title-and-annotations-count\">\n        <div class=\"search-result-bucket__title\">\n        {% if bucket.title %}\n            {{ bucket.title }}\n        {% else %}\n            {% trans %}Untitled document{% endtrans %}\n        {% endif %}\n        </div>\n        <div class=\"search-result-bucket__annotations-count\">\n        <div class=\"search-result-bucket__annotations-count-container\">\n            {{ bucket.annotations_count }}\n        </div>\n    </div>\n    </div>\n  </div>\n\n  {# The content is the area that appears / disappears on expand / collapse. #}\n  <div class=\"search-result-bucket__content\">\n    <div class=\"search-result-bucket__annotation-cards-container\" data-ref=\"content\">\n      <ol class=\"search-result-bucket__annotation-cards\">\n        {% for result in bucket.annotations %}\n          {{ annotation_card(result.annotation, request) }}\n        {% endfor %}\n      </ol>\n      {{ search_bucket_stats(bucket) }}\n    </div>\n  </div>\n</div>\n{% endmacro %}\n\n{% block content %}\n\n  {{ panel('navbar') }}\n\n  <div class=\"search-result-container\">\n    <ol class=\"search-result-list\">\n      {% for timeframe in timeframes %}\n        <li class=\"search-result__timeframe\">\n          {{ timeframe.label }}\n        </li>\n        <li>\n          {% for bucket in timeframe.document_buckets.values() %}\n            {{ search_result_bucket(bucket) }}\n          {% endfor %}\n        </li>\n      {% endfor %}\n    </ol>\n  </div>\n\n  {% if page and page.max > 1 %}\n    {% include \"h:templates/includes/paginator.html.jinja2\" %}\n  {% endif %}\n{% endblock %}\n"},{"size":1591,"relativepath":"h/templates/embed.js.jinja2","filename":"embed.js.jinja2","extension":".jinja2","content":"(function () {\n// Detect presence of Hypothesis in the page\nvar appLinkEl = document.querySelector('link[type=\"application/annotator+html\"]');\nif (appLinkEl) {\n  return {\n    installedURL: appLinkEl.href,\n  };\n}\n\nfunction injectStylesheet(href) {\n  var link = document.createElement('link');\n  link.rel = 'stylesheet';\n  link.type = 'text/css';\n  link.href = href;\n  document.head.appendChild(link);\n};\n\nfunction injectScript(src) {\n  var script = document.createElement('script');\n  script.type = 'text/javascript';\n  script.src = src;\n\n  // Set 'async' to false to maintain execution order of scripts.\n  // See https://developer.mozilla.org/en-US/docs/Web/HTML/Element/script\n  script.async = false;\n  document.head.appendChild(script);\n};\n\n/** Fetch the resources for the Hypothesis client. */\nfunction install() {\n  var resources = [];\n  if (typeof window.Annotator === 'undefined') {\n    {%- for url in inject_resource_urls %}\n    resources.push('{{ url | safe }}');\n    {%- endfor %}\n  }\n\n  resources.forEach(function (url) {\n    if (url.match(/\\.css/)) {\n      injectStylesheet(url);\n    } else {\n      injectScript(url);\n    }\n  });\n}\n\n// Register the URL of the sidebar app which the Hypothesis client should load.\n// The <link> tag is also used by browser extensions etc. to detect the\n// presence of the Hypothesis client on the page.\nvar baseUrl = document.createElement('link');\nbaseUrl.rel = 'sidebar';\nbaseUrl.href = '{{ app_html_url }}';\nbaseUrl.type = 'application/annotator+html';\ndocument.head.appendChild(baseUrl);\n\ninstall();\n\nreturn {installedURL: baseUrl.href};\n})();\n"},{"size":1456,"relativepath":"h/templates/admin/admins.html.jinja2","filename":"admins.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/admin.html.jinja2\" %}\n\n{% set page_id = 'admins' %}\n{% set page_title = 'Administrators' %}\n\n{% block content %}\n  <p>\n    On this page you can give users admin privileges! Admin privileges are\n    powerful, so please be careful who you give them to.\n  </p>\n\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h3 class=\"panel-title\">Add an admin</h3>\n    </div>\n    <div class=\"panel-body\">\n      <form method=\"POST\" class=\"form-inline\">\n        <div class=\"form-group\">\n          <label for=\"add\">Username</label>\n          <input type=\"text\" class=\"form-control\" name=\"add\">\n          <input type=\"submit\" class=\"btn btn-default\" value=\"Add\">\n        </div>\n      </form>\n    </div>\n  </div>\n\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h3 class=\"panel-title\">Current administrators</h3>\n    </div>\n    <div class=\"panel-body\">\n      <form\n        method=\"POST\" \n        action=\"{{ request.route_url('admin_admins') }}\">\n        <ul>\n          {% for user in admin_users %}\n            <li>\n              {{ user }}\n              {% if admin_users|length > 1 %}\n                <button type=\"submit\" class=\"btn btn-link btn-sm\"\n                        name=\"remove\" value=\"{{ user }}\">\n                  Remove\n                </button>\n              {% endif %}\n            </li>\n          {% endfor %}\n        </ul>\n      </form>\n    </div>\n  </div>\n{% endblock %}\n"},{"size":1835,"relativepath":"h/templates/admin/edit_cohort.html.jinja2","filename":"edit_cohort.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/admin.html.jinja2\" %}\n\n{% set page_id = 'features.cohorts.edit' %}\n{% set page_title = 'Edit Cohort ' + cohort.name  %}\n\n{% block content %}\n  <p>\n    Users currently belonging to cohort {{ cohort.name }}\n  </p>\n  <p>\n    Back to <a href=\"{{ request.route_url('admin_cohorts') }}\">Feature flag cohorts</a>\n  </p>\n\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h3 class=\"panel-title\">Add user to cohort {{ cohort.name }}</h3>\n    </div>\n    <div class=\"panel-body\">\n      <form method=\"POST\"\n            class=\"form-inline\"\n            action=\"{{ request.route_url('admin_cohorts_edit', id=cohort.id) }}\">\n        <div class=\"form-group\">\n          <label for=\"add\">Username</label>\n          <input type=\"hidden\" name=\"cohort\" value=\"{{ cohort.id }}\">\n          <input type=\"text\" class=\"form-control\" name=\"add\">\n          <input type=\"submit\" class=\"btn btn-default\" value=\"Add\">\n        </div>\n      </form>\n    </div>\n  </div>\n\n\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h3 class=\"panel-title\">Members</h3>\n    </div>\n    <div class=\"panel-body\">\n      {% if members %}\n        <form method=\"POST\" action=\"{{ request.route_url('admin_cohorts_edit', id=cohort.id) }}\">\n          <input type=\"hidden\" name=\"cohort\" value=\"{{ cohort.id }}\">\n          <ul>\n            {% for user in members %}\n              <li>\n                {{ user.username }}\n                <button type=\"submit\" class=\"btn btn-link btn-sm\"\n                        name=\"remove\" value=\"{{ user.username }}\">\n                  Remove\n                </button>\n              </li>\n            {% endfor %}\n          </ul>\n        </form>\n      {% else %}\n        <p><em>This cohort has no members&hellip;</em></p>\n      {% endif %}\n    </div>\n  </div>\n\n{% endblock %}\n"},{"size":1334,"relativepath":"h/templates/admin/cohorts.html.jinja2","filename":"cohorts.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/admin.html.jinja2\" %}\n\n{% set page_id = 'features.cohorts' %}\n{% set page_title = 'Feature Cohorts' %}\n\n{% block content %}\n  <p>\n    On this page you can see a list of all the feature cohorts.\n  </p>\n\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h3 class=\"panel-title\">Create a feature cohort</h3>\n    </div>\n    <div class=\"panel-body\">\n      <form method=\"POST\" class=\"form-inline\">\n        <div class=\"form-group\">\n          <label for=\"add\">Feature cohort name</label>\n          <input type=\"text\" class=\"form-control\" name=\"add\">\n          <input type=\"submit\" class=\"btn btn-default\" value=\"Add\">\n        </div>\n      </form>\n    </div>\n  </div>\n\n  <div class=\"table-responsive\">\n    <table class=\"table table-striped\">\n      <thead>\n        <tr>\n          <th>Name</th>\n          <th>Members</th>\n        </tr>\n      </thead>\n      <tbody>\n        {% for cohort in results %}\n          <tr>\n            <td>\n              <a href=\"{{ request.route_url('admin_cohorts_edit', id=cohort.id) }}\">\n                {{ cohort.name }}\n              </a>\n            </td>\n            <td>{{ cohort.members|length }}</td>\n          </tr>\n        {% endfor %}\n      </tbody>\n    </table>\n  </div>\n\n  {% include \"h:templates/includes/paginator.html.jinja2\" %}\n{% endblock %}\n"},{"size":1982,"relativepath":"h/templates/admin/badge.html.jinja2","filename":"badge.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/admin.html.jinja2\" %}\n\n{% set page_id = 'badge' %}\n{% set page_title = 'Chrome extension badge' %}\n\n{% block content %}\n  <p>\n    This page lets you edit the list of URIs on which the Chrome extension will\n    never show a number on its browser button badge.\n  </p>\n\n  <p>\n    The URIs that you enter here are\n    <a href=\"http://www.postgresql.org/docs/9.4/static/functions-matching.html\">\n    PostgreSQL <code>LIKE</code> patterns</a>. For example to block all pages\n    on <code>http://example.com/</code> use <code>%//example.com%</code>.\n    If a URI that you want to block contains one of the <code>LIKE</code>\n    special characters (<code>%</code> or <code>_</code>), say <code>_</code>,\n    you can backslash-escape it in your pattern: <code>\\_</code>.\n  </p>\n\n  </ul>\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h3 class=\"panel-title\">Add a URI</h3>\n    </div>\n    <div class=\"panel-body\">\n      <form method=\"POST\" class=\"form-inline\">\n        <div class=\"form-group\">\n          <label for=\"add\">URI</label>\n          <input type=\"text\" class=\"form-control\" name=\"add\">\n          <input type=\"submit\" class=\"btn btn-default\" value=\"Add\">\n        </div>\n      </form>\n    </div>\n  </div>\n\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h3 class=\"panel-title\">Remove a URI</h3>\n    </div>\n    <div class=\"panel-body\">\n      {% if uris %}\n      <form\n        method=\"POST\"\n        action=\"{{ request.route_url('admin_badge') }}\">\n        <ul>\n          {% for uri in uris %}\n            <li>\n              {{ uri }}\n              <button type=\"submit\" class=\"btn btn-link btn-sm\"\n                      name=\"remove\" value=\"{{ uri }}\">\n                Remove\n              </button>\n            </li>\n          {% endfor %}\n        </ul>\n      </form>\n      {% else %}\n        <p><em>No URIs are currently blocked&hellip;</em></p>\n      {% endif %}\n    </div>\n  </div>\n{% endblock %}\n"},{"size":1670,"relativepath":"h/templates/admin/nipsa.html.jinja2","filename":"nipsa.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/admin.html.jinja2\" %}\n\n{% set page_id = 'nipsa' %}\n{% set page_title = '\"Not in public site areas\"' %}\n\n{% block content %}\n  <p>\n    On this page you can apply (and remove) the \"not in public site areas\" flag\n    from users. Flagging a user as NIPSA means that while they will continue to see\n    all their annotations as normal, their annotations will not show up in the\n    public stream or in default public searches.\n  </p>\n\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h3 class=\"panel-title\">Flag a user</h3>\n    </div>\n    <div class=\"panel-body\">\n      <form method=\"POST\" class=\"form-inline\">\n        <div class=\"form-group\">\n          <label for=\"add\">Username</label>\n          <input type=\"text\" class=\"form-control\" name=\"add\">\n          <input type=\"submit\" class=\"btn btn-default\" value=\"Add\">\n        </div>\n      </form>\n    </div>\n  </div>\n\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h3 class=\"panel-title\">Unflag a user</h3>\n    </div>\n    <div class=\"panel-body\">\n      {% if usernames %}\n      <form \n        method=\"POST\" \n        action=\"{{ request.route_url('admin_nipsa') }}\">\n        <ul>\n          {% for username in usernames %}\n            <li>\n              {{ username }}\n              <button type=\"submit\" class=\"btn btn-link btn-sm\"\n                      name=\"remove\" value=\"{{ username }}\">\n                Remove\n              </button>\n            </li>\n          {% endfor %}\n        </ul>\n      </form>\n      {% else %}\n        <p><em>No users are currently flagged&hellip;</em></p>\n      {% endif %}\n    </div>\n  </div>\n{% endblock %}\n"},{"size":1352,"relativepath":"h/templates/admin/staff.html.jinja2","filename":"staff.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/admin.html.jinja2\" %}\n\n{% set page_id = 'staff' %}\n{% set page_title = 'Staff' %}\n\n{% block content %}\n  <p>\n    On this page you can give users staff privileges! For example some features\n    may be enabled for staff only.\n  </p>\n\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h3 class=\"panel-title\">Make a user into a staff member</h3>\n    </div>\n    <div class=\"panel-body\">\n      <form method=\"POST\" class=\"form-inline\">\n        <div class=\"form-group\">\n          <label for=\"add\">Username</label>\n          <input type=\"text\" class=\"form-control\" name=\"add\">\n          <input type=\"submit\" class=\"btn btn-default\" value=\"Add\">\n        </div>\n      </form>\n    </div>\n  </div>\n\n  <div class=\"panel panel-default\">\n    <div class=\"panel-heading\">\n      <h3 class=\"panel-title\">Current staff</h3>\n    </div>\n    <div class=\"panel-body\">\n      <form\n        method=\"POST\" \n        action=\"{{ request.route_url('admin_staff') }}\">\n        <ul>\n          {% for user in staff %}\n            <li>\n              {{ user }}\n              <button type=\"submit\" class=\"btn btn-link btn-sm\"\n                      name=\"remove\" value=\"{{ user }}\">\n                Remove\n              </button>\n            </li>\n          {% endfor %}\n        </ul>\n      </form>\n    </div>\n  </div>\n{% endblock %}\n"},{"size":436,"relativepath":"h/templates/admin/index.html.jinja2","filename":"index.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/admin.html.jinja2\" %}\n\n{% set page_id = 'index' %}\n{% set page_title = 'Administration pages' %}\n\n{% block content %}\n  <p>Welcome to the Hypothesis administration console!</p>\n  <dl class='dl-horizontal'>\n    {% for key, value in release_info|dictsort %}\n      <dt>{{ key }}</dt>\n      <dd>{% if value|trim %}{{ value }}{% else %}<em>Unknown</em>{% endif %}</dd>\n    {% endfor %}\n  </dl>\n{% endblock %}\n"},{"size":3873,"relativepath":"h/templates/admin/users.html.jinja2","filename":"users.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/admin.html.jinja2\" %}\n\n{% set page_id = 'users' %}\n{% set page_title = 'Users' %}\n\n{% block content %}\n  <p>\n    On this page you can look up users by username and see their details.\n  </p>\n\n  <form method=\"GET\" class=\"form-inline\">\n    <div class=\"form-group\">\n      <label for=\"username\">Username or email</label>\n      <input type=\"text\" class=\"form-control\" name=\"username\">\n      <input type=\"submit\" class=\"btn btn-default\" value=\"Find\">\n    </div>\n  </form>\n  {% if username %}\n  <hr>\n    {% if user %}\n      <table class=\"table table-auto table-striped\">\n        <tbody>\n          <tr><th>Username</th><td>{{ user.username }}</td></tr>\n          <tr><th>UID</th><td>{{ user.uid }}</td></tr>\n          <tr><th>Email</th><td>{{ user.email }}</td></tr>\n          <tr><th>Registered</th><td>{{ user.registered_date }}</td></tr>\n          <tr><th>Last login</th><td>{{ user.last_login_date }}</td></tr>\n          <tr>\n            <th>Is activated?</th>\n            <td>\n              {% if user.is_activated %}\n                &#x2714;\n              {% else %}\n                &#x2718;\n                <form action=\"{{request.route_path('admin_users_activate')}}\"\n                      class=\"users-activate-form\"\n                      method=\"POST\">\n                  <input type=\"hidden\"\n                         name=\"username\"\n                         value=\"{{user.username}}\">\n                  <button class=\"btn btn-primary btn-xs\" type=\"submit\">\n                    Activate\n                  </button>\n                </form>\n              {% endif %}\n            </td>\n          </tr>\n          <tr>\n            <th>Is admin?</th>\n            <td>{% if user.admin %}&#x2714;{% else %}&#x2718;{% endif %}</td>\n          </tr>\n          <tr>\n            <th>Is staff?</th>\n            <td>{% if user.staff %}&#x2714;{% else %}&#x2718;{% endif %}</td>\n          </tr>\n          <tr>\n            <th>Annotations</th>\n            <td>{{ user_meta['annotations_count'] }}</td>\n          </tr>\n        </tbody>\n      </table>\n\n      <h3>Please-be-careful Zone</h3>\n\n      <form method=\"POST\" action=\"{{request.route_path('admin_users_rename')}}\" class=\"form-inline\">\n        <input type=\"hidden\" name=\"username\" value=\"{{user.username}}\">\n        <input type=\"text\" name=\"new_username\" placeholder=\"New Username\">\n        <button class=\"btn\" type=\"submit\">Change username</button>\n      </form>\n\n      <h3>Danger Zone</h3>\n\n      <form method=\"POST\"\n            action=\"{{request.route_path('admin_users_delete')}}\"\n            class=\"form-inline js-users-delete-form\">\n        <input type=\"hidden\" name=\"username\" value=\"{{user.username}}\">\n\n        {% if user_meta['annotations_count'] > 100 %}\n          <div class=\"alert alert-warning\" role=\"alert\">\n            User has a lot of annotations, it might be safer to delete this user\n            directly in a shell.\n          </div>\n        {% endif %}\n\n        <button class=\"btn btn-danger\" type=\"submit\">Delete user</button>\n      </form>\n\n      {% if user.groups %}\n        <hr>\n\n        <h2>Groups this user belongs to</h2>\n\n        <table class=\"table table-auto table-striped\">\n          <thead>\n            <th>Name</th>\n            <th>URL</th>\n          </thead>\n          <tbody>\n            {% for group in user.groups %}\n              <tr>\n                <td>{{group.name}}</td>\n                <td>\n                  {% set group_url = request.route_url('group_read', pubid=group.pubid, slug=group.slug) %}\n                  <a href=\"{{ group_url }}\">\n                    {{ group_url }}\n                  </a>\n                </td>\n              </tr>\n            {% endfor %}\n          </tbody>\n        </table>\n      {% endif %}\n    {% else %}\n      <p>No user found with username or email <em>{{ username }}</em>!</p>\n    {% endif %}\n  {% endif %}\n{% endblock %}\n"},{"size":1308,"relativepath":"h/templates/admin/groups.html.jinja2","filename":"groups.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/admin.html.jinja2\" %}\n\n{% set page_id = 'groups' %}\n{% set page_title = 'Groups' %}\n\n{% block content %}\n  <p>\n    On this page you can see a list of all the groups and their details.\n  </p>\n\n  <p>\n    <a href=\"{{ request.route_url('admin_groups_csv') }}\">\n      Download report as CSV\n    </a>\n  </p>\n\n  <div class=\"table-responsive\">\n    <table class=\"table table-striped\">\n      <thead>\n        <tr>\n          <th>Name</th>\n          <th>URL</th>\n          <th>Created by</th>\n          <th>Members</th>\n        </tr>\n      </thead>\n      <tbody>\n        {% for group in results %}\n          <tr>\n            <td>{{ group.name }}</td>\n            <td>\n              {% set group_url = request.route_url('group_read', pubid=group.pubid, slug=group.slug) %}\n              <a href=\"{{ group_url }}\">\n                {{ group_url }}\n              </a>\n            </td>\n            <td>\n              <a href=\"{{ request.route_url('admin_users', _query={'username': group.creator.username}) }}\">\n                {{ group.creator.username }}\n              </a>\n            </td>\n            <td>{{ group.members|length }}</td>\n          </tr>\n        {% endfor %}\n      </tbody>\n    </table>\n  </div>\n\n  {% include \"h:templates/includes/paginator.html.jinja2\" %}\n{% endblock %}\n"},{"size":2178,"relativepath":"h/templates/admin/features.html.jinja2","filename":"features.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/admin.html.jinja2\" %}\n\n{% set page_id = 'features' %}\n{% set page_title = 'Feature flags' %}\n\n{% block content %}\n  <p>\n    This page allows you to configure various feature flags that change the\n    behaviour of the application.\n  </p>\n  <p>\n    <strong>N.B.</strong> your changes will take effect immediately when you\n    save.\n  </p>\n  <div class=\"table-responsive\">\n    <form method=\"POST\">\n      <input\n        type=\"hidden\"\n        name=\"csrf_token\"\n        value=\"{{ request.session.get_csrf_token() }}\">\n      <table class=\"table table-striped\">\n        <thead>\n          <tr>\n            <th></th>\n            <th>Everyone</th>\n            <th>Admins</th>\n            <th>Staff</th>\n            <th>Cohorts</th>\n            <th></th>\n          </tr>\n        </thead>\n        <tbody>\n          {% for feat in features %}\n          <tr>\n            <td>{{ feat.name }}</td>\n            <td>\n              <input\n                type=\"checkbox\"\n                name=\"{{ feat.name }}[everyone]\"\n                {% if feat.everyone %}checked{% endif %}>\n            </td>\n            <td>\n              <input\n                type=\"checkbox\"\n                name=\"{{ feat.name }}[admins]\"\n                {% if feat.admins %}checked{% endif %}>\n            </td>\n            <td>\n              <input\n                type=\"checkbox\"\n                name=\"{{ feat.name }}[staff]\"\n                {% if feat.staff %}checked{% endif %}>\n            </td>\n            <td>\n              {% for c in cohorts %}\n                <fieldset>\n                  <input\n                    type=\"checkbox\"\n                    name=\"{{ feat.name }}[cohorts][{{ c.name }}]\"\n                    {% if c in feat.cohorts %}checked{% endif %}>\n                  <label for=\"{{ feat.name }}[cohorts][{{ c.name }}]\">{{ c.name }}</label>\n                </fieldset>\n              {% endfor %}\n            </td>\n            <td>\n              {{ feat.description }}\n            </td>\n          </tr>\n          {% endfor %}\n        </tbody>\n      </table>\n      <input class=\"btn btn-primary\" type=\"submit\" value=\"Save changes\">\n    </form>\n  </div>\n{% endblock %}\n"},{"size":1694,"relativepath":"h/templates/groups/create.html.jinja2","filename":"create.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/group.html.jinja2\" %}\n\n{% set page_title = 'Create a new group' %}\n\n{% block page_content %}\n  {% if feature('activity_pages') %}\n    <h1 class=\"form-header\">Create a new group</h1>\n    {{ form }}\n\n    <footer class=\"form-footer\">\n      {# This form has at least one required field. If that changes we should update this footer. #}\n      <span class=\"form-footer__required\">\n        <span class=\"form-footer__symbol\">\n        *\n        </span>\n        <span class=\"form-footer__text\">\n          Required\n        </span>\n      </span>\n    </footer>\n  {% else %}\n    <div class=\"content content--narrow js-create-group-form\">\n      <div class=\"group-form\">\n        <i class=\"h-icon-group group-form__heading-icon\"></i>\n        <div class=\"group-form__heading\">Create a new group</div>\n        {{ form | safe }}\n      </div>\n      <div class=\"group-form-footer\">\n        <a href=\"\" class=\"group-form-footer__explain-link js-group-info-link\">Tell me more about groups</a>\n        <div class=\"group-form-footer__explain-text js-group-info-text is-hidden\">\n          {% include \"about-groups.html.jinja2\" %}\n          <p class=\"group-form-footer__heading\">How to use groups</p>\n          <ol class=\"group-form-footer__list\">\n            <li>Choose a name for your group</li>\n            <li>We'll give you a link which you can copy and paste</li>\n            <li>Send this link to the people you want to annotate with.\n                They will be able to create a Hypothes.is account and will\n                be able to publish and read annotations in this group.</li>\n          </ol>\n        </div>\n      </div>\n    </div>\n  {%- endif %}\n{% endblock page_content %}\n"},{"size":332,"relativepath":"h/templates/groups/edit.html.jinja2","filename":"edit.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/group.html.jinja2\" %}\n\n{% set page_title = 'Edit Group' %}\n\n{% block page_content %}\n  <h1 class=\"form-header\">Edit group details</h1>\n  {{ form }}\n\n  <footer class=\"form-footer\">\n    <a class=\"link\" href=\"{{ group_path }}\">&#8592; Back to the groups page</a>\n  </footer>\n{% endblock page_content %}\n"},{"size":2489,"relativepath":"h/templates/groups/join.html.jinja2","filename":"join.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/group.html.jinja2\" %}\n\n{% set page_title = group.name %}\n\n{% block page_content %}\n  {% if feature('activity_pages') %}\n    <div class=\"join-group-form\">\n      <h1 class=\"form-header\">Group invitation</h1>\n\n      <p class=\"join-group-form__label\">\n        You've been invited to join the annotation group:\n      </p>\n\n      <div class=\"join-group-form__container\">\n        <div class=\"join-group-form__group-name\">\n          {{ group.name }}\n        </div>\n        <div class=\"join-group-form__group-description\">\n          {% if group.description %}{{ group.description }}{% endif %}\n        </div>\n        {% if request.authenticated_userid %}\n          <form method=\"POST\">\n            <button class=\"btn primary-action-btn group-form__submit-btn\" type=\"submit\">\n              Join {{ group.name }}\n            </button>\n          </form>\n        {% else %}\n          <form method=\"GET\" action=\"{{ request.route_url('login') }}\">\n            <input type=\"hidden\" name=\"next\" value=\"{{ request.path }}\">\n            <button class=\"btn primary-action-btn group-form__submit-btn\" type=\"submit\">\n              Log in to join {{ group.name }}\n            </button>\n          </form>\n        {% endif %}\n      </div>\n    </div>\n\n    <footer class=\"form-footer\">\n      What is Hypothesis? <a class=\"link\" href=\"https://hypothes.is/about\">Learn more</a>\n    </footer>\n  {% else %}\n    <div class=\"content content--narrow\">\n      <div class=\"group-form\">\n        <img class=\"group-form__invite-icon\" src=\"/assets/images/icons/group-invite.svg\">\n        <div class=\"group-form__name-label\">You have been invited to annotate with the group</div>\n        <div class=\"group-form__name-input\">{{ group.name }}</div>\n        {% if request.authenticated_userid %}\n          <form method=\"POST\">\n            <button class=\"primary-action-btn\" type=\"submit\">\n              Join {{ group.name }}\n            </button>\n          </form>\n        {% else %}\n        <form method=\"GET\" action=\"{{ request.route_url('login') }}\">\n          <input type=\"hidden\" name=\"next\" value=\"{{ request.path }}\">\n          <button class=\"primary-action-btn\" type=\"submit\">\n            Log in to join {{ group.name }}\n          </button>\n        </form>\n        {% endif %}\n      </div>\n      <div class=\"group-form-footer-link\">\n        <span>What is Hypothes.is? <a href=\"https://hypothes.is/about\">Learn more</a>.</span>\n      </div>\n    </div>\n  {%- endif %}\n{% endblock page_content %}\n"},{"size":207,"relativepath":"h/templates/groups/about-groups.html.jinja2","filename":"about-groups.html.jinja2","extension":".jinja2","content":"<p class=\"group-form-footer__heading\">About Groups</p>\n<p>\n  Groups let you annotate and discuss content on the web privately.\n  <a href=\"//hypothes.is/annotating-with-groups/\" target=\"_blank\">More</a>\n</p>\n"},{"size":2973,"relativepath":"h/templates/groups/share.html.jinja2","filename":"share.html.jinja2","extension":".jinja2","content":"{% extends \"h:templates/layouts/base.html.jinja2\" %}\n\n{% set style_bundle = 'site_css' %}\n\n{% block page_title %}{{ group.name }}{% endblock page_title %}\n\n{% set group_url = request.route_url('group_read', pubid=group.pubid, slug=group.slug) %}\n\n{% block content %}\n  <div class=\"content content--narrow\">\n    <div class=\"group-form is-member-of-group\">\n      <i class=\"h-icon-group group-form__heading-icon\"></i>\n      <div class=\"group-form__heading--short\">{{ group.name }}</div>\n      {% if document_links %}\n        <a href=\"{{ request.route_url('stream') }}?q=group:{{ group.pubid }}\"\n           target=\"_blank\"\n           title=\"Recent annotations in this group\">\n           View recent group annotations</a>\n      {% else %}\n        <p class=\"group-form__nocontent-text\">This group has not shared any annotations yet.</p>\n      {% endif %}\n    </div>\n    {% if document_links %}\n    <div class=\"group-document-list\">\n        <ul class=\"group-document-list__list\">\n        <p class=\"group-document-list__heading\">Group documents:</p>\n          {% for document_link in document_links %}\n            <li>{{ document_link }}</li>\n          {% endfor %}\n        </ul>\n    </div>\n    {% endif %}\n    {% if group.members %}\n    <div class=\"group-members-list\">\n      <ul class=\"group-members-list__memberlist\">\n        <p class=\"group-members-list__heading\">Group Members:</p>\n        {% for member in group.members|sort(attribute='username')  %}\n          <li>\n            <a href=\"{{ request.route_url('stream') }}?q=group:{{ group.pubid }} user:{{ member.username }}\"\n              target=\"_blank\"\n              title=\"{{ member.username }}'s annotations in this group\">\n              {{ member.username }}\n            </a>\n          </li>\n        {% endfor %}\n      </ul>\n    </div>\n    {% endif %}\n    <div class=\"group-form-footer\">\n      <div class=\"group-form-footer__explain-text\">\n        {% include \"about-groups.html.jinja2\" %}\n        <p class=\"group-form-footer__heading\">Invite</p>\n        Invite anyone to join the group using the link below:\n        <input class=\"share-link-field\" value=\"{{ group_url }}\">\n        <a href=\"//twitter.com/intent/tweet?url={{ group_url | urlencode }}\"\n           target=\"_blank\"\n           title=\"Tweet link\"\n           class=\"share-link-icon h-icon-twitter\"></a>\n        <a href=\"//www.facebook.com/sharer/sharer.php?u={{ group_url | urlencode }}\"\n           target=\"_blank\"\n           title=\"Share on Facebook\"\n           class=\"share-link-icon h-icon-facebook\"></a>\n        <a href=\"//plus.google.com/share?url={{ group_url | urlencode }}\"\n           target=\"_blank\"\n           title=\"Post on Google Plus\"\n           class=\"share-link-icon h-icon-google-plus\"></a>\n        <a href=\"mailto:?subject=Invite to join the annotation group {{group.name}}&amp;body={{ group_url }}\"\n           title=\"Share via email\"\n            class=\"share-link-icon h-icon-mail\"></a>\n      </div>\n    </div>\n  </div>\n{% endblock content %}\n"},{"size":3654,"relativepath":"h/celery.py","filename":"celery.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"\nCelery worker bootstrap and configuration.\n\nThis module configures a Celery application for processing background jobs, and\nintegrates it with the Pyramid application by attaching a bootstrapped fake\n\"request\" object to the application where it can be retrieved by tasks.\n\"\"\"\n\nfrom __future__ import absolute_import\n\nfrom datetime import timedelta\nimport logging\nimport os\n\nfrom celery import Celery\nfrom celery import signals\nfrom celery.utils.log import get_task_logger\nfrom kombu import Exchange, Queue\nfrom raven.contrib.celery import register_signal, register_logger_signal\n\n__all__ = (\n    'celery',\n    'get_task_logger',\n)\n\nlog = logging.getLogger(__name__)\n\ncelery = Celery('h')\ncelery.conf.update(\n    # Default to using database number 10 so we don't conflict with the session\n    # store.\n    BROKER_URL=os.environ.get('CELERY_BROKER_URL',\n        os.environ.get('BROKER_URL', 'amqp://guest:guest@localhost:5672//')),\n    CELERYBEAT_SCHEDULE={\n        'delete-expired-authtickets': {\n            'task': 'h.auth.worker.delete_expired_auth_tickets',\n            'schedule': timedelta(hours=1)\n        },\n        'delete-expired-tokens': {\n            'task': 'h.auth.worker.delete_expired_tokens',\n            'schedule': timedelta(hours=1)\n        },\n    },\n    CELERY_ACCEPT_CONTENT=['json'],\n    # Enable at-least-once delivery mode. This probably isn't actually what we\n    # want for all of our queues, but it makes the failure-mode behaviour of\n    # Celery the same as our old NSQ worker:\n    CELERY_ACKS_LATE=True,\n    CELERY_DISABLE_RATE_LIMITS=True,\n    CELERY_IGNORE_RESULT=True,\n    CELERY_IMPORTS=('h.mailer', 'h.nipsa.worker', 'h.indexer', 'h.admin.worker', 'h.auth.worker'),\n    CELERY_ROUTES={\n        'h.indexer.add_annotation': 'indexer',\n        'h.indexer.delete_annotation': 'indexer',\n        'h.indexer.reindex_annotations': 'indexer',\n    },\n    CELERY_TASK_SERIALIZER='json',\n    CELERY_QUEUES=[\n        Queue('celery',\n              durable=True,\n              routing_key='celery',\n              exchange=Exchange('celery', type='direct', durable=True)),\n        Queue('indexer',\n              durable=True,\n              routing_key='indexer',\n              exchange=Exchange('indexer', type='direct', durable=True)),\n    ],\n    # Only accept one task at a time. This also probably isn't what we want\n    # (especially not for, say, a search indexer task) but it makes the\n    # behaviour consistent with the previous NSQ-based worker:\n    CELERYD_PREFETCH_MULTIPLIER=1,\n)\n\n\n@signals.worker_init.connect\ndef bootstrap_worker(sender, **kwargs):\n    request = sender.app.webapp_bootstrap()\n    sender.app.request = request\n\n    # Configure Sentry reporting on task failure\n    register_signal(request.sentry)\n    register_logger_signal(request.sentry, loglevel=logging.ERROR)\n\n\n@signals.task_prerun.connect\ndef reset_feature_flags(sender, **kwargs):\n    \"\"\"Reset feature flags before running each task.\"\"\"\n    sender.app.request.feature.clear()\n\n\n@signals.task_success.connect\ndef transaction_commit(sender, **kwargs):\n    \"\"\"Commit the request transaction after each successful task execution.\"\"\"\n    sender.app.request.tm.commit()\n\n\n@signals.task_failure.connect\ndef transaction_abort(sender, **kwargs):\n    \"\"\"Abort the request transaction after each failed task execution.\"\"\"\n    sender.app.request.tm.abort()\n\n\ndef start(argv, bootstrap):\n    \"\"\"Run the Celery CLI.\"\"\"\n    # We attach the bootstrap function directly to the Celery application\n    # instance, and it's then used in the worker bootstrap subscriber above.\n    celery.webapp_bootstrap = bootstrap\n    celery.start(argv)\n"},{"size":24,"relativepath":"h/activity/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n"},{"size":5479,"relativepath":"h/activity/bucketing.py","filename":"bucketing.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"Code for bucketing annotations by time frame and document.\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport collections\nimport datetime\n\nimport newrelic.agent\nfrom pyramid import i18n\n\nfrom h._compat import urlparse\nfrom h import presenters\n\n\n_ = i18n.TranslationStringFactory(__package__)\n\n\nclass DocumentBucket(object):\n    def __init__(self, document, annotations=None):\n        self.annotations = []\n        self.tags = set()\n        self.users = set()\n        self.uri = None\n\n        self.title = document.title\n\n        presented_document = presenters.DocumentHTMLPresenter(document)\n\n        if presented_document.web_uri:\n            parsed = urlparse.urlparse(presented_document.web_uri)\n            self.uri = parsed.geturl()\n            self.domain = parsed.netloc\n        else:\n            self.domain = _('Local file')\n\n        if annotations:\n            self.update(annotations)\n\n    @property\n    def annotations_count(self):\n        return len(self.annotations)\n\n    def append(self, annotation):\n        self.annotations.append(annotation)\n        self.tags.update(set(annotation.tags))\n        self.users.add(annotation.userid)\n\n    def update(self, annotations):\n        for annotation in annotations:\n            self.append(annotation)\n\n    def __eq__(self, other):\n        return (\n            self.annotations == other.annotations and\n            self.tags == other.tags and\n            self.users == other.users and\n            self.uri == other.uri and\n            self.domain == other.domain and\n            self.title == other.title)\n\n\nclass Timeframe(object):\n    \"\"\"\n    A timeframe into which annotations can be bucketed.\n\n    Any annotations that are added into a timeframe bucket will be further\n    bucketed by their documents, within the timeframe.\n\n    \"\"\"\n\n    def __init__(self, label, cutoff_time):\n        self.label = label\n        self.cutoff_time = cutoff_time\n        self.document_buckets = collections.OrderedDict()\n\n    @newrelic.agent.function_trace()\n    def append(self, annotation):\n        \"\"\"\n        Append an annotation to its document bucket in this timeframe.\n\n        This doesn't check whether the annotation's time is within this\n        timeframe, the caller is required to do that.\n\n        \"\"\"\n        document_bucket = self.document_buckets.get(annotation.document)\n\n        if document_bucket is None:\n            document_bucket = DocumentBucket(annotation.document)\n            self.document_buckets[annotation.document] = document_bucket\n\n        document_bucket.append(annotation)\n\n    def within_cutoff(self, annotation):\n        \"\"\"\n        Return True if annotation is within this timeframe's cutoff time.\n\n        Return ``True`` if the given annotation is newer than this timeframe's\n        cutoff time, meaning that the annotation can be bucketed into this\n        timeframe.\n\n        Return ``False`` if the given annotation is older than this timeframe's\n        cutoff time and the next timeframe needs to be generated in order to\n        bucket the annotation.\n\n        Note that this method returning ``True`` does not necessarily mean that\n        the annotation *should* be bucketed in this timeframe, since the\n        annotation may also be within the cutoff times of previous timeframes.\n        It's up to the caller to handle this.\n\n        \"\"\"\n        return annotation.updated >= self.cutoff_time\n\n    def __repr__(self):\n        return '{class_} \"{label}\" with {n} document buckets'.format(\n            class_=self.__class__, label=self.label,\n            n=len(self.document_buckets))\n\n\nclass TimeframeGenerator(object):\n\n    def __init__(self):\n        self.timeframes = [\n            Timeframe(_(\"Last 7 days\"), utcnow() - datetime.timedelta(days=7)),\n        ]\n\n    @newrelic.agent.function_trace()\n    def next(self, annotation):\n        \"\"\"\n        Return the next timeframe to be used for bucketing annotations.\n\n        :param annotation: the next annotation to be bucketed, the returned\n            timeframe is guaranteed to be the correct timeframe for this\n            annotation\n\n        \"\"\"\n        while self.timeframes:\n            timeframe = self.timeframes.pop(0)\n            if timeframe.within_cutoff(annotation):\n                return timeframe\n\n        cutoff_time = datetime.datetime(year=annotation.updated.year,\n                                        month=annotation.updated.month,\n                                        day=1)\n        timeframe = Timeframe(annotation.updated.strftime('%b %Y'),\n                              cutoff_time)\n        return timeframe\n\n\n@newrelic.agent.function_trace()\ndef bucket(annotations):\n    \"\"\"\n    Return the given annotations bucketed by timeframe and document.\n\n    :param annotations: A chronologically-ordered list of annotations.\n        This list of annotations is assumed to be sorted most recently updated\n        annotation first, otherwise the bucketing algorithm will not return the\n        right results.\n\n    :rtype: chronologically-ordered list of Timeframe objects\n\n    \"\"\"\n    if not annotations:\n        return []\n\n    generator = TimeframeGenerator()\n    timeframes = [generator.next(annotations[0])]\n\n    for annotation in annotations:\n        if not timeframes[-1].within_cutoff(annotation):\n            timeframes.append(generator.next(annotation))\n        timeframes[-1].append(annotation)\n\n    return timeframes\n\n\ndef utcnow():\n    return datetime.datetime.utcnow()\n"},{"size":5822,"relativepath":"h/activity/query.py","filename":"query.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom collections import namedtuple\n\nfrom memex.search import Search\nfrom memex.search import parser\nfrom memex.search.query import (\n    TagsAggregation,\n    UsersAggregation,\n)\nimport newrelic.agent\nfrom pyramid.httpexceptions import HTTPFound\nfrom sqlalchemy.orm import subqueryload\n\nfrom h import presenters\nfrom h.activity import bucketing\nfrom h.models import Annotation, Document, Group\nfrom memex import storage\n\n\nclass ActivityResults(namedtuple('ActivityResults', [\n    'total',\n    'aggregations',\n    'timeframes',\n])):\n    pass\n\n\n@newrelic.agent.function_trace()\ndef extract(request, parse=parser.parse):\n    \"\"\"\n    Extract and process the query present in the passed request.\n\n    Assumes that the 'q' query parameter contains a string query in a format\n    which can be parsed by :py:func:`memex.search.parser.parse`. Extracts and\n    parses the query, adds terms implied by the current matched route, if\n    necessary, and returns it.\n\n    If no query is present in the passed request, returns ``None``.\n    \"\"\"\n\n    q = parse(request.params.get('q', ''))\n\n    # If the query sent to a {group, user} search page includes a {group,\n    # user}, we override it, because otherwise we'll display the union of the\n    # results for those two {groups, users}, which would makes no sense.\n    #\n    # (Note that a query for the *intersection* of >1 users or groups is by\n    # definition empty)\n    if request.matched_route.name == 'activity.group_search':\n        q['group'] = request.matchdict['pubid']\n    elif request.matched_route.name == 'activity.user_search':\n        q['user'] = request.matchdict['username']\n\n    return q\n\n\ndef check_url(request, query, unparse=parser.unparse):\n    \"\"\"\n    Checks the request and raises a redirect if implied by the query.\n\n    If a query contains a single group or user term, then the user is\n    redirected to the specific group or user search page with that term\n    removed. For example, a request to\n\n        /search?q=group:abc123+tag:foo\n\n    will be redirected to\n\n        /groups/abc123/search?q=tag:foo\n\n    Queries containing more than one group or user term are unaffected.\n    \"\"\"\n    if request.matched_route.name != 'activity.search':\n        return\n\n    redirect = None\n\n    if _single_entry(query, 'group'):\n        pubid = query.pop('group')\n        redirect = request.route_path('activity.group_search',\n                                      pubid=pubid,\n                                      _query={'q': unparse(query)})\n\n    if _single_entry(query, 'user'):\n        username = query.pop('user')\n        redirect = request.route_path('activity.user_search',\n                                      username=username,\n                                      _query={'q': unparse(query)})\n\n    if redirect is not None:\n        raise HTTPFound(location=redirect)\n\n\n@newrelic.agent.function_trace()\ndef execute(request, query, page_size):\n    search_result = _execute_search(request, query, page_size)\n\n    result = ActivityResults(total=search_result.total,\n                             aggregations=search_result.aggregations,\n                             timeframes=[])\n\n    if result.total == 0:\n        return result\n\n    # Load all referenced annotations from the database, bucket them, and add\n    # the buckets to result.timeframes.\n    # We also load the replies from the database, but for now just ignore them.\n    anns, _ = fetch_annotations(request.db,\n                                search_result.annotation_ids,\n                                search_result.reply_ids)\n    result.timeframes.extend(bucketing.bucket(anns))\n\n    # Fetch all groups\n    group_pubids = set([a.groupid\n                        for t in result.timeframes\n                        for b in t.document_buckets.values()\n                        for a in b.annotations])\n    groups = {g.pubid: g for g in _fetch_groups(request.db, group_pubids)}\n\n    # Add group information to buckets and present annotations\n    for timeframe in result.timeframes:\n        for bucket in timeframe.document_buckets.values():\n            for index, annotation in enumerate(bucket.annotations):\n                bucket.annotations[index] = {\n                    'annotation': presenters.AnnotationHTMLPresenter(annotation),\n                    'group': groups.get(annotation.groupid)\n                }\n\n    return result\n\n\ndef aggregations_for(query):\n    aggregations = [TagsAggregation(limit=10)]\n\n    # Should we aggregate by user?\n    if _single_entry(query, 'group'):\n        aggregations.append(UsersAggregation(limit=10))\n\n    return aggregations\n\n\n@newrelic.agent.function_trace()\ndef fetch_annotations(session, ids, reply_ids):\n    def load_documents(query):\n        return query.options(subqueryload(Annotation.document))\n\n    annotations = storage.fetch_ordered_annotations(\n        session, ids, query_processor=load_documents)\n\n    replies = storage.fetch_ordered_annotations(session, reply_ids)\n\n    return (annotations, replies)\n\n\n@newrelic.agent.function_trace()\ndef _execute_search(request, query, page_size):\n    search = Search(request, separate_replies=True)\n    for agg in aggregations_for(query):\n        search.append_aggregation(agg)\n\n    query = query.copy()\n    page = request.params.get('page', 1)\n\n    try:\n        page = int(page)\n    except ValueError:\n        page = 1\n\n    # Don't allow negative page numbers.\n    if page < 1:\n        page = 1\n\n    query['limit'] = page_size\n    query['offset'] = (page - 1) * page_size\n\n    search_result = search.run(query)\n    return search_result\n\n\n@newrelic.agent.function_trace()\ndef _fetch_groups(session, pubids):\n    return session.query(Group).filter(Group.pubid.in_(pubids))\n\n\ndef _single_entry(query, key):\n    return len(query.getall(key)) == 1\n"},{"size":869,"relativepath":"h/assets.ini","filename":"assets.ini","extension":".ini","content":"[bundles]\n# Admin areas\n#\n# Note that these use a full version of Bootstrap. The new website uses a\n# minimal version that only has the features we need.\nadmin_css =\n  styles/bootstrap.css\n  styles/admin.css\n\nadmin_js =\n  scripts/raven.bundle.js\n  scripts/jquery.bundle.js\n  scripts/bootstrap.bundle.js\n  scripts/admin-site.bundle.js\n\n\n# The H website\nsite_js =\n  scripts/raven.bundle.js\n  scripts/site.bundle.js\n\nheader_js =\n  scripts/header.bundle.js\n\nsite_css =\n  styles/site.css\n  styles/icomoon.css\n\nsite_v2_css =\n  styles/site-v2.css\n\nfront_page_js =\n  scripts/jquery.bundle.js\n  scripts/bootstrap.bundle.js\n  scripts/legacy-site.bundle.js\n\nfront_page_css =\n  styles/front-page.css\n  styles/old-home.css\n  styles/icomoon.css\n\nlegacy_site_css =\n  styles/icomoon.css\n  styles/legacy-site.css\n\n# Help page\nhelp_page_css =\n  styles/icomoon.css\n  styles/help-page.css\n"},{"size":5306,"relativepath":"h/assets.py","filename":"assets.py","extension":".py","content":"# -*- coding: utf-8 -*-\nimport os\n\nimport json\nfrom pyramid.settings import aslist\nfrom pyramid.static import static_view\n\nfrom h._compat import configparser\n\n\nclass _CachedFile(object):\n\n    \"\"\"\n    Parses content from a file and caches the result until the file changes.\n\n    _CachedFile reads a file at a given path and parses the content using a\n    provided loader. The result is cached until the mtime of the file changes.\n    \"\"\"\n\n    def __init__(self, path, loader):\n        \"\"\"\n        :param path: The path to the file to load.\n        :param loader: A callable that will be passed the file object and\n                       should return the parsed content.\n        \"\"\"\n        self.path = path\n        self.loader = loader\n        self._mtime = None\n        self._cached = None\n\n    def load(self):\n        \"\"\"\n        Return the current content of the file parsed with the loader.\n\n        If the file has not been loaded or has changed since the last call\n        to load(), it will be reloaded, otherwise the cached content will\n        be returned.\n        \"\"\"\n        current_mtime = os.path.getmtime(self.path)\n        if not self._mtime or self._mtime < current_mtime:\n            self._cached = self.loader(open(self.path))\n            self._mtime = current_mtime\n        return self._cached\n\n\nclass Environment(object):\n\n    \"\"\"\n    Environment for generating URLs for Hypothesis' static assets.\n\n    Static assets are grouped into named bundles, defined in an ini-format\n    config file. The relative URL that should be used when serving a file from\n    a bundle is defined in a JSON manifest file, which is generated by the\n    static asset build pipeline.\n\n    Environment reads the set of bundles from the config file\n    and the mapping between the file path and the output URL\n    from a JSON manifest file and provides the ability to retrieve the final\n    URLs for a bundle via the urls() method.\n    \"\"\"\n\n    def __init__(self, assets_base_url, bundle_config_path, manifest_path):\n        \"\"\"\n        Construct an Environment from the given configuration files.\n\n        :param assets_base_url: The URL at which assets will be served,\n                                excluding the trailing slash.\n        :param bundle_config_path: Asset bundles config file.\n        :param manifest_path: JSON file mapping file paths in the bundle config\n                              file to cache-busted URLs.\n        \"\"\"\n        self.assets_base_url = assets_base_url\n        self.manifest = _CachedFile(manifest_path, json.load)\n        self.bundles = _CachedFile(bundle_config_path, _load_bundles)\n\n    def files(self, bundle):\n        \"\"\"Return the file paths for all files in a bundle.\"\"\"\n        bundles = self.bundles.load()\n        return bundles[bundle]\n\n    def urls(self, bundle):\n        \"\"\"\n        Return asset URLs for all files in a bundle.\n\n        Returns the URLs at which all files in a bundle are served,\n        read from the asset manifest.\n        \"\"\"\n        manifest = self.manifest.load()\n        bundles = self.bundles.load()\n\n        def asset_url(path):\n            return '{}/{}'.format(self.assets_base_url, manifest[path])\n        return [asset_url(path) for path in bundles[bundle]]\n\n\ndef _add_cors_header(wrapped):\n    def wrapper(context, request):\n        # Add a CORS header to the response because static assets from\n        # the sidebar are loaded into pages served by a different origin:\n        # The domain hosting the page into which the sidebar has been injected\n        # or embedded.\n        #\n        # Some browsers enforce cross-origin restrictions on certain types of\n        # resources, eg. Firefox enforces same-domain policy for @font-face\n        # unless a CORS header is provided.\n        response = wrapped(context, request)\n        response.headers.extend({\n            'Access-Control-Allow-Origin': '*'\n        })\n        return response\n\n    return wrapper\n\n\ndef _load_bundles(fp):\n    \"\"\"Read an asset bundle config from a file object.\"\"\"\n    parser = configparser.ConfigParser()\n    parser.readfp(fp)\n    return {k: aslist(v) for k, v in parser.items('bundles')}\n\n# Site assets\nassets_view = static_view('h:../build',\n                          cache_max_age=None,\n                          use_subpath=True)\nassets_view = _add_cors_header(assets_view)\n\n\n# Client assets\nassets_client_view = static_view('h:../node_modules/hypothesis/build',\n                                 cache_max_age=None,\n                                 use_subpath=True)\nassets_client_view = _add_cors_header(assets_client_view)\n\n\ndef includeme(config):\n    config.add_view(route_name='assets', view=assets_view)\n    config.add_view(route_name='assets_client', view=assets_client_view)\n\n    assets_env = Environment('/assets',\n                             'h/assets.ini',\n                             'build/manifest.json')\n    assets_client_env = Environment('/assets/client',\n                                    'h/assets_client.ini',\n                                    'node_modules/hypothesis/build/manifest.json')\n\n    # We store the environment objects on the registry so that the Jinja2\n    # integration can be configured in app.py\n    config.registry['assets_env'] = assets_env\n    config.registry['assets_client_env'] = assets_client_env\n"},{"size":11565,"relativepath":"h/presenters.py","filename":"presenters.py","extension":".py","content":"\"\"\"A class that wraps Annotation model objects and adds some HTML properties.\"\"\"\nfrom __future__ import unicode_literals\nimport urlparse\nimport urllib2\nfrom dateutil import parser\n\nimport jinja2\n\nfrom h._compat import text_type\n\n\ndef _format_document_link(href, title, link_text, host_or_filename):\n    \"\"\"Return a document link for the given components.\n\n    Helper function for the .document_link property below.\n\n    :returns: A document link as an HTML string, escaped and safe for\n        rendering. The returned string is a Markup object so that it won't be\n        double-escaped.\n\n    \"\"\"\n    if href and host_or_filename and host_or_filename in link_text:\n        host_or_filename = ''\n    elif not href and title == host_or_filename:\n        title = ''\n\n    def truncate(content, length=55):\n        \"\"\"Truncate the given string to at most length chars.\"\"\"\n        if len(content) <= length:\n            return content\n        else:\n            return content[:length] + jinja2.Markup('&hellip;')\n\n    host_or_filename = truncate(host_or_filename)\n    link_text = truncate(link_text)\n\n    if href and host_or_filename:\n        link = '<a href=\"{href}\" title=\"{title}\">{link_text}</a><br>{host_or_filename}'\n    elif href:\n        link = '<a href=\"{href}\" title=\"{title}\">{link_text}</a>'\n    else:\n        link = '<em>Local file:</em> {title}'\n        if host_or_filename:\n            link += '<br>{host_or_filename}'\n\n    link = link.format(\n        href=jinja2.escape(href),\n        title=jinja2.escape(title),\n        link_text=jinja2.escape(link_text),\n        host_or_filename=jinja2.escape(host_or_filename))\n\n    return jinja2.Markup(link)\n\n\nclass AnnotationHTMLPresenter(object):\n\n    \"\"\"Wraps Annotation model objects and adds some HTML properties.\"\"\"\n\n    def __init__(self, annotation):\n        self.annotation = annotation\n        if self.annotation.document:\n            self.document = DocumentHTMLPresenter(self.annotation.document)\n        else:\n            self.document = None\n\n    def _get_selection(self):\n        selectors = self.annotation.target_selectors\n        for selector in selectors:\n            if 'exact' in selector:\n                return selector['exact']\n\n    @property\n    def uri(self):\n        return jinja2.escape(self.annotation.target_uri)\n\n    @property\n    def text_rendered(self):\n        \"\"\"The body text of this annotation.\"\"\"\n\n        return self.annotation.text_rendered\n\n    @property\n    def quote(self):\n        \"\"\"The text in the document which this annotation refers to.\"\"\"\n        selection = self._get_selection()\n        if selection:\n            return jinja2.escape(selection)\n\n        return ''\n\n    @property\n    def description(self):\n        \"\"\"An HTML-formatted description of this annotation.\n\n        The description contains the target text that the user selected to\n        annotate, as a <blockquote>, and the body text of the annotation\n        itself.\n\n        \"\"\"\n\n        description = ''\n\n        selection = self._get_selection()\n        if selection:\n            selection = jinja2.escape(selection)\n            description += '&lt;blockquote&gt;{selection}&lt;/blockquote&gt;'.format(\n                selection=selection)\n\n        text = self.annotation.text\n        if text:\n            text = jinja2.escape(text)\n            description += '{text}'.format(text=text)\n\n        return description\n\n    @property\n    def created_day_string(self):\n        \"\"\"A simple created day string for this annotation.\n\n        Returns a day string like '2015-03-11' from the annotation's 'created'\n        date.\n\n        \"\"\"\n        created_string = jinja2.escape(self.annotation.created)\n        return parser.parse(created_string).strftime('%Y-%m-%d')\n\n    @property\n    def document_link(self):\n        \"\"\"Return a link to this annotation's document.\"\"\"\n        if self.document:\n            return self.document.link\n        else:\n            return ''\n\n    @property\n    def filename(self):\n        \"\"\"Return the filename of this annotation's document.\"\"\"\n        if self.document:\n            return self.document.filename\n        else:\n            return ''\n\n    @property\n    def hostname_or_filename(self):\n        \"\"\"Return the hostname of this annotation's document.\"\"\"\n        if self.document:\n            return self.document.hostname_or_filename\n        else:\n            return ''\n\n    @property\n    def href(self):\n        \"\"\"Return an href for this annotation's document, or ''.\"\"\"\n        if self.document:\n            return self.document.href\n        else:\n            return ''\n\n    @property\n    def link_text(self):\n        \"\"\"Return some link text for this annotation's document.\"\"\"\n        if self.document:\n            return self.document.link_text\n        else:\n            return ''\n\n    @property\n    def title(self):\n        \"\"\"Return a title for this annotation.\"\"\"\n        if self.document:\n            return self.document.title\n        else:\n            return ''\n\n    # Explicitly forward some annotation properties for convenient access.\n    @property\n    def id(self):\n        return self.annotation.id\n\n    @property\n    def created(self):\n        return self.annotation.created\n\n    @property\n    def updated(self):\n        return self.annotation.updated\n\n    @property\n    def userid(self):\n        return self.annotation.userid\n\n    @property\n    def username(self):\n        return self.annotation.userid.split(':')[1].split('@')[0]\n\nclass DocumentHTMLPresenter(object):\n    \"\"\"Wraps Document model objects and adds some HTML properties.\"\"\"\n\n    def __init__(self, document):\n        self.document = document\n\n    @property\n    def filename(self):\n        \"\"\"\n        Return the filename of this document, or ''.\n\n        If the document's URI is a file:// URI then return the filename part\n        of it, otherwise return ''.\n\n        The filename is escaped and safe to be rendered.\n\n        If it contains escaped characters then the filename will be a\n        Markup object so it won't be double-escaped.\n\n        \"\"\"\n        if self.uri.lower().startswith('file:///'):\n            return jinja2.escape(self.uri.split('/')[-1])\n        else:\n            return ''\n\n    @property\n    def href(self):\n        \"\"\"\n        Return an href for this document, or ''.\n\n        Returns a value suitable for use as the value of the href attribute in\n        an <a> element in an HTML document.\n\n        Returns an empty string if the document doesn't have an http(s):// URI.\n\n        The href is escaped and safe to be rendered.\n\n        If it contains escaped characters the returned value will be a\n        Markup object so that it doesn't get double-escaped.\n\n        \"\"\"\n        if self.document.web_uri:\n            return jinja2.escape(self.document.web_uri)\n        else:\n            return ''\n\n    @property\n    def hostname_or_filename(self):\n        \"\"\"\n        Return the hostname or filename of this document.\n\n        Returns the hostname part of the document's URI, e.g.\n        'www.example.com' for 'http://www.example.com/example.html'.\n\n        If the URI is a file:// URI then return the filename part of it\n        instead.\n\n        The returned hostname or filename is escaped and safe to be rendered.\n\n        If it contains escaped characters the returned value will be a Markup\n        object so that it doesn't get double-escaped.\n\n        \"\"\"\n        if self.filename:\n            return jinja2.escape(urllib2.unquote(self.filename))\n        else:\n            hostname = urlparse.urlparse(self.uri).hostname\n\n            # urlparse()'s .hostname is sometimes None.\n            hostname = hostname or ''\n\n            return jinja2.escape(hostname)\n\n    @property\n    def link(self):\n        \"\"\"\n        Return a link to this document.\n\n        Returns HTML strings like:\n\n          <a href=\"{href}\" title=\"{title}\">{link_text}</a> {hostname}\n\n          <em>Local file:</em> {title}<br>{hostname}\n\n        where:\n\n        - {href} is the uri of the document, if it has an http(s):// uri\n        - {title} is the title of the document.\n          If the document has no title then its uri will be used instead.\n          If it's a local file:// uri then only the filename part is used,\n          not the full path.\n        - {link_text} is the same as {title}, but truncated with &hellip; if\n          it's too long\n        - {hostname} is the hostname name of the document's uri without\n          the scheme (http(s)://) and www parts, e.g. 'example.com'.\n          If it's a local file:// uri then the filename is used as the\n          hostname.\n          If the hostname is too long it is truncated with &hellip;.\n\n        The {hostname} part will be missing if it wouldn't be any different\n        from the {link_text} part.\n\n        The href=\"{href}\" will be missing if there's no http(s) uri to link to\n        for this annotation's document.\n\n        User-supplied values are escaped so the string is safe for raw\n        rendering (the returned string is actually a Markup object and\n        won't be escaped by Jinja2 when rendering).\n\n        \"\"\"\n        return _format_document_link(\n            self.href, self.title, self.link_text, self.hostname_or_filename)\n\n    @property\n    def link_text(self):\n        \"\"\"\n        Return some link text for this document.\n\n        Return a text representation of this document suitable for use as the\n        link text in a link like <a ...>{link_text}</a>.\n\n        Returns the document's title if it has one, or failing that uses part\n        of the document's URI if it has one.\n\n        The link text is escaped and safe for rendering.\n\n        If it contains escaped characters the returned value will be a\n        Markup object so it doesn't get double-escaped.\n\n        \"\"\"\n        title = jinja2.escape(self.title)\n\n        # Sometimes self.title is the annotated document's URI (if the document\n        # has no title). In those cases we want to remove the http(s):// from\n        # the front and unquote it for link text.\n        lower = title.lower()\n        if lower.startswith('http://') or lower.startswith('https://'):\n            parts = urlparse.urlparse(title)\n            return urllib2.unquote(parts.netloc + parts.path)\n\n        else:\n            return title\n\n    @property\n    def title(self):\n        \"\"\"\n        Return a title for this document.\n\n        Return the document's title or if the document has no title then return\n        its filename (if it's a file:// URI) or its URI for non-file URIs.\n\n        The title is escaped and safe to be rendered.\n\n        If it contains escaped characters then the title will be a\n        Markup object, so that it won't be double-escaped.\n\n        \"\"\"\n        title = self.document.title\n        if title:\n            # Convert non-string titles into strings.\n            # We're assuming that title cannot be a byte string.\n            title = text_type(title)\n            return jinja2.escape(title)\n\n        if self.filename:\n            return jinja2.escape(urllib2.unquote(self.filename))\n        else:\n            return jinja2.escape(urllib2.unquote(self.uri))\n\n    @property\n    def uri(self):\n        if self.document.document_uris:\n            return jinja2.escape(self.document.document_uris[0].uri)\n        return ''\n\n    @property\n    def web_uri(self):\n        via_prefix = 'https://via.hypothes.is/'\n        web_uri = self.document.web_uri\n\n        if web_uri and web_uri != via_prefix and web_uri.startswith(via_prefix):\n            web_uri = web_uri[len(via_prefix):]\n\n        return web_uri\n"},{"size":4125,"relativepath":"h/routes.py","filename":"routes.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\n\ndef includeme(config):\n    # Core\n    config.add_route('index', '/')\n    config.add_route('robots', '/robots.txt')\n    config.add_route('via_redirect', '/via')\n\n    # Accounts\n    config.add_route('login', '/login')\n    config.add_route('logout', '/logout')\n    config.add_route('signup', '/signup')\n    config.add_route('activate', '/activate/{id}/{code}')\n    config.add_route('forgot_password', '/forgot-password')\n    config.add_route('account_reset', '/account/reset')\n    config.add_route('account_reset_with_code', '/account/reset/{code}')\n    config.add_route('account', '/account/settings')\n    config.add_route('account_profile', '/account/profile')\n    config.add_route('account_notifications', '/account/settings/notifications')\n    config.add_route('account_developer', '/account/developer')\n    config.add_route('claim_account_legacy', '/claim_account/{token}')\n    config.add_route('dismiss_sidebar_tutorial', '/app/dismiss_sidebar_tutorial')\n\n    # Activity\n    config.add_route('activity.search', '/search')\n    config.add_route('activity.group_search', '/groups/{pubid}/search')\n    config.add_route('activity.user_search', '/users/{username}/search')\n\n    # Admin\n    config.add_route('admin_index', '/admin/')\n    config.add_route('admin_admins', '/admin/admins')\n    config.add_route('admin_badge', '/admin/badge')\n    config.add_route('admin_features', '/admin/features')\n    config.add_route('admin_cohorts', '/admin/features/cohorts')\n    config.add_route('admin_cohorts_edit', '/admin/features/cohorts/{id}')\n    config.add_route('admin_groups', '/admin/groups')\n    config.add_route('admin_groups_csv', '/admin/groups.csv')\n    config.add_route('admin_nipsa', '/admin/nipsa')\n    config.add_route('admin_staff', '/admin/staff')\n    config.add_route('admin_users', '/admin/users')\n    config.add_route('admin_users_activate', '/admin/users/activate')\n    config.add_route('admin_users_delete', '/admin/users/delete')\n    config.add_route('admin_users_rename', '/admin/users/rename')\n\n    # Annotations & stream\n    config.add_route('annotation',\n                     '/a/{id}',\n                     factory='memex.resources:AnnotationFactory',\n                     traverse='/{id}')\n    config.add_route('stream', '/stream')\n    config.add_route('stream.user_query', '/u/{user}')\n    config.add_route('stream.tag_query', '/t/{tag}')\n\n    # Assets\n    config.add_route('assets_client', '/assets/client/*subpath')\n    config.add_route('assets', '/assets/*subpath')\n\n    # API (other than those provided by memex)\n    config.add_route('badge', '/api/badge')\n    config.add_route('token', '/api/token')\n    config.add_route('api.users', '/api/users')\n\n    # Client\n    config.add_route('session', '/app')\n    config.add_route('widget', '/app.html')\n    config.add_route('embed', '/embed.js')\n\n    # Feeds\n    config.add_route('stream_atom', '/stream.atom')\n    config.add_route('stream_rss', '/stream.rss')\n\n    # Groups\n    config.add_route('group_create', '/groups/new')\n    config.add_route('group_edit',\n                     '/groups/{pubid}/edit',\n                     factory='h.models.group:GroupFactory',\n                     traverse='/{pubid}')\n    config.add_route('group_leave',\n                     '/groups/{pubid}/leave',\n                     factory='h.models.group:GroupFactory',\n                     traverse='/{pubid}')\n    # Match \"/<pubid>/\": we redirect to the version with the slug.\n    config.add_route('group_read',\n                     '/groups/{pubid}/{slug:[^/]*}',\n                     factory='h.models.group:GroupFactory',\n                     traverse='/{pubid}')\n    config.add_route('group_read_noslug',\n                     '/groups/{pubid}',\n                     factory='h.models.group:GroupFactory',\n                     traverse='/{pubid}')\n\n    # Help\n    config.add_route('help', '/docs/help')\n    config.add_route('onboarding', '/welcome/')\n    config.add_route('custom_onboarding', '/welcome/{slug}')\n\n    # Notification\n    config.add_route('unsubscribe', '/notification/unsubscribe/{token}')\n"},{"size":575,"relativepath":"h/nipsa/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom h.nipsa import services\nfrom h.nipsa import search\n\n\ndef includeme(config):\n    # Register the transform_annotation subscriber so that nipsa fields are\n    # written into annotations on save.\n    config.add_subscriber('h.nipsa.subscribers.transform_annotation',\n                          'memex.events.AnnotationTransformEvent')\n\n    # Register the NIPSA service\n    config.register_service_factory(services.nipsa_factory, name='nipsa')\n\n    # Register an additional filter with the API search module\n    config.add_search_filter(search.Filter)\n"},{"size":350,"relativepath":"h/nipsa/subscribers.py","filename":"subscribers.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\ndef transform_annotation(event):\n    \"\"\"Add a {\"nipsa\": True} field on annotations whose users are flagged.\"\"\"\n    annotation = event.annotation_dict\n    nipsa_service = event.request.find_service(name='nipsa')\n    if 'user' in annotation and nipsa_service.is_flagged(annotation['user']):\n        annotation['nipsa'] = True\n"},{"size":2174,"relativepath":"h/nipsa/search.py","filename":"search.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\nclass Filter(object):\n    def __init__(self, request):\n        self.request = request\n\n    def __call__(self, _):\n        return nipsa_filter(self.request.authenticated_userid)\n\n\ndef nipsa_filter(userid=None):\n    \"\"\"Return an Elasticsearch filter for filtering out NIPSA'd annotations.\n\n    The returned filter is suitable for inserting into an Es query dict.\n    For example:\n\n        query = {\n            \"query\": {\n                \"filtered\": {\n                    \"filter\": nipsa_filter(),\n                    \"query\": {...}\n                }\n            }\n        }\n\n    :param userid: The ID of a user whose annotations should not be filtered.\n        The returned filtered query won't filter out this user's annotations,\n        even if the annotations have the NIPSA flag.\n    :type userid: unicode\n\n    \"\"\"\n    # If any one of these \"should\" clauses is true then the annotation will\n    # get through the filter.\n    should_clauses = [{\"not\": {\"term\": {\"nipsa\": True}}}]\n\n    if userid is not None:\n        # Always show the logged-in user's annotations even if they have nipsa.\n        should_clauses.append({\"term\": {\"user\": userid.lower()}})\n\n    return {\"bool\": {\"should\": should_clauses}}\n\n\ndef query_for_users_annotations(userid):\n    \"\"\"Return an Elasticsearch query for all the given user's annotations.\"\"\"\n    return {\n        \"query\": {\n            \"filtered\": {\n                \"filter\": {\n                    \"bool\": {\n                        \"must\": [{\"term\": {\"user\": userid.lower()}}]\n                    }\n                }\n            }\n        }\n    }\n\n\ndef nipsad_annotations(userid):\n    \"\"\"Return an Elasticsearch query for the user's NIPSA'd annotations.\"\"\"\n    query = query_for_users_annotations(userid)\n    query[\"query\"][\"filtered\"][\"filter\"][\"bool\"][\"must\"].append(\n        {\"term\": {\"nipsa\": True}})\n    return query\n\n\ndef not_nipsad_annotations(userid):\n    \"\"\"Return an Elasticsearch query for the user's non-NIPSA'd annotations.\"\"\"\n    query = query_for_users_annotations(userid)\n    query[\"query\"][\"filtered\"][\"filter\"][\"bool\"][\"must\"].append(\n        {\"not\": {\"term\": {\"nipsa\": True}}})\n    return query\n"},{"size":1627,"relativepath":"h/nipsa/services.py","filename":"services.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom h.models import User\nfrom h.nipsa import worker\n\n\nclass NipsaService(object):\n\n    \"\"\"\n    A service which provides access to the state of \"not-in-public-site-areas\"\n    (NIPSA) flags on userids.\n    \"\"\"\n\n    def __init__(self, session):\n        self.session = session\n\n    @property\n    def flagged_users(self):\n        \"\"\"\n        A list of all the NIPSA'd users.\n\n        :rtype: list of unicode strings\n        \"\"\"\n        return self.session.query(User).filter_by(nipsa=True)\n\n    def is_flagged(self, userid):\n        \"\"\"Return whether the given userid is flagged as \"NIPSA\".\"\"\"\n        cnt = self.session.query(User).filter_by(userid=userid,\n                                                 nipsa=True).count()\n        return cnt != 0\n\n    def flag(self, user):\n        \"\"\"\n        Add a NIPSA flag for a user.\n\n        Add the given user's ID to the list of NIPSA'd user IDs. If the user\n        is already NIPSA'd then nothing will happen (but an \"add_nipsa\"\n        message for the user will still be published to the queue).\n        \"\"\"\n        user.nipsa = True\n        worker.add_nipsa.delay(user.userid)\n\n    def unflag(self, user):\n        \"\"\"\n        Remove the NIPSA flag for a user.\n\n        If the user isn't NIPSA'd then nothing will happen (but a\n        \"remove_nipsa\" message for the user will still be published to the\n        queue).\n        \"\"\"\n        user.nipsa = False\n        worker.remove_nipsa.delay(user.userid)\n\n\ndef nipsa_factory(context, request):\n    \"\"\"Return a NipsaService instance for the passed context and request.\"\"\"\n    return NipsaService(request.db)\n"},{"size":2430,"relativepath":"h/nipsa/worker.py","filename":"worker.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"Worker functions for the NIPSA feature.\"\"\"\n\nfrom elasticsearch import helpers\n\nfrom h.celery import celery\nfrom h.celery import get_task_logger\nfrom h.nipsa import search\n\nlog = get_task_logger(__name__)\n\n\ndef add_nipsa_action(index, annotation):\n    \"\"\"Return an Elasticsearch action for adding NIPSA to the annotation.\"\"\"\n    return {\n        \"_op_type\": \"update\",\n        \"_index\": index,\n        \"_type\": \"annotation\",\n        \"_id\": annotation[\"_id\"],\n        \"doc\": {\"nipsa\": True}\n    }\n\n\ndef remove_nipsa_action(index, annotation):\n    \"\"\"Return an Elasticsearch action to remove NIPSA from the annotation.\"\"\"\n    source = annotation[\"_source\"].copy()\n    source.pop(\"nipsa\", None)\n    return {\n        \"_op_type\": \"index\",\n        \"_index\": index,\n        \"_type\": \"annotation\",\n        \"_id\": annotation[\"_id\"],\n        \"_source\": source,\n    }\n\n\ndef bulk_update_annotations(client, query, action):\n    \"\"\"\n    Bulk update annotations matching a query with a passed action function.\n\n    This uses Elasticsearch's scan/scroll query and bulk update APIs to perform\n    updates to a set of annotations. Annotations matching the passed query will\n    be passed one-by-one to the passed \"action\" function, which must return an\n    action dictionary in the form dictated by the Elasticsearch bulk update\n    API.\n\n    :param client: the Elasticsearch client instance\n    :type client: memex.search.client.Client\n\n    :param query: a query dict selecting annotations to update\n    :type query: dict\n\n    :param action: a function mapping annotations to bulk actions\n    :type action: function\n    \"\"\"\n    annotations = helpers.scan(client=client.conn,\n                               index=client.index,\n                               query=query)\n    actions = [action(client.index, a) for a in annotations]\n    helpers.bulk(client=client.conn, actions=actions)\n\n\n@celery.task\ndef add_nipsa(userid):\n    log.info(\"setting nipsa flag for user annotations: %s\", userid)\n\n    bulk_update_annotations(celery.request.es,\n                            search.not_nipsad_annotations(userid),\n                            add_nipsa_action)\n\n\n@celery.task\ndef remove_nipsa(userid):\n    log.info(\"clearing nipsa flag for user annotations: %s\", userid)\n\n    bulk_update_annotations(celery.request.es,\n                            search.nipsad_annotations(userid),\n                            remove_nipsa_action)\n"},{"size":4709,"relativepath":"h/streamer/streamer.py","filename":"streamer.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport logging\nimport sys\n\nimport gevent\n\nfrom h import db\nfrom h import stats\nfrom h.streamer import messages\nfrom h.streamer import websocket\n\nlog = logging.getLogger(__name__)\n\n# Queue of messages to process, from both client websockets and message queues\n# to which the streamer is subscribed.\n#\n# The maxsize ensures that memory used by this queue is bounded. Producers\n# writing to the queue must consider their behaviour when the queue is full,\n# using .put(...) with a timeout or .put_nowait(...) as appropriate.\nWORK_QUEUE = gevent.queue.Queue(maxsize=4096)\n\n# Message queues that the streamer processes messages from\nANNOTATION_TOPIC = 'annotation'\nUSER_TOPIC = 'user'\n\n\nclass UnknownMessageType(Exception):\n    \"\"\"Raised if a message in the work queue if of an unknown type.\"\"\"\n\n\ndef start(event):\n    \"\"\"\n    Start some greenlets to process the incoming data from the message queue.\n\n    This subscriber is called when the application is booted, and kicks off\n    greenlets running `process_queue` for each message queue we subscribe to.\n    The function does not block.\n    \"\"\"\n    settings = event.app.registry.settings\n    greenlets = [\n        # Start greenlets to process messages from RabbitMQ\n        gevent.spawn(messages.process_messages,\n                     settings,\n                     ANNOTATION_TOPIC,\n                     WORK_QUEUE),\n        gevent.spawn(messages.process_messages,\n                     settings,\n                     USER_TOPIC,\n                     WORK_QUEUE),\n        # A greenlet to periodically report to statsd\n        gevent.spawn(report_stats, settings),\n        # And one to process the queued work\n        gevent.spawn(process_work_queue, settings, WORK_QUEUE)\n    ]\n\n    # Start a \"greenlet of last resort\" to monitor the worker greenlets and\n    # bail if any unexpected errors occur.\n    gevent.spawn(supervise, greenlets)\n\n\ndef process_work_queue(settings, queue, session_factory=None):\n    \"\"\"\n    Process each message from the queue in turn, handling exceptions.\n\n    This is the core of the streamer: we pull messages off the work queue,\n    dispatching them as appropriate. The handling of each message is wrapped in\n    code that ensures the database session is appropriately committed and\n    closed between messages.\n    \"\"\"\n    if session_factory is None:\n        session_factory = _get_session\n    s = stats.get_client(settings).pipeline()\n    session = session_factory(settings)\n    topic_handlers = {\n        ANNOTATION_TOPIC: messages.handle_annotation_event,\n        USER_TOPIC: messages.handle_user_event,\n    }\n\n    for msg in queue:\n        t_total = s.timer('streamer.msg.handler_total')\n        t_total.start()\n        try:\n            # All access to the database in the streamer is currently\n            # read-only, so enforce that:\n            session.execute(\"SET TRANSACTION \"\n                            \"ISOLATION LEVEL SERIALIZABLE \"\n                            \"READ ONLY \"\n                            \"DEFERRABLE\")\n\n            if isinstance(msg, messages.Message):\n                with s.timer('streamer.msg.handler_message'):\n                    messages.handle_message(msg, session, topic_handlers)\n            elif isinstance(msg, websocket.Message):\n                with s.timer('streamer.msg.handler_websocket'):\n                    websocket.handle_message(msg, session)\n            else:\n                raise UnknownMessageType(repr(msg))\n\n        except (KeyboardInterrupt, SystemExit):\n            session.rollback()\n            raise\n        except:\n            log.exception('Caught exception handling streamer message:')\n            session.rollback()\n        else:\n            session.commit()\n        finally:\n            session.close()\n        t_total.stop()\n        s.send()\n\n\ndef report_stats(settings):\n    client = stats.get_client(settings)\n    while True:\n        client.gauge('streamer.connected_clients',\n                     len(websocket.WebSocket.instances))\n        client.gauge('streamer.queue_length', WORK_QUEUE.qsize())\n        gevent.sleep(10)\n\n\ndef supervise(greenlets):\n    try:\n        gevent.joinall(greenlets, raise_error=True)\n    except (KeyboardInterrupt, SystemExit):\n        raise\n    except:\n        log.critical('Unexpected exception in streamer greenlet:',\n                     exc_info=True)\n    else:\n        log.critical('Unexpected early exit of streamer greenlets. Aborting!')\n    # If the worker greenlets exit early, our best option is to kill the worker\n    # process and let the app server take care of restarting it.\n    sys.exit(1)\n\n\ndef _get_session(settings):\n    engine = db.make_engine(settings)\n    return db.Session(bind=engine)\n"},{"size":3786,"relativepath":"h/streamer/websocket.py","filename":"websocket.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom collections import namedtuple\nimport json\nimport logging\nimport weakref\n\nfrom gevent.queue import Full\nimport jsonschema\nfrom ws4py.websocket import WebSocket as _WebSocket\n\nfrom memex import storage\nfrom h.streamer import filter\n\nlog = logging.getLogger(__name__)\n\n# An incoming message from a WebSocket client.\nMessage = namedtuple('Message', ['socket', 'payload'])\n\n\nclass WebSocket(_WebSocket):\n    # All instances of WebSocket, allowing us to iterate over open websockets\n    instances = weakref.WeakSet()\n    origins = []\n\n    # Instance attributes\n    client_id = None\n    filter = None\n    query = None\n\n    def __init__(self, sock, protocols=None, extensions=None, environ=None):\n        super(WebSocket, self).__init__(sock,\n                                        protocols=protocols,\n                                        extensions=extensions,\n                                        environ=environ,\n                                        heartbeat_freq=30.0)\n\n        self.authenticated_userid = environ['h.ws.authenticated_userid']\n        self.effective_principals = environ['h.ws.effective_principals']\n        self.registry = environ['h.ws.registry']\n\n        self._work_queue = environ['h.ws.streamer_work_queue']\n\n    def __new__(cls, *args, **kwargs):\n        instance = super(WebSocket, cls).__new__(cls, *args, **kwargs)\n        cls.instances.add(instance)\n        return instance\n\n    def received_message(self, msg):\n        try:\n            self._work_queue.put(Message(socket=self, payload=msg.data),\n                                 timeout=0.1)\n        except Full:\n            log.warn('Streamer work queue full! Unable to queue message from '\n                     'WebSocket client having waited 0.1s: giving up.')\n\n    def closed(self, code, reason=None):\n        try:\n            self.instances.remove(self)\n        except KeyError:\n            pass\n\n    def send_json(self, payload):\n        if not self.terminated:\n            self.send(json.dumps(payload))\n\n\ndef handle_message(message, session=None):\n    \"\"\"\n    Handle an incoming message from a client websocket.\n\n    Receives a :py:class:`~h.streamer.websocket.Message` instance, which holds\n    references to the :py:class:`~h.streamer.websocket.WebSocket` instance\n    associated with the client connection, as well as the message payload.\n\n    It updates state on the :py:class:`~h.streamer.websocket.WebSocket`\n    instance in response to the message content.\n\n    It may also passed a database session which *must* be used for any\n    communication with the database.\n    \"\"\"\n    socket = message.socket\n\n    data = json.loads(message.payload)\n\n    try:\n        msg_type = data.get('messageType', 'filter')\n\n        if msg_type == 'filter':\n            payload = data['filter']\n\n            # Let's try to validate the schema\n            jsonschema.validate(payload, filter.SCHEMA)\n\n            if session is not None:\n                # Add backend expands for clauses\n                _expand_clauses(session, payload)\n\n            socket.filter = filter.FilterHandler(payload)\n        elif msg_type == 'client_id':\n            socket.client_id = data.get('value')\n    except:\n        # TODO: clean this up, catch specific errors, narrow the scope\n        log.exception(\"Parsing filter: %s\", data)\n        socket.close()\n        raise\n\n\ndef _expand_clauses(session, payload):\n    for clause in payload['clauses']:\n        if clause['field'] == '/uri':\n            _expand_uris(session, clause)\n\n\ndef _expand_uris(session, clause):\n    uris = clause['value']\n    expanded = set()\n\n    if not isinstance(uris, list):\n        uris = [uris]\n\n    for item in uris:\n        expanded.update(storage.expand_uri(session, item))\n\n    clause['value'] = list(expanded)\n"},{"size":207,"relativepath":"h/streamer/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\ndef includeme(config):\n    config.include('h.streamer.views')\n\n    config.add_subscriber('h.streamer.streamer.start',\n                          'pyramid.events.ApplicationCreated')\n"},{"size":7314,"relativepath":"h/streamer/messages.py","filename":"messages.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom collections import namedtuple\nimport logging\n\nfrom gevent.queue import Full\n\nfrom h import realtime\nfrom h.realtime import Consumer\nfrom memex import presenters\nfrom memex import storage\nfrom memex.links import LinksService\nfrom h.auth.util import translate_annotation_principals\nfrom h.nipsa.services import NipsaService\nfrom h.streamer import websocket\nimport h.sentry\nimport h.stats\n\nlog = logging.getLogger(__name__)\n\n\n# An incoming message from a subscribed realtime consumer\nMessage = namedtuple('Message', ['topic', 'payload'])\n\n\ndef process_messages(settings, routing_key, work_queue, raise_error=True):\n    \"\"\"\n    Configure, start, and monitor a realtime consumer for the specified\n    routing key.\n\n    This sets up a :py:class:`h.realtime.Consumer` to route messages from\n    `routing_key` to the passed `work_queue`, and starts it. The consumer\n    should never return. If it does, this function will raise an exception.\n    \"\"\"\n\n    def _handler(payload):\n        try:\n            message = Message(topic=routing_key, payload=payload)\n            work_queue.put(message, timeout=0.1)\n        except Full:\n            log.warn('Streamer work queue full! Unable to queue message from '\n                     'h.realtime having waited 0.1s: giving up.')\n\n    conn = realtime.get_connection(settings)\n    sentry_client = h.sentry.get_client(settings)\n    statsd_client = h.stats.get_client(settings)\n    consumer = Consumer(connection=conn,\n                        routing_key=routing_key,\n                        handler=_handler,\n                        sentry_client=sentry_client,\n                        statsd_client=statsd_client)\n    consumer.run()\n\n    if raise_error:\n        raise RuntimeError('Realtime consumer quit unexpectedly!')\n\n\ndef handle_message(message, session, topic_handlers):\n    \"\"\"\n    Deserialize and process a message from the reader.\n\n    For each message, `handler` is called with the deserialized message and a\n    single :py:class:`h.streamer.WebSocket` instance, and should return the\n    message to be sent to the client on that socket. The handler can return\n    `None`, to signify that no message should be sent, or a JSON-serializable\n    object. It is assumed that there is a 1:1 request-reply mapping between\n    incoming messages and messages to be sent out over the websockets.\n    \"\"\"\n    try:\n        handler = topic_handlers[message.topic]\n    except KeyError:\n        raise RuntimeError(\"Don't know how to handle message from topic: \"\n                           \"{}\".format(message.topic))\n\n    # N.B. We iterate over a non-weak list of instances because there's nothing\n    # to stop connections being added or dropped during iteration, and if that\n    # happens Python will throw a \"Set changed size during iteration\" error.\n    sockets = list(websocket.WebSocket.instances)\n    handler(message.payload, sockets, session)\n\n\ndef handle_annotation_event(message, sockets, session):\n    id_ = message['annotation_id']\n    annotation = storage.fetch_annotation(session, id_)\n\n    # FIXME: It isn't really nice to try and get the userid from the fetched\n    # annotation or otherwise get it from the maybe-already serialized\n    # annotation dict, to then only access the database for the nipsa flag once.\n    # We do this because the event action is `delete` at which point we can't\n    # load the annotation from the database. Handling annotation deletions is\n    # a known problem and will be fixed in the future.\n    userid = None\n    if annotation:\n        userid = annotation.userid\n    else:\n        userid = message.get('annotation_dict', {}).get('user')\n    nipsa_service = NipsaService(session)\n    user_nipsad = nipsa_service.is_flagged(userid)\n\n    for socket in sockets:\n        reply = _generate_annotation_event(message, socket, annotation, user_nipsad)\n        if reply is None:\n            continue\n        socket.send_json(reply)\n\n\ndef handle_user_event(message, sockets, _):\n    for socket in sockets:\n        reply = _generate_user_event(message, socket)\n        if reply is None:\n            continue\n        socket.send_json(reply)\n\n\ndef _generate_annotation_event(message, socket, annotation, user_nipsad):\n    \"\"\"\n    Get message about annotation event `message` to be sent to `socket`.\n\n    Inspects the embedded annotation event and decides whether or not the\n    passed socket should receive notification of the event.\n\n    Returns None if the socket should not receive any message about this\n    annotation event, otherwise a dict containing information about the event.\n    \"\"\"\n    action = message['action']\n\n    if action == 'read':\n        return None\n\n    if message['src_client_id'] == socket.client_id:\n        return None\n\n    # We don't send anything until we have received a filter from the client\n    if socket.filter is None:\n        return None\n\n    notification = {\n        'type': 'annotation-notification',\n        'options': {'action': action},\n    }\n    id_ = message['annotation_id']\n\n    # Return early when action is delete\n    serialized = None\n    if action == 'delete':\n        serialized = message['annotation_dict']\n    else:\n        if annotation is None:\n            return None\n\n        base_url = socket.registry.settings.get('h.app_url',\n                                                'http://localhost:5000')\n        links_service = LinksService(base_url, socket.registry)\n        serialized = presenters.AnnotationJSONPresenter(annotation,\n                                                        links_service).asdict()\n\n    userid = serialized.get('user')\n    if user_nipsad and socket.authenticated_userid != userid:\n        return None\n\n    permissions = serialized.get('permissions')\n    if not _authorized_to_read(socket.effective_principals, permissions):\n        return None\n\n    if not socket.filter.match(serialized, action):\n        return None\n\n    notification['payload'] = [serialized]\n    if action == 'delete':\n        notification['payload'] = [{'id': id_}]\n    return notification\n\n\ndef _generate_user_event(message, socket):\n    \"\"\"\n    Get message about user event `message` to be sent to `socket`.\n\n    Inspects the embedded user event and decides whether or not the passed\n    socket should receive notification of the event.\n\n    Returns None if the socket should not receive any message about this user\n    event, otherwise a dict containing information about the event.\n    \"\"\"\n    if socket.authenticated_userid != message['userid']:\n        return None\n\n    # for session state change events, the full session model\n    # is included so that clients can update themselves without\n    # further API requests\n    return {\n        'type': 'session-change',\n        'action': message['type'],\n        'model': message['session_model']\n    }\n\n\ndef _authorized_to_read(effective_principals, permissions):\n    \"\"\"Return True if the passed request is authorized to read the annotation.\n\n    If the annotation belongs to a private group, this will return False if the\n    authenticated user isn't a member of that group.\n    \"\"\"\n    read_permissions = permissions.get('read', [])\n    read_principals = translate_annotation_principals(read_permissions)\n    if set(read_principals).intersection(effective_principals):\n        return True\n    return False\n"},{"size":2979,"relativepath":"h/streamer/views.py","filename":"views.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom pyramid import httpexceptions\nfrom pyramid.config import aslist\nfrom pyramid.view import forbidden_view_config\nfrom pyramid.view import notfound_view_config\nfrom pyramid.view import view_config\nfrom ws4py.exc import HandshakeError\nfrom ws4py.server.wsgiutils import WebSocketWSGIApplication\n\nfrom h.streamer import streamer, websocket\n\n\n@view_config(route_name='ws')\ndef websocket_view(request):\n    # WebSockets can be opened across origins and send cookies. To prevent\n    # scripts on other sites from using this socket, ensure that the Origin\n    # header (if present) matches the request host URL or is whitelisted.\n    origin = request.headers.get('Origin')\n    allowed = request.registry.settings['origins']\n    if origin is not None:\n        if origin != request.host_url and origin not in allowed:\n            return httpexceptions.HTTPForbidden()\n\n    # Provide environment which the WebSocket handler can use...\n    request.environ.update({\n        'h.ws.authenticated_userid': request.authenticated_userid,\n        'h.ws.effective_principals': request.effective_principals,\n        'h.ws.registry': request.registry,\n        'h.ws.streamer_work_queue': streamer.WORK_QUEUE,\n    })\n\n    # ...and ensure that any persistent connections associated with this\n    # WebSocket connection are closed.\n    request.db.close()\n\n    app = WebSocketWSGIApplication(handler_cls=websocket.WebSocket)\n    return request.get_response(app)\n\n\n@notfound_view_config(renderer='json')\ndef notfound(exc, request):\n    request.response.status_code = 404\n    request.stats.incr('streamer.error.not_found')\n    return {\n        'ok': False,\n        'error': 'not_found',\n        'reason': 'These are not the droids you are looking for.',\n    }\n\n\n@forbidden_view_config(renderer='json')\ndef forbidden(exc, request):\n    request.response.status_code = 403\n    request.stats.incr('streamer.error.forbidden')\n    return {\n        'ok': False,\n        'error': 'forbidden',\n        'reason': 'You are not allowed here. Are you connecting from an '\n                  'allowed origin?',\n    }\n\n\n@view_config(context=HandshakeError, renderer='json')\ndef error_badhandshake(exc, request):\n    request.response.status_code = 400\n    request.stats.incr('streamer.error.bad_handshake')\n    return {\n        'ok': False,\n        'error': 'bad_handshake',\n        'reason': 'Handshake failed. Are you a WebSocket client?',\n    }\n\n\n@view_config(context=Exception, renderer='json')\ndef error(context, request):\n    request.response.status_code = 500\n    request.sentry.captureException()\n    request.stats.incr('streamer.error.server_error')\n    if request.debug:\n        raise\n    return {\n        'ok': False,\n        'error': 'server_error',\n        'reason': 'An unexpected error occurred and has been reported.',\n    }\n\n\ndef includeme(config):\n    settings = config.registry.settings\n    settings['origins'] = aslist(settings.get('origins', ''))\n\n    config.scan(__name__)\n"},{"size":6008,"relativepath":"h/streamer/filter.py","filename":"filter.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport copy\nimport operator\nimport unicodedata\n\nfrom jsonpointer import resolve_pointer\nfrom h._compat import text_type\n\nSCHEMA = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"name\": {\"type\": \"string\", \"optional\": True},\n        \"match_policy\": {\n            \"type\": \"string\",\n            \"enum\": [\"include_any\", \"include_all\",\n                     \"exclude_any\", \"exclude_all\"]\n        },\n        \"actions\": {\n            \"create\": {\"type\": \"boolean\", \"default\":  True},\n            \"update\": {\"type\": \"boolean\", \"default\":  True},\n            \"delete\": {\"type\": \"boolean\", \"default\":  True},\n        },\n        \"clauses\": {\n            \"type\": \"array\",\n            \"items\": {\n                \"field\": {\"type\": \"string\", \"format\": \"json-pointer\"},\n                \"operator\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"equals\", \"matches\", \"lt\", \"le\", \"gt\", \"ge\",\n                             \"one_of\", \"first_of\", \"match_of\",\n                             \"lene\", \"leng\", \"lenge\", \"lenl\", \"lenle\"]\n                },\n                \"value\": \"object\",\n                \"options\": {\"type\": \"object\", \"default\": {}}\n            }\n        },\n    },\n    \"required\": [\"match_policy\", \"clauses\", \"actions\"]\n}\n\n\nclass FilterHandler(object):\n    def __init__(self, filter_json):\n        self.filter = filter_json\n\n    # operators\n    operators = {\n        'equals': 'eq',\n        'matches': 'contains',\n        'lt': 'lt',\n        'le': 'le',\n        'gt': 'gt',\n        'ge': 'ge',\n        'one_of': 'contains',\n        'first_of': 'first_of',\n        'match_of': 'match_of',\n        'lene': 'lene',\n        'leng': 'leng',\n        'lenge': 'lenge',\n        'lenl': 'lenl',\n        'lenle': 'lenle',\n    }\n\n    def evaluate_clause(self, clause, target):\n        if isinstance(clause['field'], list):\n            for field in clause['field']:\n                copied = copy.deepcopy(clause)\n                copied['field'] = field\n                result = self.evaluate_clause(copied, target)\n                if result:\n                    return True\n            return False\n        else:\n            field_value = resolve_pointer(target, clause['field'], None)\n            if field_value is None:\n                return False\n\n            cval = clause['value']\n            fval = field_value\n\n            if isinstance(cval, list):\n                tval = []\n                for cv in cval:\n                    tval.append(uni_fold(cv))\n                cval = tval\n            else:\n                cval = uni_fold(cval)\n\n            if isinstance(fval, list):\n                tval = []\n                for fv in fval:\n                    tval.append(uni_fold(fv))\n                fval = tval\n            else:\n                fval = uni_fold(fval)\n\n            reversed_order = False\n            # Determining operator order\n            # Normal order: field_value, clause['value']\n            # i.e. condition created > 2000.01.01\n            # Here clause['value'] = '2001.01.01'.\n            # The field_value is target['created']\n            # So the natural order is: ge(field_value, clause['value']\n\n            # But!\n            # Reversed operator order for contains (b in a)\n            if isinstance(cval, list) or isinstance(fval, list):\n                if clause['operator'] in ['one_of', 'matches']:\n                    reversed_order = True\n                    # But not in every case. (i.e. tags matches 'b')\n                    # Here field_value is a list, because an annotation can\n                    # have many tags.\n                    if isinstance(field_value, list):\n                        reversed_order = False\n\n            if reversed_order:\n                lval = cval\n                rval = fval\n            else:\n                lval = fval\n                rval = cval\n\n            op = getattr(operator, self.operators[clause['operator']])\n            return op(lval, rval)\n\n    # match_policies\n    def include_any(self, target):\n        for clause in self.filter['clauses']:\n            if self.evaluate_clause(clause, target):\n                return True\n        return False\n\n    def include_all(self, target):\n        for clause in self.filter['clauses']:\n            if not self.evaluate_clause(clause, target):\n                return False\n        return True\n\n    def exclude_all(self, target):\n        for clause in self.filter['clauses']:\n            if not self.evaluate_clause(clause, target):\n                return True\n        return False\n\n    def exclude_any(self, target):\n        for clause in self.filter['clauses']:\n            if self.evaluate_clause(clause, target):\n                return False\n        return True\n\n    def match(self, target, action=None):\n        if not action or action == 'past' or action in self.filter['actions']:\n            if len(self.filter['clauses']) > 0:\n                return getattr(self, self.filter['match_policy'])(target)\n            else:\n                return True\n        else:\n            return False\n\n\ndef first_of(a, b):\n    return a[0] == b\nsetattr(operator, 'first_of', first_of)\n\n\ndef match_of(a, b):\n    for subb in b:\n        if subb in a:\n            return True\n    return False\nsetattr(operator, 'match_of', match_of)\n\n\ndef lene(a, b):\n    return len(a) == b\nsetattr(operator, 'lene', lene)\n\n\ndef leng(a, b):\n    return len(a) > b\nsetattr(operator, 'leng', leng)\n\n\ndef lenge(a, b):\n    return len(a) >= b\nsetattr(operator, 'lenge', lenge)\n\n\ndef lenl(a, b):\n    return len(a) < b\nsetattr(operator, 'lenl', lenl)\n\n\ndef lenle(a, b):\n    return len(a) <= b\nsetattr(operator, 'lenle', lenle)\n\n\ndef uni_fold(text):\n    # Convert bytes to text\n    if isinstance(text, bytes):\n        text = text_type(text, \"utf-8\")\n\n    # Do not touch other types\n    if not isinstance(text, text_type):\n        return text\n\n    text = text.lower()\n    text = unicodedata.normalize('NFKD', text)\n    return u\"\".join([c for c in text if not unicodedata.combining(c)])\n"},{"size":173,"relativepath":"h/admin/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\ndef includeme(config):\n    config.register_service_factory('.services.user.rename_user_factory', name='rename_user')\n\n    config.include('.views')\n"},{"size":1264,"relativepath":"h/admin/views/groups.py","filename":"groups.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom pyramid.view import view_config\n\nfrom h import models\nfrom h import paginator\n\n\n@view_config(route_name='admin_groups',\n             request_method='GET',\n             renderer='h:templates/admin/groups.html.jinja2',\n             permission='admin_groups')\n@paginator.paginate_query\ndef groups_index(context, request):\n    return request.db.query(models.Group).order_by(models.Group.created.desc())\n\n\n@view_config(route_name='admin_groups_csv',\n             request_method='GET',\n             renderer='csv',\n             permission='admin_groups')\ndef groups_index_csv(request):\n    groups = request.db.query(models.Group)\n\n    header = ['Group name', 'Group URL', 'Creator username',\n              'Creator email', 'Number of members']\n    rows = [[group.name,\n             request.route_url('group_read',\n                               pubid=group.pubid,\n                               slug=group.slug),\n             group.creator.username,\n             group.creator.email,\n             len(group.members)] for group in groups]\n\n    filename = 'groups.csv'\n    request.response.content_disposition = 'attachment;filename=' + filename\n\n    return {'header': header, 'rows': rows}\n\n\ndef includeme(config):\n    config.scan(__name__)\n"},{"size":1788,"relativepath":"h/admin/views/staff.py","filename":"staff.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom pyramid import httpexceptions\nfrom pyramid.view import view_config\n\nfrom h import models\nfrom h.i18n import TranslationString as _\n\n\n@view_config(route_name='admin_staff',\n             request_method='GET',\n             renderer='h:templates/admin/staff.html.jinja2',\n             permission='admin_staff')\ndef staff_index(request):\n    \"\"\"A list of all the staff members as an HTML page.\"\"\"\n    staff = request.db.query(models.User).filter(models.User.staff)\n    return {\"staff\": [u.username for u in staff]}\n\n\n@view_config(route_name='admin_staff',\n             request_method='POST',\n             request_param='add',\n             renderer='h:templates/admin/staff.html.jinja2',\n             permission='admin_staff')\ndef staff_add(request):\n    \"\"\"Make a given user a staff member.\"\"\"\n    username = request.params['add']\n    user = models.User.get_by_username(request.db, username)\n    if user is None:\n        request.session.flash(\n            _(\"User {username} doesn't exist.\".format(username=username)),\n            \"error\")\n    else:\n        user.staff = True\n    index = request.route_path('admin_staff')\n    return httpexceptions.HTTPSeeOther(location=index)\n\n\n@view_config(route_name='admin_staff',\n             request_method='POST',\n             request_param='remove',\n             renderer='h:templates/admin/staff.html.jinja2',\n             permission='admin_staff')\ndef staff_remove(request):\n    \"\"\"Remove a user from the staff.\"\"\"\n    username = request.params['remove']\n    user = models.User.get_by_username(request.db, username)\n    if user is not None:\n        user.staff = False\n    index = request.route_path('admin_staff')\n    return httpexceptions.HTTPSeeOther(location=index)\n\n\ndef includeme(config):\n    config.scan(__name__)\n"},{"size":5042,"relativepath":"h/admin/views/users.py","filename":"users.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom elasticsearch import helpers as es_helpers\nimport jinja2\nfrom pyramid import httpexceptions\nfrom pyramid.view import view_config\n\nfrom h import models\nfrom h.accounts.events import ActivationEvent\nfrom h.admin import worker\nfrom h.admin.services.user import UserRenameError\nfrom memex import storage\nfrom h.i18n import TranslationString as _\n\n\nclass UserDeletionError(Exception):\n    pass\n\n\nclass UserNotFoundError(Exception):\n    pass\n\n\n@view_config(route_name='admin_users',\n             request_method='GET',\n             renderer='h:templates/admin/users.html.jinja2',\n             permission='admin_users')\ndef users_index(request):\n    user = None\n    user_meta = {}\n    username = request.params.get('username')\n\n    if username:\n        user = models.User.get_by_username(request.db, username)\n        if user is None:\n            user = models.User.get_by_email(request.db, username)\n\n    if user is not None:\n        n_annots = _all_user_annotations(request, user).count()\n        user_meta['annotations_count'] = n_annots\n\n    return {'username': username, 'user': user, 'user_meta': user_meta}\n\n\n@view_config(route_name='admin_users_activate',\n             request_method='POST',\n             request_param='username',\n             permission='admin_users')\ndef users_activate(request):\n    user = _form_request_user(request)\n\n    user.activate()\n\n    request.session.flash(jinja2.Markup(_(\n        'User {name} has been activated!'.format(name=user.username))),\n        'success')\n\n    request.registry.notify(ActivationEvent(request, user))\n\n    return httpexceptions.HTTPFound(\n        location=request.route_path('admin_users',\n                                    _query=(('username', user.username),)))\n\n\n@view_config(route_name='admin_users_rename',\n             request_method='POST',\n             permission='admin_users')\ndef users_rename(request):\n    user = _form_request_user(request)\n\n    old_username = user.username\n    new_username = request.params.get('new_username')\n\n    try:\n        svc = request.find_service(name='rename_user')\n        svc.check(new_username)\n\n        worker.rename_user.delay(user.id, new_username)\n\n        request.session.flash(\n            'The user \"%s\" will be renamed to \"%s\" in the backgroud. Refresh this page to see if it\\'s already done' %\n            (old_username, new_username), 'success')\n\n        return httpexceptions.HTTPFound(\n            location=request.route_path('admin_users',\n                                        _query=(('username', new_username),)))\n\n    except (UserRenameError, ValueError) as e:\n        request.session.flash(str(e), 'error')\n        return httpexceptions.HTTPFound(\n            location=request.route_path('admin_users',\n                                        _query=(('username', old_username),)))\n\n\n@view_config(route_name='admin_users_delete',\n             request_method='POST',\n             permission='admin_users')\ndef users_delete(request):\n    user = _form_request_user(request)\n\n    try:\n        delete_user(request, user)\n        request.session.flash(\n            'Successfully deleted user %s' % user.username, 'success')\n    except UserDeletionError as e:\n        request.session.flash(str(e), 'error')\n\n    return httpexceptions.HTTPFound(\n        location=request.route_path('admin_users'))\n\n\n@view_config(context=UserNotFoundError)\ndef user_not_found(exc, request):\n    request.session.flash(jinja2.Markup(_(exc.message)), 'error')\n    return httpexceptions.HTTPFound(location=request.route_path('admin_users'))\n\n\ndef delete_user(request, user):\n    \"\"\"\n    Deletes a user with all their group memberships and annotations.\n\n    Raises UserDeletionError when deletion fails with the appropriate error\n    message.\n    \"\"\"\n\n    if models.Group.created_by(request.db, user).count() > 0:\n        raise UserDeletionError('Cannot delete user who is a group creator.')\n\n    user.groups = []\n\n    query = _all_user_annotations_query(request, user)\n    annotations = es_helpers.scan(client=request.es.conn, query={'query': query})\n    for annotation in annotations:\n        storage.delete_annotation(request.db, annotation['_id'])\n\n    request.db.delete(user)\n\n\ndef _all_user_annotations_query(request, user):\n    \"\"\"Query matching all annotations (shared and private) owned by user.\"\"\"\n    return {\n        'filtered': {\n            'filter': {'term': {'user': user.userid.lower()}},\n            'query': {'match_all': {}}\n        }\n    }\n\n\ndef _all_user_annotations(request, user):\n    return (request.db.query(models.Annotation)\n            .filter(models.Annotation.userid == user.userid)\n            .yield_per(100))\n\n\ndef _form_request_user(request):\n    \"\"\"Return the User which a user admin form action relates to.\"\"\"\n    username = request.params['username']\n    user = models.User.get_by_username(request.db, username)\n\n    if user is None:\n        raise UserNotFoundError(\"Could not find user with username %s\" % username)\n\n    return user\n\n\ndef includeme(config):\n    config.scan(__name__)\n"},{"size":1608,"relativepath":"h/admin/views/badge.py","filename":"badge.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom pyramid import httpexceptions\nfrom pyramid.view import view_config\nfrom sqlalchemy.exc import IntegrityError\n\nfrom h import models\nfrom h.i18n import TranslationString as _\n\n\n@view_config(route_name='admin_badge',\n             request_method='GET',\n             renderer='h:templates/admin/badge.html.jinja2',\n             permission='admin_badge')\ndef badge_index(request):\n    return {\"uris\": request.db.query(models.Blocklist).all()}\n\n\n@view_config(route_name='admin_badge',\n             request_method='POST',\n             request_param='add',\n             permission='admin_badge')\ndef badge_add(request):\n    uri = request.params['add']\n    item = models.Blocklist(uri=uri)\n    request.db.add(item)\n\n    # There's a uniqueness constraint on `uri`, so we flush the session,\n    # catching any IntegrityError and responding appropriately.\n    try:\n        request.db.flush()\n    except IntegrityError:\n        request.db.rollback()\n        msg = _(\"{uri} is already blocked.\").format(uri=uri)\n        request.session.flash(msg, 'error')\n\n    index = request.route_path('admin_badge')\n    return httpexceptions.HTTPSeeOther(location=index)\n\n\n@view_config(route_name='admin_badge',\n             request_method='POST',\n             request_param='remove',\n             permission='admin_badge')\ndef badge_remove(request):\n    uri = request.params['remove']\n    request.db.query(models.Blocklist).filter_by(uri=uri).delete()\n\n    index = request.route_path('admin_badge')\n    return httpexceptions.HTTPSeeOther(location=index)\n\n\ndef includeme(config):\n    config.scan(__name__)\n"},{"size":286,"relativepath":"h/admin/views/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\ndef includeme(config):\n    config.include('.index')\n    config.include('.admins')\n    config.include('.badge')\n    config.include('.features')\n    config.include('.groups')\n    config.include('.nipsa')\n    config.include('.staff')\n    config.include('.users')\n"},{"size":4470,"relativepath":"h/admin/views/features.py","filename":"features.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom pyramid import httpexceptions\nfrom pyramid import session\nfrom pyramid.view import view_config\n\nfrom h import models\nfrom h import paginator\nfrom h.i18n import TranslationString as _\n\n\n@view_config(route_name='admin_features',\n             request_method='GET',\n             renderer='h:templates/admin/features.html.jinja2',\n             permission='admin_features')\ndef features_index(request):\n    return {\n        \"features\": models.Feature.all(request.db),\n        \"cohorts\": request.db.query(models.FeatureCohort).all(),\n    }\n\n\n@view_config(route_name='admin_features',\n             request_method='POST',\n             permission='admin_features')\ndef features_save(request):\n    session.check_csrf_token(request)\n    for feat in models.Feature.all(request.db):\n        for attr in ['everyone', 'admins', 'staff']:\n            val = request.POST.get('{0}[{1}]'.format(feat.name, attr))\n            if val == 'on':\n                setattr(feat, attr, True)\n            else:\n                setattr(feat, attr, False)\n        for cohort in request.db.query(models.FeatureCohort).all():\n            val = request.POST.get('{0}[cohorts][{1}]'.format(feat.name, cohort.name))\n            if val == 'on':\n                if cohort not in feat.cohorts:\n                    feat.cohorts.append(cohort)\n            else:\n                if cohort in feat.cohorts:\n                    feat.cohorts.remove(cohort)\n\n    request.session.flash(_(\"Changes saved.\"), \"success\")\n    return httpexceptions.HTTPSeeOther(\n        location=request.route_url('admin_features'))\n\n\n@view_config(route_name='admin_cohorts',\n             request_method='GET',\n             renderer='h:templates/admin/cohorts.html.jinja2',\n             permission='admin_features')\n@paginator.paginate_query\ndef cohorts_index(context, request):\n    query = request.db.query(models.FeatureCohort)\n    return query.order_by(models.FeatureCohort.name)\n\n\n@view_config(route_name='admin_cohorts',\n             request_method='POST',\n             request_param='add',\n             renderer='h:templates/admin/cohorts.html.jinja2',\n             permission='admin_features')\ndef cohorts_add(request):\n    \"\"\"Create a new feature cohort.\"\"\"\n    cohort_name = request.params['add']\n    cohort = models.FeatureCohort(name=cohort_name)\n    request.db.add(cohort)\n\n    url = request.route_url('admin_cohorts')\n    return httpexceptions.HTTPSeeOther(url)\n\n\n@view_config(route_name='admin_cohorts_edit',\n             request_method='GET',\n             renderer='h:templates/admin/edit_cohort.html.jinja2',\n             permission='admin_features')\ndef cohorts_edit(context, request):\n    id = request.matchdict['id']\n    cohort = request.db.query(models.FeatureCohort).get(id)\n    return {'cohort': cohort, 'members': cohort.members}\n\n\n@view_config(route_name='admin_cohorts_edit',\n             request_method='POST',\n             request_param='add',\n             renderer='h:templates/admin/edit_cohort.html.jinja2',\n             permission='admin_features')\ndef cohorts_edit_add(request):\n    member_name = request.params['add']\n    cohort_id = request.matchdict['id']\n\n    member = models.User.get_by_username(request.db, member_name)\n    if member is None:\n        request.session.flash(\n            _(\"User {member_name} doesn't exist.\".format(member_name=member_name)),\n            \"error\")\n    else:\n        cohort = request.db.query(models.FeatureCohort).get(cohort_id)\n        cohort.members.append(member)\n\n    url = request.route_url('admin_cohorts_edit', id=cohort_id)\n    return httpexceptions.HTTPSeeOther(url)\n\n\n@view_config(route_name='admin_cohorts_edit',\n             request_method='POST',\n             request_param='remove',\n             renderer='h:templates/admin/edit_cohort.html.jinja2',\n             permission='admin_features')\ndef cohorts_edit_remove(request):\n    member_name = request.params['remove']\n    cohort_id = request.matchdict['id']\n\n    cohort = request.db.query(models.FeatureCohort).get(cohort_id)\n    member = request.db.query(models.User).filter_by(username=member_name).first()\n    try:\n        cohort.members.remove(member)\n    except ValueError:\n        request.session.flash(\n            _(\"User {member_name} doesn't exist.\".format(member_name=member_name)),\n            \"error\")\n\n    url = request.route_url('admin_cohorts_edit', id=cohort_id)\n    return httpexceptions.HTTPSeeOther(url)\n\n\ndef includeme(config):\n    config.scan(__name__)\n"},{"size":1890,"relativepath":"h/admin/views/nipsa.py","filename":"nipsa.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom pyramid import httpexceptions\nfrom pyramid.view import view_config\n\nfrom h import models\nfrom h.i18n import TranslationString as _\n\n\nclass UserNotFoundError(Exception):\n    pass\n\n\n@view_config(route_name='admin_nipsa',\n             request_method='GET',\n             renderer='h:templates/admin/nipsa.html.jinja2',\n             permission='admin_nipsa')\ndef nipsa_index(request):\n    nipsa_service = request.find_service(name='nipsa')\n    return {\"usernames\": [u.username for u in nipsa_service.flagged_users]}\n\n\n@view_config(route_name='admin_nipsa',\n             request_method='POST',\n             request_param='add',\n             permission='admin_nipsa')\ndef nipsa_add(request):\n    user = _form_request_user(request, 'add')\n\n    nipsa_service = request.find_service(name='nipsa')\n    nipsa_service.flag(user)\n\n    index = request.route_path(\"admin_nipsa\")\n    return httpexceptions.HTTPSeeOther(index)\n\n\n@view_config(route_name='admin_nipsa',\n             request_method='POST',\n             request_param='remove',\n             permission='admin_nipsa')\ndef nipsa_remove(request):\n    user = _form_request_user(request, 'remove')\n\n    nipsa_service = request.find_service(name='nipsa')\n    nipsa_service.unflag(user)\n\n    index = request.route_path(\"admin_nipsa\")\n    return httpexceptions.HTTPSeeOther(index)\n\n\n@view_config(context=UserNotFoundError)\ndef user_not_found(exc, request):\n    request.session.flash(exc.message, 'error')\n    return httpexceptions.HTTPFound(location=request.route_path('admin_nipsa'))\n\n\ndef _form_request_user(request, param):\n    username = request.params[param]\n    user = models.User.get_by_username(request.db, username)\n\n    if user is None:\n        raise UserNotFoundError(\n            _(\"Could not find user with username %s\" % username)\n        )\n\n    return user\n\n\ndef includeme(config):\n    config.scan(__name__)\n"},{"size":1919,"relativepath":"h/admin/views/admins.py","filename":"admins.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom pyramid import httpexceptions\nfrom pyramid.view import view_config\n\nfrom h import models\nfrom h.i18n import TranslationString as _\n\n\n@view_config(route_name='admin_admins',\n             request_method='GET',\n             renderer='h:templates/admin/admins.html.jinja2',\n             permission='admin_admins')\ndef admins_index(request):\n    \"\"\"A list of all the admin users as an HTML page.\"\"\"\n    admins = request.db.query(models.User).filter(models.User.admin)\n    return {\"admin_users\": [u.username for u in admins]}\n\n\n@view_config(route_name='admin_admins',\n             request_method='POST',\n             request_param='add',\n             renderer='h:templates/admin/admins.html.jinja2',\n             permission='admin_admins')\ndef admins_add(request):\n    \"\"\"Make a given user an admin.\"\"\"\n    username = request.params['add']\n    user = models.User.get_by_username(request.db, username)\n    if user is None:\n        request.session.flash(\n            _(\"User {username} doesn't exist.\".format(username=username)),\n            \"error\")\n    else:\n        user.admin = True\n    index = request.route_path('admin_admins')\n    return httpexceptions.HTTPSeeOther(location=index)\n\n\n@view_config(route_name='admin_admins',\n             request_method='POST',\n             request_param='remove',\n             renderer='h:templates/admin/admins.html.jinja2',\n             permission='admin_admins')\ndef admins_remove(request):\n    \"\"\"Remove a user from the admins.\"\"\"\n    n_admins = request.db.query(models.User).filter(models.User.admin).count()\n    if n_admins > 1:\n        username = request.params['remove']\n        user = models.User.get_by_username(request.db, username)\n        if user is not None:\n            user.admin = False\n    index = request.route_path('admin_admins')\n    return httpexceptions.HTTPSeeOther(location=index)\n\n\ndef includeme(config):\n    config.scan(__name__)\n"},{"size":536,"relativepath":"h/admin/views/index.py","filename":"index.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport platform\n\nfrom pyramid.view import view_config\n\nfrom h import __version__\n\n\n@view_config(route_name='admin_index',\n             request_method='GET',\n             renderer='h:templates/admin/index.html.jinja2',\n             permission='admin_index')\ndef index(_):\n    return {\n        'release_info': {\n            'hostname': platform.node(),\n            'python_version': platform.python_version(),\n            'version': __version__,\n        }\n    }\n\n\ndef includeme(config):\n    config.scan(__name__)\n"},{"size":486,"relativepath":"h/admin/worker.py","filename":"worker.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom h import models\nfrom h.celery import celery\nfrom h.celery import get_task_logger\n\n\nlog = get_task_logger(__name__)\n\n\n@celery.task\ndef rename_user(user_id, new_username):\n    user = celery.request.db.query(models.User).get(user_id)\n    if user is None:\n        raise ValueError(\"Could not find user with id %d\" % user_id)\n\n    svc = celery.request.find_service(name='rename_user')\n    svc.rename(user, new_username)\n"},{"size":2603,"relativepath":"h/admin/services/user.py","filename":"user.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom h import models\nfrom memex.search import index\n\n\nclass UserRenameError(Exception):\n    pass\n\n\nclass RenameUserService(object):\n    \"\"\"\n    Renames a user and updates all its annotations.\n\n    ``check`` should be called first\n\n    Validates the new username and updates the User. The user's annotations\n    userid field will be updated. It accepts a reindex function that gets a\n    list of annotation ids, it is then the function's responsibility to reindex\n    these annotations in the search index.\n\n    This also invalidates all authentication tickets, forcing the user to\n    login again.\n\n    May raise a ValueError if the new username does not validate or\n    UserRenameError if the new username is already taken by another account.\n    \"\"\"\n    def __init__(self, session, reindex):\n        self.session = session\n        self.reindex = reindex\n\n    def check(self, new_username):\n        existing_user = models.User.get_by_username(self.session, new_username)\n        if existing_user:\n            raise UserRenameError('Another user already has the username \"%s\"' % new_username)\n\n        return True\n\n    def rename(self, user, new_username):\n        self.check(new_username)\n\n        old_userid = user.userid\n\n        user.username = new_username\n        new_userid = user.userid\n\n        self._purge_auth_tickets(user)\n\n        ids = self._change_annotations(old_userid, new_userid)\n\n        self.reindex(ids)\n\n    def _purge_auth_tickets(self, user):\n        self.session.query(models.AuthTicket) \\\n            .filter(models.AuthTicket.user_id == user.id) \\\n            .delete()\n\n    def _change_annotations(self, old_userid, new_userid):\n        annotations = self._fetch_annotations(old_userid)\n\n        ids = set()\n        for annotation in annotations:\n            annotation.userid = new_userid\n            ids.add(annotation.id)\n\n        return ids\n\n    def _fetch_annotations(self, userid):\n        return (self.session.query(models.Annotation)\n                .filter(models.Annotation.userid == userid)\n                .yield_per(100))\n\n\ndef make_indexer(request):\n    def _reindex(ids):\n        if not ids:\n            return\n\n        request.tm.commit()\n        indexer = index.BatchIndexer(request.db, request.es, request)\n        indexer.index(ids)\n    return _reindex\n\n\ndef rename_user_factory(context, request):\n    \"\"\"Return a RenameUserService instance for the passed context and request.\"\"\"\n    return RenameUserService(session=request.db,\n                             reindex=make_indexer(request))\n"},{"size":1080,"relativepath":"h/indexer.py","filename":"indexer.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport logging\n\nfrom h.celery import celery\n\nfrom memex import storage\nfrom memex.search.index import index\nfrom memex.search.index import delete\nfrom memex.search.index import reindex\n\n__all__ = (\n    'add_annotation',\n    'delete_annotation',\n    'reindex_annotations',\n)\n\n\nlog = logging.getLogger(__name__)\n\n\n@celery.task\ndef add_annotation(id_):\n    annotation = storage.fetch_annotation(celery.request.db, id_)\n    if annotation:\n        index(celery.request.es, annotation, celery.request)\n\n\n@celery.task\ndef delete_annotation(id_):\n    delete(celery.request.es, id_)\n\n\n@celery.task\ndef reindex_annotations():\n    reindex(celery.request.db, celery.request.es, celery.request)\n\n\ndef subscribe_annotation_event(event):\n    if event.action in ['create', 'update']:\n        add_annotation.delay(event.annotation_id)\n    elif event.action == 'delete':\n        delete_annotation.delay(event.annotation_id)\n\n\ndef includeme(config):\n    config.add_subscriber('h.indexer.subscribe_annotation_event',\n                          'memex.events.AnnotationEvent')\n"},{"size":101,"relativepath":"h/util/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom h.util import user\nfrom h.util import view\n\n__all__ = ('user', 'view')\n"},{"size":638,"relativepath":"h/util/view.py","filename":"view.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom pyramid.view import view_config\n\n\ndef handle_exception(request):\n    \"\"\"Handle an uncaught exception for the passed request.\"\"\"\n    request.response.status_int = 500\n    request.sentry.captureException()\n    # In debug mode we should just reraise, so that the exception is caught by\n    # the debug toolbar.\n    if request.debug:\n        raise\n\n\ndef json_view(**settings):\n    \"\"\"A view configuration decorator with JSON defaults.\"\"\"\n    settings.setdefault('accept', 'application/json')\n    settings.setdefault('renderer', 'json')\n    return view_config(**settings)\n"},{"size":648,"relativepath":"h/util/user.py","filename":"user.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"Some shared utility functions for manipulating user data.\"\"\"\nimport re\n\n\ndef split_user(userid):\n    \"\"\"Return the user and domain parts from the given user id as a dict.\n\n    For example if userid is u'acct:seanh@hypothes.is' then return\n    {'username': u'seanh', 'domain': u'hypothes.is'}'\n\n    :raises ValueError: if the given userid isn't a valid userid\n\n    \"\"\"\n    match = re.match(r'^acct:([^@]+)@(.*)$', userid)\n    if match:\n        return {\n            'username': match.groups()[0],\n            'domain': match.groups()[1]\n        }\n    raise ValueError(\"{userid} isn't a valid userid\".format(userid=userid))\n"},{"size":4226,"relativepath":"h/paginator.py","filename":"paginator.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import division\n\nimport functools\nimport math\n\nPAGE_SIZE = 20\n\n\ndef paginate(request, total, page_size=PAGE_SIZE):\n    first = 1\n    page_max = int(math.ceil(total / page_size))\n    page_max = max(1, page_max)  # There's always at least one page.\n\n    try:\n        current_page = int(request.params['page'])\n    except (KeyError, ValueError):\n        current_page = 1\n    current_page = max(1, current_page)\n    current_page = min(current_page, page_max)\n\n    next_ = current_page + 1 if current_page < page_max else None\n    prev = current_page - 1 if current_page > 1 else None\n\n    # Construct the page_numbers array so that the first and the\n    # last pages are always shown. There should be at most 3 pages\n    # to the left and 3 to the right of the current page. Any more\n    # pages than that are represented by ellipses on either side.\n    # Ex: [1, '...',27, 28, 29, 30, 31, 32, 33, '...', 60]\n\n    page_numbers = []\n    buffer = 3\n\n    # Add the first page.\n    if first < current_page:\n        page_numbers.append(first)\n\n    # If there are more than 3 pages to the left of current, add the\n    # ellipsis.\n    max_left = current_page - buffer\n\n    if (max_left - first) > 1:\n        page_numbers.append('...')\n\n    # If there are 1-3 pages to the left of current, add the pages.\n    i = current_page - buffer\n    while i >= max_left and i < current_page:\n        if i > first:\n            page_numbers.append(i)\n        i += 1\n\n    # Add the current page.\n    page_numbers.append(current_page)\n\n    # If there are 1-3 pages to the right of current, add the pages.\n    max_right = current_page + buffer\n\n    i = current_page + 1\n    while i <= max_right and i > current_page and i < page_max:\n        page_numbers.append(i)\n        i += 1\n\n    # If there are more than 3 pages to the right of current, add the\n    # ellipsis.\n    if (page_max - max_right) > 1:\n        page_numbers.append('...')\n\n    # Add the last page.\n    if page_max > current_page:\n        page_numbers.append(page_max)\n\n    def url_for(page):\n        query = request.params.dict_of_lists()\n        query['page'] = page\n        return request.current_route_path(_query=query)\n\n    return {\n        'cur': current_page,\n        'max': page_max,\n        'next': next_,\n        'numbers': page_numbers,\n        'prev': prev,\n        'url_for': url_for,\n    }\n\n\ndef paginate_query(wrapped=None, page_size=PAGE_SIZE):\n    \"\"\"\n    Decorate a view function, providing basic pagination facilities.\n\n    Wraps a view function that returns a :py:class:`sqlalchemy.orm.query.Query`\n    object in order to enable basic pagination. Returns a dictionary containing\n    the results for the current page and page metadata. For example, the simple\n    view function\n\n        @paginate_query\n        def my_view(context, request):\n            return request.db.query(User)\n\n    will, when wrapped, return a dictionary like the following:\n\n        {\n            \"results\": [<user1>, <user2>, ..., <user20>],\n            \"total\": 135,\n            \"page\": {\n                \"cur\": 1,\n                \"max\": 7,\n                \"next\": 2,\n                \"prev\": None,\n            }\n        }\n\n    You can also call :py:func:`paginate_query` as a function which returns a\n    decorator, if you wish to modify the options used by the function:\n\n        paginate = paginator.paginate_query(page_size=10)\n\n        @paginate_query\n        def my_view(...):\n            ...\n\n    N.B. The wrapped view function must accept two arguments: the request\n    context and the current request. This decorator does not support view\n    functions which accept only a single argument.\n    \"\"\"\n    if wrapped is None:\n        def decorator(wrap):\n            return paginate_query(wrap, page_size=page_size)\n        return decorator\n\n    @functools.wraps(wrapped)\n    def wrapper(context, request):\n        result = wrapped(context, request)\n        total = result.count()\n        page = paginate(request, total, page_size)\n        offset = (page['cur'] - 1) * page_size\n        return {\n            'results': result.offset(offset).limit(page_size).all(),\n            'total': total,\n            'page': page,\n        }\n    return wrapper\n"},{"size":219,"relativepath":"h/authz.py","filename":"authz.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"Authorization configuration.\"\"\"\n\nfrom pyramid.authorization import ACLAuthorizationPolicy\n\n__all__ = ()\n\n\ndef includeme(config):\n    config.set_authorization_policy(ACLAuthorizationPolicy())\n"},{"size":5600,"relativepath":"h/form.py","filename":"form.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"\nConfigure deform to use custom templates.\n\nSets up the form handling and rendering library, deform, to use our own custom\nform templates in preference to the defaults. Uses `deform_jinja2` to provide\nthe fallback templates in Jinja2 format, which we can then extend and modify as\nnecessary.\n\"\"\"\nimport deform\nimport jinja2\nfrom pyramid import httpexceptions\nimport pyramid_jinja2\nfrom pyramid.path import AssetResolver\n\nfrom h import i18n\n\n\nENVIRONMENT_KEY = 'h.form.jinja2_environment'\n\nSEARCH_PATHS = (\n    'h:templates/deform/',\n    'deform_jinja2:bootstrap_templates/',\n)\n\n\n_ = i18n.TranslationString\n\n\nclass Jinja2Renderer(object):\n    \"\"\"An alternate Deform renderer that uses Jinja2 to render templates.\"\"\"\n\n    def __init__(self, env, system=None):\n        \"\"\"\n        Return a new callable Jinja2Renderer object.\n\n        :param env: the Jinja2 environment used by this renderer\n        :type env: :py:class:`jinja2.Environment`\n\n        :param system: a dictionary of system renderer globals\n        :type system: dict\n        \"\"\"\n        self._env = env\n        self._system = system if system is not None else {}\n\n    def __call__(self, template_name, **kwargs):\n        \"\"\"Render the named template with the passed keywords as context.\"\"\"\n        if not template_name.endswith('.jinja2'):\n            template_name += '.jinja2'\n\n        template = self._env.get_template(template_name)\n        context = self._system.copy()\n        context.update(kwargs)\n\n        return jinja2.Markup(template.render(context))\n\n\ndef create_environment(base):\n    \"\"\"\n    Create a Jinja2 environment for rendering forms.\n\n    Creates an overlay environment based on the passed `base` environment that\n    is suitable for rendering the Deform templates.\n    \"\"\"\n    # Build a template loader based on SEARCH_PATHS\n    resolver = AssetResolver()\n    searchpath = [resolver.resolve(path).abspath() for path in SEARCH_PATHS]\n    loader = pyramid_jinja2.SmartAssetSpecLoader(searchpath)\n\n    # Make an overlay environment from the main Jinja2 environment. See:\n    #\n    #   http://jinja.pocoo.org/docs/dev/api/#jinja2.Environment.overlay\n    return base.overlay(autoescape=True, loader=loader)\n\n\ndef create_form(request, *args, **kwargs):\n    \"\"\"\n    Create a :py:class:`deform.Form` instance for this request.\n\n    This request method creates a :py:class:`deform.Form` object which (by\n    default) will use the renderer configured in the :py:mod:`h.form` module.\n    \"\"\"\n    env = request.registry[ENVIRONMENT_KEY]\n    renderer = Jinja2Renderer(env, {\n        'feature': request.feature,\n    })\n    kwargs.setdefault('renderer', renderer)\n\n    return deform.Form(*args, **kwargs)\n\n\ndef configure_environment(config):  # pragma: no cover\n    \"\"\"Configure the form template environment and store it in the registry.\"\"\"\n    base = config.get_jinja2_environment()\n    config.registry[ENVIRONMENT_KEY] = create_environment(base)\n\n\ndef handle_form_submission(request, form, on_success, on_failure):\n    \"\"\"\n    Handle the submission of the given form in a standard way.\n\n    :param request: the Pyramid request\n\n    :param form: the form that was submitted\n    :type form: deform.form.Form\n\n    :param on_success:\n        A callback function to be called if the form validates successfully.\n\n        This function should carry out the action that the form submission\n        requests (for example for a change password form, this function would\n        change the user's password) and return the view callable result that\n        should be returned if this is not an XHR request.\n\n        If on_success() returns ``None`` then ``handle_form_submission()``\n        will return ``HTTPFound(location=request.url)`` by default.\n    :type on_success: callable\n\n    :param on_failure:\n        A callback function that will be called if form validation fails in\n        order to get the view callable result that should be returned if this is\n        not an XHR request.\n    :type on_failure: callable\n\n    \"\"\"\n    try:\n        appstruct = form.validate(request.POST.items())\n    except deform.ValidationFailure:\n        result = on_failure()\n        request.response.status_int = 400\n    else:\n        result = on_success(appstruct)\n\n        if result is None:\n            result = httpexceptions.HTTPFound(location=request.url)\n\n        if not request.is_xhr:\n            request.session.flash(_(\"Success. We've saved your changes.\"),\n                                  'success')\n\n    return to_xhr_response(request, result, form)\n\n\ndef to_xhr_response(request, non_xhr_result, form):\n    \"\"\"\n    Return an XHR response for the given ``form``, or ``non_xhr_result``.\n\n    If the given ``request`` is an XMLHttpRequest then return an XHR form\n    submission response for the given form (contains only the ``<form>``\n    element as an HTML snippet, not the entire HTML page).\n\n    If ``request`` is not an XHR request then return ``non_xhr_result``, which\n    should be the result that the view callable would normally return if this\n    were not an XHR request.\n\n    :param request: the Pyramid request\n\n    :param non_xhr_result: the view callable result that should be returned if\n        ``request`` is *not* an XHR request\n\n    :param form: the form that was submitted\n    :type form: deform.form.Form\n\n    \"\"\"\n    if not request.is_xhr:\n        return non_xhr_result\n\n    request.override_renderer = 'string'\n    return form.render()\n\n\ndef includeme(config):  # pragma: no cover\n    config.action(None, configure_environment, args=(config,))\n    config.add_request_method(create_form)\n"},{"size":134,"relativepath":"h/i18n.py","filename":"i18n.py","extension":".py","content":"# -*- coding: utf-8 -*-\nfrom pyramid.i18n import TranslationStringFactory\n\nTranslationString = TranslationStringFactory('hypothesis')\n"},{"size":4183,"relativepath":"h/tweens.py","filename":"tweens.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport collections\nimport logging\nimport sys\nfrom pyramid import httpexceptions\nfrom pyramid.util import DottedNameResolver\n\nlog = logging.getLogger(__name__)\nresolver = DottedNameResolver(None)\n\n\ndef auth_token(handler, registry):\n    \"\"\"\n    A tween that copies the value of the Annotator token header into the the\n    HTTP Authorization header with the Bearer token type.\n    \"\"\"\n\n    def tween(request):\n        token = request.headers.get('X-Annotator-Auth-Token')\n        if token is not None:\n            request.authorization = ('Bearer', token)\n        return handler(request)\n\n    return tween\n\n\ndef conditional_http_tween_factory(handler, registry):\n    \"\"\"A tween that sets up conditional response handling for some requests.\"\"\"\n    def conditional_http_tween(request):\n        response = handler(request)\n\n        # If the Last-Modified header has been set, we want to enable the\n        # conditional response processing.\n        if response.last_modified is not None:\n            response.conditional_response = True\n\n        # We want to only enable the conditional machinery if either we were\n        # given an explicit ETag header by the view...\n        if response.etag is not None:\n            response.conditional_response = True\n            return response\n\n        # ...or we have a buffered response and can generate the ETag header\n        # ourself. We only do this for GET or HEAD requests that result in a\n        # status code of 200. The subtleties of doing it correctly in other\n        # cases don't bear thinking about (at the moment).\n        have_buffered_response = (isinstance(response.app_iter,\n                                             collections.Sequence) and\n                                  len(response.app_iter) == 1)\n        cacheable = (request.method in {\"GET\", \"HEAD\"} and\n                     response.status_code == 200)\n        if have_buffered_response and cacheable:\n            response.conditional_response = True\n            response.md5_etag()\n\n        return response\n    return conditional_http_tween\n\n\ndef csrf_tween_factory(handler, registry):\n    \"\"\"A tween that sets a 'XSRF-TOKEN' cookie.\"\"\"\n\n    def csrf_tween(request):\n        response = handler(request)\n\n        # NB: the session does not necessarily supply __len__.\n        session_is_empty = len(request.session.keys()) == 0\n\n        # Ignore an empty session.\n        if request.session.new and session_is_empty:\n            return response\n\n        csrft = request.session.get_csrf_token()\n\n        if request.cookies.get('XSRF-TOKEN') != csrft:\n            response.set_cookie('XSRF-TOKEN', csrft)\n\n        return response\n\n    return csrf_tween\n\n\ndef content_security_policy_tween_factory(handler, registry):\n    if not registry.settings.get('csp.enabled', False):\n        return handler\n\n    policy = registry.settings.get('csp', {})\n    policy = \"; \".join([\n        \" \".join([k] + [v2 for v2 in v if v2 is not None])\n        for k, v in sorted(policy.items())\n        if [v2 for v2 in v if v2 is not None]\n    ])\n\n    if registry.settings.get('csp.report_only', False):\n        header_name = 'Content-Security-Policy-Report-Only'\n    else:\n        header_name = 'Content-Security-Policy'\n\n    def content_security_policy_tween(request):\n        resp = handler(request)\n        resp.headers[header_name] = policy.format(request=request)\n        return resp\n\n    return content_security_policy_tween\n\n\nREDIRECTS = [\n    ('/profile/notifications', 'account_notifications'),\n    ('/profile/developer', 'account_developer'),\n    ('/profile', 'account'),\n    ('/register', 'signup'),\n    ('/forgot_password', 'forgot_password'),\n    ('/reset_password', 'account_reset'),\n]\n\n\ndef redirect_tween_factory(handler, registry, redirects=REDIRECTS):\n    def redirect_tween(request):\n        for old_path, route_name in redirects:\n            if request.path.startswith(old_path):\n                url = request.route_url(route_name)\n                suffix = request.path.replace(old_path, '', 1)\n                return httpexceptions.HTTPMovedPermanently(location=(url + suffix))\n        return handler(request)\n\n    return redirect_tween\n"},{"size":128,"relativepath":"h/groups/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\ndef includeme(config):\n    config.register_service_factory('.services.groups_factory', name='groups')\n"},{"size":2421,"relativepath":"h/groups/services.py","filename":"services.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom functools import partial\n\nfrom h import session\nfrom h.models import Group\n\n\nclass GroupsService(object):\n\n    \"\"\"A service for manipulating groups and group membership.\"\"\"\n\n    def __init__(self, session, user_fetcher, publish=None):\n        \"\"\"\n        Create a new groups service.\n\n        :param session: the SQLAlchemy session object\n        :param user_fetcher: a callable for fetching users by userid\n        :param publish: a callable for publishing events\n        \"\"\"\n        self.session = session\n        self.user_fetcher = user_fetcher\n        self.publish = publish\n\n    def create(self, name, userid, description=None):\n        \"\"\"\n        Create a new group.\n\n        :param name: the human-readable name of the group\n        :param userid: the userid of the group creator\n        :param description: the description of the group\n\n        :returns: the created group\n        \"\"\"\n        creator = self.user_fetcher(userid)\n        group = Group(name=name, creator=creator, description=description)\n        self.session.add(group)\n        self.session.flush()\n\n        if self.publish:\n            self.publish('group-join', group.pubid, userid)\n\n        return group\n\n    def member_join(self, group, userid):\n        \"\"\"Add `userid` to the member list of `group`.\"\"\"\n        user = self.user_fetcher(userid)\n\n        if user in group.members:\n            return\n\n        group.members.append(user)\n\n        if self.publish:\n            self.publish('group-join', group.pubid, userid)\n\n    def member_leave(self, group, userid):\n        \"\"\"Remove `userid` from the member list of `group`.\"\"\"\n        user = self.user_fetcher(userid)\n\n        if user not in group.members:\n            return\n\n        group.members.remove(user)\n\n        if self.publish:\n            self.publish('group-leave', group.pubid, userid)\n\n\ndef groups_factory(context, request):\n    \"\"\"Return a GroupsService instance for the passed context and request.\"\"\"\n    user_service = request.find_service(name='user')\n    return GroupsService(session=request.db,\n                         user_fetcher=user_service.fetch,\n                         publish=partial(_publish, request))\n\n\ndef _publish(request, event_type, groupid, userid):\n    request.realtime.publish_user({\n        'type': event_type,\n        'session_model': session.model(request),\n        'userid': userid,\n        'group': groupid,\n    })\n"},{"size":2462,"relativepath":"h/groups/schemas.py","filename":"schemas.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport colander\nimport deform\n\nimport slugify\n\nfrom h import i18n\nfrom h import validators\nfrom h.accounts.schemas import CSRFSchema\nfrom h.models.group import (\n    GROUP_DESCRIPTION_MAX_LENGTH,\n    GROUP_NAME_MIN_LENGTH,\n    GROUP_NAME_MAX_LENGTH,\n)\n\n\n_ = i18n.TranslationString\n\nGROUPSLUG_BLACKLIST = set(['edit', 'leave'])\n\n\ndef unblacklisted_group_name_slug(node, value, blacklist=GROUPSLUG_BLACKLIST):\n    \"\"\"Colander validator that ensures the \"slugified\" group name is not blacklisted.\"\"\"\n    if slugify.slugify(value).lower() in blacklist:\n        raise colander.Invalid(node, _(\"Sorry, this group name is not allowed. \"\n                                       \"Please choose another one.\"))\n\n\nclass GroupSchema(CSRFSchema):\n\n    \"\"\"The schema for the create-a-new-group form.\"\"\"\n\n    name = colander.SchemaNode(\n        colander.String(),\n        title=_(\"Name\"),\n        validator=colander.All(\n            validators.Length(min=GROUP_NAME_MIN_LENGTH, max=GROUP_NAME_MAX_LENGTH),\n            unblacklisted_group_name_slug),\n        widget=deform.widget.TextInputWidget(\n            autofocus=True,\n            show_required=True,\n            css_class=\"group-form__name-input js-group-name-input\",\n            disable_autocomplete=True,\n            label_css_class=\"group-form__name-label\",\n            max_length=GROUP_NAME_MAX_LENGTH))\n\n    description = colander.SchemaNode(\n        colander.String(),\n        title=_(\"Description\"),\n        validator=validators.Length(max=GROUP_DESCRIPTION_MAX_LENGTH),\n        missing=None,\n        widget=deform.widget.TextAreaWidget(\n            css_class=\"group-form__description-input\",\n            label_css_class=\"group-form__description-label\",\n            min_length=0,\n            max_length=GROUP_DESCRIPTION_MAX_LENGTH))\n\n\nclass LegacyGroupSchema(CSRFSchema):\n\n    \"\"\"The legacy schema for the create-a-new-group form.\"\"\"\n\n    name = colander.SchemaNode(\n        colander.String(),\n        title=_(\"What do you want to call the group?\"),\n        validator=validators.Length(\n            min=GROUP_NAME_MIN_LENGTH,\n            max=GROUP_NAME_MAX_LENGTH),\n        widget=deform.widget.TextInputWidget(\n            autofocus=True,\n            css_class=\"group-form__name-input js-group-name-input\",\n            disable_autocomplete=True,\n            label_css_class=\"group-form__name-label\",\n            max_length=GROUP_NAME_MAX_LENGTH,\n            placeholder=_(\"Group Name\")))\n"},{"size":335,"relativepath":"src/memex/resources.py","filename":"resources.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom memex import storage\n\n\nclass AnnotationFactory(object):\n    def __init__(self, request):\n        self.request = request\n\n    def __getitem__(self, id):\n        annotation = storage.fetch_annotation(self.request.db, id)\n        if annotation is None:\n            raise KeyError()\n        return annotation\n"},{"size":8999,"relativepath":"src/memex/parse_document_claims.py","filename":"parse_document_claims.py","extension":".py","content":"\"\"\"\nFunctions for parsing document claims data from the client.\n\nFunctions for parsing the document claims (document metadata claims and URI\nequivalence claims) that the client POSTS in the JSON \"document\" sub-object in\nannotation create and update requests.\n\nThe data is parsed into a format suitable for storage in our database model,\nand returned.\n\n\"\"\"\nfrom __future__ import unicode_literals\n\n\ndef document_uris_from_data(document_data, claimant):\n    \"\"\"\n    Return one or more document URI dicts for the given document data.\n\n    Returns one document uri dict for each document equivalence claim in\n    document_data.\n\n    Each dict can be used to init a DocumentURI object directly:\n\n        document_uri = DocumentURI(**document_uri_dict)\n\n    Always returns at least one \"self-claim\" document URI whose URI is the\n    claimant URI itself.\n\n    :param document_data: the \"document\" sub-object that was POSTed to the API\n        as part of a new or updated annotation\n    :type document_data: dict\n\n    :param claimant: the URI that the browser was at when this annotation was\n        created (the top-level \"uri\" field of the annotation)\n    :type claimant: unicode\n\n    :returns: a list of one or more document URI dicts\n    :rtype: list of dicts\n\n    \"\"\"\n    document_uris = document_uris_from_links(document_data.get('link', []),\n                                             claimant)\n\n    document_uris.extend(\n        document_uris_from_highwire_pdf(document_data.get('highwire', {}),\n                                        claimant)\n    )\n\n    document_uris.extend(\n        document_uris_from_highwire_doi(document_data.get('highwire', {}),\n                                        claimant)\n    )\n\n    document_uris.extend(\n        document_uris_from_dc(document_data.get('dc', {}),\n                              claimant)\n    )\n\n    document_uris.append(document_uri_self_claim(claimant))\n\n    for document_uri in document_uris:\n        uri = document_uri['uri']\n        if uri:\n            document_uri['uri'] = uri.strip()\n\n    document_uris = [d for d in document_uris if d['uri']]\n\n    return document_uris\n\n\ndef document_metas_from_data(document_data, claimant):\n    \"\"\"\n    Return a list of document meta dicts for the given document data.\n\n    Returns one document meta dict for each document metadata claim in\n    document_data.\n\n    Each dict can be used to init a DocumentMeta object directly:\n\n        document_meta = DocumentMeta(**document_meta_dict)\n\n    :param document_data: the \"document\" sub-object that the client POSTed to\n        the API as part of a new or updated annotation\n    :type document_data: dict\n\n    :param claimant: the URI that the browser was at when this annotation was\n        created (the top-level \"uri\" field of the annotation)\n    :type claimant: unicode\n\n    :returns: a list of zero or more document meta dicts\n    :rtype: list of dicts\n\n    \"\"\"\n    def transform_meta_(document_meta_dicts, items, path_prefix=None):\n        \"\"\"Fill document_meta_dicts with document meta dicts for the items.\"\"\"\n        if path_prefix is None:\n            path_prefix = []\n\n        for key, value in items.iteritems():\n            keypath = path_prefix[:]\n            keypath.append(key)\n\n            if isinstance(value, dict):\n                transform_meta_(document_meta_dicts,\n                                value,\n                                path_prefix=keypath)\n            else:\n                if not isinstance(value, list):\n                    value = [value]\n\n                type_ = '.'.join(keypath)\n\n                if type_ == 'title':\n                    # We don't allow None, empty strings, whitespace-only\n                    # strings, leading or trailing whitespaces, or empty arrays\n                    # in document title values.\n                    value = [v.strip() for v in value if v and v.strip()]\n                    if not value:\n                        continue\n\n                document_meta_dicts.append({\n                    'type': type_,\n                    'value': value,\n                    'claimant': claimant,\n                })\n\n    items = {k: v for k, v in document_data.iteritems() if k != 'link'}\n    document_meta_dicts = []\n    transform_meta_(document_meta_dicts, items)\n    return document_meta_dicts\n\n\ndef document_uris_from_links(link_dicts, claimant):\n    \"\"\"\n    Return document URI dicts for the given document.link data.\n\n    Process a document.link list of dicts that the client submitted as part of\n    an annotation create or update request and return document URI dicts for\n    all of the document equivalence claims that it makes.\n\n    \"\"\"\n    document_uris = []\n    for link in link_dicts:\n\n        # Disregard self-claim URLs as they're added separately later.\n        if link.keys() == ['href'] and link['href'] == claimant:\n            continue\n\n        # Disregard doi links as these are being added separately from the\n        # highwire and dc metadata later on.\n        if link.keys() == ['href'] and link['href'].startswith('doi:'):\n            continue\n\n        # Disregard Highwire PDF links as these are being added separately from\n        # the highwire metadata later on.\n        if set(link.keys()) == set(['href', 'type']):\n            if link['type'] == 'application/pdf':\n                continue\n\n        uri_ = link['href']\n\n        # Handle rel=\"...\" links.\n        if 'rel' in link:\n            type_ = 'rel-{}'.format(link['rel'])\n        else:\n            type_ = ''\n\n        # The \"type\" item in link dicts becomes content_type in DocumentURIs.\n        content_type = link.get('type', '')\n\n        document_uris.append({\n            'claimant': claimant,\n            'uri': uri_,\n            'type': type_,\n            'content_type': content_type,\n        })\n\n    return document_uris\n\n\ndef document_uris_from_highwire_pdf(highwire_dict, claimant):\n    \"\"\"\n    Return PDF document URI dicts for the given 'highwire' document metadata.\n\n    Process a document.highwire dict that the client submitted as part of an\n    annotation create or update request and return document URI dicts for all\n    of the PDF document equivalence claims that it makes.\n\n    \"\"\"\n    document_uris = []\n    hwpdfvalues = highwire_dict.get('pdf_url', [])\n    for pdf in hwpdfvalues:\n        document_uris.append({'claimant': claimant,\n                              'uri': pdf,\n                              'type': 'highwire-pdf',\n                              'content_type': 'application/pdf'})\n    return document_uris\n\n\ndef document_uris_from_highwire_doi(highwire_dict, claimant):\n    \"\"\"\n    Return DOI document URI dicts for the given 'highwire' document metadata.\n\n    Process a document.highwire dict that the client submitted as part of an\n    annotation create or update request and return document URI dicts for all\n    of the 'doi:' document equivalence claims that it makes.\n\n    \"\"\"\n    document_uris = []\n    hwdoivalues = highwire_dict.get('doi', [])\n    for doi in hwdoivalues:\n        doi = doi_uri_from_string(doi)\n        if doi is not None:\n            document_uris.append({'claimant': claimant,\n                                  'uri': doi,\n                                  'type': 'highwire-doi',\n                                  'content_type': ''})\n    return document_uris\n\n\ndef document_uris_from_dc(dc_dict, claimant):\n    \"\"\"\n    Return document URI dicts for the given 'dc' document metadata.\n\n    Process a document.dc dict that the client submitted as part of an\n    annotation create or update request and return document URI dicts for all\n    of the document equivalence claims that it makes.\n\n    \"\"\"\n    document_uris = []\n    dcdoivalues = dc_dict.get('identifier', [])\n    for doi in dcdoivalues:\n        doi = doi_uri_from_string(doi)\n        if doi is not None:\n            document_uris.append({'claimant': claimant,\n                                  'uri': doi,\n                                  'type': 'dc-doi',\n                                  'content_type': ''})\n\n    return document_uris\n\n\ndef document_uri_self_claim(claimant):\n    \"\"\"Return a \"self-claim\" document URI dict for the given claimant.\"\"\"\n    return {\n        'claimant': claimant,\n        'uri': claimant,\n        'type': u'self-claim',\n        'content_type': '',\n    }\n\n\ndef doi_uri_from_string(s):\n    \"\"\"\n    Return the DOI URI from the given user-supplied string, or None.\n\n    Return a string of the format \"doi:<id>\". Leading and trailing whitespace\n    is stripped from the string as a whole and from the <id> substring.\n\n    If the given string doesn't already start with \"doi:\" it is prepended.\n\n    If the given string does not contain a DOI URI then None is returned.\n    Examples of strings that do not include a DOI are:\n    '', ' ', 'doi:', 'doi: ', ' doi:', ' doi: '.\n\n    \"\"\"\n    s = s.strip()\n\n    if s.startswith('doi:'):\n        s = s[len('doi:'):]\n\n    s = s.strip()\n\n    if not s:\n        return None\n\n    s = 'doi:{}'.format(s)\n\n    return s\n"},{"size":4555,"relativepath":"src/memex/search/core.py","filename":"core.py","extension":".py","content":"# -*- coding: utf-8 -*-\nimport logging\nfrom collections import namedtuple\n\nfrom memex.search import query\n\nFILTERS_KEY = 'memex.search.filters'\nMATCHERS_KEY = 'memex.search.matchers'\n\nlog = logging.getLogger(__name__)\n\nSearchResult = namedtuple('SearchResult', [\n    'total',\n    'annotation_ids',\n    'reply_ids',\n    'aggregations'])\n\n\nclass Search(object):\n    \"\"\"\n    Search is the primary way to initiate a search on the annotation index.\n\n    :param request: the request object\n    :type request: pyramid.request.Request\n\n    :param separate_replies: Wheter or not to return all replies to the\n        annotations returned by this search. If this is True then the\n        resulting annotations will only include top-leve annotations, not replies.\n    :type separate_replies: bool\n    \"\"\"\n    def __init__(self, request, separate_replies=False):\n        self.request = request\n        self.es = request.es\n        self.separate_replies = separate_replies\n\n        self.builder = default_querybuilder(request)\n        self.reply_builder = default_querybuilder(request)\n\n    def run(self, params):\n        \"\"\"\n        Execute the search query\n\n        :param params: the search parameters\n        :type params: dict-like\n\n        :returns: The search results\n        :rtype: SearchResult\n        \"\"\"\n        total, annotation_ids, aggregations = self.search_annotations(params)\n        reply_ids = self.search_replies(annotation_ids)\n\n        return SearchResult(total, annotation_ids, reply_ids, aggregations)\n\n    def append_filter(self, filter_):\n        \"\"\"Append a search filter to the annotation and reply query.\"\"\"\n        self.builder.append_filter(filter_)\n        self.reply_builder.append_filter(filter_)\n\n    def append_matcher(self, matcher):\n        \"\"\"Append a search matcher to the annotation and reply query.\"\"\"\n        self.builder.append_matcher(matcher)\n        self.reply_builder.append_matcher(matcher)\n\n    def append_aggregation(self, aggregation):\n        self.builder.append_aggregation(aggregation)\n\n    def search_annotations(self, params):\n        if self.separate_replies:\n            self.builder.append_filter(query.TopLevelAnnotationsFilter())\n\n        response = self.es.conn.search(index=self.es.index,\n                                       doc_type=self.es.t.annotation,\n                                       _source=False,\n                                       body=self.builder.build(params))\n        total = response['hits']['total']\n        annotation_ids = [hit['_id'] for hit in response['hits']['hits']]\n        aggregations = self._parse_aggregation_results(response.get('aggregations', None))\n        return (total, annotation_ids, aggregations)\n\n    def search_replies(self, annotation_ids):\n        if not self.separate_replies:\n            return []\n\n        self.reply_builder.append_matcher(query.RepliesMatcher(annotation_ids))\n        response = self.es.conn.search(index=self.es.index,\n                                       doc_type=self.es.t.annotation,\n                                       _source=False,\n                                       body=self.reply_builder.build({'limit': 200}))\n\n        if len(response['hits']['hits']) < response['hits']['total']:\n            log.warn(\"The number of reply annotations exceeded the page size \"\n                     \"of the Elasticsearch query. We currently don't handle \"\n                     \"this, our search API doesn't support pagination of the \"\n                     \"reply set.\")\n\n        return [hit['_id'] for hit in response['hits']['hits']]\n\n    def _parse_aggregation_results(self, aggregations):\n        if not aggregations:\n            return {}\n\n        results = {}\n        for key, result in aggregations.iteritems():\n            for agg in self.builder.aggregations:\n                if key != agg.key:\n                    continue\n\n                results[key] = agg.parse_result(result)\n                break\n\n        return results\n\n\ndef default_querybuilder(request):\n    builder = query.Builder()\n    builder.append_filter(query.AuthFilter(request))\n    builder.append_filter(query.UriFilter(request))\n    builder.append_filter(query.GroupFilter())\n    builder.append_filter(query.UserFilter())\n    builder.append_matcher(query.AnyMatcher())\n    builder.append_matcher(query.TagsMatcher())\n    for factory in request.registry.get(FILTERS_KEY, []):\n        builder.append_filter(factory(request))\n    for factory in request.registry.get(MATCHERS_KEY, []):\n        builder.append_matcher(factory(request))\n    return builder\n"},{"size":11246,"relativepath":"src/memex/search/config.py","filename":"config.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"\nIndex mappings and analysis settings for Elasticsearch, and associated tools.\n\nThis module contains the index mappings and analysis settings for data indexed\ninto Elasticsearch. It also contains some helper functions to create and update\nthese settings in an Elasticsearch instance.\n\"\"\"\n\nfrom __future__ import unicode_literals\nimport logging\n\nimport elasticsearch\n\nlog = logging.getLogger(__name__)\n\nANNOTATION_MAPPING = {\n    '_id': {'path': 'id'},\n    '_source': {'excludes': ['id']},\n    'analyzer': 'keyword',\n    'properties': {\n        'annotator_schema_version': {'type': 'string'},\n        'created': {'type': 'date'},\n        'updated': {'type': 'date'},\n        'quote': {'type': 'string', 'analyzer': 'uni_normalizer'},\n        'tags': {'type': 'string', 'analyzer': 'uni_normalizer'},\n        'text': {'type': 'string', 'analyzer': 'uni_normalizer'},\n        'deleted': {'type': 'boolean'},\n        'uri': {\n            'type': 'string',\n            'index_analyzer': 'uri',\n            'search_analyzer': 'uri',\n            'fields': {\n                'parts': {\n                    'type': 'string',\n                    'index_analyzer': 'uri_parts',\n                    'search_analyzer': 'uri_parts',\n                },\n            },\n        },\n        'user': {'type': 'string', 'index': 'analyzed', 'analyzer': 'user'},\n        'user_raw': {'type': 'string', 'index': 'not_analyzed'},\n        'target': {\n            'properties': {\n                'source': {\n                    'type': 'string',\n                    'index_analyzer': 'uri',\n                    'search_analyzer': 'uri',\n                    'copy_to': ['uri'],\n                },\n                # We store the 'scope' unanalyzed and only do term filters\n                # against this field.\n                'scope': {\n                    'type': 'string',\n                    'index': 'not_analyzed',\n                },\n                'selector': {\n                    'properties': {\n                        'type': {'type': 'string', 'index': 'no'},\n\n                        # Annotator XPath+offset selector\n                        'startContainer': {'type': 'string', 'index': 'no'},\n                        'startOffset': {'type': 'long', 'index': 'no'},\n                        'endContainer': {'type': 'string', 'index': 'no'},\n                        'endOffset': {'type': 'long', 'index': 'no'},\n\n                        # Open Annotation TextQuoteSelector\n                        'exact': {\n                            'path': 'just_name',\n                            'type': 'string',\n                            'fields': {\n                                'quote': {\n                                    'type': 'string',\n                                    'analyzer': 'uni_normalizer',\n                                },\n                            },\n                        },\n                        'prefix': {'type': 'string'},\n                        'suffix': {'type': 'string'},\n\n                        # Open Annotation (Data|Text)PositionSelector\n                        'start': {'type': 'long'},\n                        'end':   {'type': 'long'},\n                    }\n                }\n            }\n        },\n        'permissions': {\n            'index_name': 'permission',\n            'properties': {\n                'read': {'type': 'string'},\n                'update': {'type': 'string'},\n                'delete': {'type': 'string'},\n                'admin': {'type': 'string'}\n            }\n        },\n        'references': {'type': 'string'},\n        'document': {\n            'enabled': False,  # indexed explicitly by the save function\n        },\n        'thread': {\n            'type': 'string',\n            'analyzer': 'thread'\n        },\n        'group': {\n            'type': 'string',\n        }\n    }\n}\n\nANNOTATION_ANALYSIS = {\n    'char_filter': {\n        'strip_scheme': {\n            'type': 'pattern_replace',\n            'pattern': r'^(?:[A-Za-z][A-Za-z.+-]+:)?/{0,3}',\n            'replacement': '',\n        },\n    },\n    'filter': {\n        'path_url': {\n            'type': 'pattern_capture',\n            'preserve_original': 'false',\n            'patterns': [\n                r'([0-9.\\-A-Za-z]+(?::\\d+)?(?:/[^?#]*))?',\n            ],\n        },\n        'rstrip_slash': {\n            'type': 'pattern_replace',\n            'pattern': '/$',\n            'replacement': '',\n        },\n        'user': {\n            'type': 'pattern_capture',\n            'preserve_original': 'true',\n            'patterns': ['^acct:((.+)@.*)$']\n        }\n    },\n    'tokenizer': {\n        'uri_part': {\n            'type': 'pattern',\n            'pattern': r'[#+/:=?.-]|(?:%2[3BF])|(?:%3[ADF])',\n        }\n    },\n    'analyzer': {\n        'thread': {\n            'tokenizer': 'path_hierarchy'\n        },\n        'uri': {\n            'tokenizer': 'keyword',\n            'char_filter': ['strip_scheme'],\n            'filter': ['path_url', 'rstrip_slash', 'lowercase'],\n        },\n        'uri_parts': {\n            'tokenizer': 'uri_part',\n            'filter': ['unique'],\n        },\n        'user': {\n            'tokenizer': 'keyword',\n            'filter': ['user', 'lowercase']\n        },\n        'uni_normalizer': {\n            'tokenizer': 'icu_tokenizer',\n            'filter': ['icu_folding']\n        }\n    }\n}\n\nDOCUMENT_MAPPING = {\n    '_id': {'path': 'id'},\n    '_source': {'excludes': ['id']},\n    'analyzer': 'keyword',\n    'date_detection': False,\n    'properties': {\n        'id': {'type': 'string', 'index': 'no'},\n        'annotator_schema_version': {'type': 'string'},\n        'created': {'type': 'date'},\n        'updated': {'type': 'date'},\n        'title': {'type': 'string', 'analyzer': 'standard'},\n        'link': {\n            'type': 'nested',\n            'properties': {\n                'type': {'type': 'string'},\n                'href': {'type': 'string'},\n            }\n        },\n        'dc': {\n            'type': 'nested',\n            'properties': {\n                # by default elastic search will try to parse this as\n                # a date but unfortunately the data that is in the wild\n                # may not be parsable by ES which throws an exception\n                'date': {'type': 'string'}\n            }\n        }\n    }\n}\n\nDOCUMENT_ANALYSIS = {}\n\n\ndef configure_index(client, index=None):\n    \"\"\"Configure the elasticsearch index.\"\"\"\n\n    if index is None:\n        index = client.index\n\n    # Ensure the ICU analysis plugin is installed\n    _ensure_icu_plugin(client.conn)\n\n    # Construct desired mappings and analysis settings\n    mappings = {}\n    analysis = {}\n    _append_config(mappings,\n                   analysis,\n                   client.t.annotation,\n                   ANNOTATION_MAPPING,\n                   ANNOTATION_ANALYSIS)\n    _append_config(mappings,\n                   analysis,\n                   client.t.document,\n                   DOCUMENT_MAPPING,\n                   DOCUMENT_ANALYSIS)\n\n    # Try to create the index with the correct settings. This will not fail if\n    # the index already exists.\n    _create_index(client.conn, index, {\n        'mappings': mappings,\n        'settings': {'analysis': analysis},\n    })\n\n    # For indices we didn't just create: try and update the analysis and\n    # mappings to their current values. May throw an exception if elasticsearch\n    # throws a MergeMappingException indicating that the index cannot be\n    # updated without reindexing.\n    _update_index_analysis(client.conn, index, analysis)\n    _update_index_mappings(client.conn, index, mappings)\n\n\ndef _ensure_icu_plugin(conn):\n    \"\"\"Ensure that the ICU analysis plugin is installed for ES.\"\"\"\n    # Pylint issue #258: https://bitbucket.org/logilab/pylint/issue/258\n    #\n    # pylint: disable=unexpected-keyword-arg\n    names = [x.strip() for x in conn.cat.plugins(h='component').split('\\n')]\n    if 'analysis-icu' not in names:\n        message = (\"The Elasticsearch ICU Analysis plugin is not installed. \"\n                   \"Refer to \"\n                   \"https://github.com/elastic/elasticsearch-analysis-icu \"\n                   \"for installation instructions.\")\n        raise RuntimeError(message)\n\n\ndef _append_config(mappings, analysis, doc_type, type_mappings, type_analysis):\n    \"\"\"\n    Append config for the named type to pre-existing config.\n\n    This function takes a mappings dict and an analysis dict which may contain\n    prior data, and attempts to update them with mappings and analysis settings\n    for the named type.\n    \"\"\"\n    mappings.update({doc_type: type_mappings})\n    for section, items in type_analysis.items():\n        existing_items = analysis.setdefault(section, {})\n        for name in items:\n            if name in existing_items:\n                fmt = \"Duplicate definition of 'index.analysis.{}.{}'.\"\n                msg = fmt.format(section, name)\n                raise RuntimeError(msg)\n        existing_items.update(items)\n\n\ndef _create_index(conn, name, settings):\n    \"\"\"\n    Create index with the specific name and settings.\n\n    This function will ignore errors caused by the index already existing.\n    \"\"\"\n    # Check if the index exists (perhaps as an alias) and if so, return.\n    if conn.indices.exists(index=name):\n        return\n\n    # Otherwise, try to create the index\n    conn.indices.create(name, body=settings)\n\n\ndef _update_index_analysis(conn, name, analysis):\n    \"\"\"Attempt to update the index analysis settings.\"\"\"\n    name = _resolve_alias(conn, name)\n    settings = conn.indices.get_settings(index=name)\n    existing = settings[name]['settings']['index'].get('analysis', {})\n    if existing != analysis:\n        try:\n            conn.indices.close(index=name)\n            conn.indices.put_settings(index=name, body={\n                'analysis': analysis\n            })\n        finally:\n            conn.indices.open(index=name)\n\n\ndef _update_index_mappings(conn, name, mappings):\n    \"\"\"Attempt to update the index mappings.\"\"\"\n    name = _resolve_alias(conn, name)\n    try:\n        for doc_type, body in mappings.items():\n            conn.indices.put_mapping(index=name,\n                                     doc_type=doc_type,\n                                     body=body)\n    except elasticsearch.exceptions.RequestError as e:\n        if not e.error.startswith('MergeMappingException'):\n            raise\n\n        message = (\"Elasticsearch index mapping cannot be automatically \"\n                   \"updated! Please reindex it. You may find the `hypothesis \"\n                   \"reindex` command helpful.\")\n        log.critical(message)\n        raise RuntimeError(message)\n\n\ndef _resolve_alias(conn, name):\n    \"\"\"Resolve an alias into the underlying index name.\"\"\"\n    result = conn.indices.get_alias(index=name)\n\n    # If there are no returned results, this isn't an alias\n    if not result:\n        return name\n\n    # If there are multiple keys, we have to raise, because this code doesn't\n    # support updating mappings for multiple indices.\n    if len(result) > 1:\n        raise RuntimeError(\"We don't support autocreating/updating aliases \"\n                           \"that point to multiple indices at the moment!\")\n\n    return result.keys()[0]\n"},{"size":1722,"relativepath":"src/memex/search/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom pyramid.settings import asbool\n\nfrom memex.search.client import Client\nfrom memex.search.config import configure_index\nfrom memex.search.core import Search\nfrom memex.search.core import FILTERS_KEY\nfrom memex.search.core import MATCHERS_KEY\n\n__all__ = ('Search',)\n\n\ndef _get_client(settings):\n    \"\"\"Return a client for the Elasticsearch index.\"\"\"\n    host = settings['es.host']\n    index = settings['es.index']\n    kwargs = {}\n    kwargs['timeout'] = settings.get('es.client_timeout', 10)\n\n    if 'es.client_poolsize' in settings:\n        kwargs['maxsize'] = settings['es.client_poolsize']\n\n    return Client(host, index, **kwargs)\n\n\ndef includeme(config):\n    settings = config.registry.settings\n    settings.setdefault('es.host', 'http://localhost:9200')\n    settings.setdefault('es.index', 'hypothesis')\n\n    # Allow users of this module to register additional search filter and\n    # search matcher factories.\n    config.registry[FILTERS_KEY] = []\n    config.registry[MATCHERS_KEY] = []\n    config.add_directive('add_search_filter',\n                         lambda c, f: c.registry[FILTERS_KEY].append(f))\n    config.add_directive('add_search_matcher',\n                         lambda c, m: c.registry[MATCHERS_KEY].append(m))\n\n    # Add a property to all requests for easy access to the elasticsearch\n    # client. This can be used for direct or bulk access without having to\n    # reread the settings.\n    config.add_request_method(\n        lambda r: _get_client(r.registry.settings),\n        name='es',\n        reify=True)\n\n    # If requested, automatically configure the index\n    if asbool(settings.get('h.search.autoconfig', False)):\n        configure_index(_get_client(settings))\n"},{"size":701,"relativepath":"src/memex/search/client.py","filename":"client.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport elasticsearch\n\n\nclass Client(object):\n\n    \"\"\"\n    A convenience wrapper around a connection to Elasticsearch.\n\n    Holds a connection object, an index name, and an enumeration of document\n    types stored in the index.\n\n    :param host: Elasticsearch host URL\n    :param index: index name\n    \"\"\"\n\n    class t(object):\n        \"\"\"Document types\"\"\"\n        annotation = 'annotation'\n        document = 'document'\n\n    def __init__(self, host, index, **kwargs):\n        self.index = index\n        self.conn = elasticsearch.Elasticsearch([host],\n                                                verify_certs=True,\n                                                **kwargs)\n"},{"size":4267,"relativepath":"src/memex/search/parser.py","filename":"parser.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"\nThe query parser which converts our subset of the Apache Lucene syntax and\ntransforms it into a MultiDict structure that memex.search understands.\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom collections import namedtuple\n\nimport pyparsing as pp\nfrom webob.multidict import MultiDict\n\n# Enable memoizing of the parsing logic\npp.ParserElement.enablePackrat()\n\n# Named fields we support when querying (e.g. `user:luke`)\nnamed_fields = ['user', 'tag', 'group', 'uri']\n\nwhitespace = set([\n    \"\\u0009\",  # character tabulation\n    \"\\u000a\",  # line feed\n    \"\\u000b\",  # line tabulation\n    \"\\u000c\",  # form feed\n    \"\\u000d\",  # carriage return\n    \"\\u0020\",  # space\n    \"\\u0085\",  # next line\n    \"\\u00a0\",  # no-break space\n    \"\\u1680\",  # ogham space mark\n    \"\\u2000\",  # en quad\n    \"\\u2001\",  # em quad\n    \"\\u2002\",  # en space\n    \"\\u2003\",  # em space\n    \"\\u2004\",  # three-per-em space\n    \"\\u2005\",  # four-per-em space\n    \"\\u2006\",  # six-per-em space\n    \"\\u2007\",  # figure space\n    \"\\u2008\",  # punctuation space\n    \"\\u2009\",  # thin space\n    \"\\u200a\",  # hair space\n    \"\\u2028\",  # line separator\n    \"\\u2029\",  # paragraph separator\n    \"\\u202f\",  # narrow no-break space\n    \"\\u205f\",  # medium mathematical space\n    \"\\u3000\",  # ideographic space\n])\n\nparser = None\nMatch = namedtuple('Match', ['key', 'value'])\n\n\ndef parse(q):\n    \"\"\"Parse a free text, Lucene-like, query string into a MultiDict.\n\n    \"user:luke tag:foobar tag:news hello world\" is parsed into:\n    ``\n    {\n        \"user\": \"luke\",\n        \"tag\": \"foobar\",\n        \"tag\": \"news\",\n        \"any\": \"hello\",\n        \"any\": \"world\"\n    }\n    ``\n\n    Supported keys for fields are ``user``, ``group``, ``tag``, ``uri``.\n    Any other search terms will get the key ``any``.\n    \"\"\"\n    parser = _get_parser()\n    parse_results = parser.parseString(q)\n\n    # The parser returns all matched strings, even the field names, we use a\n    # parse action to turn matches into a key/value pair (Match), but we need\n    # to filter out any other matches that the parser returns.\n    return MultiDict([m for m in parse_results if isinstance(m, Match)])\n\n\ndef unparse(q):\n    \"\"\"\n    Turn a dict-like object into a Lucene-like query string.\n\n    This can be considered the reverse of the\n    :py:func:`memex.search.parser.parse` function, as it can be used to\n    transform the MultiDict returned from that function back into a string\n    query.\n    \"\"\"\n    terms = []\n\n    for key, val in q.iteritems():\n        if key == 'any':\n            terms.append(_escape_term(val))\n        else:\n            terms.append('{key}:{val}'.format(key=key, val=_escape_term(val)))\n\n    return ' '.join(terms)\n\n\ndef _get_parser():\n    global parser\n    if parser is None:\n        parser = _make_parser()\n    return parser\n\n\ndef _make_parser():\n    word = pp.CharsNotIn(''.join(whitespace))\n    word.skipWhitespace = True\n\n    value = pp.MatchFirst([\n        pp.dblQuotedString.copy().setParseAction(pp.removeQuotes),\n        pp.sglQuotedString.copy().setParseAction(pp.removeQuotes),\n        pp.Empty() + pp.CharsNotIn(''.join(whitespace)),\n    ])\n\n    expressions = []\n\n    for field in named_fields:\n        exp = pp.Suppress(pp.CaselessLiteral(field) + ':') + \\\n            value.copy().setParseAction(_decorate_match(field))\n        expressions.append(exp)\n\n    any_ = value.copy().setParseAction(_decorate_match('any'))\n    expressions.append(any_)\n\n    return pp.ZeroOrMore(pp.MatchFirst(expressions))\n\n\ndef _decorate_match(key):\n    def parse_action_impl(t):\n        return Match(key, t[0])\n    return parse_action_impl\n\n\ndef _escape_term(term):\n    # Only surround with quotes if the term contains whitespace\n    if whitespace.intersection(term):\n        # Originally double quoted and contained escaped double quotes\n        if '\\\\\"' in term:\n            return '\"' + term + '\"'\n        # Originally single quoted and contained escaped single quotes\n        elif \"\\\\'\" in term:\n            return \"'\" + term + \"'\"\n        # Contains unescaped single quotes, so easiest to double quote\n        elif \"'\" in term:\n            return '\"' + term + '\"'\n        # None of the above: prefer single quotes\n        else:\n            return \"'\" + term + \"'\"\n    return term\n"},{"size":7271,"relativepath":"src/memex/search/query.py","filename":"query.py","extension":".py","content":"# -*- coding: utf-8 -*-\nfrom memex import storage\nfrom memex import uri\n\nLIMIT_DEFAULT = 20\nLIMIT_MAX = 200\n\n\nclass Builder(object):\n\n    \"\"\"\n    Build a query for execution in Elasticsearch.\n    \"\"\"\n\n    def __init__(self):\n        self.filters = []\n        self.matchers = []\n        self.aggregations = []\n\n    def append_filter(self, f):\n        self.filters.append(f)\n\n    def append_matcher(self, m):\n        self.matchers.append(m)\n\n    def append_aggregation(self, a):\n        self.aggregations.append(a)\n\n    def build(self, params):\n        \"\"\"Get the resulting query object from this query builder.\"\"\"\n        params = params.copy()\n\n        p_from = extract_offset(params)\n        p_size = extract_limit(params)\n        p_sort = extract_sort(params)\n\n        filters = [f(params) for f in self.filters]\n        matchers = [m(params) for m in self.matchers]\n        aggregations = {a.key: a(params) for a in self.aggregations}\n        filters = [f for f in filters if f is not None]\n        matchers = [m for m in matchers if m is not None]\n\n        # Remaining parameters are added as straightforward key-value matchers\n        for key, value in params.items():\n            matchers.append({\"match\": {key: value}})\n\n        query = {\"match_all\": {}}\n\n        if matchers:\n            query = {\"bool\": {\"must\": matchers}}\n\n        if filters:\n            query = {\n                \"filtered\": {\n                    \"filter\": {\"and\": filters},\n                    \"query\": query,\n                }\n            }\n\n        return {\n            \"from\": p_from,\n            \"size\": p_size,\n            \"sort\": p_sort,\n            \"query\": query,\n            \"aggs\": aggregations,\n        }\n\n\ndef extract_offset(params):\n    try:\n        val = int(params.pop(\"offset\"))\n        if val < 0:\n            raise ValueError\n    except (ValueError, KeyError):\n        return 0\n    else:\n        return val\n\n\ndef extract_limit(params):\n    try:\n        val = int(params.pop(\"limit\"))\n        val = min(val, LIMIT_MAX)\n        if val < 0:\n            raise ValueError\n    except (ValueError, KeyError):\n        return LIMIT_DEFAULT\n    else:\n        return val\n\n\ndef extract_sort(params):\n    return [{\n        params.pop(\"sort\", \"updated\"): {\n            \"ignore_unmapped\": True,\n            \"order\": params.pop(\"order\", \"desc\"),\n        }\n    }]\n\n\nclass TopLevelAnnotationsFilter(object):\n\n    \"\"\"Matches top-level annotations only, filters out replies.\"\"\"\n\n    def __call__(self, _):\n        return {'missing': {'field': 'references'}}\n\n\nclass AuthFilter(object):\n\n    \"\"\"\n    A filter that selects only annotations the user is authorised to see.\n\n    Only annotations where the 'read' permission contains one or more of the\n    user's effective principals will pass through this filter.\n    \"\"\"\n\n    def __init__(self, request):\n        \"\"\"Initialize a new AuthFilter.\n\n        :param request: the pyramid.request object\n        \"\"\"\n        self.request = request\n\n    def __call__(self, params):\n        principals = list(self.request.effective_principals)\n\n        # We always want annotations with 'group:__world__' in their read\n        # permissions to show up in the search results, but 'group:__world__'\n        # is not in effective_principals for unauthenticated requests.\n        #\n        # FIXME: If public annotations used 'system.Everyone'\n        # instead of 'group:__world__' we wouldn't have to do this.\n        if 'group:__world__' not in principals:\n            principals.insert(0, 'group:__world__')\n\n        return {'terms': {'permissions.read': principals}}\n\n\nclass GroupFilter(object):\n\n    \"\"\"\n    Matches only those annotations belonging to the specified group.\n    \"\"\"\n\n    def __call__(self, params):\n        # Remove parameter if passed, preventing fall-through to default query\n        group = params.pop(\"group\", None)\n\n        if group is not None:\n            return {\"term\": {\"group\": group}}\n\n\nclass UriFilter(object):\n\n    \"\"\"\n    A filter that selects only annotations where the 'uri' parameter matches.\n    \"\"\"\n\n    def __init__(self, request):\n        \"\"\"Initialize a new UriFilter.\n\n        :param request: the pyramid.request object\n\n        \"\"\"\n        self.request = request\n\n    def __call__(self, params):\n        if 'uri' not in params:\n            return None\n        query_uris = [v for k, v in params.items() if k == 'uri']\n        del params['uri']\n\n        uris = set()\n        for query_uri in query_uris:\n            expanded = storage.expand_uri(self.request.db, query_uri)\n\n            us = [uri.normalize(u) for u in expanded]\n            uris.update(us)\n\n        return {\"terms\": {\"target.scope\": list(uris)}}\n\n\nclass UserFilter(object):\n\n    \"\"\"\n    A filter that selects only annotations where the 'user' parameter matches.\n    \"\"\"\n\n    def __call__(self, params):\n        if 'user' not in params:\n            return None\n\n        users = [v.lower() for k, v in params.items() if k == 'user']\n        del params['user']\n\n        return {'terms': {'user': users}}\n\n\nclass AnyMatcher(object):\n\n    \"\"\"\n    Matches the contents of a selection of fields against the `any` parameter.\n    \"\"\"\n\n    def __call__(self, params):\n        if \"any\" not in params:\n            return None\n        qs = ' '.join([v for k, v in params.items() if k == \"any\"])\n        result = {\n            \"simple_query_string\": {\n                \"fields\": [\"quote\", \"tags\", \"text\", \"uri.parts\"],\n                \"query\": qs,\n            }\n        }\n        del params[\"any\"]\n        return result\n\n\nclass TagsMatcher(object):\n\n    \"\"\"Matches the tags field against 'tag' or 'tags' parameters.\"\"\"\n\n    def __call__(self, params):\n        tags = set(v for k, v in params.items() if k in ['tag', 'tags'])\n        try:\n            del params['tag']\n            del params['tags']\n        except KeyError:\n            pass\n        matchers = [{'match': {'tags': {'query': t, 'operator': 'and'}}}\n                    for t in tags]\n        return {'bool': {'must': matchers}} if matchers else None\n\n\nclass RepliesMatcher(object):\n\n    \"\"\"Matches any replies to any of the given annotation ids.\"\"\"\n\n    def __init__(self, ids):\n        self.annotation_ids = ids\n\n    def __call__(self, _):\n        return {\n            'terms': {'references': self.annotation_ids}\n        }\n\n\nclass TagsAggregation(object):\n    def __init__(self, limit=0):\n        self.key = 'tags'\n        self.limit = limit\n\n    def __call__(self, _):\n        return {\n            \"terms\": {\n                \"field\": \"tags\",\n                \"size\": self.limit\n            }\n        }\n\n    def parse_result(self, result):\n        if not result:\n            return {}\n\n        return [\n            {'tag': b['key'], 'count': b['doc_count']}\n            for b in result['buckets']\n        ]\n\n\nclass UsersAggregation(object):\n    def __init__(self, limit=0):\n        self.key = 'users'\n        self.limit = limit\n\n    def __call__(self, _):\n        return {\n            \"terms\": {\n                \"field\": \"user_raw\",\n                \"size\": self.limit\n            }\n        }\n\n    def parse_result(self, result):\n        if not result:\n            return {}\n\n        return [\n            {'user': b['key'], 'count': b['doc_count']}\n            for b in result['buckets']\n        ]\n"},{"size":8853,"relativepath":"src/memex/search/index.py","filename":"index.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"Functions for updating the search index.\"\"\"\n\nfrom __future__ import unicode_literals\nfrom collections import namedtuple\nimport itertools\nimport logging\nfrom memex._compat import xrange\n\nimport elasticsearch\nfrom elasticsearch import helpers as es_helpers\nfrom sqlalchemy.orm import subqueryload\n\nfrom memex import models\nfrom memex import presenters\nfrom memex.events import AnnotationTransformEvent\n\n\nlog = logging.getLogger(__name__)\n\n\nclass Window(namedtuple('Window', ['start', 'end'])):\n    pass\n\n\ndef index(es, annotation, request):\n    \"\"\"\n    Index an annotation into the search index.\n\n    A new annotation document will be created in the search index or,\n    if the index already contains an annotation document with the same ID as\n    the given annotation then it will be updated.\n\n    :param es: the Elasticsearch client object to use\n    :type es: memex.search.Client\n\n    :param annotation: the annotation to index\n    :type annotation: memex.models.Annotation\n\n    \"\"\"\n    presenter = presenters.AnnotationSearchIndexPresenter(annotation)\n    annotation_dict = presenter.asdict()\n\n    event = AnnotationTransformEvent(request, annotation_dict)\n    request.registry.notify(event)\n\n    es.conn.index(\n        index=es.index,\n        doc_type=es.t.annotation,\n        body=annotation_dict,\n        id=annotation_dict[\"id\"],\n    )\n\n\ndef delete(es, annotation_id):\n    \"\"\"\n    Delete an annotation from the search index.\n\n    If no annotation with the given annotation's ID exists in the search index,\n    just log the resulting elasticsearch exception (don't crash).\n\n    :param es: the Elasticsearch client object to use\n    :type es: memex.search.Client\n\n    :param annotation_id: the annotation id whose corresponding document to\n        delete from the search index\n    :type annotation_id: str\n\n    \"\"\"\n    try:\n        es.conn.delete(\n            index=es.index,\n            doc_type=es.t.annotation,\n            id=annotation_id,\n        )\n    except elasticsearch.NotFoundError:\n        log.exception('Tried to delete a nonexistent annotation from the '\n                      'search index, annotation id: %s', annotation_id)\n\n\ndef reindex(session, es, request):\n    indexing = BatchIndexer(session, es, request)\n    indexing.index_all()\n\n    deleting = BatchDeleter(session, es)\n    deleting.delete_all()\n\n\nclass BatchIndexer(object):\n    \"\"\"\n    A convenience class for reindexing all annotations from the database to\n    the search index.\n    \"\"\"\n\n    def __init__(self, session, es_client, request):\n        self.session = session\n        self.es_client = es_client\n        self.request = request\n\n    def index_all(self):\n        \"\"\"Reindex all annotations, and retry failed indexing operations once.\"\"\"\n\n        errored = None\n        for _ in range(2):\n            errored = self.index(errored)\n            log.debug(\n                'Failed to index {} annotations, might retry'.format(len(errored)))\n\n            if not errored:\n                break\n\n    def index(self, annotation_ids=None):\n        \"\"\"\n        Reindex annotations.\n\n        :param annotation_ids: a list of ids to reindex, reindexes all when `None`.\n        :type annotation_ids: collection\n\n        :returns: a set of errored ids\n        :rtype: set\n        \"\"\"\n        if not annotation_ids:\n            annotations = self._stream_all_annotations()\n        else:\n            annotations = self._stream_filtered_annotations(annotation_ids)\n\n        indexing = es_helpers.streaming_bulk(self.es_client.conn, annotations,\n                                             chunk_size=100,\n                                             raise_on_error=False,\n                                             expand_action_callback=self._prepare)\n        errored = set()\n        for ok, item in indexing:\n            if not ok:\n                errored.add(item['index']['_id'])\n        return errored\n\n    def _prepare(self, annotation):\n        action = {'index': {'_index': self.es_client.index,\n                            '_type': self.es_client.t.annotation,\n                            '_id': annotation.id}}\n        data = presenters.AnnotationSearchIndexPresenter(annotation).asdict()\n\n        event = AnnotationTransformEvent(self.request, data)\n        self.request.registry.notify(event)\n\n        return (action, data)\n\n    def _stream_all_annotations(self, chunksize=2000):\n        # This is using a windowed query for loading all annotations in batches.\n        # It is the most performant way of loading a big set of records from\n        # the database while still supporting eagerloading of associated\n        # document data.\n\n        updated = self.session.query(models.Annotation.updated). \\\n                execution_options(stream_results=True). \\\n                order_by(models.Annotation.updated.desc()).all()\n\n        count = len(updated)\n        windows = [Window(start=updated[min(x+chunksize, count)-1].updated,\n                          end=updated[x].updated)\n                   for x in xrange(0, count, chunksize)]\n        basequery = self._eager_loaded_query().order_by(models.Annotation.updated.asc())\n\n        for window in windows:\n            in_window = models.Annotation.updated.between(window.start, window.end)\n            for a in basequery.filter(in_window):\n                yield a\n\n    def _stream_filtered_annotations(self, annotation_ids):\n        annotations = self._eager_loaded_query(). \\\n            execution_options(stream_results=True). \\\n            filter(models.Annotation.id.in_(annotation_ids))\n\n        for a in annotations:\n            yield a\n\n    def _eager_loaded_query(self):\n        return self.session.query(models.Annotation).options(\n            subqueryload(models.Annotation.document).subqueryload(models.Document.document_uris),\n            subqueryload(models.Annotation.document).subqueryload(models.Document.meta)\n        )\n\n\nclass BatchDeleter(object):\n    \"\"\"\n    A convenience class for removing all annotations that are deleted from the\n    database from the search index.\n    \"\"\"\n\n    def __init__(self, session, es_client):\n        self.session = session\n        self.es_client = es_client\n\n    def delete_all(self):\n        \"\"\"Remove all deleted annotations, and retry failed delete operations once.\"\"\"\n        ids = self.deleted_annotation_ids()\n        for _ in range(2):\n            if not ids:\n                break\n\n            ids = self.delete(ids)\n            log.debug(\n                'Failed to delete {} annotations, might retry'.format(len(ids)))\n\n    def deleted_annotation_ids(self):\n        \"\"\"\n        Get a list of deleted annotation ids by comparing all ids in the search\n        index and comparing them to all ids in the database.\n\n        :returns: a set of deleted annotation ids\n        :rtype: set\n        \"\"\"\n        ids = set()\n        for batch in self._batch_iter(2000, self._es_scan()):\n            ids.update({a['_id'] for a in batch})\n\n        for batch in self._batch_iter(2000, self._pg_ids()):\n            ids.difference_update({a.id for a in batch})\n        return ids\n\n    def delete(self, annotation_ids):\n        \"\"\"\n        Delete annotations from the search index.\n\n        :param annotation_ids: a list of ids to delete.\n        :type annotation_ids: collection\n\n        :returns: a set of errored ids\n        :rtype: set\n        \"\"\"\n        if not annotation_ids:\n            return set()\n\n        deleting = es_helpers.streaming_bulk(self.es_client.conn, annotation_ids,\n                                             chunk_size=100,\n                                             expand_action_callback=self._prepare,\n                                             raise_on_error=False)\n        errored = set()\n        for ok, item in deleting:\n            if not ok and item['delete']['status'] != 404:\n                errored.add(item['delete']['_id'])\n        return errored\n\n    def _prepare(self, id_):\n        action = {'delete': {'_index': self.es_client.index,\n                             '_type': self.es_client.t.annotation,\n                             '_id': id_}}\n        return (action, None)\n\n    def _pg_ids(self):\n        # This is using a Postgres cursor for better query performance.\n        return self.session.query(models.Annotation.id).execution_options(stream_results=True)\n\n    def _es_scan(self):\n        query = {'_source': False, 'query': {'match_all': {}}}\n        return es_helpers.scan(self.es_client.conn,\n                               index=self.es_client.index,\n                               doc_type=self.es_client.t.annotation,\n                               query=query)\n\n    def _batch_iter(self, n, iterable):\n        it = iter(iterable)\n        while True:\n            batch = list(itertools.islice(it, n))\n            if not batch:\n                return\n            yield batch\n"},{"size":855,"relativepath":"src/memex/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n__all__ = ('__version__',)\n__version__ = '0.39.0+dev'\n\n\ndef includeme(config):\n    config.include('memex.eventqueue')\n    config.include('memex.links')\n    config.include('memex.presenters')\n    config.include('memex.search')\n    config.include('memex.views')\n\n    config.add_route('api.index', '/')\n    config.add_route('api.annotations', '/annotations')\n    config.add_route('api.annotation',\n                     '/annotations/{id:[A-Za-z0-9_-]{20,22}}',\n                     factory='memex.resources:AnnotationFactory',\n                     traverse='/{id}')\n    config.add_route('api.annotation.jsonld',\n                     '/annotations/{id:[A-Za-z0-9_-]{20,22}}.jsonld',\n                     factory='memex.resources:AnnotationFactory',\n                     traverse='/{id}')\n    config.add_route('api.search', '/search')\n"},{"size":16343,"relativepath":"src/memex/models/document.py","filename":"document.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nfrom datetime import datetime\nimport logging\n\nimport sqlalchemy as sa\nimport transaction\nfrom sqlalchemy.dialects import postgresql as pg\nfrom sqlalchemy.ext.hybrid import hybrid_property\n\nfrom memex.db import Base\nfrom memex.db import mixins\nfrom memex.models import Annotation\nfrom memex.uri import normalize as uri_normalize\nfrom memex._compat import urlparse\n\n\nlog = logging.getLogger(__name__)\n\n\nclass ConcurrentUpdateError(transaction.interfaces.TransientError):\n    \"\"\"Raised when concurrent updates to document data conflict.\"\"\"\n\n\nclass Document(Base, mixins.Timestamps):\n    __tablename__ = 'document'\n\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n\n    #: The denormalized value of the first DocumentMeta record with type title.\n    title = sa.Column('title', sa.UnicodeText())\n\n    #: The denormalized value of the first http(s) DocumentURI\n    web_uri = sa.Column('web_uri', sa.UnicodeText())\n\n    # FIXME: This relationship should be named `uris` again after the\n    #        dependency on the annotator-store is removed, as it clashes with\n    #        making the Postgres and Elasticsearch interface of a Document\n    #        object behave the same way.\n    document_uris = sa.orm.relationship('DocumentURI',\n                                        backref='document',\n                                        order_by='DocumentURI.updated.desc()')\n    meta = sa.orm.relationship('DocumentMeta',\n                               backref='document',\n                               order_by='DocumentMeta.updated.desc()')\n\n    def __repr__(self):\n        return '<Document %s>' % self.id\n\n    @classmethod\n    def find_by_uris(cls, session, uris):\n        \"\"\"Find documents by a list of uris.\"\"\"\n        query_uris = [uri_normalize(u) for u in uris]\n\n        matching_claims = (\n            session.query(DocumentURI)\n                   .filter(DocumentURI.uri_normalized.in_(query_uris))\n                   .distinct(DocumentURI.document_id)\n                   .subquery()\n        )\n\n        return session.query(Document).join(matching_claims)\n\n    @classmethod\n    def find_or_create_by_uris(cls, session, claimant_uri, uris,\n                               created=None, updated=None):\n        \"\"\"\n        Find or create documents from a claimant uri and a list of uris.\n\n        It tries to find a document based on the claimant and the set of uris.\n        If none can be found it will return a new document with the claimant\n        uri as its only document uri as a self-claim. It is the callers\n        responsibility to create any other document uris.\n        \"\"\"\n\n        finduris = [claimant_uri] + uris\n        documents = cls.find_by_uris(session, finduris)\n\n        if documents.count() == 0:\n            doc = Document(created=created, updated=updated)\n            DocumentURI(document=doc,\n                        claimant=claimant_uri,\n                        uri=claimant_uri,\n                        type='self-claim',\n                        created=created,\n                        updated=updated)\n            session.add(doc)\n\n        try:\n            session.flush()\n        except sa.exc.IntegrityError:\n            raise ConcurrentUpdateError('concurrent document creation')\n\n        return documents\n\n\nclass DocumentURI(Base, mixins.Timestamps):\n    __tablename__ = 'document_uri'\n    __table_args__ = (\n        sa.UniqueConstraint('claimant_normalized',\n                            'uri_normalized',\n                            'type',\n                            'content_type'),\n        sa.Index('ix__document_uri_document_id', 'document_id'),\n        sa.Index('ix__document_uri_updated', 'updated'),\n    )\n\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n\n    _claimant = sa.Column('claimant',\n                          sa.UnicodeText,\n                          nullable=False)\n    _claimant_normalized = sa.Column('claimant_normalized',\n                                     sa.UnicodeText,\n                                     nullable=False)\n\n    _uri = sa.Column('uri',\n                     sa.UnicodeText,\n                     nullable=False)\n    _uri_normalized = sa.Column('uri_normalized',\n                                sa.UnicodeText,\n                                nullable=False,\n                                index=True)\n\n    type = sa.Column(sa.UnicodeText,\n                     nullable=False,\n                     default='',\n                     server_default='')\n    content_type = sa.Column(sa.UnicodeText,\n                             nullable=False,\n                             default='',\n                             server_default='')\n\n    document_id = sa.Column(sa.Integer,\n                            sa.ForeignKey('document.id'),\n                            nullable=False)\n\n    @hybrid_property\n    def claimant(self):\n        return self._claimant\n\n    @claimant.setter\n    def claimant(self, value):\n        self._claimant = value\n        self._claimant_normalized = uri_normalize(value)\n\n    @hybrid_property\n    def claimant_normalized(self):\n        return self._claimant_normalized\n\n    @hybrid_property\n    def uri(self):\n        return self._uri\n\n    @uri.setter\n    def uri(self, value):\n        self._uri = value\n        self._uri_normalized = uri_normalize(value)\n\n    @hybrid_property\n    def uri_normalized(self):\n        return self._uri_normalized\n\n    def __repr__(self):\n        return '<DocumentURI %s>' % self.id\n\n\nclass DocumentMeta(Base, mixins.Timestamps):\n    __tablename__ = 'document_meta'\n    __table_args__ = (\n        sa.UniqueConstraint('claimant_normalized', 'type'),\n        sa.Index('ix__document_meta_document_id', 'document_id'),\n        sa.Index('ix__document_meta_updated', 'updated'),\n    )\n\n    id = sa.Column(sa.Integer, autoincrement=True, primary_key=True)\n\n    _claimant = sa.Column('claimant',\n                          sa.UnicodeText,\n                          nullable=False)\n    _claimant_normalized = sa.Column('claimant_normalized',\n                                     sa.UnicodeText,\n                                     nullable=False)\n\n    type = sa.Column(sa.UnicodeText, nullable=False)\n    value = sa.Column(pg.ARRAY(sa.UnicodeText, zero_indexes=True),\n                      nullable=False)\n\n    document_id = sa.Column(sa.Integer,\n                            sa.ForeignKey('document.id'),\n                            nullable=False)\n\n    @hybrid_property\n    def claimant(self):\n        return self._claimant\n\n    @claimant.setter\n    def claimant(self, value):\n        self._claimant = value\n        self._claimant_normalized = uri_normalize(value)\n\n    @hybrid_property\n    def claimant_normalized(self):\n        return self._claimant_normalized\n\n    def __repr__(self):\n        return '<DocumentMeta %s>' % self.id\n\n\ndef create_or_update_document_uri(session,\n                                  claimant,\n                                  uri,\n                                  type,\n                                  content_type,\n                                  document,\n                                  created,\n                                  updated):\n    \"\"\"\n    Create or update a DocumentURI with the given parameters.\n\n    If an equivalent DocumentURI already exists in the database then its\n    updated time will be updated.\n\n    If no equivalent DocumentURI exists in the database then a new one will be\n    created and added to the database.\n\n    To be considered \"equivalent\" an existing DocumentURI must have the same\n    claimant, uri, type and content_type, but the Document object that it\n    belongs to may be different. The claimant and uri are normalized before\n    comparing.\n\n    :param session: the database session\n    :type session: sqlalchemy.orm.session.Session\n\n    :param claimant: the .claimant property of the DocumentURI\n    :type claimant: unicode\n\n    :param uri: the .uri property of the DocumentURI\n    :type uri: unicode\n\n    :param type: the .type property of the DocumentURI\n    :type type: unicode\n\n    :param content_type: the .content_type property of the DocumentURI\n    :type content_type: unicode\n\n    :param document: the Document that the new DocumentURI will belong to, if a\n        new DocumentURI is created\n    :type document: memex.models.Document\n\n    :param created: the time that will be used as the .created time for the new\n        DocumentURI, if a new one is created\n    :type created: datetime.datetime\n\n    :param updated: the time that will be set as the .updated time for the new\n        or existing DocumentURI\n    :type updated: datetime.datetime\n\n    \"\"\"\n    docuri = session.query(DocumentURI).filter(\n        DocumentURI.claimant_normalized == uri_normalize(claimant),\n        DocumentURI.uri_normalized == uri_normalize(uri),\n        DocumentURI.type == type,\n        DocumentURI.content_type == content_type).first()\n\n    if docuri is None:\n        docuri = DocumentURI(claimant=claimant,\n                             uri=uri,\n                             type=type,\n                             content_type=content_type,\n                             document=document,\n                             created=created,\n                             updated=updated)\n        session.add(docuri)\n    elif not docuri.document == document:\n        log.warn(\"Found DocumentURI (id: %d)'s document_id (%d) doesn't match \"\n                 \"given Document's id (%d)\",\n                 docuri.id, docuri.document_id, document.id)\n\n    docuri.updated = updated\n\n    if not document.web_uri:\n        parsed = urlparse.urlparse(uri)\n        if parsed.scheme in ['http', 'https']:\n            document.web_uri = uri\n\n    try:\n        session.flush()\n    except sa.exc.IntegrityError:\n        raise ConcurrentUpdateError('concurrent document uri updates')\n\n\ndef create_or_update_document_meta(session,\n                                   claimant,\n                                   type,\n                                   value,\n                                   document,\n                                   created,\n                                   updated):\n    \"\"\"\n    Create or update a DocumentMeta with the given parameters.\n\n    If an equivalent DocumentMeta already exists in the database then its value\n    and updated time will be updated.\n\n    If no equivalent DocumentMeta exists in the database then a new one will be\n    created and added to the database.\n\n    To be considered \"equivalent\" an existing DocumentMeta must have the given\n    claimant and type, but its value, document and created and updated times\n    needn't match the given ones.\n\n    :param session: the database session\n    :type session: sqlalchemy.orm.session.Session\n\n    :param claimant: the value to use for the DocumentMeta's claimant attribute\n        if a new DocumentMeta is created\n    :type claimant: unicode\n\n    :param type: the value of the new or existing DocumentMeta's type attribute\n    :type type: unicode\n\n    :param value: the value to set the new or existing DocumentMeta's value\n        attribute to\n    :type value: list of unicode strings\n\n    :param document: the value to use for the DocumentMeta's document if a new\n        DocumentMeta is created\n    :type document: memex.models.Document\n\n    :param created: the value to use for the DocumentMeta's created attribute\n        if a new DocumentMeta is created\n    :type created: datetime.datetime\n\n    :param updated: the value to set the new or existing DocumentMeta's updated\n        attribute to\n    :type updated: datetime.datetime\n\n    \"\"\"\n    existing_dm = session.query(DocumentMeta).filter(\n        DocumentMeta.claimant_normalized == uri_normalize(claimant),\n        DocumentMeta.type == type).one_or_none()\n\n    if existing_dm is None:\n        session.add(DocumentMeta(\n                    claimant=claimant,\n                    type=type,\n                    value=value,\n                    document=document,\n                    created=created,\n                    updated=updated,\n                    ))\n    else:\n        existing_dm.value = value\n        existing_dm.updated = updated\n        if not existing_dm.document == document:\n            log.warn(\"Found DocumentMeta (id: %d)'s document_id (%d) doesn't \"\n                     \"match given Document's id (%d)\",\n                     existing_dm.id, existing_dm.document_id, document.id)\n\n    if type == 'title' and value and not document.title:\n        document.title = value[0]\n\n    try:\n        session.flush()\n    except sa.exc.IntegrityError:\n        raise ConcurrentUpdateError('concurrent document meta updates')\n\n\ndef merge_documents(session, documents, updated=None):\n    \"\"\"\n    Takes a list of documents and merges them together. It returns the new\n    master document.\n\n    The support for setting a specific value for the `updated` should only\n    be used during the Postgres migration. It should be removed afterwards.\n    \"\"\"\n    if updated is None:\n        updated = datetime.utcnow()\n\n    master = documents[0]\n    duplicates = documents[1:]\n    duplicate_ids = [doc.id for doc in duplicates]\n\n    for doc in duplicates:\n        for _ in range(len(doc.document_uris)):\n            u = doc.document_uris.pop()\n            u.document = master\n            u.updated = updated\n\n        for _ in range(len(doc.meta)):\n            m = doc.meta.pop()\n            m.document = master\n            m.updated = updated\n\n    try:\n        session.flush()\n        session.query(Annotation) \\\n            .filter(Annotation.document_id.in_(duplicate_ids)) \\\n            .update({Annotation.document_id: master.id}, synchronize_session='fetch')\n        session.query(Document) \\\n            .filter(Document.id.in_(duplicate_ids)) \\\n            .delete(synchronize_session='fetch')\n    except sa.exc.IntegrityError:\n        raise ConcurrentUpdateError('concurrent document merges')\n\n    return master\n\n\ndef update_document_metadata(session,\n                             target_uri,\n                             document_meta_dicts,\n                             document_uri_dicts,\n                             created=None,\n                             updated=None):\n    \"\"\"\n    Create and update document metadata from the given annotation.\n\n    Document, DocumentURI and DocumentMeta objects will be created, updated\n    and deleted in the database as required by the given annotation and\n    document meta and uri dicts.\n\n    :param target_uri: the target_uri of the annotation from which the document metadata comes from\n    :type target_uri: unicode\n\n    :param document_meta_dicts: the document metadata dicts that were derived\n        by validation from the \"document\" dict that the client posted\n    :type document_meta_dicts: list of dicts\n\n    :param document_uri_dicts: the document URI dicts that were derived by\n        validation from the \"document\" dict that the client posted\n    :type document_uri_dicts: list of dicts\n\n    :param created: Date and time value for the new document records\n    :type created: datetime.datetime\n\n    :param updated: Date and time value for the new document records\n    :type updated: datetime.datetime\n\n    :returns: the matched or created document\n    :rtype: memex.models.Document\n    \"\"\"\n    if created is None:\n        created = datetime.utcnow()\n    if updated is None:\n        updated = datetime.utcnow()\n\n    documents = Document.find_or_create_by_uris(\n        session,\n        target_uri,\n        [u['uri'] for u in document_uri_dicts],\n        created=created,\n        updated=updated)\n\n    if documents.count() > 1:\n        document = merge_documents(session,\n                                   documents,\n                                   updated=updated)\n    else:\n        document = documents.first()\n\n    document.updated = updated\n\n    for document_uri_dict in document_uri_dicts:\n        create_or_update_document_uri(\n            session=session,\n            document=document,\n            created=created,\n            updated=updated,\n            **document_uri_dict)\n\n    for document_meta_dict in document_meta_dicts:\n        create_or_update_document_meta(\n            session=session,\n            document=document,\n            created=created,\n            updated=updated,\n            **document_meta_dict)\n\n    return document\n"},{"size":1027,"relativepath":"src/memex/models/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"\nAnnotations API domain model classes.\n\nThis package is currently in flux as we transition between a set of models\nwhich save data to ElasticSearch and a set of models which save data in a\nPostgreSQL database.\n\nPlease note: access to these model objects should almost certainly not be\ndirect to the submodules of this package, but rather through the helper\nfunctions in `memex.storage`.\n\"\"\"\n\nfrom memex.models.annotation import Annotation\nfrom memex.models.document import create_or_update_document_meta\nfrom memex.models.document import create_or_update_document_uri\nfrom memex.models.document import Document\nfrom memex.models.document import DocumentMeta\nfrom memex.models.document import DocumentURI\nfrom memex.models.document import merge_documents\nfrom memex.models.document import update_document_metadata\n\n\n__all__ = (\n    'Annotation',\n    'create_or_update_document_meta',\n    'create_or_update_document_uri',\n    'Document',\n    'DocumentMeta',\n    'DocumentURI',\n    'merge_documents',\n)\n"},{"size":6316,"relativepath":"src/memex/models/annotation.py","filename":"annotation.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport datetime\n\nfrom pyramid import security\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects import postgresql as pg\nfrom sqlalchemy.ext.hybrid import hybrid_property\nfrom sqlalchemy.ext.mutable import MutableDict\n\nfrom memex import markdown\nfrom memex import uri\nfrom memex.db import Base\nfrom memex.db import types\n\n\nclass Annotation(Base):\n\n    \"\"\"Model class representing a single annotation.\"\"\"\n\n    __tablename__ = 'annotation'\n    __table_args__ = (\n        # Tags are stored in an array-type column, and indexed using a\n        # generalised inverted index. For more information on the use of GIN\n        # indices for array columns, see:\n        #\n        #   http://www.databasesoup.com/2015/01/tag-all-things.html\n        #   http://www.postgresql.org/docs/9.5/static/gin-intro.html\n        #\n        sa.Index('ix__annotation_tags', 'tags', postgresql_using='gin'),\n        sa.Index('ix__annotation_updated', 'updated'),\n    )\n\n    #: Annotation ID: these are stored as UUIDs in the database, and mapped\n    #: transparently to a URL-safe Base64-encoded string.\n    id = sa.Column(types.URLSafeUUID,\n                   server_default=sa.func.uuid_generate_v1mc(),\n                   primary_key=True)\n\n    #: The timestamp when the annotation was created.\n    created = sa.Column(sa.DateTime,\n                        default=datetime.datetime.utcnow,\n                        server_default=sa.func.now(),\n                        nullable=False)\n\n    #: The timestamp when the user edited the annotation last.\n    updated = sa.Column(sa.DateTime,\n                        server_default=sa.func.now(),\n                        default=datetime.datetime.utcnow,\n                        nullable=False)\n\n    #: The full userid (e.g. 'acct:foo@example.com') of the owner of this\n    #: annotation.\n    userid = sa.Column(sa.UnicodeText,\n                       nullable=False,\n                       index=True)\n    #: The string id of the group in which this annotation is published.\n    #: Defaults to the global public group, \"__world__\".\n    groupid = sa.Column(sa.UnicodeText,\n                        default='__world__',\n                        server_default='__world__',\n                        nullable=False,\n                        index=True)\n\n    #: The textual body of the annotation.\n    _text = sa.Column('text', sa.UnicodeText)\n    #: The Markdown-rendered and HTML-sanitized textual body of the annotation.\n    _text_rendered = sa.Column('text_rendered', sa.UnicodeText)\n    #: The tags associated with the annotation.\n    tags = sa.Column(\n        types.MutableList.as_mutable(\n            pg.ARRAY(sa.UnicodeText, zero_indexes=True)))\n\n    #: A boolean indicating whether this annotation is shared with members of\n    #: the group it is published in. \"Private\"/\"Only me\" annotations have\n    #: shared=False.\n    shared = sa.Column(sa.Boolean,\n                       nullable=False,\n                       default=False,\n                       server_default=sa.sql.expression.false())\n\n    #: The URI of the annotated page, as provided by the client.\n    _target_uri = sa.Column('target_uri', sa.UnicodeText)\n    #: The URI of the annotated page in normalized form.\n    _target_uri_normalized = sa.Column('target_uri_normalized', sa.UnicodeText)\n    #: The serialized selectors for the annotation on the annotated page.\n    target_selectors = sa.Column(types.AnnotationSelectorJSONB,\n                                 default=list,\n                                 server_default=sa.func.jsonb('[]'))\n\n    #: An array of annotation IDs which are ancestors of this annotation.\n    references = sa.Column(pg.ARRAY(types.URLSafeUUID),\n                           default=list,\n                           server_default=sa.text('ARRAY[]::uuid[]'))\n\n    #: Any additional serialisable data provided by the client.\n    extra = sa.Column(MutableDict.as_mutable(pg.JSONB),\n                      default=dict,\n                      server_default=sa.func.jsonb('{}'),\n                      nullable=False)\n\n    document_id = sa.Column(sa.Integer,\n                            sa.ForeignKey('document.id'),\n                            nullable=False)\n\n    document = sa.orm.relationship('Document', backref='annotations')\n\n    @hybrid_property\n    def target_uri(self):\n        return self._target_uri\n\n    @target_uri.setter\n    def target_uri(self, value):\n        self._target_uri = value\n        self._target_uri_normalized = uri.normalize(value)\n\n    @hybrid_property\n    def target_uri_normalized(self):\n        return self._target_uri_normalized\n\n    @hybrid_property\n    def text(self):\n        return self._text\n\n    @text.setter\n    def text(self, value):\n        self._text = value\n        self._text_rendered = markdown.render(value)\n\n    @hybrid_property\n    def text_rendered(self):\n        return self._text_rendered\n\n    @property\n    def parent_id(self):\n        \"\"\"\n        Return the ID of the annotation that this annotation is a reply to.\n\n        Return None if this annotation is not a reply.\n\n        \"\"\"\n        if self.references:\n            return self.references[-1]\n\n    @property\n    def thread_root_id(self):\n        \"\"\"\n        Return the ID of the root annotation of this annotation's thread.\n\n        Return the ID of the root annotation of the thread to which this\n        annotation belongs. May be this annotation's own ID if it is the root\n        annotation of its thread.\n\n        \"\"\"\n        if self.references:\n            return self.references[0]\n        else:\n            return self.id\n\n    def __acl__(self):\n        \"\"\"Return a Pyramid ACL for this annotation.\"\"\"\n        acl = []\n        if self.shared:\n            group = 'group:{}'.format(self.groupid)\n            if self.groupid == '__world__':\n                group = security.Everyone\n\n            acl.append((security.Allow, group, 'read'))\n        else:\n            acl.append((security.Allow, self.userid, 'read'))\n\n        for action in ['admin', 'update', 'delete']:\n            acl.append((security.Allow, self.userid, action))\n\n        # If we haven't explicitly authorized it, it's not allowed.\n        acl.append(security.DENY_ALL)\n\n        return acl\n\n    def __repr__(self):\n        return '<Annotation %s>' % self.id\n"},{"size":7156,"relativepath":"src/memex/storage.py","filename":"storage.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"\nAnnotation storage API.\n\nThis module provides the core API with access to basic persistence functions\nfor storing and retrieving annotations. Data passed to these functions is\nassumed to be validated.\n\"\"\"\n\nfrom datetime import datetime\n\nfrom pyramid import i18n\n\nfrom memex import schemas\nfrom memex import models\nfrom memex.db import types\n\n\n_ = i18n.TranslationStringFactory(__package__)\n\n\ndef fetch_annotation(session, id_):\n    \"\"\"\n    Fetch the annotation with the given id.\n\n    :param session: the database session\n    :type session: sqlalchemy.orm.session.Session\n\n    :param id_: the annotation ID\n    :type id_: str\n\n    :returns: the annotation, if found, or None.\n    :rtype: memex.models.Annotation, NoneType\n    \"\"\"\n    try:\n        return session.query(models.Annotation).get(id_)\n    except types.InvalidUUID:\n        return None\n\n\ndef fetch_ordered_annotations(session, ids, query_processor=None):\n    \"\"\"\n    Fetch all annotations with the given ids and order them based on the list\n    of ids.\n\n    The optional `query_processor` parameter allows for passing in a function\n    that can change the query before it is run, especially useful for\n    eager-loading certain data. The function will get the query as an argument\n    and has to return a query object again.\n\n    :param session: the database session\n    :type session: sqlalchemy.orm.session.Session\n\n    :param ids: the list of annotation ids\n    :type ids: list\n\n    :param query_processor: an optional function that takes the query and\n                            returns an updated query\n    :type query_processor: callable\n\n    :returns: the annotation, if found, or None.\n    :rtype: memex.models.Annotation, NoneType\n    \"\"\"\n    if not ids:\n        return []\n\n    ordering = {x: i for i, x in enumerate(ids)}\n\n    query = session.query(models.Annotation).filter(models.Annotation.id.in_(ids))\n    if query_processor:\n        query = query_processor(query)\n\n    anns = sorted(query, key=lambda a: ordering.get(a.id))\n    return anns\n\n\ndef create_annotation(request, data):\n    \"\"\"\n    Create an annotation from passed data.\n\n    :param request: the request object\n    :type request: pyramid.request.Request\n\n    :param data: a dictionary of annotation properties\n    :type data: dict\n\n    :returns: the created and flushed annotation\n    :rtype: dict\n    \"\"\"\n    created = updated = datetime.utcnow()\n\n    document_uri_dicts = data['document']['document_uri_dicts']\n    document_meta_dicts = data['document']['document_meta_dicts']\n    del data['document']\n\n    # Replies must have the same group as their parent.\n    if data['references']:\n        top_level_annotation_id = data['references'][0]\n        top_level_annotation = fetch_annotation(request.db,\n                                                top_level_annotation_id)\n        if top_level_annotation:\n            data['groupid'] = top_level_annotation.groupid\n        else:\n            raise schemas.ValidationError(\n                'references.0: ' +\n                _('Annotation {id} does not exist').format(\n                    id=top_level_annotation_id)\n            )\n\n    # The user must have permission to create an annotation in the group\n    # they've asked to create one in.\n    if data['groupid'] != '__world__':\n        group_principal = 'group:{}'.format(data['groupid'])\n        if group_principal not in request.effective_principals:\n            raise schemas.ValidationError('group: ' +\n                                          _('You may not create annotations '\n                                            'in groups you are not a member '\n                                            'of!'))\n\n    annotation = models.Annotation(**data)\n    annotation.created = created\n    annotation.updated = updated\n\n    document = models.update_document_metadata(\n        request.db,\n        annotation.target_uri,\n        document_meta_dicts,\n        document_uri_dicts,\n        created=created,\n        updated=updated)\n    annotation.document = document\n\n    request.db.add(annotation)\n    request.db.flush()\n\n    return annotation\n\n\ndef update_annotation(session, id_, data):\n    \"\"\"\n    Update an existing annotation and its associated document metadata.\n\n    Update the annotation identified by id_ with the given\n    data. Create, delete and update document metadata as appropriate.\n\n    :param session: the database session\n    :type session: sqlalchemy.orm.session.Session\n\n    :param id_: the ID of the annotation to be updated, this is assumed to be a\n        validated ID of an annotation that does already exist in the database\n    :type id_: string\n\n    :param data: the validated data with which to update the annotation\n    :type data: dict\n\n    :returns: the updated annotation\n    :rtype: memex.models.Annotation\n\n    \"\"\"\n    updated = datetime.utcnow()\n\n    # Remove any 'document' field first so that we don't try to save it on the\n    # annotation object.\n    document = data.pop('document', None)\n\n    annotation = session.query(models.Annotation).get(id_)\n    annotation.updated = updated\n\n    annotation.extra.update(data.pop('extra', {}))\n\n    for key, value in data.items():\n        setattr(annotation, key, value)\n\n    if document:\n        document_uri_dicts = document['document_uri_dicts']\n        document_meta_dicts = document['document_meta_dicts']\n        document = models.update_document_metadata(session,\n                                                   annotation.target_uri,\n                                                   document_meta_dicts,\n                                                   document_uri_dicts,\n                                                   updated=updated)\n        annotation.document = document\n\n    return annotation\n\n\ndef delete_annotation(session, id_):\n    \"\"\"\n    Delete the annotation with the given id.\n\n    :param session: the database session\n    :type session: sqlalchemy.orm.session.Session\n\n    :param id_: the annotation ID\n    :type id_: str\n    \"\"\"\n    session.query(models.Annotation).filter_by(id=id_).delete()\n\n\ndef expand_uri(session, uri):\n    \"\"\"\n    Return all URIs which refer to the same underlying document as `uri`.\n\n    This function determines whether we already have \"document\" records for the\n    passed URI, and if so returns the set of all URIs which we currently\n    believe refer to the same document.\n\n    :param session: the database session\n    :type session: sqlalchemy.orm.session.Session\n\n    :param uri: a URI associated with the document\n    :type uri: str\n\n    :returns: a list of equivalent URIs\n    :rtype: list\n    \"\"\"\n    doc = models.Document.find_by_uris(session, [uri]).one_or_none()\n\n    if doc is None:\n        return [uri]\n\n    # We check if the match was a \"canonical\" link. If so, all annotations\n    # created on that page are guaranteed to have that as their target.source\n    # field, so we don't need to expand to other URIs and risk false positives.\n    docuris = doc.document_uris\n    for docuri in docuris:\n        if docuri.uri == uri and docuri.type == 'rel-canonical':\n            return [uri]\n\n    return [docuri.uri for docuri in docuris]\n"},{"size":3133,"relativepath":"src/memex/cors.py","filename":"cors.py","extension":".py","content":"# -*- coding: utf-8 -*-\nfrom pyramid.httpexceptions import HTTPBadRequest\n\n\ndef policy(allow_credentials=False,\n           allow_headers=None,\n           allow_methods=None,\n           expose_headers=None,\n           max_age=86400):\n    \"\"\"\n    View decorator that provides CORS support.\n\n    CORS stands for \"Cross-Origin Resource Sharing,\" and is a protocol\n    implemented in browsers to allow safe dispatch of XMLHttpRequests across\n    origins.\n    \"\"\"\n\n    def cors_decorator(wrapped):\n        def wrapper(context, request):\n            response = wrapped(context, request)\n            return set_cors_headers(request, response,\n                                    allow_credentials=allow_credentials,\n                                    allow_headers=allow_headers,\n                                    allow_methods=allow_methods,\n                                    expose_headers=expose_headers,\n                                    max_age=max_age)\n\n        return wrapper\n\n    return cors_decorator\n\n\ndef set_cors_headers(request, response,\n                     allow_credentials=False,\n                     allow_headers=None,\n                     allow_methods=None,\n                     expose_headers=None,\n                     max_age=86400):\n    # If the request is anything other than an OPTIONS request, we just\n    # pass it through and add \"A-C-A-O: *\" to the response headers.\n    if request.method != 'OPTIONS':\n        response.headers['Access-Control-Allow-Origin'] = '*'\n        return response\n\n    # Otherwise, we're dealing with a CORS preflight request, which,\n    # according to the spec:\n    #\n    #  http://www.w3.org/TR/cors/#resource-preflight-requests\n    #\n    # ...MUST have an Origin header.\n    origin = request.headers.get('Origin')\n    if origin is None:\n        raise HTTPBadRequest('CORS preflight request lacks Origin header.')\n\n    # ...MUST have an Access-Control-Request-Method header.\n    request_method = request.headers.get('Access-Control-Request-Method')\n    if request_method is None:\n        raise HTTPBadRequest('CORS preflight request lacks '\n                             'Access-Control-Request-Method header.')\n\n    # Always explicitly allow OPTIONS requests.\n    methods = set(['OPTIONS'])\n    if allow_methods is not None:\n        methods.update(allow_methods)\n\n    # We *could* verify that the preflight Access-Control-Request-Headers and\n    # Access-Control-Request-Method match up with the allowed headers and\n    # methods, but there's no need to do this as we can simply return what is\n    # allowed and the browser will do the rest.\n    headers = response.headers\n    headers['Access-Control-Allow-Origin'] = origin\n    headers['Access-Control-Allow-Methods'] = ', '.join(methods)\n    headers['Access-Control-Max-Age'] = str(max_age)\n\n    if allow_credentials:\n        headers['Access-Control-Allow-Credentials'] = 'true'\n\n    if allow_headers is not None:\n        headers['Access-Control-Allow-Headers'] = ', '.join(allow_headers)\n\n    if expose_headers is not None:\n        headers['Access-Control-Expose-Headers'] = ', '.join(expose_headers)\n\n    return response\n"},{"size":3957,"relativepath":"src/memex/links.py","filename":"links.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"\nTools for generating links to domain objects.\n\"\"\"\n\nfrom __future__ import unicode_literals\n\nfrom pyramid.request import Request\n\nLINK_GENERATORS_KEY = 'memex.links.link_generators'\n\n\nclass LinksService(object):\n\n    \"\"\"A service for generating links to annotations.\"\"\"\n\n    def __init__(self, base_url, registry):\n        \"\"\"\n        Create a new links service.\n\n        :param base_url: the base URL for link construction\n        :param registry: the registry in which to look up routes\n        :type registry: pyramid.registry.Registry\n        \"\"\"\n        self.base_url = base_url\n        self.registry = registry\n\n        # It would be absolutely fair if at this point you asked yourself any\n        # of the following questions:\n        #\n        # - Why are we constructing a fake request here?\n        # - Didn't we have a request and then discard it in the service\n        #   factory?\n        # - This looks really janky!\n        #\n        # Well, apart from the fact that the last one there isn't a question,\n        # those are good questions. The reason for doing this is that we need\n        # to be able to generate links to annotations in situations where we\n        # don't necessarily have a request object around, such as in the\n        # WebSocket server, or in a CLI command.\n        #\n        # In these situations, it should suffice to have an application\n        # registry (for the routing table) and a base URL. The reason we\n        # generate a request object is that this is the simplest and least\n        # error-prone way to get access to the route_url function, which can\n        # be used by link generators.\n        self._request = Request.blank('/', base_url=base_url)\n        self._request.registry = registry\n\n    def get(self, annotation, name):\n        \"\"\"Get the link named `name` for the passed `annotation`.\"\"\"\n        g, _ = self.registry[LINK_GENERATORS_KEY][name]\n        return g(self._request, annotation)\n\n    def get_all(self, annotation):\n        \"\"\"Get all (non-hidden) links for the passed `annotation`.\"\"\"\n        links = {}\n        for name, (g, hidden) in self.registry[LINK_GENERATORS_KEY].items():\n            if hidden:\n                continue\n            l = g(self._request, annotation)\n            if l is not None:\n                links[name] = l\n        return links\n\n\ndef links_factory(context, request):\n    \"\"\"Return a LinksService instance for the passed context and request.\"\"\"\n    base_url = request.registry.settings.get('h.app_url',\n                                             'http://localhost:5000')\n    return LinksService(base_url=base_url,\n                        registry=request.registry)\n\n\ndef add_annotation_link_generator(registry, name, generator, hidden=False):\n    \"\"\"\n    Registers a function which generates a named link for an annotation.\n\n    Annotation hypermedia links are added to the rendered annotations in a\n    `links` property or similar. `name` is the unique identifier for the link\n    type, and `generator` is a callable which accepts two arguments -- the\n    current request, and the annotation for which to generate a link -- and\n    returns a string.\n\n    If `hidden` is True, then the link generator will not be included in the\n    default links output when rendering annotations.\n    \"\"\"\n    if LINK_GENERATORS_KEY not in registry:\n        registry[LINK_GENERATORS_KEY] = {}\n    registry[LINK_GENERATORS_KEY][name] = (generator, hidden)\n\n\ndef _add_annotation_link_generator(config, name, generator, hidden=False):\n    add_annotation_link_generator(config.registry,\n                                  name,\n                                  generator,\n                                  hidden=hidden)\n\n\ndef includeme(config):  # pragma: no cover\n    config.register_service_factory(links_factory, name='links')\n\n    config.add_directive('add_annotation_link_generator',\n                         _add_annotation_link_generator)\n"},{"size":791,"relativepath":"src/memex/events.py","filename":"events.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\nclass AnnotationEvent(object):\n    \"\"\"An event representing an action on an annotation.\"\"\"\n\n    def __init__(self, request, annotation_id, action, annotation_dict=None):\n        self.request = request\n        self.annotation_id = annotation_id\n        self.action = action\n        self.annotation_dict = annotation_dict\n\n\nclass AnnotationTransformEvent(object):\n\n    \"\"\"\n    An event fired before an annotation is indexed or otherwise needs to be\n    transformed by third-party code.\n\n    This event can be used by subscribers who wish to modify the content of an\n    annotation just before it is indexed or in other use-cases.\n    \"\"\"\n\n    def __init__(self, request, annotation_dict):\n        self.request = request\n        self.annotation_dict = annotation_dict\n"},{"size":9072,"relativepath":"src/memex/views.py","filename":"views.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"\nHTTP/REST API for storage and retrieval of annotation data.\n\nThis module contains the views which implement our REST API, mounted by default\nat ``/api``. Currently, the endpoints are limited to:\n\n- basic CRUD (create, read, update, delete) operations on annotations\n- annotation search\n- a handful of authentication related endpoints\n\nIt is worth noting up front that in general, authorization for requests made to\neach endpoint is handled outside of the body of the view functions. In\nparticular, requests to the CRUD API endpoints are protected by the Pyramid\nauthorization system. You can find the mapping between annotation \"permissions\"\nobjects and Pyramid ACLs in :mod:`memex.resources`.\n\"\"\"\nfrom pyramid import i18n\nfrom pyramid import security\nfrom pyramid.view import view_config\nfrom sqlalchemy.orm import subqueryload\n\nfrom memex import cors\nfrom memex import models\nfrom memex.events import AnnotationEvent\nfrom memex.presenters import AnnotationJSONPresenter\nfrom memex.presenters import AnnotationJSONLDPresenter\nfrom memex import search as search_lib\nfrom memex import schemas\nfrom memex import storage\n\n_ = i18n.TranslationStringFactory(__package__)\n\ncors_policy = cors.policy(\n    allow_headers=(\n        'Authorization',\n        'Content-Type',\n        'X-Annotator-Auth-Token',\n        'X-Client-Id',\n    ),\n    allow_methods=('HEAD', 'GET', 'POST', 'PUT', 'DELETE'))\n\n\nclass APIError(Exception):\n\n    \"\"\"Base exception for problems handling API requests.\"\"\"\n\n    def __init__(self, message, status_code=500):\n        self.status_code = status_code\n        super(APIError, self).__init__(message)\n\n\nclass PayloadError(APIError):\n\n    \"\"\"Exception raised for API requests made with missing/invalid payloads.\"\"\"\n\n    def __init__(self):\n        super(PayloadError, self).__init__(\n            _('Expected a valid JSON payload, but none was found!'),\n            status_code=400\n        )\n\n\ndef api_config(**settings):\n    \"\"\"\n    A view configuration decorator with defaults.\n\n    JSON in and out. CORS with tokens and client id but no cookie.\n    \"\"\"\n    settings.setdefault('accept', 'application/json')\n    settings.setdefault('renderer', 'json')\n    settings.setdefault('decorator', cors_policy)\n    return view_config(**settings)\n\n\n@api_config(context=APIError)\ndef error_api(context, request):\n    request.response.status_code = context.status_code\n    return {'status': 'failure', 'reason': context.message}\n\n\n@api_config(context=schemas.ValidationError)\ndef error_validation(context, request):\n    request.response.status_code = 400\n    return {'status': 'failure', 'reason': context.message}\n\n\n@api_config(route_name='api.index')\ndef index(context, request):\n    \"\"\"Return the API descriptor document.\n\n    Clients may use this to discover endpoints for the API.\n    \"\"\"\n    # Because request.route_url urlencodes parameters, we can't just pass in\n    # \":id\" as the id here.\n    annotation_url = request.route_url('api.annotation', id='123')\\\n                            .replace('123', ':id')\n    return {\n        'message': \"Annotator Store API\",\n        'links': {\n            'annotation': {\n                'create': {\n                    'method': 'POST',\n                    'url': request.route_url('api.annotations'),\n                    'desc': \"Create a new annotation\"\n                },\n                'read': {\n                    'method': 'GET',\n                    'url': annotation_url,\n                    'desc': \"Get an existing annotation\"\n                },\n                'update': {\n                    'method': 'PUT',\n                    'url': annotation_url,\n                    'desc': \"Update an existing annotation\"\n                },\n                'delete': {\n                    'method': 'DELETE',\n                    'url': annotation_url,\n                    'desc': \"Delete an annotation\"\n                }\n            },\n            'search': {\n                'method': 'GET',\n                'url': request.route_url('api.search'),\n                'desc': 'Basic search API'\n            },\n        }\n    }\n\n\n@api_config(route_name='api.search')\ndef search(request):\n    \"\"\"Search the database for annotations matching with the given query.\"\"\"\n    params = request.params.copy()\n\n    separate_replies = params.pop('_separate_replies', False)\n    result = search_lib.Search(request, separate_replies=separate_replies) \\\n        .run(params)\n\n    out = {\n        'total': result.total,\n        'rows': _present_annotations(request, result.annotation_ids)\n    }\n\n    if separate_replies:\n        out['replies'] = _present_annotations(request, result.reply_ids)\n\n    return out\n\n\n@api_config(route_name='api.annotations',\n            request_method='POST',\n            effective_principals=security.Authenticated)\ndef create(request):\n    \"\"\"Create an annotation from the POST payload.\"\"\"\n    schema = schemas.CreateAnnotationSchema(request)\n    appstruct = schema.validate(_json_payload(request))\n    annotation = storage.create_annotation(request, appstruct)\n\n    _publish_annotation_event(request, annotation, 'create')\n\n    links_service = request.find_service(name='links')\n    presenter = AnnotationJSONPresenter(annotation, links_service)\n    return presenter.asdict()\n\n\n@api_config(route_name='api.annotation',\n            request_method='GET',\n            permission='read')\ndef read(annotation, request):\n    \"\"\"Return the annotation (simply how it was stored in the database).\"\"\"\n    links_service = request.find_service(name='links')\n    presenter = AnnotationJSONPresenter(annotation, links_service)\n    return presenter.asdict()\n\n\n@api_config(route_name='api.annotation.jsonld',\n            request_method='GET',\n            permission='read')\ndef read_jsonld(annotation, request):\n    request.response.content_type = 'application/ld+json'\n    request.response.content_type_params = {\n        'profile': AnnotationJSONLDPresenter.CONTEXT_URL}\n    links_service = request.find_service(name='links')\n    presenter = AnnotationJSONLDPresenter(annotation, links_service)\n    return presenter.asdict()\n\n\n@api_config(route_name='api.annotation',\n            request_method='PUT',\n            permission='update')\ndef update(annotation, request):\n    \"\"\"Update the specified annotation with data from the PUT payload.\"\"\"\n    schema = schemas.UpdateAnnotationSchema(request,\n                                            annotation.target_uri,\n                                            annotation.groupid)\n    appstruct = schema.validate(_json_payload(request))\n\n    annotation = storage.update_annotation(request.db,\n                                           annotation.id,\n                                           appstruct)\n\n    _publish_annotation_event(request, annotation, 'update')\n\n    links_service = request.find_service(name='links')\n    presenter = AnnotationJSONPresenter(annotation, links_service)\n    return presenter.asdict()\n\n\n@api_config(route_name='api.annotation',\n            request_method='DELETE',\n            permission='delete')\ndef delete(annotation, request):\n    \"\"\"Delete the specified annotation.\"\"\"\n    storage.delete_annotation(request.db, annotation.id)\n\n    # N.B. We publish the original model (including all the original annotation\n    # fields) so that queue subscribers have context needed to decide how to\n    # process the delete event. For example, the streamer needs to know the\n    # target URLs of the deleted annotation in order to know which clients to\n    # forward the delete event to.\n    _publish_annotation_event(\n        request,\n        annotation,\n        'delete')\n\n    return {'id': annotation.id, 'deleted': True}\n\n\ndef _json_payload(request):\n    \"\"\"\n    Return a parsed JSON payload for the request.\n\n    :raises PayloadError: if the body has no valid JSON body\n    \"\"\"\n    try:\n        return request.json_body\n    except ValueError:\n        raise PayloadError()\n\n\ndef _present_annotations(request, ids):\n    \"\"\"Load annotations by id from the database and present them.\"\"\"\n    def eager_load_documents(query):\n        return query.options(\n            subqueryload(models.Annotation.document))\n\n    annotations = storage.fetch_ordered_annotations(request.db, ids,\n                                                    query_processor=eager_load_documents)\n    links_service = request.find_service(name='links')\n    return [AnnotationJSONPresenter(ann, links_service).asdict()\n            for ann in annotations]\n\n\ndef _publish_annotation_event(request,\n                              annotation,\n                              action):\n    \"\"\"Publish an event to the annotations queue for this annotation action.\"\"\"\n    links_service = request.find_service(name='links')\n    annotation_dict = None\n    if action == 'delete':\n        presenter = AnnotationJSONPresenter(annotation, links_service)\n        annotation_dict = presenter.asdict()\n\n    event = AnnotationEvent(request, annotation.id, action, annotation_dict)\n    request.notify_after_commit(event)\n\n\ndef includeme(config):\n    config.scan(__name__)\n"},{"size":686,"relativepath":"src/memex/_compat.py","filename":"_compat.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"Helpers for the Python 2 to Python 3 transition.\"\"\"\n\nimport sys\n\nPY2 = sys.version_info[0] == 2\n\nif not PY2:\n    text_type = str\n    string_types = (str,)\n    xrange = xrange\nelse:\n    text_type = unicode\n    string_types = (str, unicode)\n    xrange = range\n\ntry:\n    from urllib import parse as urlparse\n    url_quote = urlparse.quote\n    url_quote_plus = urlparse.quote_plus\n    url_unquote = urlparse.unquote\n    url_unquote_plus = urlparse.unquote_plus\nexcept ImportError:\n    import urllib\n    import urlparse\n    url_quote = urllib.quote\n    url_quote_plus = urllib.quote_plus\n    url_unquote = urllib.unquote\n    url_unquote_plus = urllib.unquote_plus\n"},{"size":8063,"relativepath":"src/memex/db/types.py","filename":"types.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"Custom SQLAlchemy types for use with the Annotations API database.\"\"\"\n\nimport binascii\nimport base64\nimport uuid\n\nfrom sqlalchemy import types\nfrom sqlalchemy.dialects import postgresql\nfrom sqlalchemy.exc import DontWrapMixin\nfrom sqlalchemy.ext.mutable import Mutable\n\n\n# A magic byte (expressed as two hexadecimal nibbles) which we use to expand a\n# 15-byte ElasticSearch flake ID into a 16-byte UUID.\n#\n# The UUID specification defines UUIDs as taking the form\n#\n#     xxxxxxxx-xxxx-Mxxx-Nxxx-xxxxxxxxxxxx\n#\n# in the canonical hexadecimal representation. M and N represent the UUID\n# version and variant fields respectively. The four bits M can take values {1,\n# 2, 3, 4, 5} in specified UUID types, and the first three bits of N can take\n# the values {8, 9, 0xa, 0xb} in specified UUID types.\n#\n# In order to expand a 15-byte ElasticSearch flake ID into a value that can be\n# stored in the UUID field, we insert the magic nibbles 0xe, 0x5 into the\n# version and variant fields respectively. These values are disjoint with any\n# specified UUID so the resulting UUID can be distinguished from those\n# generated by, for example, PostgreSQL's uuid_generate_v1mc(), and mapped back\n# to a 20-char ElasticSearch flake ID.\nES_FLAKE_MAGIC_BYTE = ['e', '5']\n\n\nclass InvalidUUID(Exception, DontWrapMixin):\n    pass\n\n\nclass URLSafeUUID(types.TypeDecorator):\n\n    \"\"\"\n    Expose UUIDs as URL-safe base64-encoded strings.\n\n    Fields decorated with this type decorator use PostgreSQL UUID fields for\n    storage, but expose URL-safe strings in the application.\n\n    This type decorator will handle the transformation between any UUID and a\n    URL-safe, base64-encoded string version of that UUID (which will be 22\n    characters long). In addition, it will transparently map post-v1.4\n    ElasticSearch flake IDs (which are 20 characters long and map to 15 bytes\n    of data).\n    \"\"\"\n\n    impl = postgresql.UUID\n\n    def process_bind_param(self, value, dialect):\n        if value is None:\n            return None\n        return _get_hex_from_urlsafe(value)\n\n    def process_result_value(self, value, dialect):\n        if value is None:\n            return None\n        hexstring = uuid.UUID(value).hex\n        return _get_urlsafe_from_hex(hexstring)\n\n\n# This class can be deleted when we upgrade to SQLAlchemy 1.1 which adds\n# sqlalchemy.ext.mutable.MutableList.\nclass MutableList(Mutable, list):\n\n    \"\"\"\n    A list subclass that persists in-place changes.\n\n    If you use a normal list as an attribute of an ORM class then in-place\n    changes to the list won't be persisted to the session, so use this class\n    instead.\n\n    To use this class wrap another list-like type in this class's as_mutable()\n    class method when declaring a column:\n\n        my_array_column = sa.Column(\n            MutableList.as_mutable(pg.Array(sa.UnicodeText)))\n\n    See: http://docs.sqlalchemy.org/en/rel_1_0/orm/extensions/mutable.html\n    \"\"\"\n\n    @classmethod\n    def coerce(cls, key, value):\n        if not isinstance(value, MutableList):\n            if isinstance(value, list):\n                return MutableList(value)\n            return Mutable.coerce(key, value)\n        else:\n            return value\n\n    def __setitem__(self, idx, value):\n        list.__setitem__(self, idx, value)\n        self.changed()\n\n    def __setslice__(self, start, stop, values):\n        list.__setslice__(self, start, stop, values)\n        self.changed()\n\n    def __delitem__(self, idx):\n        list.__delitem__(self, idx)\n        self.changed()\n\n    def __delslice__(self, start, stop):\n        list.__delslice__(self, start, stop)\n        self.changed()\n\n    def append(self, value):\n        list.append(self, value)\n        self.changed()\n\n    def insert(self, idx, value):\n        list.insert(self, idx, value)\n        self.changed()\n\n    def extend(self, values):\n        list.extend(self, values)\n        self.changed()\n\n    def pop(self, *args, **kw):\n        value = list.pop(self, *args, **kw)\n        self.changed()\n        return value\n\n    def remove(self, value):\n        list.remove(self, value)\n        self.changed()\n\n    def sort(self, *args, **kwargs):\n        list.sort(self, *args, **kwargs)\n        self.changed()\n\n    def reverse(self):\n        list.reverse(self)\n        self.changed()\n\n\nclass AnnotationSelectorJSONB(types.TypeDecorator):\n\n    \"\"\"\n    Special type for the Annotation selector column.\n\n    It transparently escapes NULL (\\u0000) bytes to \\\\u0000 when writing to the\n    database, and the other way around when reading from the database, but\n    only on the prefix/exact/suffix fields in a TextQuoteSelector.\n    \"\"\"\n\n    impl = postgresql.JSONB\n\n    def process_bind_param(self, value, dialect):\n        return _transform_quote_selector(value, _escape_null_byte)\n\n    def process_result_value(self, value, dialect):\n        return _transform_quote_selector(value, _unescape_null_byte)\n\n\ndef _get_hex_from_urlsafe(value):\n    bytestr = bytes(value)\n\n    def _fail():\n        raise InvalidUUID('{0!r} is not a valid encoded UUID'.format(value))\n\n    if len(bytestr) == 22:\n        # 22-char inputs represent 16 bytes of data, which when normally\n        # base64-encoded would have two bytes of padding on the end, so we add\n        # that back before decoding.\n        try:\n            data = _must_b64_decode(bytestr + b'==', expected_size=16)\n        except TypeError:\n            _fail()\n        return binascii.hexlify(data)\n\n    if len(bytestr) == 20:\n        # 20-char inputs represent 15 bytes of data, which requires no padding\n        # corrections.\n        try:\n            data = _must_b64_decode(bytestr, expected_size=15)\n        except TypeError:\n            _fail()\n        hexstring = binascii.hexlify(data)\n        # These are ElasticSearch flake IDs, so to convert them into UUIDs we\n        # insert the magic nibbles at the appropriate points. See the comments\n        # on ES_FLAKE_MAGIC_BYTE for details.\n        return (hexstring[0:12] +\n                ES_FLAKE_MAGIC_BYTE[0] +\n                hexstring[12:15] +\n                ES_FLAKE_MAGIC_BYTE[1] +\n                hexstring[15:30])\n\n    # Fallthrough: we must have a received a string of invalid length\n    _fail()\n\n\ndef _get_urlsafe_from_hex(value):\n    # Validate and normalise hex string\n    hexstring = uuid.UUID(hex=value).hex\n\n    is_flake_id = (hexstring[12] == ES_FLAKE_MAGIC_BYTE[0] and\n                   hexstring[16] == ES_FLAKE_MAGIC_BYTE[1])\n\n    if is_flake_id:\n        # The hex representation of the flake ID is simply the UUID without the\n        # two magic nibbles.\n        data = binascii.unhexlify(hexstring[0:12] +\n                                  hexstring[13:16] +\n                                  hexstring[17:32])\n        return base64.urlsafe_b64encode(data)\n\n    # Encode UUID bytes and strip two bytes of padding\n    data = binascii.unhexlify(hexstring)\n    return base64.urlsafe_b64encode(data)[:-2]\n\n\ndef _must_b64_decode(data, expected_size=None):\n    result = base64.urlsafe_b64decode(data)\n    if expected_size is not None and len(result) != expected_size:\n        raise TypeError('incorrect data size')\n    return result\n\n\ndef _transform_quote_selector(selectors, transform_func):\n    if selectors is None:\n        return None\n\n    if not isinstance(selectors, list):\n        return selectors\n\n    for selector in selectors:\n        if not isinstance(selector, dict):\n            continue\n\n        if not selector.get('type') == 'TextQuoteSelector':\n            continue\n\n        if 'prefix' in selector:\n            selector['prefix'] = transform_func(selector['prefix'])\n        if 'exact' in selector:\n            selector['exact'] = transform_func(selector['exact'])\n        if 'suffix' in selector:\n            selector['suffix'] = transform_func(selector['suffix'])\n\n    return selectors\n\n\ndef _escape_null_byte(s):\n    if s is None:\n        return s\n\n    return s.replace(u\"\\u0000\", u\"\\\\u0000\")\n\n\ndef _unescape_null_byte(s):\n    if s is None:\n        return s\n\n    return s.replace(u\"\\\\u0000\", u\"\\u0000\")\n"},{"size":1582,"relativepath":"src/memex/db/__init__.py","filename":"__init__.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom sqlalchemy import MetaData\nfrom sqlalchemy.ext import declarative\n\n\n# Create a default metadata object with naming conventions for indexes and\n# constraints. This makes changing such constraints and indexes with alembic\n# after creation much easier. See:\n#\n#   http://docs.sqlalchemy.org/en/latest/core/constraints.html#configuring-constraint-naming-conventions\n#\n# The migrations we run with alembic use the naming convention from\n# :py:mod:`h.db`. In order that auto-created tables (i.e. those created by\n# `Base.metadata.create_all()`) are compatible with these naming conventions,\n# we need to specify them here, too, as `memex` has its own global metadata\n# object.\n#\n# N.B. This must be kept in sync with the naming conventions in :py:mod:`h.db`.\n#\nmetadata = MetaData(naming_convention={\n    \"ix\": \"ix__%(column_0_label)s\",\n    \"uq\": \"uq__%(table_name)s__%(column_0_name)s\",\n    \"ck\": \"ck__%(table_name)s__%(constraint_name)s\",\n    \"fk\": \"fk__%(table_name)s__%(column_0_name)s__%(referred_table_name)s\",\n    \"pk\": \"pk__%(table_name)s\"\n})\n\nBase = declarative.declarative_base(metadata=metadata)  # pylint: disable=invalid-name\n\n\ndef init(engine, base=Base, should_create=False, should_drop=False):\n    \"\"\"Initialise the database tables managed by `memex.db`.\"\"\"\n    if should_drop:\n        base.metadata.drop_all(engine)\n    if should_create:\n        # In order to be able to generate UUIDs, we load the uuid-ossp\n        # extension.\n        engine.execute('CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";')\n        base.metadata.create_all(engine)\n"},{"size":630,"relativepath":"src/memex/db/mixins.py","filename":"mixins.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"Reusable mixins for SQLAlchemy declarative models.\"\"\"\n\nfrom __future__ import unicode_literals\n\nimport datetime\n\nimport sqlalchemy as sa\n\n\nclass Timestamps(object):\n    created = sa.Column(sa.DateTime,\n                        default=datetime.datetime.utcnow,\n                        server_default=sa.func.now(),\n                        nullable=False)\n    updated = sa.Column(sa.DateTime,\n                        server_default=sa.func.now(),\n                        default=datetime.datetime.utcnow,\n                        onupdate=datetime.datetime.utcnow,\n                        nullable=False)\n"},{"size":1263,"relativepath":"src/memex/eventqueue.py","filename":"eventqueue.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nimport collections\nimport logging\n\n\nlog = logging.getLogger(__name__)\n\n\nclass EventQueue(object):\n    def __init__(self, request):\n        self.request = request\n        self.queue = collections.deque()\n\n        request.add_response_callback(self.response_callback)\n\n    def __call__(self, event):\n        self.queue.append(event)\n\n    def publish_all(self):\n        while True:\n            try:\n                event = self.queue.popleft()\n            except IndexError:\n                break\n\n            try:\n                self.request.registry.notify(event)\n            except Exception:\n                sentry = getattr(event.request, 'sentry', None)\n                if sentry is not None:\n                    sentry.captureException()\n                else:\n                    log.exception('Queued event subscriber failed')\n\n                if event.request.debug:\n                    raise\n\n    def response_callback(self, request, response):\n        if request.exception is not None:\n            return\n\n        with request.tm:\n            self.publish_all()\n\n\ndef includeme(config):\n    config.add_request_method(EventQueue,\n                              name='notify_after_commit',\n                              reify=True)\n"},{"size":7135,"relativepath":"src/memex/presenters.py","filename":"presenters.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"\nPresenters for API data.\n\"\"\"\n\nimport collections\nimport copy\n\n\nclass AnnotationBasePresenter(object):\n    def __init__(self, annotation, links_service):\n        self.annotation = annotation\n\n        self._links_service = links_service\n\n    @property\n    def created(self):\n        if self.annotation.created:\n            return utc_iso8601(self.annotation.created)\n\n    @property\n    def updated(self):\n        if self.annotation.updated:\n            return utc_iso8601(self.annotation.updated)\n\n    @property\n    def links(self):\n        \"\"\"A dictionary of named hypermedia links for this annotation.\"\"\"\n        return self._links_service.get_all(self.annotation)\n\n    @property\n    def text(self):\n        if self.annotation.text:\n            return self.annotation.text\n        else:\n            return ''\n\n    @property\n    def tags(self):\n        if self.annotation.tags:\n            return self.annotation.tags\n        else:\n            return []\n\n    @property\n    def target(self):\n        target = {'source': self.annotation.target_uri}\n        if self.annotation.target_selectors:\n            target['selector'] = self.annotation.target_selectors\n\n        return [target]\n\n\nclass AnnotationJSONPresenter(AnnotationBasePresenter):\n\n    \"\"\"Present an annotation in the JSON format returned by API requests.\"\"\"\n\n    def asdict(self):\n        docpresenter = DocumentJSONPresenter(self.annotation.document)\n\n        base = {\n            'id': self.annotation.id,\n            'created': self.created,\n            'updated': self.updated,\n            'user': self.annotation.userid,\n            'uri': self.annotation.target_uri,\n            'text': self.text,\n            'tags': self.tags,\n            'group': self.annotation.groupid,\n            'permissions': self.permissions,\n            'target': self.target,\n            'document': docpresenter.asdict(),\n            'links': self.links,\n        }\n\n        if self.annotation.references:\n            base['references'] = self.annotation.references\n\n        annotation = copy.copy(self.annotation.extra) or {}\n        annotation.update(base)\n\n        return annotation\n\n    @property\n    def permissions(self):\n        return _permissions(self.annotation)\n\n\nclass AnnotationSearchIndexPresenter(AnnotationBasePresenter):\n\n    \"\"\"Present an annotation in the JSON format used in the search index.\"\"\"\n    def __init__(self, annotation):\n        self.annotation = annotation\n\n    def asdict(self):\n        docpresenter = DocumentSearchIndexPresenter(self.annotation.document)\n\n        base = {\n            'id': self.annotation.id,\n            'created': self.created,\n            'updated': self.updated,\n            'user': self.annotation.userid,\n            'user_raw': self.annotation.userid,\n            'uri': self.annotation.target_uri,\n            'text': self.text,\n            'tags': self.tags,\n            'group': self.annotation.groupid,\n            'permissions': self.permissions,\n            'target': self.target,\n            'document': docpresenter.asdict(),\n        }\n\n        base['target'][0]['scope'] = [self.annotation.target_uri_normalized]\n\n        if self.annotation.references:\n            base['references'] = self.annotation.references\n\n        annotation = copy.copy(self.annotation.extra) or {}\n        annotation.update(base)\n\n        return annotation\n\n    @property\n    def links(self):\n        # The search index presenter has no need to generate links, and so the\n        # `links_service` parameter has been removed from the constructor.\n        raise NotImplementedError(\"search index presenter doesn't have links\")\n\n    @property\n    def permissions(self):\n        return _permissions(self.annotation)\n\n\nclass AnnotationJSONLDPresenter(AnnotationBasePresenter):\n\n    \"\"\"\n    Presenter for annotations that renders a JSON-LD format compatible with the\n    draft Web Annotation Data Model, as defined at:\n\n      https://www.w3.org/TR/annotation-model/\n    \"\"\"\n\n    CONTEXT_URL = 'http://www.w3.org/ns/anno.jsonld'\n\n    def asdict(self):\n        return {\n            '@context': self.CONTEXT_URL,\n            'type': 'Annotation',\n            'id': self.id,\n            'created': self.created,\n            'modified': self.updated,\n            'creator': self.annotation.userid,\n            'body': self.bodies,\n            'target': self.target,\n        }\n\n    @property\n    def id(self):\n        return self._links_service.get(self.annotation, 'jsonld_id')\n\n    @property\n    def bodies(self):\n        bodies = [{\n            'type': 'TextualBody',\n            'text': self.text,\n            'format': 'text/markdown',\n        }]\n        for t in self.tags:\n            bodies.append({\n                'type': 'TextualBody',\n                'text': t,\n                'purpose': 'tagging',\n            })\n        return bodies\n\n\nclass DocumentJSONPresenter(object):\n    def __init__(self, document):\n        self.document = document\n\n    def asdict(self):\n        if not self.document:\n            return {}\n\n        d = {}\n        title = self.document.title\n        if title:\n            d['title'] = [title]\n\n        return d\n\n\nclass DocumentSearchIndexPresenter(object):\n    def __init__(self, document):\n        self.document = document\n\n    def asdict(self):\n        if not self.document:\n            return {}\n\n        d = {}\n        if self.document.title:\n            d['title'] = [self.document.title]\n\n        if self.document.web_uri:\n            d['web_uri'] = self.document.web_uri\n\n        return d\n\n\ndef utc_iso8601(datetime):\n    return datetime.strftime('%Y-%m-%dT%H:%M:%S.%f+00:00')\n\n\ndef deep_merge_dict(a, b):\n    \"\"\"Recursively merges dict `b` into dict `a`.\"\"\"\n\n    for k, v in b.items():\n        if isinstance(v, collections.Mapping):\n            if k not in a or not isinstance(a[k], dict):\n                a[k] = dict()\n            deep_merge_dict(a[k], v)\n        else:\n            a[k] = v\n\n\ndef _json_link(request, annotation):\n    return request.route_url('api.annotation', id=annotation.id)\n\n\ndef _jsonld_id_link(request, annotation):\n    return request.route_url('annotation', id=annotation.id)\n\n\ndef _permissions(annotation):\n    \"\"\"\n    Return a permissions dict for the given annotation.\n\n    Converts our simple internal annotation storage format into the legacy\n    complex permissions dict format that is still used in some places.\n\n    \"\"\"\n    read = annotation.userid\n    if annotation.shared:\n        read = 'group:{}'.format(annotation.groupid)\n\n    return {'read': [read],\n            'admin': [annotation.userid],\n            'update': [annotation.userid],\n            'delete': [annotation.userid]}\n\n\ndef includeme(config):\n    # Add a default 'json' link type\n    config.add_annotation_link_generator('json', _json_link)\n\n    # Add a 'jsonld_id' link type for generating the \"id\" field for JSON-LD\n    # annotations. This is hidden, and so not rendered in the annotation's\n    # \"links\" field.\n    config.add_annotation_link_generator('jsonld_id',\n                                         _jsonld_id_link,\n                                         hidden=True)\n"},{"size":8661,"relativepath":"src/memex/uri.py","filename":"uri.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\n\"\"\"\nTools for dealing with URIs within the Hypothesis API.\n\nThere are two main ways of considering the relationship between annotations and\nannotated objects:\n\n1. Annotations are, practically speaking, made on web pages, and thus they have\n   a URL associated with them.\n\n2. Annotations are made on documents, and the particular HTML or PDF page being\n   annotated is merely a specific manifestation of the abstract document that\n   is being annotated. In this scenario, a document may be identified by one or\n   more URIs.\n\nThe second model is more complex from both a conceptual point of view and in\nterms of implementation, but it offers substantial benefits. If we talk of\nannotations attached to documents, without regard to presentation format or\nlocation, we are able to do many interesting things:\n\n- Alice makes an annotation on a PDF; Bob visits an HTML version of the same\n  document, and sees Alice's annotation.\n- Alice makes an annotation on an Instapaper-hosted version of a web page which\n  contains a <link rel=canonical> tag. Bob visits the original article and sees\n  Alice's annotation.\n- Bob makes an annotation on a PDF which is on his local machine. Alice opens\n  the same PDF on her machine, and see's Bob's annotations even if the PDF has\n  never been uploaded to a webserver. (We can do this because of the\n  immutability of PDF documents -- we can uniquely fingerprint each one and\n  form a \"URN\" of the form \"urn:x-pdf:<fingerprint>\".)\n\nThe challenge, then, is to enable these features without making the public API\nfor creating and updating annotations overly complex. It turns out this is\npossible if we can answer two questions:\n\n1. Given two URI strings, do they both refer to the same URI, practically\n   speaking? (AKA \"normalization\".)\n\n   e.g. on the web, the following URLs will *usually* refer to the same web\n   page::\n\n       http://example.com/foo?a=hello&b=world\n       http://exAMPle.com/foo?a=hello&b=world\n       http://example.com/foo/?a=hello&b=world\n       http://example.com/foo?b=world&a=hello\n       http://example.com/foo?a=hello&b=world#somefragment\n\n2. Given a URI, what are all the known URIs of the underlying *document* (in\n   the sense given above). (AKA \"expansion\".)\n\n   e.g. we may know (from page metadata or otherwise) that all the following\n   URIs refer to the same content, even if in differing formats::\n\n       http://example.com/research/papers/2015-discoveries.html\n       http://example.com/research/papers/2015-discoveries.pdf\n       http://example.org/reprints/example-com-2015-discoveries.pdf\n       urn:x-pdf:c83fa94bd1d522276a32f81682a43d29\n       urn:doi:10.1000/12345\n\nThis package is responsible for defining URI normalization routines for use\nelsewhere in the Hypothesis application. URI expansion is handled by\n:py:function:`memex.storage.expand_uri`.\n\"\"\"\nimport re\n\nfrom memex._compat import text_type\nfrom memex._compat import urlparse\nfrom memex._compat import url_quote, url_quote_plus\nfrom memex._compat import url_unquote, url_unquote_plus\n\n\nURL_SCHEMES = set(['http', 'https'])\n\n# List of regular expressions matching the names of query parameters that we\n# strip from URLs as part of normalization.\nBLACKLISTED_QUERY_PARAMS = [re.compile(regex) for regex in set([\n    # Google AdWords tracking identifier. Reference:\n    #\n    #    https://support.google.com/analytics/answer/2938246?hl=en\n    #\n    r'^gclid$',\n    # Google Analytics campaigns. Reference:\n    #\n    #     https://support.google.com/analytics/answer/1033867?hl=en\n    #\n    r'^utm_(campaign|content|medium|source|term)$',\n    # WebTrends Analytics query params. Reference:\n    #\n    #     http://help.webtrends.com/en/analytics10/#qpr_about.html\n    #\n    r'^WT\\..+$',\n])]\n\n# From RFC3986. The ABNF for path segments is\n#\n#   path-abempty  = *( \"/\" segment )\n#   ...\n#   segment       = *pchar\n#   ...\n#   pchar         = unreserved / pct-encoded / sub-delims / \":\" / \"@\"\n#   ...\n#   unreserved    = ALPHA / DIGIT / \"-\" / \".\" / \"_\" / \"~\"\n#   sub-delims    = \"!\" / \"$\" / \"&\" / \"'\" / \"(\" / \")\"\n#                    / \"*\" / \"+\" / \",\" / \";\" / \"=\"\n#\n# Taken together, this implies the following set of \"unreserved\" characters for\n# path segments (excluding ALPHA and DIGIT which are handled already).\nUNRESERVED_PATHSEGMENT = \"-._~:@!$&'()*+,;=\"\n\n# From RFC3986. The ABNF for query strings is\n#\n#   query         = *( pchar / \"/\" / \"?\" )\n#\n# Where the definition of pchar is as given above.\n#\n# We exclude \"&\" and \";\" from both names and values, and \"=\" from names, as\n# they are used as delimiters in HTTP URL query strings. In addition, \"+\" is\n# used to denote the space character, so for legacy reasons this is also\n# excluded.\nUNRESERVED_QUERY_NAME = \"-._~:@!$'()*,\"\nUNRESERVED_QUERY_VALUE = \"-._~:@!$'()*,=\"\n\n# The string that gets prefixed onto a URI if you paste the URI into our Via\n# form. For example pasting https://example.com would\n# redirect your browser to https://via.hypothes.is/https://example.com.\nVIA_PREFIX = \"https://via.hypothes.is/\"\n\n\ndef normalize(uristr):\n    \"\"\"Translate the given URI into a normalized form.\"\"\"\n    uristr = uristr.encode('utf-8')\n\n    # Strip proxy prefix for proxied URLs\n    for scheme in URL_SCHEMES:\n        if uristr.startswith(VIA_PREFIX + scheme + ':'):\n            uristr = uristr[len(VIA_PREFIX):]\n            break\n\n    # Try to extract the scheme\n    uri = urlparse.urlsplit(uristr)\n\n    # If this isn't a URL, we don't perform any normalization\n    if uri.scheme.lower() not in URL_SCHEMES:\n        return text_type(uristr, 'utf-8')\n\n    # Don't perform normalization on URLs with no hostname.\n    if uri.hostname is None:\n        return text_type(uristr, 'utf-8')\n\n    scheme = _normalize_scheme(uri)\n    netloc = _normalize_netloc(uri)\n    path = _normalize_path(uri)\n    query = _normalize_query(uri)\n    fragment = None\n\n    uri = urlparse.SplitResult(scheme, netloc, path, query, fragment)\n\n    return text_type(uri.geturl(), 'utf-8')\n\n\ndef _normalize_scheme(uri):\n    scheme = uri.scheme\n\n    if scheme in URL_SCHEMES:\n        scheme = 'httpx'\n\n    return scheme\n\n\ndef _normalize_netloc(uri):\n    netloc = uri.netloc\n    ipv6_hostname = '[' in netloc and ']' in netloc\n\n    username = uri.username\n    password = uri.password\n    hostname = uri.hostname\n    port = uri.port\n\n    # Normalise hostname to lower case\n    hostname = hostname.lower()\n\n    # Remove port if default for the scheme\n    if uri.scheme == 'http' and port == 80:\n        port = None\n    elif uri.scheme == 'https' and port == 443:\n        port = None\n\n    # Put it all back together again...\n    userinfo = None\n    if username is not None:\n        userinfo = username\n    if password is not None:\n        userinfo += ':' + password\n\n    if ipv6_hostname:\n        hostname = '[' + hostname + ']'\n\n    hostinfo = hostname\n    if port is not None:\n        hostinfo += ':' + str(port)\n\n    if userinfo is not None:\n        netloc = '@'.join([userinfo, hostinfo])\n    else:\n        netloc = hostinfo\n\n    return netloc\n\n\ndef _normalize_path(uri):\n    path = uri.path\n\n    while path.endswith('/'):\n        path = path[:-1]\n\n    segments = path.split('/')\n    segments = [_normalize_pathsegment(s) for s in segments]\n    path = '/'.join(segments)\n\n    return path\n\n\ndef _normalize_pathsegment(segment):\n    return url_quote(url_unquote(segment), safe=UNRESERVED_PATHSEGMENT)\n\n\ndef _normalize_query(uri):\n    query = uri.query\n\n    try:\n        items = urlparse.parse_qsl(query, keep_blank_values=True, strict_parsing=True)\n    except ValueError:\n        # If we can't parse the query string, we better preserve it as it was.\n        return query\n\n    # Python sorts are stable, so preserving relative ordering of items with\n    # the same key doesn't require any work from us\n    items = sorted(items, key=lambda x: x[0])\n\n    # Remove query params that are blacklisted\n    items = [i for i in items if not _blacklisted_query_param(i[0])]\n\n    # Normalise percent-encoding for query items\n    query = _normalize_queryitems(items)\n\n    return query\n\n\ndef _normalize_queryitems(items):\n    segments = ['='.join([_normalize_queryname(i[0]),\n                          _normalize_queryvalue(i[1])]) for i in items]\n    return '&'.join(segments)\n\n\ndef _normalize_queryname(name):\n    return url_quote_plus(url_unquote_plus(name), safe=UNRESERVED_QUERY_NAME)\n\n\ndef _normalize_queryvalue(value):\n    return url_quote_plus(url_unquote_plus(value), safe=UNRESERVED_QUERY_VALUE)\n\n\ndef _blacklisted_query_param(s):\n    \"\"\"Return True if the given string matches any BLACKLISTED_QUERY_PARAMS.\"\"\"\n    return any(re.match(patt, s) for patt in BLACKLISTED_QUERY_PARAMS)\n"},{"size":10721,"relativepath":"src/memex/schemas.py","filename":"schemas.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\"\"\"Classes for validating data passed to the annotations API.\"\"\"\n\nimport copy\nimport jsonschema\nfrom jsonschema.exceptions import best_match\nfrom pyramid import i18n\n\nfrom memex import parse_document_claims\n\n_ = i18n.TranslationStringFactory(__package__)\n\n\nclass ValidationError(Exception):\n    pass\n\n\nclass JSONSchema(object):\n\n    \"\"\"\n    Validate data according to a Draft 4 JSON Schema.\n\n    Inherit from this class and override the `schema` class property with a\n    valid JSON schema.\n    \"\"\"\n\n    schema = {}\n\n    def __init__(self):\n        self.validator = jsonschema.Draft4Validator(self.schema)\n\n    def validate(self, data):\n        \"\"\"\n        Validate `data` according to the current schema.\n\n        :param data: The data to be validated\n        :return: valid data\n        :raises ValidationError: if the data is invalid\n        \"\"\"\n        # Take a copy to ensure we don't modify what we were passed.\n        appstruct = copy.deepcopy(data)\n        error = best_match(self.validator.iter_errors(appstruct))\n        if error is not None:\n            raise ValidationError(_format_jsonschema_error(error))\n        return appstruct\n\n\nclass AnnotationSchema(JSONSchema):\n\n    \"\"\"Validate an annotation object.\"\"\"\n\n    schema = {\n        'type': 'object',\n        'properties': {\n            'document': {\n                'type': 'object',\n                'properties': {\n                    'dc': {\n                        'type': 'object',\n                        'properties': {\n                            'identifier': {\n                                'type': 'array',\n                                'items': {\n                                    'type': 'string',\n                                },\n                            },\n                        },\n                    },\n                    'highwire': {\n                        'type': 'object',\n                        'properties': {\n                            'doi': {\n                                'type': 'array',\n                                'items': {\n                                    'type': 'string',\n                                },\n                            },\n                            'pdf_url': {\n                                'type': 'array',\n                                'items': {\n                                    'type': 'string',\n                                },\n                            },\n                        },\n                    },\n                    'link': {\n                        'type': 'array',\n                        'items': {\n                            'type': 'object',\n                            'properties': {\n                                'href': {\n                                    'type': 'string',\n                                },\n                                'type': {\n                                    'type': 'string',\n                                },\n                            },\n                            'required': [\n                                'href',\n                            ],\n                        },\n                    },\n                },\n            },\n            'group': {\n                'type': 'string',\n            },\n            'permissions': {\n                'title': 'Permissions',\n                'description': 'Annotation action access control list',\n                'type': 'object',\n                'patternProperties': {\n                    '^(admin|delete|read|update)$': {\n                        'type': 'array',\n                        'items': {\n                            'type': 'string',\n                            'pattern': '^(acct:|group:).+$',\n                        },\n                    }\n                },\n                'required': [\n                    'read',\n                ],\n            },\n            'references': {\n                'type': 'array',\n                'items': {\n                    'type': 'string',\n                },\n            },\n            'tags': {\n                'type': 'array',\n                'items': {\n                    'type': 'string',\n                },\n            },\n            'target': {\n                'type': 'array',\n                'items': [\n                    {\n                        'type': 'object',\n                        'properties': {\n                            'selector': {\n                            },\n                        },\n                    },\n                ],\n            },\n            'text': {\n                'type': 'string',\n            },\n            'uri': {\n                'type': 'string',\n            },\n        },\n    }\n\n\nclass CreateAnnotationSchema(object):\n\n    \"\"\"Validate the POSTed data of a create annotation request.\"\"\"\n\n    def __init__(self, request):\n        self.structure = AnnotationSchema()\n        self.request = request\n\n    def validate(self, data):\n        appstruct = self.structure.validate(data)\n\n        new_appstruct = {}\n\n        _remove_protected_fields(appstruct)\n\n        new_appstruct['userid'] = self.request.authenticated_userid\n\n        uri = appstruct.pop('uri', u'').strip()\n        if not uri:\n            raise ValidationError('uri: ' + _(\"'uri' is a required property\"))\n        new_appstruct['target_uri'] = uri\n\n        new_appstruct['text'] = appstruct.pop('text', u'')\n        new_appstruct['tags'] = appstruct.pop('tags', [])\n        new_appstruct['groupid'] = appstruct.pop('group', u'__world__')\n        new_appstruct['references'] = appstruct.pop('references', [])\n\n        if 'permissions' in appstruct:\n            new_appstruct['shared'] = _shared(appstruct.pop('permissions'),\n                                              new_appstruct['groupid'])\n        else:\n            new_appstruct['shared'] = False\n\n        if 'target' in appstruct:\n            new_appstruct['target_selectors'] = _target_selectors(\n                appstruct.pop('target'))\n\n        # Replies always get the same groupid as their parent. The parent's\n        # groupid is added to the reply annotation later by the storage code.\n        # Here we just delete any group sent by the client from replies.\n        if new_appstruct['references'] and 'groupid' in new_appstruct:\n            del new_appstruct['groupid']\n\n        new_appstruct['document'] = _document(appstruct.pop('document', {}),\n                                              new_appstruct['target_uri'])\n\n        new_appstruct['extra'] = appstruct\n\n        return new_appstruct\n\n\nclass UpdateAnnotationSchema(object):\n\n    \"\"\"Validate the POSTed data of an update annotation request.\"\"\"\n\n    def __init__(self, request, existing_target_uri, groupid):\n        self.request = request\n        self.existing_target_uri = existing_target_uri\n        self.groupid = groupid\n        self.structure = AnnotationSchema()\n\n    def validate(self, data):\n        appstruct = self.structure.validate(data)\n\n        new_appstruct = {}\n\n        _remove_protected_fields(appstruct)\n\n        # Some fields are not allowed to be changed in annotation updates.\n        for key in ['group', 'groupid', 'userid', 'references']:\n            appstruct.pop(key, '')\n\n        # Fields that are allowed to be updated and that have a different name\n        # internally than in the public API.\n        if 'uri' in appstruct:\n            new_uri = appstruct.pop('uri').strip()\n            if not new_uri:\n                raise ValidationError(\n                    'uri: ' + _(\"'uri' is a required property\"))\n            new_appstruct['target_uri'] = new_uri\n\n        if 'permissions' in appstruct:\n            new_appstruct['shared'] = _shared(appstruct.pop('permissions'),\n                                              self.groupid)\n\n        if 'target' in appstruct:\n            new_appstruct['target_selectors'] = _target_selectors(\n                appstruct.pop('target'))\n\n        # Fields that are allowed to be updated and that have the same internal\n        # and external name.\n        for key in ['text', 'tags']:\n            if key in appstruct:\n                new_appstruct[key] = appstruct.pop(key)\n\n        if 'document' in appstruct:\n            new_appstruct['document'] = _document(\n                appstruct.pop('document'),\n                new_appstruct.get('target_uri', self.existing_target_uri))\n\n        new_appstruct['extra'] = appstruct\n\n        return new_appstruct\n\n\ndef _document(document, claimant):\n    \"\"\"\n    Return document meta and document URI data from the given document dict.\n\n    Transforms the \"document\" dict that the client posts into a convenient\n    format for creating DocumentURI and DocumentMeta objects later.\n\n    \"\"\"\n    document = document or {}\n    document_uri_dicts = parse_document_claims.document_uris_from_data(\n        copy.deepcopy(document),\n        claimant=claimant)\n    document_meta_dicts = parse_document_claims.document_metas_from_data(\n        copy.deepcopy(document),\n        claimant=claimant)\n    return {\n        'document_uri_dicts': document_uri_dicts,\n        'document_meta_dicts': document_meta_dicts\n    }\n\n\ndef _format_jsonschema_error(error):\n    \"\"\"Format a :py:class:`jsonschema.ValidationError` as a string.\"\"\"\n    if error.path:\n        dotted_path = '.'.join([str(c) for c in error.path])\n        return '{path}: {message}'.format(path=dotted_path,\n                                          message=error.message)\n    return error.message\n\n\ndef _remove_protected_fields(appstruct):\n    # Some fields are not to be set by the user, ignore them.\n    for field in ['created', 'updated', 'user', 'id', 'links']:\n        appstruct.pop(field, None)\n\n\ndef _shared(permissions, groupid):\n    \"\"\"\n    Return True if the given permissions object represents shared permissions.\n\n    Return False otherwise.\n\n    Reduces the client's complex permissions dict to a simple shared boolean.\n\n    :param permissions: the permissions dict sent by the client in an\n        annotation create or update request\n    :type permissions: dict\n\n    :param groupid: the groupid of the annotation that the permissions dict\n        applies to\n    :type groupid: unicode\n\n    \"\"\"\n    return permissions['read'] == ['group:{id}'.format(id=groupid)]\n\n\ndef _target_selectors(targets):\n    \"\"\"\n    Return the target selectors from the given target list.\n\n    Transforms the target lists that the client sends in annotation create and\n    update requests into our internal target_selectors format.\n\n    \"\"\"\n    # Any targets other than the first in the list are discarded.\n    # Any fields of the target other than 'selector' are discarded.\n    if targets and 'selector' in targets[0]:\n        return targets[0]['selector']\n    else:\n        return []\n"},{"size":2927,"relativepath":"src/memex/markdown.py","filename":"markdown.py","extension":".py","content":"# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport re\n\nimport bleach\nfrom bleach import callbacks as linkify_callbacks\nimport mistune\n\nLINK_REL = 'nofollow noopener'\n\nMARKDOWN_TAGS = [\n    'a', 'blockquote', 'code', 'em', 'hr', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6',\n    'img', 'li', 'ol', 'p', 'pre', 'strong', 'ul',\n]\nALLOWED_TAGS = set(bleach.ALLOWED_TAGS + MARKDOWN_TAGS)\n\n\ndef _filter_link_attributes(name, value):\n    if name in ['href', 'title']:\n        return True\n\n    if name == 'target' and value == '_blank':\n        return True\n\n    if name == 'rel' and value == LINK_REL:\n        return True\n\n    return False\n\nMARKDOWN_ATTRIBUTES = {\n    'a': _filter_link_attributes,\n    'img': ['alt', 'src', 'title'],\n}\nALLOWED_ATTRIBUTES = dict(bleach.ALLOWED_ATTRIBUTES.items() + MARKDOWN_ATTRIBUTES.items())\n\n# Singleton instance of the Markdown instance\nmarkdown = None\n\n\nclass MathMarkdown(mistune.Markdown):\n    def output_block_math(self):\n        return self.renderer.block_math(self.token['text'])\n\n\nclass MathInlineLexer(mistune.InlineLexer):\n    def __init__(self, *args, **kwargs):\n        super(MathInlineLexer, self).__init__(*args, **kwargs)\n        self.rules.inline_math = re.compile(r'\\\\\\((.*?)\\\\\\)', re.DOTALL)\n        self.default_rules.insert(0, 'inline_math')\n\n    def output_inline_math(self, m):\n        return self.renderer.inline_math(m.group(1))\n\n\nclass MathBlockLexer(mistune.BlockLexer):\n    def __init__(self, *args, **kwargs):\n        super(MathBlockLexer, self).__init__(*args, **kwargs)\n        self.rules.block_math = re.compile(r'^\\$\\$(.*?)\\$\\$', re.DOTALL)\n        self.default_rules.insert(0, 'block_math')\n\n    def parse_block_math(self, m):\n        self.tokens.append({\n            'type': 'block_math',\n            'text': m.group(1)\n        })\n\n\nclass MathRenderer(mistune.Renderer):\n    def __init__(self, **kwargs):\n        super(MathRenderer, self).__init__(**kwargs)\n\n    def block_math(self, text):\n        return '<p>$$%s$$</p>\\n' % text\n\n    def inline_math(self, text):\n        return '\\\\(%s\\\\)' % text\n\n\ndef render(text):\n    if text is not None:\n        render = _get_markdown()\n        return sanitize(render(text))\n    return None\n\n\ndef sanitize(text):\n    linkified = bleach.linkify(text, callbacks=[\n        linkify_callbacks.target_blank,\n        linkify_rel,\n    ])\n\n    return bleach.clean(linkified,\n                        tags=ALLOWED_TAGS,\n                        attributes=ALLOWED_ATTRIBUTES)\n\n\ndef linkify_rel(attrs, new=False):\n    if attrs['href'].startswith('mailto:'):\n        return attrs\n\n    attrs['rel'] = LINK_REL\n\n    return attrs\n\n\ndef _get_markdown():\n    global markdown\n    if markdown is None:\n        markdown = MathMarkdown(renderer=MathRenderer(),\n                                inline=MathInlineLexer,\n                                block=MathBlockLexer,\n                                escape=True)\n    return markdown\n"},{"size":1565,"relativepath":"Dockerfile","filename":"Dockerfile","extension":"","content":"FROM gliderlabs/alpine:3.4\nMAINTAINER Hypothes.is Project and contributors\n\n# Install system build and runtime dependencies.\nRUN apk-install \\\n    ca-certificates \\\n    libffi \\\n    libpq \\\n    python \\\n    py-pip \\\n    nodejs \\\n    git\n\n# Create the hypothesis user, group, home directory and package directory.\nRUN addgroup -S hypothesis && adduser -S -G hypothesis -h /var/lib/hypothesis hypothesis\nWORKDIR /var/lib/hypothesis\n\n# Copy minimal data to allow installation of dependencies.\nCOPY src/memex/__init__.py ./src/memex/\nCOPY README.rst setup.* requirements.txt ./\n\n# Install build deps, build, and then clean up.\nRUN apk-install --virtual build-deps \\\n    build-base \\\n    libffi-dev \\\n    postgresql-dev \\\n    python-dev \\\n  && pip install --no-cache-dir -U pip \\\n  && pip install --no-cache-dir -r requirements.txt \\\n  && apk del build-deps\n\n# Copy the rest of the application files.\nCOPY . .\n\n# Build frontend assets\nRUN SASS_BINARY_PATH=$PWD/vendor/node-sass-linux-x64.node npm install --production \\\n  && SASS_BINARY_PATH=$PWD/vendor/node-sass-linux-x64.node NODE_ENV=production node_modules/.bin/gulp build \\\n  && (find node_modules -name hypothesis -prune -o -mindepth 1 -maxdepth 1 -print0 | xargs -0 rm -r) \\\n  && npm cache clean\n\n# Expose the default port.\nEXPOSE 5000\n\n# Set the application environment\nENV PATH /var/lib/hypothesis/bin:$PATH\nENV PYTHONIOENCODING utf_8\nENV PYTHONPATH /var/lib/hypothesis:$PYTHONPATH\n\n# Start the web server by default\nUSER hypothesis\nCMD [\"newrelic-admin\", \"run-program\", \"gunicorn\", \"--paste\", \"conf/app.ini\"]\n"},{"size":1216,"relativepath":"conf/development-app.ini","filename":"development-app.ini","extension":".ini","content":"[pipeline:main]\npipeline: h\n\n[app:h]\nuse: call:h.app:create_app\n\nes.host: http://localhost:9200\n\npyramid.debug_all: True\npyramid.reload_templates: True\n\nh.auth_domain: localhost\n\n# Set a default persistent secret for development. DO NOT copy this into a\n# production settings file.\nh.client_id: nosuchid\nh.client_secret: nosuchsecret\n\nh.debug: True\n\nsecret_key: notverysecretafterall\n\nsqlalchemy.url: postgresql://postgres@localhost/postgres\n\n;http://docs.pylonsproject.org/projects/pyramid-debugtoolbar/en/latest/#settings\ndebugtoolbar.show_on_exc_only: True\n\n[server:main]\nuse: egg:gunicorn\nhost: localhost\nport: 5000\ngraceful_timeout: 0\ntimeout: 0\nerrorlog: -\nreload: True\n\n[loggers]\nkeys = root, gunicorn.error, h, raven\n\n[handlers]\nkeys = console\n\n[formatters]\nkeys = generic\n\n[logger_root]\nlevel = WARNING\nhandlers = console\n\n[logger_gunicorn.error]\nlevel = INFO\nhandlers =\nqualname = gunicorn.error\n\n[logger_h]\nlevel = INFO\nhandlers =\nqualname = h\n\n[logger_raven]\nlevel = WARNING\nhandlers = console\nqualname = raven\npropagate = 0\n\n[handler_console]\nlevel = NOTSET\nclass = StreamHandler\nargs = ()\nformatter = generic\n\n[formatter_generic]\nformat = %(asctime)s [%(process)d] [%(name)s:%(levelname)s] %(message)s\n"},{"size":1552,"relativepath":"conf/app.ini","filename":"app.ini","extension":".ini","content":"[pipeline:main]\n# Most errors will be handled in exception views within the application. The\n# raven middleware is here primarily as a fail-safe, and to capture errors\n# thrown by framework code.\npipeline:\n  proxy-prefix\n  raven\n  h\n\n[app:h]\nuse: call:h.app:create_app\n\n# Elasticsearch configuration\n#es.host: http://localhost:9200\n#es.index: hypothesis\n\n# OAuth settings\n# These client credentials are used by the built-in Web client.\n# If not provided, both default to a random URL-safe base64-encoded string.\n#h.client_id:\n#h.client_secret:\n\n# SQLAlchemy configuration -- See SQLAlchemy documentation\nsqlalchemy.url: postgresql://postgres@localhost/postgres\n\n[filter:proxy-prefix]\nuse: egg:PasteDeploy#prefix\n\n[filter:raven]\nuse: egg:raven#raven\n\n[server:main]\nuse: egg:gunicorn\nhost: 0.0.0.0\nport: 5000\n\n[loggers]\nkeys = root, alembic, gunicorn.error, h, sentry\n\n[handlers]\nkeys = console, sentry\n\n[formatters]\nkeys = generic\n\n[logger_root]\nlevel = WARNING\nhandlers = console, sentry\n\n[logger_alembic]\nlevel = INFO\nhandlers =\nqualname = alembic\n\n[logger_gunicorn.error]\nlevel = INFO\nhandlers =\nqualname = gunicorn.error\n\n[logger_h]\nlevel = INFO\nhandlers =\nqualname = h\n\n[logger_sentry]\nlevel = WARNING\nhandlers = console\nqualname = sentry.errors\npropagate = 0\n\n[handler_console]\nlevel = NOTSET\nclass = StreamHandler\nargs = ()\nformatter = generic\n\n[handler_sentry]\nlevel = WARNING\nclass = raven.handlers.logging.SentryHandler\nargs = ()\nformatter = generic\n\n[formatter_generic]\nformat = %(asctime)s [%(process)d] [%(name)s:%(levelname)s] %(message)s\n"},{"size":467,"relativepath":"conf/alembic.ini","filename":"alembic.ini","extension":".ini","content":"[alembic]\n# path to migration scripts\nscript_location = h:migrations\n\n# template used to generate migration files\n# file_template = %%(rev)s_%%(slug)s\n\n# max length of characters to apply to the\n# \"slug\" field\n#truncate_slug_length = 40\n\n# set to 'true' to run the environment during\n# the 'revision' command, regardless of autogenerate\n# revision_environment = false\n\n# Edit the engine string for production.\nsqlalchemy.url: postgresql://postgres@localhost/postgres\n"},{"size":994,"relativepath":"conf/development-websocket.ini","filename":"development-websocket.ini","extension":".ini","content":"[app:main]\nuse: call:h.websocket:create_app\n\n# Allowed websocket origins\norigins:\n    http://localhost:5000\n\n# Use gevent-compatible transport for the Sentry client\nraven.transport: gevent\n\nsecret_key: notverysecretafterall\n\n# SQLAlchemy configuration -- See SQLAlchemy documentation\nsqlalchemy.url: postgresql://postgres@localhost/postgres\n\n[server:main]\nuse: egg:gunicorn\nhost: localhost\nport: 5001\nworker_class: h.websocket.Worker\ngraceful_timeout: 0\n\n[loggers]\nkeys = root, gunicorn.error, h, raven\n\n[handlers]\nkeys = console\n\n[formatters]\nkeys = generic\n\n[logger_root]\nlevel = WARNING\nhandlers = console\n\n[logger_gunicorn.error]\nlevel = INFO\nhandlers =\nqualname = gunicorn.error\n\n[logger_h]\nlevel = INFO\nhandlers =\nqualname = h\n\n[logger_raven]\nlevel = WARNING\nhandlers = console\nqualname = raven\npropagate = 0\n\n[handler_console]\nlevel = NOTSET\nclass = StreamHandler\nargs = ()\nformatter = generic\n\n[formatter_generic]\nformat = %(asctime)s [%(process)d] [%(name)s:%(levelname)s] %(message)s\n"},{"size":976,"relativepath":"conf/websocket.ini","filename":"websocket.ini","extension":".ini","content":"[app:main]\nuse: call:h.websocket:create_app\n\n# Use gevent-compatible transport for the Sentry client\nraven.transport: gevent\n\n# SQLAlchemy configuration -- See SQLAlchemy documentation\nsqlalchemy.url: postgresql://postgres@localhost/postgres\n\n[server:main]\nuse: egg:gunicorn\nhost: 0.0.0.0\nport: 5001\nworker_class: h.websocket.Worker\ngraceful_timeout: 0\n\n[loggers]\nkeys = root, gunicorn.error, sentry\n\n[handlers]\nkeys = console, sentry\n\n[formatters]\nkeys = generic\n\n[logger_root]\nlevel = WARNING\nhandlers = console, sentry\n\n[logger_gunicorn.error]\nlevel = INFO\nhandlers =\nqualname = gunicorn.error\n\n[logger_sentry]\nlevel = WARNING\nhandlers = console\nqualname = sentry.errors\npropagate = 0\n\n[handler_console]\nlevel = NOTSET\nclass = StreamHandler\nargs = ()\nformatter = generic\n\n[handler_sentry]\nlevel = WARNING\nclass = raven.handlers.logging.SentryHandler\nargs = ()\nformatter = generic\n\n[formatter_generic]\nformat = %(asctime)s [%(process)d] [%(name)s:%(levelname)s] %(message)s\n"},{"size":4931,"relativepath":"LICENSE","filename":"LICENSE","extension":"","content":"Copyright (c) 2013-2014 Hypothes.is Project and contributors\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nSubcomponents\n\nThe project includes a number of subcomponents with separate\ncopyright notices and license terms. Your use of the code for the these\nsubcomponents is subject to the terms and conditions of the following licenses.\n\nFor the AngularJS subcomponents:\n\n Copyright (c) 2010-2012 Google, Inc. http://angularjs.org\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n\nFor the annotator subcomponent:\n\n Copyright 2012 Aron Carroll, Rufus Pollock, and Nick Stenning.\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\n\nFor the KaTex subcomponent:\n\n The MIT License (MIT)\n\n Copyright (c) 2014 Khan Academy\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in all\n copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n SOFTWARE.\n"},{"size":1249,"relativepath":"tox.ini","filename":"tox.ini","extension":".ini","content":"[tox]\nenvlist = py27-{h,memex}\n\n[pytest]\nminversion = 2.8\naddopts = --pyargs\ntestpaths = tests\n\n[testenv]\nskip_install =\n    h: true\n    memex: false\n# N.B. \"hypothesis\" in the list below is the property-based testing library,\n#      not our own code.\ndeps =\n    coverage\n    mock\n    # Pin pytest until https://github.com/pytest-dev/pytest/issues/1905 is\n    # resolved\n    pytest==3.0.1\n    hypothesis\n    factory-boy\n    h: -rrequirements.txt\npassenv =\n    TEST_DATABASE_URL\ncommands =\n    h: coverage run --parallel --source h -m pytest {posargs:tests/h/}\n    memex: coverage run --parallel --source memex -m pytest {posargs:tests/memex/}\n\n[testenv:functional]\nskip_install = true\ndeps =\n    # Pin pytest until https://github.com/pytest-dev/pytest/issues/1905 is\n    # resolved\n    pytest==3.0.1\n    webtest\n    factory-boy\n    -rrequirements.txt\npassenv =\n    BROKER_URL\n    ELASTICSEARCH_HOST\n    TEST_DATABASE_URL\ncommands = py.test {posargs:tests/functional/}\n\n[testenv:clean]\ndeps = coverage\nskip_install = true\ncommands = coverage erase\n\n[testenv:coverage]\ndeps = coverage\nskip_install = true\ncommands =\n    coverage combine\n    coverage report\n\n[testenv:codecov]\ndeps = codecov\nskip_install = true\npassenv = CI TRAVIS*\ncommands = codecov\n"},{"size":1731,"relativepath":"Makefile","filename":"Makefile","extension":"","content":"DOCKER_TAG = dev\n\nGULP := node_modules/.bin/gulp\n\n# Unless the user has specified otherwise in their environment, it's probably a\n# good idea to refuse to install unless we're in an activated virtualenv.\nifndef PIP_REQUIRE_VIRTUALENV\nPIP_REQUIRE_VIRTUALENV = 1\nendif\nexport PIP_REQUIRE_VIRTUALENV\n\n.PHONY: default\ndefault: test\n\nbuild/manifest.json: node_modules/.uptodate\n\t$(GULP) build\n\n## Clean up runtime artifacts (needed after a version update)\n.PHONY: clean\nclean:\n\tfind . -type f -name \"*.py[co]\" -delete\n\tfind . -type d -name \"__pycache__\" -delete\n\trm -f node_modules/.uptodate .pydeps\n\trm -rf build\n\n## Run the development H server locally\n.PHONY: dev\ndev: build/manifest.json .pydeps\n\t@bin/hypothesis devserver\n\n## Build hypothesis/hypothesis docker image\n.PHONY: docker\ndocker:\n\tgit archive HEAD | docker build -t hypothesis/hypothesis:$(DOCKER_TAG) -\n\n## Run test suite\n.PHONY: test\ntest: node_modules/.uptodate\n\t@pip install -q tox\n\ttox\n\t$(GULP) test\n\n################################################################################\n\n# Fake targets to aid with deps installation\n.pydeps: setup.py requirements.txt\n\t@echo installing python dependencies\n\t@pip install --use-wheel -r requirements-dev.in tox\n\t@touch $@\n\nnode_modules/.uptodate: package.json\n\t@echo installing javascript dependencies\n\t@node_modules/.bin/check-dependencies 2>/dev/null || npm install\n\t@touch $@\n\n# Self documenting Makefile\n.PHONY: help\nhelp:\n\t@echo \"The following targets are available:\"\n\t@echo \" clean      Clean up runtime artifacts (needed after a version update)\"\n\t@echo \" dev        Run the development H server locally\"\n\t@echo \" docker     Build hypothesis/hypothesis docker image\"\n\t@echo \" test       Run the test suite (default)\"\n"},{"size":450,"relativepath":"AUTHORS","filename":"AUTHORS","extension":"","content":"The following individuals (or organizations) have made contributions\nto this repository. The list in not necessarily complete. Please add\nyour name, if you desire, in the appropriate place.\n\nDan Whaley <dwhaley@hypothes.is>\nJehan Tremback <jehan@hypothes.is>\nRandall Leeds <tilgovi@hypothes.is>\nKristof Csillag <csillag@hypothes.is>\nGergely Ujvari <ujvari@hypothes.is>\nJake Hartnell <jakehartnell@hypothes.is>\nBenjamin Young <bigbluehat@hypothes.is>\n"},{"size":2602,"relativepath":"README.rst","filename":"README.rst","extension":".rst","content":"Hypothesis\n==========\n\n.. image:: https://travis-ci.org/hypothesis/h.svg?branch=master\n   :target: https://travis-ci.org/hypothesis/h\n   :alt: Build Status\n.. image:: https://codecov.io/github/hypothesis/h/coverage.svg?branch=master\n   :target: https://codecov.io/github/hypothesis/h?branch=master\n   :alt: Code Coverage\n.. image:: https://img.shields.io/badge/IRC-%23hypothes.is-blue.svg\n   :target: `#hypothes.is`_\n   :alt: #hypothes.is IRC channel\n.. image:: https://img.shields.io/badge/license-BSD-blue.svg\n   :target: https://github.com/hypothesis/h/blob/master/LICENSE\n   :alt: License badge\n.. image:: https://img.shields.io/badge/python-2.7-blue.svg\n   :alt: Python version badge\n\n\nAbout\n-----\n\nHypothesis is a tool for annotating the web.\n\n- A service for storing community annotations\n- An account system for user registration\n- Authorization for client applications\n- A browser-based annotator client featuring:\n\n  - Chrome and Firefox browser extensions\n  - A bookmarklet\n  - A publisher embed code\n\n\nDevelopment\n-----------\n\nSee the `Contributor's guide`_ for instructions on setting up a development\nenvironment and contributing to h.\n\n\nCommunity\n---------\n\nJoin us in `#hypothes.is`_ on freenode_ for discussion.\n\nIf you'd like to contribute to the project, you should also `subscribe`_ to the\n`development mailing list`_ and read our `Contributor's guide`_. Then consider\ngetting started on one of the issues that are ready for work. Issues tagged with\nthe label '`New Contributor Friendly`_' are ideal for those just getting\nstarted.\n\nPlease note that this project is released with a Contributor Code of Conduct.\nBy participating in this project you agree to abide by its terms.\n\n.. _#hypothes.is: https://www.irccloud.com/invite?channel=%23hypothes.is&amp;hostname=irc.freenode.net&amp;port=6667&amp;ssl=1\n.. _freenode: http://freenode.net/\n.. _subscribe: mailto:dev+subscribe@list.hypothes.is\n.. _development mailing list: https://groups.google.com/a/list.hypothes.is/forum/#!forum/dev\n.. _Contributor's guide: https://h.readthedocs.io/en/latest/developing/\n.. _New Contributor Friendly: https://github.com/hypothesis/h/issues?q=is%3Aopen+is%3Aissue+label%3A%22New+Contributor+Friendly%22\n\n\nLicense\n-------\n\nHypothesis is released under the `2-Clause BSD License`_, sometimes referred\nto as the \"Simplified BSD License\" or the \"FreeBSD License\". Some third-party\ncomponents are included. They are subject to their own licenses. All of the\nlicense information can be found in the included `<LICENSE>`_ file.\n\n.. _2-Clause BSD License: http://www.opensource.org/licenses/BSD-2-Clause\n"},{"size":8042,"relativepath":"gulpfile.js","filename":"gulpfile.js","extension":".js","content":"'use strict';\n\nrequire('core-js/es6/promise');\nrequire('core-js/fn/object/assign');\nrequire('core-js/fn/string');\n\nvar path = require('path');\n\nvar batch = require('gulp-batch');\nvar changed = require('gulp-changed');\nvar commander = require('commander');\nvar endOfStream = require('end-of-stream');\nvar gulp = require('gulp');\nvar gulpIf = require('gulp-if');\nvar gulpUtil = require('gulp-util');\nvar newer = require('gulp-newer');\nvar postcss = require('gulp-postcss');\nvar postcssURL = require('postcss-url');\nvar svgmin = require('gulp-svgmin');\nvar through = require('through2');\n\nvar createBundle = require('./scripts/gulp/create-bundle');\nvar createStyleBundle = require('./scripts/gulp/create-style-bundle');\nvar manifest = require('./scripts/gulp/manifest');\n\nvar IS_PRODUCTION_BUILD = process.env.NODE_ENV === 'production';\nvar SCRIPT_DIR = 'build/scripts';\nvar STYLE_DIR = 'build/styles';\nvar FONTS_DIR = 'build/fonts';\nvar IMAGES_DIR = 'build/images';\n\nfunction parseCommandLine() {\n  commander\n    // Test configuration.\n    // See https://github.com/karma-runner/karma-mocha#configuration\n    .option('--grep [pattern]', 'Run only tests matching a given pattern')\n    .parse(process.argv);\n\n  if (commander.grep) {\n    gulpUtil.log(`Running tests matching pattern /${commander.grep}/`);\n  }\n\n  return {\n    grep: commander.grep,\n  };\n}\n\nvar taskArgs = parseCommandLine();\n\nfunction getEnv(key) {\n  if (!process.env.hasOwnProperty(key)) {\n    throw new Error(`Environment variable ${key} is not set`);\n  }\n  return process.env[key];\n}\n\nvar vendorBundles = {\n  jquery: ['jquery'],\n  bootstrap: ['bootstrap'],\n  raven: ['raven-js'],\n};\nvar vendorModules = ['jquery', 'bootstrap', 'raven-js'];\nvar vendorNoParseModules = ['jquery'];\n\n// Builds the bundles containing vendor JS code\ngulp.task('build-vendor-js', function () {\n  var finished = [];\n  Object.keys(vendorBundles).forEach(function (name) {\n    finished.push(createBundle({\n      name: name,\n      require: vendorBundles[name],\n      minify: IS_PRODUCTION_BUILD,\n      path: SCRIPT_DIR,\n      noParse: vendorNoParseModules,\n    }));\n  });\n  return Promise.all(finished);\n});\n\nvar bundleBaseConfig = {\n  path: SCRIPT_DIR,\n  external: vendorModules,\n  minify: IS_PRODUCTION_BUILD,\n  noParse: vendorNoParseModules,\n};\n\nvar bundles = [{\n  // Public-facing website\n  name: 'site',\n  entry: './h/static/scripts/site',\n},{\n  // Admin areas of the site\n  name: 'admin-site',\n  entry: './h/static/scripts/admin-site',\n},{\n  // Legacy site bundle (for old homepage)\n  name: 'legacy-site',\n  entry: './h/static/scripts/legacy-site',\n},{\n  // Header script inserted inline at the top of the page\n  name: 'header',\n  entry: './h/static/scripts/header',\n}];\n\nvar bundleConfigs = bundles.map(function (config) {\n  return Object.assign({}, bundleBaseConfig, config);\n});\n\ngulp.task('build-js', ['build-vendor-js'], function () {\n  return Promise.all(bundleConfigs.map(function (config) {\n    return createBundle(config);\n  }));\n});\n\ngulp.task('watch-js', ['build-vendor-js'], function () {\n  bundleConfigs.map(function (config) {\n    createBundle(config, {watch: true});\n  });\n});\n\n// Rewrite font URLs to look for fonts in 'build/fonts' instead of\n// 'build/styles/fonts'\nfunction rewriteCSSURL(url) {\n  return url.replace(/^fonts\\//, '../fonts/');\n}\n\ngulp.task('build-vendor-css', function () {\n  var vendorCSSFiles = [\n    // `front-page.css` is a pre-built bundle of legacy CSS used by the home\n    // page\n    './h/static/styles/front-page.css',\n\n    // `legacy-site.css` is a pre-built bundle of legacy CSS used by the\n    // login and account settings pages\n    './h/static/styles/legacy-site.css',\n\n    // Icon font\n    './h/static/styles/vendor/icomoon.css',\n    './node_modules/bootstrap/dist/css/bootstrap.css',\n  ];\n\n  var cssURLRewriter = postcssURL({\n    url: rewriteCSSURL,\n  });\n\n  return gulp.src(vendorCSSFiles)\n    .pipe(newer(STYLE_DIR))\n    .pipe(postcss([cssURLRewriter]))\n    .pipe(gulp.dest(STYLE_DIR));\n});\n\nvar styleBundleEntryFiles = [\n  './h/static/styles/admin.scss',\n  './h/static/styles/help-page.scss',\n  './h/static/styles/site.scss',\n  './h/static/styles/site-v2.scss',\n  './h/static/styles/old-home.scss',\n];\n\nfunction buildStyleBundle(entryFile, options) {\n  return createStyleBundle({\n    input: entryFile,\n    output: './build/styles/' + path.basename(entryFile, '.scss') + '.css',\n    minify: IS_PRODUCTION_BUILD,\n    urlRewriter: rewriteCSSURL,\n    watch: options.watch,\n  });\n}\n\ngulp.task('build-css', ['build-vendor-css'], function () {\n  return Promise.all(styleBundleEntryFiles.map(buildStyleBundle));\n});\n\ngulp.task('watch-css', function () {\n  // Build initial CSS bundles. This is done rather than adding 'build-css' as\n  // a dependency of this task so that the process continues in the event of an\n  // error.\n  Promise.all(styleBundleEntryFiles.map(buildStyleBundle)).catch(gulpUtil.log);\n  gulp.watch('h/static/styles/**/*.scss', ['build-css']);\n});\n\nvar fontFiles = 'h/static/styles/vendor/fonts/*.woff';\n\ngulp.task('build-fonts', function () {\n  gulp.src(fontFiles)\n    .pipe(changed(FONTS_DIR))\n    .pipe(gulp.dest(FONTS_DIR));\n});\n\ngulp.task('watch-fonts', function () {\n  gulp.watch(fontFiles, ['build-fonts']);\n});\n\nvar imageFiles = 'h/static/images/**/*';\ngulp.task('build-images', function () {\n  var shouldMinifySVG = function (file) {\n    return IS_PRODUCTION_BUILD && file.path.match(/\\.svg$/);\n  };\n\n  gulp.src(imageFiles)\n    .pipe(changed(IMAGES_DIR))\n    .pipe(gulpIf(shouldMinifySVG, svgmin()))\n    .pipe(gulp.dest(IMAGES_DIR));\n});\n\ngulp.task('watch-images', function () {\n  gulp.watch(imageFiles, ['build-images']);\n});\n\nvar MANIFEST_SOURCE_FILES = 'build/@(fonts|images|scripts|styles)/*.@(js|css|woff|jpg|png|svg)';\n\n/**\n * Generate a JSON manifest mapping file paths to\n * URLs containing cache-busting query string parameters.\n */\nfunction generateManifest() {\n  gulp.src(MANIFEST_SOURCE_FILES)\n    .pipe(manifest({name: 'manifest.json'}))\n    .pipe(through.obj(function (file, enc, callback) {\n      gulpUtil.log('Updated asset manifest');\n      this.push(file);\n      callback();\n    }))\n    .pipe(gulp.dest('build/'));\n}\n\ngulp.task('watch-manifest', function () {\n  gulp.watch(MANIFEST_SOURCE_FILES, batch(function (events, done) {\n    endOfStream(generateManifest(), function () {\n      done();\n    });\n  }));\n});\n\ngulp.task('build',\n          ['build-js',\n           'build-css',\n           'build-fonts',\n           'build-images'],\n          generateManifest);\n\ngulp.task('watch',\n          ['watch-js',\n           'watch-css',\n           'watch-fonts',\n           'watch-images',\n           'watch-manifest']);\n\nfunction runKarma(baseConfig, opts, done) {\n  // See https://github.com/karma-runner/karma-mocha#configuration\n  var cliOpts = {\n    client: {\n      mocha: {\n        grep: taskArgs.grep,\n      }\n    },\n  };\n\n  // Work around a bug in Karma 1.10 which causes console log messages not to\n  // be displayed when using a non-default reporter.\n  // See https://github.com/karma-runner/karma/pull/2220\n  var BaseReporter = require('karma/lib/reporters/base');\n  BaseReporter.decoratorFactory.$inject =\n    BaseReporter.decoratorFactory.$inject.map(dep =>\n        dep.replace('browserLogOptions', 'browserConsoleLogOptions'));\n\n  var karma = require('karma');\n  new karma.Server(Object.assign({}, {\n    configFile: path.resolve(__dirname, baseConfig),\n  }, cliOpts, opts), done).start();\n}\n\ngulp.task('test', function (callback) {\n  runKarma('./h/static/scripts/karma.config.js', {singleRun:true}, callback);\n});\n\ngulp.task('test-watch', function (callback) {\n  runKarma('./h/static/scripts/karma.config.js', {}, callback);\n});\n\ngulp.task('lint', function () {\n  // Adapted from usage example at https://www.npmjs.com/package/gulp-eslint\n  // `gulp-eslint` is loaded lazily so that it is not required during Docker image builds\n  var eslint = require('gulp-eslint');\n  return gulp.src(['h/static/scripts/**/*.js'])\n    .pipe(eslint())\n    .pipe(eslint.format())\n    .pipe(eslint.failAfterError());\n});\n"},{"size":4862,"relativepath":"scripts/list-changes-since.py","filename":"list-changes-since.py","extension":".py","content":"#!/usr/bin/env python\n\nimport argparse\nimport dateutil.parser\nimport re\nimport requests\nimport subprocess\nimport textwrap\nfrom subprocess import PIPE\n\nGITHUB_API_URL = 'https://api.github.com'\n\n\nclass CompletedProcess(object):\n    def __init__(self, stdout, stderr):\n        self.stdout = stdout\n        self.stderr = stderr\n\n\n# Replace with subprocess.run() when we move to Python 3\ndef run(args, **kw):\n    proc = subprocess.Popen(args, **kw)\n    (stdout, stderr) = proc.communicate()\n    return CompletedProcess(stdout, stderr)\n\n\nclass PRInfo(object):\n    def __init__(self, id, title):\n        self.id = id\n        self.title = title\n\n\ndef get_last_tag():\n    tags = run(['git','tag','--list','--sort=-taggerdate'],\n        stdout=PIPE)\n    return tags.stdout.decode().splitlines()[0]\n\n\ndef get_tag_date(tag):\n    tag_date_result = run(['git', 'tag', '--list', tag, '--format=%(taggerdate)'],\n        stdout=PIPE)\n    tag_date_str = tag_date_result.stdout.decode().strip()\n    return dateutil.parser.parse(tag_date_str)\n\n\ndef github_request(auth_token, repo, path, **kwargs):\n    \"\"\"\n    Make a GitHub API request and return an iterator over items in the response.\n\n    `github_request` follows `next` links in paged responses automatically.\n    \"\"\"\n    params = kwargs\n    url = '{}/repos/{}/{}'.format(GITHUB_API_URL, repo, path)\n    headers = {}\n    if auth_token:\n        headers['Authorization'] = 'token {}'.format(auth_token)\n\n    while url:\n        res = requests.get(url, headers=headers, params=params)\n        if res.status_code != 200:\n            raise Exception('GitHub request failed:', res.text)\n\n        page = res.json()\n        if isinstance(page, list):\n            for item in page:\n                yield item\n            try:\n                url = res.links['next']['url']\n            except KeyError:\n                url = None\n            params = None\n        else:\n            yield page\n            break\n\n\ndef get_prs_merged_since(auth_token, repo, tag):\n    \"\"\"\n    Return all pull requests merged since `tag` was created.\n\n    Pull requests are sorted in ascending order of merge date.\n    \"\"\"\n    tag_date = get_tag_date(tag)\n    prs = []\n\n    def merge_date(pr):\n        if pr.get('merged_at'):\n            return dateutil.parser.parse(pr['merged_at'])\n        else:\n            return None\n\n    # The GitHub API does not provide a `since` parameter to retrieve PRs\n    # closed since a given date, so instead we iterate over PRs in descending\n    # order of last update and stop when we reach a PR that was last updated\n    # before the given tag was created.\n    for closed_pr in github_request(auth_token, repo, 'pulls', state='closed',\n                                    sort='updated', direction='desc'):\n        pr_date = dateutil.parser.parse(closed_pr['updated_at'])\n        if pr_date < tag_date:\n            break\n        merged_at = merge_date(closed_pr)\n        if merged_at and merged_at > tag_date:\n            prs += [closed_pr]\n\n    return sorted(prs, key=merge_date)\n\n\ndef format_list(items):\n    def format_item(item, col_width):\n        formatted = ''\n        for line in iter(textwrap.wrap(item, col_width - 2)):\n            if len(formatted) == 0:\n                formatted = formatted + '- ' + line\n            else:\n                formatted = formatted + '\\n  ' + line\n        return formatted\n\n    return '\\n\\n'.join([format_item(item, 80) for item in items])\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\n\"\"\"\nGenerates a list of changes since a given tag was created in the format used by\nthe CHANGES file.\n\nChange descriptions are taken from pull request titles.\n\nIf no tag is specified, the most recently created tag is used.\n\nThis tool does not require authentication but the GitHub API has a relatively\nlow rate limit for unauthenticated requests, so you will probably want to use\nan OAuth token. See\nhttps://help.github.com/articles/creating-an-access-token-for-command-line-use/\n\"\"\"\n)\n    parser.add_argument('--tag')\n    parser.add_argument('--repo', default='hypothesis/h')\n    parser.add_argument('--token')\n    args = parser.parse_args()\n    tag = args.tag or get_last_tag()\n\n    pr_details = []\n    for pr in get_prs_merged_since(args.token, args.repo, tag):\n        pr_details += [PRInfo(pr['number'], title=pr['title'].strip())]\n\n    def item_label(pr):\n        return '{} (#{}).'.format(pr.title, pr.id)\n\n    print('Changes since {} {}:\\n'.format(args.repo, tag))\n    print(\"\"\"\n****\nPlease edit the output below before including it in CHANGES.\n\nOnly include entries which have a reasonable chance of being interesting to a\ndownstream consumer of this package, and use language which does not assume\ndetailed knowledge of package internals where possible.\n****\n\"\"\")\n    print(format_list([item_label(pr) for pr in pr_details]))\n\n\nif __name__ == '__main__':\n    main()\n"},{"size":1140,"relativepath":"scripts/update-icon-font.py","filename":"update-icon-font.py","extension":".py","content":"#!/usr/bin/env python\n\nimport argparse\nimport os\nfrom base64 import b64encode\nfrom zipfile import ZipFile\n\n\ndef main():\n    parser = argparse.ArgumentParser('Update the icomoon icon font from the provided archive')\n    parser.add_argument('archive', help='Path to .zip file generated by icomoon')\n    args = parser.parse_args()\n\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    vendor_style_dir = script_dir + '/../h/static/styles/vendor'\n\n    icon_font_archive = ZipFile(args.archive)\n    icon_font_archive.extract('selection.json', vendor_style_dir + '/fonts')\n    icon_font_archive.extract('fonts/h.woff', vendor_style_dir)\n    css_input_file = icon_font_archive.open('style.css')\n\n    css_output_file = open(vendor_style_dir + '/icomoon.css', 'w')\n\n    for line in css_input_file:\n        if \"format('woff')\" in line:\n            # Rewrite the H font URL\n            css_output_file.write(\"  src: url('../fonts/h.woff') format('woff');\\n\")\n        elif \"url(\" in line:\n            # skip non-WOFF format fonts\n            pass\n        else:\n            css_output_file.write(line)\n\n\nif __name__ == '__main__':\n    main()\n"},{"size":1803,"relativepath":"scripts/gulp/create-style-bundle.js","filename":"create-style-bundle.js","extension":".js","content":"'use strict';\n\n/* eslint-disable no-console */\n\nvar fs = require('fs');\nvar path = require('path');\n\nvar autoprefixer = require('autoprefixer');\nvar gulpUtil = require('gulp-util');\nvar postcss = require('postcss');\nvar postcssURL = require('postcss-url');\nvar sass = require('node-sass');\n\nvar log = gulpUtil.log;\n\n/**\n * Compile a SASS file and postprocess the result.\n *\n * @param {options} options - Object specifying the input and output paths and\n *                  whether to minify the result.\n * @return {Promise} Promise for completion of the build.\n */\nfunction compileSass(options) {\n  var sourcemapPath = options.output + '.map';\n\n  var postcssPlugins = [autoprefixer];\n\n  if (options.urlRewriter) {\n    postcssPlugins.push(postcssURL({\n      url: options.urlRewriter,\n    }));\n  }\n\n  var sassBuild = new Promise((resolve, reject) => {\n    sass.render({\n      file: options.input,\n      importer: options.onImport,\n      includePaths: [path.dirname(options.input)],\n      outputStyle: options.minify ? 'compressed' : 'nested',\n      sourceMap: sourcemapPath,\n    }, (err, result) => {\n      if (err) {\n        reject(err);\n      } else {\n        resolve(result);\n      }\n    });\n  });\n\n  return sassBuild.then(result => {\n    return postcss(postcssPlugins)\n      .process(result.css, {\n        from: options.output,\n        to: options.output,\n        map: {\n          inline: false,\n          prev: result.map.toString(),\n        },\n      });\n  }).then(result => {\n    fs.writeFileSync(options.output, result.css);\n    fs.writeFileSync(sourcemapPath, result.map.toString());\n  }).catch(srcErr => {\n    // Rewrite error so that the message property contains the file path\n    throw new Error(`SASS build error in ${srcErr.file}: ${srcErr.message}`);\n  });\n}\n\nmodule.exports = compileSass;\n"},{"size":1048,"relativepath":"scripts/gulp/manifest.js","filename":"manifest.js","extension":".js","content":"'use strict';\n\nvar path = require('path');\nvar crypto = require('crypto');\n\nvar through = require('through2');\nvar VinylFile = require('vinyl');\n\n/**\n * Gulp plugin that generates a cache-busting manifest file.\n *\n * Returns a function that creates a stream which takes\n * a stream of Vinyl files as inputs and outputs a JSON\n * manifest mapping input paths (eg. \"scripts/foo.js\")\n * to URLs with cache-busting query parameters (eg. \"scripts/foo.js?af95bd\").\n */\nmodule.exports = function (opts) {\n  var manifest = {};\n\n  return through.obj(function (file, enc, callback) {\n    var hash = crypto.createHash('sha1');\n    hash.update(file.contents);\n\n    var hashSuffix = hash.digest('hex').slice(0, 6);\n    var relPath = path.relative('build/', file.path);\n    manifest[relPath] = relPath + '?' + hashSuffix;\n\n    callback();\n  }, function (callback) {\n    var manifestFile = new VinylFile({\n      path: opts.name,\n      contents: new Buffer(JSON.stringify(manifest, null, 2), 'utf-8'),\n    });\n    this.push(manifestFile);\n    callback();\n  });\n};\n"},{"size":5909,"relativepath":"scripts/gulp/create-bundle.js","filename":"create-bundle.js","extension":".js","content":"/**\n * Shared functions for creating JS code bundles using Browserify.\n */\n'use strict';\n\nvar fs = require('fs');\nvar path = require('path');\n\nvar browserify = require('browserify');\nvar exorcist = require('exorcist');\nvar gulpUtil = require('gulp-util');\nvar mkdirp = require('mkdirp');\nvar uglifyify = require('uglifyify');\nvar watchify = require('watchify');\n\nvar log = gulpUtil.log;\n\nfunction streamFinished(stream) {\n  return new Promise(function (resolve, reject) {\n    stream.on('finish', resolve);\n    stream.on('error', reject);\n  });\n}\n\nfunction waitForever() {\n  return new Promise(function () {});\n}\n\n/**\n * interface BundleOptions {\n *   name: string;\n *   path: string;\n *\n *   entry?: string[];\n *   require?: string[];\n *\n *   minify?: boolean;\n * }\n *\n * interface BuildOptions {\n *   watch?: boolean;\n * }\n */\n\n/**\n * Generates a JavaScript application or library bundle and source maps\n * for debugging.\n *\n * @param {BundleOptions} config - Configuration information for this bundle,\n *                                 specifying the name of the bundle, what\n *                                 modules to include and which code\n *                                 transformations to apply.\n * @param {BuildOptions} buildOpts\n * @return {Promise} Promise for when the bundle is fully written\n *                   if opts.watch is false or a promise that\n *                   waits forever otherwise.\n */\nmodule.exports = function createBundle(config, buildOpts) {\n  mkdirp.sync(config.path);\n\n  buildOpts = buildOpts || {watch: false};\n\n  var bundleOpts = {\n    debug: true,\n\n    // Browserify will try to detect and automatically provide\n    // browser implementations of Node modules.\n    //\n    // This can bloat the bundle hugely if implementations for large\n    // modules like 'Buffer' or 'crypto' are inadvertently pulled in.\n    // Here we explicitly whitelist the builtins that can be used.\n    //\n    // In particular 'Buffer' is excluded from the list of automatically\n    // detected variables.\n    //\n    // See node_modules/browserify/lib/builtins.js to find out which\n    // modules provide the implementations of these.\n    builtins: [\n      'console',\n      '_process',\n      'querystring',\n    ],\n    insertGlobalVars: {\n      // The Browserify polyfill for the `Buffer` global is large and\n      // unnecessary, but can get pulled into the bundle by modules that can\n      // optionally use it if present.\n      Buffer: undefined,\n      // Override the default stub for the `global` var which defaults to\n      // the `global`, `self` and `window` globals in that order.\n      //\n      // This can break on web pages which provide their own definition of\n      // `global`. See https://github.com/hypothesis/h/issues/2723\n      global: function () {\n        return 'typeof self !== \"undefined\" ? self : window';\n      },\n    },\n  };\n\n  if (buildOpts.watch) {\n    bundleOpts.cache = {};\n    bundleOpts.packageCache = {};\n  }\n\n  // Specify modules that Browserify should not parse.\n  // The 'noParse' array must contain full file paths,\n  // not module names.\n  bundleOpts.noParse = (config.noParse || []).map(function (id) {\n    // If package.json specifies a custom entry point for the module for\n    // use in the browser, resolve that.\n    var packageConfig = require('../../package.json');\n    if (packageConfig.browser && packageConfig.browser[id]) {\n      return require.resolve('../../' + packageConfig.browser[id]);\n    } else {\n      return require.resolve(id);\n    }\n  });\n\n  var name = config.name;\n\n  var bundleFileName = name + '.bundle.js';\n  var bundlePath = config.path + '/' + bundleFileName;\n  var sourcemapPath = bundlePath + '.map';\n\n  var bundle = browserify([], bundleOpts);\n\n  (config.require || []).forEach(function (req) {\n    // When another bundle uses 'bundle.external(<module path>)',\n    // the module path is rewritten relative to the\n    // base directory and a '/' prefix is added, so\n    // if the other bundle contains \"require('./dir/module')\",\n    // then Browserify will generate \"require('/dir/module')\".\n    //\n    // In the bundle which provides './dir/module', we\n    // therefore need to expose the module as '/dir/module'.\n    if (req[0] === '.') {\n      bundle.require(req, {expose: req.slice(1)});\n    } else if (req[0] === '/') {\n      // If the require path is absolute, the same rules as\n      // above apply but the path needs to be relative to\n      // the root of the repository\n      var repoRootPath = path.join(__dirname, '../../');\n      var relativePath = path.relative(path.resolve(repoRootPath),\n                                       path.resolve(req));\n      bundle.require(req, {expose: '/' + relativePath});\n    } else {\n      // this is a package under node_modules/, no\n      // rewriting required.\n      bundle.require(req);\n    }\n  });\n\n  bundle.add(config.entry || []);\n  bundle.external(config.external || []);\n\n  if (config.minify) {\n    bundle.transform({global: true}, uglifyify);\n  }\n\n  function build() {\n    var output = fs.createWriteStream(bundlePath);\n    var b = bundle.bundle();\n    b.on('error', function (err) {\n      log('Build error', err.toString());\n    });\n    var stream = b.pipe(exorcist(sourcemapPath))\n                  .pipe(output);\n    return streamFinished(stream);\n  }\n\n  if (buildOpts.watch) {\n    bundle.plugin(watchify);\n    bundle.on('update', function (ids) {\n      var start = Date.now();\n\n      log('Source files changed', ids);\n      build().then(function () {\n        log('Updated %s (%d ms)', bundleFileName, Date.now() - start);\n      }).catch(function (err) {\n        console.error('Building updated bundle failed:', err);\n      });\n    });\n    build().then(function () {\n      log('Built ' + bundleFileName);\n    }).catch(function (err) {\n      console.error('Error building bundle:', err);\n    });\n\n    return waitForever();\n  } else {\n    return build();\n  }\n};\n"},{"size":2431,"relativepath":"Jenkinsfile","filename":"Jenkinsfile","extension":"","content":"#!groovy\n\nnode {\n    // -------------------------------------------------------------------------\n    stage 'Build'\n\n    checkout scm\n\n    buildVersion = sh(\n        script: 'python -c \"import h; print(h.__version__)\"',\n        returnStdout: true\n    ).trim()\n\n    // Docker tags may not contain '+'\n    dockerTag = buildVersion.replace('+', '-')\n\n    // Set build metadata\n    currentBuild.displayName = buildVersion\n    currentBuild.description = \"Docker: ${dockerTag}\"\n\n    // Build docker image\n    sh \"make docker DOCKER_TAG=${dockerTag}\"\n    img = docker.image \"hypothesis/hypothesis:${dockerTag}\"\n\n    // -------------------------------------------------------------------------\n    stage 'Test'\n\n    hostIp = sh(script: 'facter ipaddress_eth0', returnStdout: true).trim()\n\n    postgres = docker.image('postgres:9.4').run('-P -e POSTGRES_DB=htest')\n    databaseUrl = \"postgresql://postgres@${hostIp}:${containerPort(postgres, 5432)}/htest\"\n\n    elasticsearch = docker.image('nickstenning/elasticsearch-icu').run('-P')\n    elasticsearchHost = \"http://${hostIp}:${containerPort(elasticsearch, 9200)}\"\n\n    rabbit = docker.image('rabbitmq').run('-P')\n    brokerUrl = \"amqp://guest:guest@${hostIp}:${containerPort(rabbit, 5672)}//\"\n\n    try {\n        // Run our Python tests inside the built container\n        img.inside(\"-u root \" +\n                   \"-e BROKER_URL=${brokerUrl} \" +\n                   \"-e ELASTICSEARCH_HOST=${elasticsearchHost} \" +\n                   \"-e TEST_DATABASE_URL=${databaseUrl}\") {\n            // Test dependencies\n            sh 'apk-install build-base libffi-dev postgresql-dev python-dev'\n            sh 'pip install -q tox'\n\n            // Unit tests\n            sh 'cd /var/lib/hypothesis && tox'\n            // Functional tests\n            sh 'cd /var/lib/hypothesis && tox -e functional'\n        }\n    } finally {\n        rabbit.stop()\n        elasticsearch.stop()\n        postgres.stop()\n    }\n\n    // We only push the image to the Docker Hub if we're on master\n    if (env.BRANCH_NAME != 'master') {\n        return\n    }\n\n    // -------------------------------------------------------------------------\n    stage 'Push'\n\n    docker.withRegistry('', 'docker-hub-build') {\n        img.push()\n        img.push('latest')\n    }\n}\n\ndef containerPort(container, port) {\n    return sh(\n        script: \"docker port ${container.id} ${port} | cut -d: -f2\",\n        returnStdout: true\n    ).trim()\n}\n"}];